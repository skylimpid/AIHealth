/home/luhui/anaconda3/bin/python /media/luhui/E/AIDev/AIHealth/Training/train_classifier.py
2017-12-03 01:11:59.647832: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
2017-12-03 01:11:59.647870: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2017-12-03 01:11:59.647879: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
2017-12-03 01:11:59.647886: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
2017-12-03 01:11:59.647893: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.
2017-12-03 01:11:59.797645: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:893] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2017-12-03 01:11:59.798257: I tensorflow/core/common_runtime/gpu/gpu_device.cc:955] Found device 0 with properties:
name: GeForce GTX 1070
major: 6 minor: 1 memoryClockRate (GHz) 1.645
pciBusID 0000:01:00.0
Total memory: 7.92GiB
Free memory: 7.22GiB
2017-12-03 01:11:59.798268: I tensorflow/core/common_runtime/gpu/gpu_device.cc:976] DMA: 0
2017-12-03 01:11:59.798271: I tensorflow/core/common_runtime/gpu/gpu_device.cc:986] 0:   Y
2017-12-03 01:11:59.798277: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1070, pci bus id: 0000:01:00.0)
Variables to be restored: global/detector_scope/global/detector_scope/convBlock/conv1/kernel:0
Variables to be restored: global/detector_scope/global/detector_scope/convBlock/conv1/bias:0
Variables to be restored: global/detector_scope/global/detector_scope/convBlock/batch_normalization/beta:0
Variables to be restored: global/detector_scope/global/detector_scope/convBlock/batch_normalization/gamma:0
Variables to be restored: global/detector_scope/global/detector_scope/convBlock/batch_normalization/moving_mean:0
Variables to be restored: global/detector_scope/global/detector_scope/convBlock/batch_normalization/moving_variance:0
Variables to be restored: global/detector_scope/global/detector_scope/convBlock/conv2/kernel:0
Variables to be restored: global/detector_scope/global/detector_scope/convBlock/conv2/bias:0
Variables to be restored: global/detector_scope/global/detector_scope/convBlock/conv2_nm/beta:0
Variables to be restored: global/detector_scope/global/detector_scope/convBlock/conv2_nm/gamma:0
Variables to be restored: global/detector_scope/global/detector_scope/convBlock/conv2_nm/moving_mean:0
Variables to be restored: global/detector_scope/global/detector_scope/convBlock/conv2_nm/moving_variance:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock1/resBlock1-1_conv1/kernel:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock1/resBlock1-1_conv1/bias:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock1/resBlock1-1_conv1_bn/beta:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock1/resBlock1-1_conv1_bn/gamma:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock1/resBlock1-1_conv1_bn/moving_mean:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock1/resBlock1-1_conv1_bn/moving_variance:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock1/resBlock1-1_conv2/kernel:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock1/resBlock1-1_conv2/bias:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock1/resBlock1-1_conv2_bn/beta:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock1/resBlock1-1_conv2_bn/gamma:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock1/resBlock1-1_conv2_bn/moving_mean:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock1/resBlock1-1_conv2_bn/moving_variance:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock1/resBlock1-1_shortcut/kernel:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock1/resBlock1-1_shortcut/bias:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock1/resBlock1-1_shortcut_bn/beta:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock1/resBlock1-1_shortcut_bn/gamma:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock1/resBlock1-1_shortcut_bn/moving_mean:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock1/resBlock1-1_shortcut_bn/moving_variance:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock1/resBlock1-2_conv1/kernel:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock1/resBlock1-2_conv1/bias:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock1/resBlock1-2_conv1_bn/beta:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock1/resBlock1-2_conv1_bn/gamma:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock1/resBlock1-2_conv1_bn/moving_mean:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock1/resBlock1-2_conv1_bn/moving_variance:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock1/resBlock1-2_conv2/kernel:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock1/resBlock1-2_conv2/bias:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock1/resBlock1-2_conv2_bn/beta:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock1/resBlock1-2_conv2_bn/gamma:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock1/resBlock1-2_conv2_bn/moving_mean:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock1/resBlock1-2_conv2_bn/moving_variance:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock2/resBlock2-1_conv1/kernel:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock2/resBlock2-1_conv1/bias:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock2/resBlock2-1_conv1_bn/beta:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock2/resBlock2-1_conv1_bn/gamma:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock2/resBlock2-1_conv1_bn/moving_mean:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock2/resBlock2-1_conv1_bn/moving_variance:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock2/resBlock2-1_conv2/kernel:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock2/resBlock2-1_conv2/bias:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock2/resBlock2-1_conv2_bn/beta:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock2/resBlock2-1_conv2_bn/gamma:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock2/resBlock2-1_conv2_bn/moving_mean:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock2/resBlock2-1_conv2_bn/moving_variance:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock2/resBlock2-1_shortcut/kernel:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock2/resBlock2-1_shortcut/bias:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock2/resBlock2-1_shortcut_bn/beta:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock2/resBlock2-1_shortcut_bn/gamma:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock2/resBlock2-1_shortcut_bn/moving_mean:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock2/resBlock2-1_shortcut_bn/moving_variance:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock2/resBlock2-2_conv1/kernel:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock2/resBlock2-2_conv1/bias:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock2/resBlock2-2_conv1_bn/beta:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock2/resBlock2-2_conv1_bn/gamma:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock2/resBlock2-2_conv1_bn/moving_mean:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock2/resBlock2-2_conv1_bn/moving_variance:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock2/resBlock2-2_conv2/kernel:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock2/resBlock2-2_conv2/bias:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock2/resBlock2-2_conv2_bn/beta:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock2/resBlock2-2_conv2_bn/gamma:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock2/resBlock2-2_conv2_bn/moving_mean:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock2/resBlock2-2_conv2_bn/moving_variance:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock3/resBlock3-1_conv1/kernel:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock3/resBlock3-1_conv1/bias:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock3/resBlock3-1_conv1_bn/beta:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock3/resBlock3-1_conv1_bn/gamma:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock3/resBlock3-1_conv1_bn/moving_mean:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock3/resBlock3-1_conv1_bn/moving_variance:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock3/resBlock3-1_conv2/kernel:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock3/resBlock3-1_conv2/bias:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock3/resBlock3-1_conv2_bn/beta:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock3/resBlock3-1_conv2_bn/gamma:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock3/resBlock3-1_conv2_bn/moving_mean:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock3/resBlock3-1_conv2_bn/moving_variance:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock3/resBlock3-2_conv1/kernel:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock3/resBlock3-2_conv1/bias:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock3/resBlock3-2_conv1_bn/beta:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock3/resBlock3-2_conv1_bn/gamma:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock3/resBlock3-2_conv1_bn/moving_mean:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock3/resBlock3-2_conv1_bn/moving_variance:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock3/resBlock3-2_conv2/kernel:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock3/resBlock3-2_conv2/bias:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock3/resBlock3-2_conv2_bn/beta:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock3/resBlock3-2_conv2_bn/gamma:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock3/resBlock3-2_conv2_bn/moving_mean:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock3/resBlock3-2_conv2_bn/moving_variance:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock3/resBlock3-3_conv1/kernel:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock3/resBlock3-3_conv1/bias:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock3/resBlock3-3_conv1_bn/beta:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock3/resBlock3-3_conv1_bn/gamma:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock3/resBlock3-3_conv1_bn/moving_mean:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock3/resBlock3-3_conv1_bn/moving_variance:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock3/resBlock3-3_conv2/kernel:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock3/resBlock3-3_conv2/bias:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock3/resBlock3-3_conv2_bn/beta:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock3/resBlock3-3_conv2_bn/gamma:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock3/resBlock3-3_conv2_bn/moving_mean:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock3/resBlock3-3_conv2_bn/moving_variance:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock4/resBlock4-1_conv1/kernel:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock4/resBlock4-1_conv1/bias:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock4/resBlock4-1_conv1_bn/beta:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock4/resBlock4-1_conv1_bn/gamma:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock4/resBlock4-1_conv1_bn/moving_mean:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock4/resBlock4-1_conv1_bn/moving_variance:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock4/resBlock4-1_conv2/kernel:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock4/resBlock4-1_conv2/bias:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock4/resBlock4-1_conv2_bn/beta:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock4/resBlock4-1_conv2_bn/gamma:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock4/resBlock4-1_conv2_bn/moving_mean:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock4/resBlock4-1_conv2_bn/moving_variance:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock4/resBlock4-2_conv1/kernel:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock4/resBlock4-2_conv1/bias:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock4/resBlock4-2_conv1_bn/beta:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock4/resBlock4-2_conv1_bn/gamma:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock4/resBlock4-2_conv1_bn/moving_mean:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock4/resBlock4-2_conv1_bn/moving_variance:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock4/resBlock4-2_conv2/kernel:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock4/resBlock4-2_conv2/bias:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock4/resBlock4-2_conv2_bn/beta:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock4/resBlock4-2_conv2_bn/gamma:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock4/resBlock4-2_conv2_bn/moving_mean:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock4/resBlock4-2_conv2_bn/moving_variance:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock4/resBlock4-3_conv1/kernel:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock4/resBlock4-3_conv1/bias:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock4/resBlock4-3_conv1_bn/beta:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock4/resBlock4-3_conv1_bn/gamma:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock4/resBlock4-3_conv1_bn/moving_mean:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock4/resBlock4-3_conv1_bn/moving_variance:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock4/resBlock4-3_conv2/kernel:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock4/resBlock4-3_conv2/bias:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock4/resBlock4-3_conv2_bn/beta:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock4/resBlock4-3_conv2_bn/gamma:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock4/resBlock4-3_conv2_bn/moving_mean:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock4/resBlock4-3_conv2_bn/moving_variance:0
Variables to be restored: global/detector_scope/global/detector_scope/up1/up1/kernel:0
Variables to be restored: global/detector_scope/global/detector_scope/up1/up1_bn/beta:0
Variables to be restored: global/detector_scope/global/detector_scope/up1/up1_bn/gamma:0
Variables to be restored: global/detector_scope/global/detector_scope/up1/up1_bn/moving_mean:0
Variables to be restored: global/detector_scope/global/detector_scope/up1/up1_bn/moving_variance:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock5/resBlock5_1_conv1/kernel:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock5/resBlock5_1_conv1/bias:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock5/resBlock5_1_conv1_bn/beta:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock5/resBlock5_1_conv1_bn/gamma:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock5/resBlock5_1_conv1_bn/moving_mean:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock5/resBlock5_1_conv1_bn/moving_variance:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock5/resBlock5_1_conv2/kernel:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock5/resBlock5_1_conv2/bias:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock5/resBlock5_1_conv2_bn/beta:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock5/resBlock5_1_conv2_bn/gamma:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock5/resBlock5_1_conv2_bn/moving_mean:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock5/resBlock5_1_conv2_bn/moving_variance:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock5/resBlock5_1_shortcut/kernel:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock5/resBlock5_1_shortcut/bias:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock5/resBlock5_1_shortcut_bn/beta:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock5/resBlock5_1_shortcut_bn/gamma:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock5/resBlock5_1_shortcut_bn/moving_mean:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock5/resBlock5_1_shortcut_bn/moving_variance:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock5/resBlock5-2_conv1/kernel:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock5/resBlock5-2_conv1/bias:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock5/resBlock5-2_conv1_bn/beta:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock5/resBlock5-2_conv1_bn/gamma:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock5/resBlock5-2_conv1_bn/moving_mean:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock5/resBlock5-2_conv1_bn/moving_variance:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock5/resBlock5-2_conv2/kernel:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock5/resBlock5-2_conv2/bias:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock5/resBlock5-2_conv2_bn/beta:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock5/resBlock5-2_conv2_bn/gamma:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock5/resBlock5-2_conv2_bn/moving_mean:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock5/resBlock5-2_conv2_bn/moving_variance:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock5/resBlock5-3_conv1/kernel:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock5/resBlock5-3_conv1/bias:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock5/resBlock5-3_conv1_bn/beta:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock5/resBlock5-3_conv1_bn/gamma:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock5/resBlock5-3_conv1_bn/moving_mean:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock5/resBlock5-3_conv1_bn/moving_variance:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock5/resBlock5-3_conv2/kernel:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock5/resBlock5-3_conv2/bias:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock5/resBlock5-3_conv2_bn/beta:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock5/resBlock5-3_conv2_bn/gamma:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock5/resBlock5-3_conv2_bn/moving_mean:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock5/resBlock5-3_conv2_bn/moving_variance:0
Variables to be restored: global/detector_scope/global/detector_scope/up2/up2/kernel:0
Variables to be restored: global/detector_scope/global/detector_scope/up2/up2_bn/beta:0
Variables to be restored: global/detector_scope/global/detector_scope/up2/up2_bn/gamma:0
Variables to be restored: global/detector_scope/global/detector_scope/up2/up2_bn/moving_mean:0
Variables to be restored: global/detector_scope/global/detector_scope/up2/up2_bn/moving_variance:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock6/resBlock6_1_conv1/kernel:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock6/resBlock6_1_conv1/bias:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock6/resBlock6_1_conv1_bn/beta:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock6/resBlock6_1_conv1_bn/gamma:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock6/resBlock6_1_conv1_bn/moving_mean:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock6/resBlock6_1_conv1_bn/moving_variance:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock6/resBlock6_1_conv2/kernel:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock6/resBlock6_1_conv2/bias:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock6/resBlock6_1_conv2_bn/beta:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock6/resBlock6_1_conv2_bn/gamma:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock6/resBlock6_1_conv2_bn/moving_mean:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock6/resBlock6_1_conv2_bn/moving_variance:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock6/resBlock6_1_shortcut/kernel:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock6/resBlock6_1_shortcut/bias:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock6/resBlock6_1_shortcut_bn/beta:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock6/resBlock6_1_shortcut_bn/gamma:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock6/resBlock6_1_shortcut_bn/moving_mean:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock6/resBlock6_1_shortcut_bn/moving_variance:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock6/resBlock6-2_conv1/kernel:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock6/resBlock6-2_conv1/bias:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock6/resBlock6-2_conv1_bn/beta:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock6/resBlock6-2_conv1_bn/gamma:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock6/resBlock6-2_conv1_bn/moving_mean:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock6/resBlock6-2_conv1_bn/moving_variance:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock6/resBlock6-2_conv2/kernel:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock6/resBlock6-2_conv2/bias:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock6/resBlock6-2_conv2_bn/beta:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock6/resBlock6-2_conv2_bn/gamma:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock6/resBlock6-2_conv2_bn/moving_mean:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock6/resBlock6-2_conv2_bn/moving_variance:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock6/resBlock6-3_conv1/kernel:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock6/resBlock6-3_conv1/bias:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock6/resBlock6-3_conv1_bn/beta:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock6/resBlock6-3_conv1_bn/gamma:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock6/resBlock6-3_conv1_bn/moving_mean:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock6/resBlock6-3_conv1_bn/moving_variance:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock6/resBlock6-3_conv2/kernel:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock6/resBlock6-3_conv2/bias:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock6/resBlock6-3_conv2_bn/beta:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock6/resBlock6-3_conv2_bn/gamma:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock6/resBlock6-3_conv2_bn/moving_mean:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock6/resBlock6-3_conv2_bn/moving_variance:0
Variables to be restored: global/detector_scope/global/detector_scope/output/conv3d/kernel:0
Variables to be restored: global/detector_scope/global/detector_scope/output/conv3d/bias:0
Variables to be restored: global/detector_scope/global/detector_scope/output/conv3d_1/kernel:0
Variables to be restored: global/detector_scope/global/detector_scope/output/conv3d_1/bias:0
Variables to be restored: global/detector_scope/global/detector_scope/convBlock/conv1/kernel/Adadelta:0
Variables to be restored: global/detector_scope/global/detector_scope/convBlock/conv1/kernel/Adadelta_1:0
Variables to be restored: global/detector_scope/global/detector_scope/convBlock/conv1/bias/Adadelta:0
Variables to be restored: global/detector_scope/global/detector_scope/convBlock/conv1/bias/Adadelta_1:0
Variables to be restored: global/detector_scope/global/detector_scope/convBlock/batch_normalization/beta/Adadelta:0
Variables to be restored: global/detector_scope/global/detector_scope/convBlock/batch_normalization/beta/Adadelta_1:0
Variables to be restored: global/detector_scope/global/detector_scope/convBlock/batch_normalization/gamma/Adadelta:0
Variables to be restored: global/detector_scope/global/detector_scope/convBlock/batch_normalization/gamma/Adadelta_1:0
Variables to be restored: global/detector_scope/global/detector_scope/convBlock/conv2/kernel/Adadelta:0
Variables to be restored: global/detector_scope/global/detector_scope/convBlock/conv2/kernel/Adadelta_1:0
Variables to be restored: global/detector_scope/global/detector_scope/convBlock/conv2/bias/Adadelta:0
Variables to be restored: global/detector_scope/global/detector_scope/convBlock/conv2/bias/Adadelta_1:0
Variables to be restored: global/detector_scope/global/detector_scope/convBlock/conv2_nm/beta/Adadelta:0
Variables to be restored: global/detector_scope/global/detector_scope/convBlock/conv2_nm/beta/Adadelta_1:0
Variables to be restored: global/detector_scope/global/detector_scope/convBlock/conv2_nm/gamma/Adadelta:0
Variables to be restored: global/detector_scope/global/detector_scope/convBlock/conv2_nm/gamma/Adadelta_1:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock1/resBlock1-1_conv1/kernel/Adadelta:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock1/resBlock1-1_conv1/kernel/Adadelta_1:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock1/resBlock1-1_conv1/bias/Adadelta:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock1/resBlock1-1_conv1/bias/Adadelta_1:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock1/resBlock1-1_conv1_bn/beta/Adadelta:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock1/resBlock1-1_conv1_bn/beta/Adadelta_1:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock1/resBlock1-1_conv1_bn/gamma/Adadelta:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock1/resBlock1-1_conv1_bn/gamma/Adadelta_1:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock1/resBlock1-1_conv2/kernel/Adadelta:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock1/resBlock1-1_conv2/kernel/Adadelta_1:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock1/resBlock1-1_conv2/bias/Adadelta:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock1/resBlock1-1_conv2/bias/Adadelta_1:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock1/resBlock1-1_conv2_bn/beta/Adadelta:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock1/resBlock1-1_conv2_bn/beta/Adadelta_1:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock1/resBlock1-1_conv2_bn/gamma/Adadelta:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock1/resBlock1-1_conv2_bn/gamma/Adadelta_1:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock1/resBlock1-1_shortcut/kernel/Adadelta:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock1/resBlock1-1_shortcut/kernel/Adadelta_1:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock1/resBlock1-1_shortcut/bias/Adadelta:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock1/resBlock1-1_shortcut/bias/Adadelta_1:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock1/resBlock1-1_shortcut_bn/beta/Adadelta:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock1/resBlock1-1_shortcut_bn/beta/Adadelta_1:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock1/resBlock1-1_shortcut_bn/gamma/Adadelta:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock1/resBlock1-1_shortcut_bn/gamma/Adadelta_1:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock1/resBlock1-2_conv1/kernel/Adadelta:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock1/resBlock1-2_conv1/kernel/Adadelta_1:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock1/resBlock1-2_conv1/bias/Adadelta:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock1/resBlock1-2_conv1/bias/Adadelta_1:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock1/resBlock1-2_conv1_bn/beta/Adadelta:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock1/resBlock1-2_conv1_bn/beta/Adadelta_1:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock1/resBlock1-2_conv1_bn/gamma/Adadelta:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock1/resBlock1-2_conv1_bn/gamma/Adadelta_1:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock1/resBlock1-2_conv2/kernel/Adadelta:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock1/resBlock1-2_conv2/kernel/Adadelta_1:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock1/resBlock1-2_conv2/bias/Adadelta:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock1/resBlock1-2_conv2/bias/Adadelta_1:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock1/resBlock1-2_conv2_bn/beta/Adadelta:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock1/resBlock1-2_conv2_bn/beta/Adadelta_1:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock1/resBlock1-2_conv2_bn/gamma/Adadelta:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock1/resBlock1-2_conv2_bn/gamma/Adadelta_1:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock2/resBlock2-1_conv1/kernel/Adadelta:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock2/resBlock2-1_conv1/kernel/Adadelta_1:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock2/resBlock2-1_conv1/bias/Adadelta:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock2/resBlock2-1_conv1/bias/Adadelta_1:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock2/resBlock2-1_conv1_bn/beta/Adadelta:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock2/resBlock2-1_conv1_bn/beta/Adadelta_1:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock2/resBlock2-1_conv1_bn/gamma/Adadelta:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock2/resBlock2-1_conv1_bn/gamma/Adadelta_1:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock2/resBlock2-1_conv2/kernel/Adadelta:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock2/resBlock2-1_conv2/kernel/Adadelta_1:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock2/resBlock2-1_conv2/bias/Adadelta:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock2/resBlock2-1_conv2/bias/Adadelta_1:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock2/resBlock2-1_conv2_bn/beta/Adadelta:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock2/resBlock2-1_conv2_bn/beta/Adadelta_1:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock2/resBlock2-1_conv2_bn/gamma/Adadelta:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock2/resBlock2-1_conv2_bn/gamma/Adadelta_1:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock2/resBlock2-1_shortcut/kernel/Adadelta:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock2/resBlock2-1_shortcut/kernel/Adadelta_1:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock2/resBlock2-1_shortcut/bias/Adadelta:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock2/resBlock2-1_shortcut/bias/Adadelta_1:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock2/resBlock2-1_shortcut_bn/beta/Adadelta:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock2/resBlock2-1_shortcut_bn/beta/Adadelta_1:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock2/resBlock2-1_shortcut_bn/gamma/Adadelta:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock2/resBlock2-1_shortcut_bn/gamma/Adadelta_1:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock2/resBlock2-2_conv1/kernel/Adadelta:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock2/resBlock2-2_conv1/kernel/Adadelta_1:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock2/resBlock2-2_conv1/bias/Adadelta:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock2/resBlock2-2_conv1/bias/Adadelta_1:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock2/resBlock2-2_conv1_bn/beta/Adadelta:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock2/resBlock2-2_conv1_bn/beta/Adadelta_1:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock2/resBlock2-2_conv1_bn/gamma/Adadelta:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock2/resBlock2-2_conv1_bn/gamma/Adadelta_1:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock2/resBlock2-2_conv2/kernel/Adadelta:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock2/resBlock2-2_conv2/kernel/Adadelta_1:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock2/resBlock2-2_conv2/bias/Adadelta:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock2/resBlock2-2_conv2/bias/Adadelta_1:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock2/resBlock2-2_conv2_bn/beta/Adadelta:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock2/resBlock2-2_conv2_bn/beta/Adadelta_1:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock2/resBlock2-2_conv2_bn/gamma/Adadelta:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock2/resBlock2-2_conv2_bn/gamma/Adadelta_1:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock3/resBlock3-1_conv1/kernel/Adadelta:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock3/resBlock3-1_conv1/kernel/Adadelta_1:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock3/resBlock3-1_conv1/bias/Adadelta:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock3/resBlock3-1_conv1/bias/Adadelta_1:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock3/resBlock3-1_conv1_bn/beta/Adadelta:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock3/resBlock3-1_conv1_bn/beta/Adadelta_1:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock3/resBlock3-1_conv1_bn/gamma/Adadelta:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock3/resBlock3-1_conv1_bn/gamma/Adadelta_1:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock3/resBlock3-1_conv2/kernel/Adadelta:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock3/resBlock3-1_conv2/kernel/Adadelta_1:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock3/resBlock3-1_conv2/bias/Adadelta:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock3/resBlock3-1_conv2/bias/Adadelta_1:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock3/resBlock3-1_conv2_bn/beta/Adadelta:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock3/resBlock3-1_conv2_bn/beta/Adadelta_1:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock3/resBlock3-1_conv2_bn/gamma/Adadelta:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock3/resBlock3-1_conv2_bn/gamma/Adadelta_1:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock3/resBlock3-2_conv1/kernel/Adadelta:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock3/resBlock3-2_conv1/kernel/Adadelta_1:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock3/resBlock3-2_conv1/bias/Adadelta:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock3/resBlock3-2_conv1/bias/Adadelta_1:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock3/resBlock3-2_conv1_bn/beta/Adadelta:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock3/resBlock3-2_conv1_bn/beta/Adadelta_1:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock3/resBlock3-2_conv1_bn/gamma/Adadelta:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock3/resBlock3-2_conv1_bn/gamma/Adadelta_1:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock3/resBlock3-2_conv2/kernel/Adadelta:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock3/resBlock3-2_conv2/kernel/Adadelta_1:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock3/resBlock3-2_conv2/bias/Adadelta:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock3/resBlock3-2_conv2/bias/Adadelta_1:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock3/resBlock3-2_conv2_bn/beta/Adadelta:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock3/resBlock3-2_conv2_bn/beta/Adadelta_1:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock3/resBlock3-2_conv2_bn/gamma/Adadelta:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock3/resBlock3-2_conv2_bn/gamma/Adadelta_1:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock3/resBlock3-3_conv1/kernel/Adadelta:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock3/resBlock3-3_conv1/kernel/Adadelta_1:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock3/resBlock3-3_conv1/bias/Adadelta:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock3/resBlock3-3_conv1/bias/Adadelta_1:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock3/resBlock3-3_conv1_bn/beta/Adadelta:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock3/resBlock3-3_conv1_bn/beta/Adadelta_1:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock3/resBlock3-3_conv1_bn/gamma/Adadelta:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock3/resBlock3-3_conv1_bn/gamma/Adadelta_1:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock3/resBlock3-3_conv2/kernel/Adadelta:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock3/resBlock3-3_conv2/kernel/Adadelta_1:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock3/resBlock3-3_conv2/bias/Adadelta:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock3/resBlock3-3_conv2/bias/Adadelta_1:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock3/resBlock3-3_conv2_bn/beta/Adadelta:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock3/resBlock3-3_conv2_bn/beta/Adadelta_1:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock3/resBlock3-3_conv2_bn/gamma/Adadelta:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock3/resBlock3-3_conv2_bn/gamma/Adadelta_1:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock4/resBlock4-1_conv1/kernel/Adadelta:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock4/resBlock4-1_conv1/kernel/Adadelta_1:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock4/resBlock4-1_conv1/bias/Adadelta:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock4/resBlock4-1_conv1/bias/Adadelta_1:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock4/resBlock4-1_conv1_bn/beta/Adadelta:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock4/resBlock4-1_conv1_bn/beta/Adadelta_1:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock4/resBlock4-1_conv1_bn/gamma/Adadelta:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock4/resBlock4-1_conv1_bn/gamma/Adadelta_1:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock4/resBlock4-1_conv2/kernel/Adadelta:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock4/resBlock4-1_conv2/kernel/Adadelta_1:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock4/resBlock4-1_conv2/bias/Adadelta:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock4/resBlock4-1_conv2/bias/Adadelta_1:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock4/resBlock4-1_conv2_bn/beta/Adadelta:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock4/resBlock4-1_conv2_bn/beta/Adadelta_1:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock4/resBlock4-1_conv2_bn/gamma/Adadelta:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock4/resBlock4-1_conv2_bn/gamma/Adadelta_1:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock4/resBlock4-2_conv1/kernel/Adadelta:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock4/resBlock4-2_conv1/kernel/Adadelta_1:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock4/resBlock4-2_conv1/bias/Adadelta:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock4/resBlock4-2_conv1/bias/Adadelta_1:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock4/resBlock4-2_conv1_bn/beta/Adadelta:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock4/resBlock4-2_conv1_bn/beta/Adadelta_1:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock4/resBlock4-2_conv1_bn/gamma/Adadelta:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock4/resBlock4-2_conv1_bn/gamma/Adadelta_1:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock4/resBlock4-2_conv2/kernel/Adadelta:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock4/resBlock4-2_conv2/kernel/Adadelta_1:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock4/resBlock4-2_conv2/bias/Adadelta:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock4/resBlock4-2_conv2/bias/Adadelta_1:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock4/resBlock4-2_conv2_bn/beta/Adadelta:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock4/resBlock4-2_conv2_bn/beta/Adadelta_1:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock4/resBlock4-2_conv2_bn/gamma/Adadelta:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock4/resBlock4-2_conv2_bn/gamma/Adadelta_1:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock4/resBlock4-3_conv1/kernel/Adadelta:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock4/resBlock4-3_conv1/kernel/Adadelta_1:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock4/resBlock4-3_conv1/bias/Adadelta:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock4/resBlock4-3_conv1/bias/Adadelta_1:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock4/resBlock4-3_conv1_bn/beta/Adadelta:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock4/resBlock4-3_conv1_bn/beta/Adadelta_1:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock4/resBlock4-3_conv1_bn/gamma/Adadelta:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock4/resBlock4-3_conv1_bn/gamma/Adadelta_1:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock4/resBlock4-3_conv2/kernel/Adadelta:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock4/resBlock4-3_conv2/kernel/Adadelta_1:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock4/resBlock4-3_conv2/bias/Adadelta:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock4/resBlock4-3_conv2/bias/Adadelta_1:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock4/resBlock4-3_conv2_bn/beta/Adadelta:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock4/resBlock4-3_conv2_bn/beta/Adadelta_1:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock4/resBlock4-3_conv2_bn/gamma/Adadelta:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock4/resBlock4-3_conv2_bn/gamma/Adadelta_1:0
Variables to be restored: global/detector_scope/global/detector_scope/up1/up1/kernel/Adadelta:0
Variables to be restored: global/detector_scope/global/detector_scope/up1/up1/kernel/Adadelta_1:0
Variables to be restored: global/detector_scope/global/detector_scope/up1/up1_bn/beta/Adadelta:0
Variables to be restored: global/detector_scope/global/detector_scope/up1/up1_bn/beta/Adadelta_1:0
Variables to be restored: global/detector_scope/global/detector_scope/up1/up1_bn/gamma/Adadelta:0
Variables to be restored: global/detector_scope/global/detector_scope/up1/up1_bn/gamma/Adadelta_1:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock5/resBlock5_1_conv1/kernel/Adadelta:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock5/resBlock5_1_conv1/kernel/Adadelta_1:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock5/resBlock5_1_conv1/bias/Adadelta:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock5/resBlock5_1_conv1/bias/Adadelta_1:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock5/resBlock5_1_conv1_bn/beta/Adadelta:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock5/resBlock5_1_conv1_bn/beta/Adadelta_1:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock5/resBlock5_1_conv1_bn/gamma/Adadelta:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock5/resBlock5_1_conv1_bn/gamma/Adadelta_1:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock5/resBlock5_1_conv2/kernel/Adadelta:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock5/resBlock5_1_conv2/kernel/Adadelta_1:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock5/resBlock5_1_conv2/bias/Adadelta:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock5/resBlock5_1_conv2/bias/Adadelta_1:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock5/resBlock5_1_conv2_bn/beta/Adadelta:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock5/resBlock5_1_conv2_bn/beta/Adadelta_1:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock5/resBlock5_1_conv2_bn/gamma/Adadelta:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock5/resBlock5_1_conv2_bn/gamma/Adadelta_1:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock5/resBlock5_1_shortcut/kernel/Adadelta:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock5/resBlock5_1_shortcut/kernel/Adadelta_1:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock5/resBlock5_1_shortcut/bias/Adadelta:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock5/resBlock5_1_shortcut/bias/Adadelta_1:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock5/resBlock5_1_shortcut_bn/beta/Adadelta:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock5/resBlock5_1_shortcut_bn/beta/Adadelta_1:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock5/resBlock5_1_shortcut_bn/gamma/Adadelta:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock5/resBlock5_1_shortcut_bn/gamma/Adadelta_1:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock5/resBlock5-2_conv1/kernel/Adadelta:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock5/resBlock5-2_conv1/kernel/Adadelta_1:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock5/resBlock5-2_conv1/bias/Adadelta:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock5/resBlock5-2_conv1/bias/Adadelta_1:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock5/resBlock5-2_conv1_bn/beta/Adadelta:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock5/resBlock5-2_conv1_bn/beta/Adadelta_1:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock5/resBlock5-2_conv1_bn/gamma/Adadelta:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock5/resBlock5-2_conv1_bn/gamma/Adadelta_1:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock5/resBlock5-2_conv2/kernel/Adadelta:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock5/resBlock5-2_conv2/kernel/Adadelta_1:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock5/resBlock5-2_conv2/bias/Adadelta:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock5/resBlock5-2_conv2/bias/Adadelta_1:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock5/resBlock5-2_conv2_bn/beta/Adadelta:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock5/resBlock5-2_conv2_bn/beta/Adadelta_1:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock5/resBlock5-2_conv2_bn/gamma/Adadelta:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock5/resBlock5-2_conv2_bn/gamma/Adadelta_1:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock5/resBlock5-3_conv1/kernel/Adadelta:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock5/resBlock5-3_conv1/kernel/Adadelta_1:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock5/resBlock5-3_conv1/bias/Adadelta:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock5/resBlock5-3_conv1/bias/Adadelta_1:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock5/resBlock5-3_conv1_bn/beta/Adadelta:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock5/resBlock5-3_conv1_bn/beta/Adadelta_1:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock5/resBlock5-3_conv1_bn/gamma/Adadelta:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock5/resBlock5-3_conv1_bn/gamma/Adadelta_1:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock5/resBlock5-3_conv2/kernel/Adadelta:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock5/resBlock5-3_conv2/kernel/Adadelta_1:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock5/resBlock5-3_conv2/bias/Adadelta:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock5/resBlock5-3_conv2/bias/Adadelta_1:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock5/resBlock5-3_conv2_bn/beta/Adadelta:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock5/resBlock5-3_conv2_bn/beta/Adadelta_1:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock5/resBlock5-3_conv2_bn/gamma/Adadelta:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock5/resBlock5-3_conv2_bn/gamma/Adadelta_1:0
Variables to be restored: global/detector_scope/global/detector_scope/up2/up2/kernel/Adadelta:0
Variables to be restored: global/detector_scope/global/detector_scope/up2/up2/kernel/Adadelta_1:0
Variables to be restored: global/detector_scope/global/detector_scope/up2/up2_bn/beta/Adadelta:0
Variables to be restored: global/detector_scope/global/detector_scope/up2/up2_bn/beta/Adadelta_1:0
Variables to be restored: global/detector_scope/global/detector_scope/up2/up2_bn/gamma/Adadelta:0
Variables to be restored: global/detector_scope/global/detector_scope/up2/up2_bn/gamma/Adadelta_1:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock6/resBlock6_1_conv1/kernel/Adadelta:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock6/resBlock6_1_conv1/kernel/Adadelta_1:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock6/resBlock6_1_conv1/bias/Adadelta:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock6/resBlock6_1_conv1/bias/Adadelta_1:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock6/resBlock6_1_conv1_bn/beta/Adadelta:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock6/resBlock6_1_conv1_bn/beta/Adadelta_1:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock6/resBlock6_1_conv1_bn/gamma/Adadelta:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock6/resBlock6_1_conv1_bn/gamma/Adadelta_1:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock6/resBlock6_1_conv2/kernel/Adadelta:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock6/resBlock6_1_conv2/kernel/Adadelta_1:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock6/resBlock6_1_conv2/bias/Adadelta:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock6/resBlock6_1_conv2/bias/Adadelta_1:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock6/resBlock6_1_conv2_bn/beta/Adadelta:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock6/resBlock6_1_conv2_bn/beta/Adadelta_1:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock6/resBlock6_1_conv2_bn/gamma/Adadelta:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock6/resBlock6_1_conv2_bn/gamma/Adadelta_1:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock6/resBlock6_1_shortcut/kernel/Adadelta:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock6/resBlock6_1_shortcut/kernel/Adadelta_1:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock6/resBlock6_1_shortcut/bias/Adadelta:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock6/resBlock6_1_shortcut/bias/Adadelta_1:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock6/resBlock6_1_shortcut_bn/beta/Adadelta:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock6/resBlock6_1_shortcut_bn/beta/Adadelta_1:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock6/resBlock6_1_shortcut_bn/gamma/Adadelta:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock6/resBlock6_1_shortcut_bn/gamma/Adadelta_1:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock6/resBlock6-2_conv1/kernel/Adadelta:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock6/resBlock6-2_conv1/kernel/Adadelta_1:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock6/resBlock6-2_conv1/bias/Adadelta:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock6/resBlock6-2_conv1/bias/Adadelta_1:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock6/resBlock6-2_conv1_bn/beta/Adadelta:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock6/resBlock6-2_conv1_bn/beta/Adadelta_1:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock6/resBlock6-2_conv1_bn/gamma/Adadelta:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock6/resBlock6-2_conv1_bn/gamma/Adadelta_1:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock6/resBlock6-2_conv2/kernel/Adadelta:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock6/resBlock6-2_conv2/kernel/Adadelta_1:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock6/resBlock6-2_conv2/bias/Adadelta:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock6/resBlock6-2_conv2/bias/Adadelta_1:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock6/resBlock6-2_conv2_bn/beta/Adadelta:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock6/resBlock6-2_conv2_bn/beta/Adadelta_1:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock6/resBlock6-2_conv2_bn/gamma/Adadelta:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock6/resBlock6-2_conv2_bn/gamma/Adadelta_1:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock6/resBlock6-3_conv1/kernel/Adadelta:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock6/resBlock6-3_conv1/kernel/Adadelta_1:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock6/resBlock6-3_conv1/bias/Adadelta:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock6/resBlock6-3_conv1/bias/Adadelta_1:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock6/resBlock6-3_conv1_bn/beta/Adadelta:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock6/resBlock6-3_conv1_bn/beta/Adadelta_1:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock6/resBlock6-3_conv1_bn/gamma/Adadelta:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock6/resBlock6-3_conv1_bn/gamma/Adadelta_1:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock6/resBlock6-3_conv2/kernel/Adadelta:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock6/resBlock6-3_conv2/kernel/Adadelta_1:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock6/resBlock6-3_conv2/bias/Adadelta:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock6/resBlock6-3_conv2/bias/Adadelta_1:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock6/resBlock6-3_conv2_bn/beta/Adadelta:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock6/resBlock6-3_conv2_bn/beta/Adadelta_1:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock6/resBlock6-3_conv2_bn/gamma/Adadelta:0
Variables to be restored: global/detector_scope/global/detector_scope/resBlock6/resBlock6-3_conv2_bn/gamma/Adadelta_1:0
Step: 10, avg loss: 1.224589, loss: 1.224589, accuracy: 0.300000
Step: 20, avg loss: 0.857136, loss: 0.489684, accuracy: 0.700000
Step: 30, avg loss: 0.841502, loss: 0.810234, accuracy: 0.800000
Step: 40, avg loss: 0.838855, loss: 0.830913, accuracy: 0.300000
Step: 50, avg loss: 0.762212, loss: 0.455639, accuracy: 0.700000
Step: 60, avg loss: 0.723539, loss: 0.530173, accuracy: 0.600000
Step: 70, avg loss: 0.682080, loss: 0.433326, accuracy: 0.800000
Step: 80, avg loss: 0.651579, loss: 0.438076, accuracy: 0.800000
Step: 90, avg loss: 0.647097, loss: 0.611238, accuracy: 0.600000
Step: 100, avg loss: 0.650969, loss: 0.685821, accuracy: 0.800000
Step: 110, avg loss: 0.609681, loss: 0.196800, accuracy: 0.900000
Step: 120, avg loss: 0.654911, loss: 1.152435, accuracy: 0.400000
Step: 130, avg loss: 0.623155, loss: 0.242082, accuracy: 0.900000
Step: 140, avg loss: 0.598270, loss: 0.274769, accuracy: 0.900000
Step: 150, avg loss: 0.605728, loss: 0.710140, accuracy: 0.600000
Step: 160, avg loss: 0.572787, loss: 0.078679, accuracy: 1.000000
Step: 170, avg loss: 0.592353, loss: 0.905398, accuracy: 0.700000
Step: 180, avg loss: 0.597264, loss: 0.680753, accuracy: 0.800000
Step: 190, avg loss: 0.605538, loss: 0.754474, accuracy: 0.600000
Step: 200, avg loss: 0.610932, loss: 0.713426, accuracy: 0.600000
Step: 210, avg loss: 0.618217, loss: 0.763907, accuracy: 0.600000
Step: 220, avg loss: 0.615600, loss: 0.560650, accuracy: 0.600000
Step: 230, avg loss: 0.614327, loss: 0.586320, accuracy: 0.500000
Step: 240, avg loss: 0.605405, loss: 0.400185, accuracy: 0.800000
Step: 250, avg loss: 0.603135, loss: 0.548662, accuracy: 0.700000
Step: 260, avg loss: 0.597093, loss: 0.446057, accuracy: 0.900000
Step: 270, avg loss: 0.599840, loss: 0.671257, accuracy: 0.600000
Step: 280, avg loss: 0.591380, loss: 0.362944, accuracy: 0.700000
Step: 290, avg loss: 0.591614, loss: 0.598169, accuracy: 0.500000
Step: 300, avg loss: 0.580273, loss: 0.251387, accuracy: 0.900000
Step: 310, avg loss: 0.568661, loss: 0.220294, accuracy: 0.900000
Step: 320, avg loss: 0.556937, loss: 0.193491, accuracy: 0.900000
Step: 330, avg loss: 0.546148, loss: 0.200929, accuracy: 0.900000
Step: 340, avg loss: 0.562888, loss: 1.115306, accuracy: 0.700000
Step: 350, avg loss: 0.557155, loss: 0.362223, accuracy: 0.800000
Step: 360, avg loss: 0.550146, loss: 0.304828, accuracy: 0.900000
Step: 370, avg loss: 0.556257, loss: 0.776264, accuracy: 0.800000
Step: 380, avg loss: 0.563116, loss: 0.816874, accuracy: 0.600000
Step: 390, avg loss: 0.559003, loss: 0.402732, accuracy: 0.800000
Step: 400, avg loss: 0.552157, loss: 0.285162, accuracy: 0.900000
Step: 410, avg loss: 0.557006, loss: 0.750962, accuracy: 0.700000
Step: 420, avg loss: 0.555521, loss: 0.494631, accuracy: 0.800000
Step: 430, avg loss: 0.550213, loss: 0.327285, accuracy: 0.900000
Step: 440, avg loss: 0.557190, loss: 0.857201, accuracy: 0.600000
Step: 450, avg loss: 0.559236, loss: 0.649233, accuracy: 0.600000
Step: 460, avg loss: 0.555857, loss: 0.403816, accuracy: 0.800000
Step: 470, avg loss: 0.558395, loss: 0.675166, accuracy: 0.800000
Step: 480, avg loss: 0.559745, loss: 0.623199, accuracy: 0.700000
Step: 490, avg loss: 0.562164, loss: 0.678243, accuracy: 0.700000
Step: 500, avg loss: 0.562089, loss: 0.558448, accuracy: 0.600000
Step: 510, avg loss: 0.560996, loss: 0.506338, accuracy: 0.700000
Step: 520, avg loss: 0.552200, loss: 0.103589, accuracy: 1.000000
Step: 530, avg loss: 0.548517, loss: 0.357026, accuracy: 0.800000
Step: 540, avg loss: 0.548778, loss: 0.562580, accuracy: 0.800000
Step: 550, avg loss: 0.550709, loss: 0.654992, accuracy: 0.800000
Step: 560, avg loss: 0.550427, loss: 0.534933, accuracy: 0.800000
Step: 570, avg loss: 0.546589, loss: 0.331643, accuracy: 0.900000
Step: 580, avg loss: 0.543189, loss: 0.349371, accuracy: 0.800000
Step: 590, avg loss: 0.549484, loss: 0.914594, accuracy: 0.600000
Step: 600, avg loss: 0.544480, loss: 0.249293, accuracy: 0.900000
Step: 610, avg loss: 0.545236, loss: 0.590545, accuracy: 0.800000
Step: 620, avg loss: 0.539613, loss: 0.196633, accuracy: 0.900000
Step: 630, avg loss: 0.536500, loss: 0.343491, accuracy: 0.900000
Step: 640, avg loss: 0.539566, loss: 0.732703, accuracy: 0.700000
Step: 650, avg loss: 0.539054, loss: 0.506294, accuracy: 0.700000
Step: 660, avg loss: 0.536828, loss: 0.392159, accuracy: 0.800000
Step: 670, avg loss: 0.537646, loss: 0.591614, accuracy: 0.700000
Step: 680, avg loss: 0.539549, loss: 0.667061, accuracy: 0.800000
Step: 690, avg loss: 0.537155, loss: 0.374359, accuracy: 0.800000
Step: 700, avg loss: 0.539634, loss: 0.710680, accuracy: 0.700000
Step: 710, avg loss: 0.543598, loss: 0.821065, accuracy: 0.500000
Step: 720, avg loss: 0.543051, loss: 0.504206, accuracy: 0.800000
Step: 730, avg loss: 0.537434, loss: 0.133016, accuracy: 1.000000
Step: 740, avg loss: 0.539379, loss: 0.681424, accuracy: 0.800000
Step: 750, avg loss: 0.538256, loss: 0.455118, accuracy: 0.800000
Step: 760, avg loss: 0.533183, loss: 0.152685, accuracy: 1.000000
Step: 770, avg loss: 0.533181, loss: 0.533048, accuracy: 0.900000
Step: 780, avg loss: 0.534946, loss: 0.670827, accuracy: 0.800000
Step: 790, avg loss: 0.535350, loss: 0.566932, accuracy: 0.800000
Step: 800, avg loss: 0.533748, loss: 0.407114, accuracy: 0.800000
Step: 810, avg loss: 0.531237, loss: 0.330411, accuracy: 0.900000
Step: 820, avg loss: 0.533172, loss: 0.689931, accuracy: 0.800000
Step: 830, avg loss: 0.530345, loss: 0.298471, accuracy: 0.900000
Step: 840, avg loss: 0.531922, loss: 0.662856, accuracy: 0.600000
Step: 850, avg loss: 0.528755, loss: 0.262694, accuracy: 0.900000
Step: 860, avg loss: 0.533410, loss: 0.929066, accuracy: 0.500000
Step: 870, avg loss: 0.533394, loss: 0.532078, accuracy: 0.800000
Step: 880, avg loss: 0.531575, loss: 0.373321, accuracy: 0.800000
Step: 890, avg loss: 0.534173, loss: 0.762738, accuracy: 0.400000
Step: 900, avg loss: 0.532595, loss: 0.392199, accuracy: 0.900000
Step: 910, avg loss: 0.533914, loss: 0.652653, accuracy: 0.700000
Step: 920, avg loss: 0.532746, loss: 0.426371, accuracy: 0.800000
Step: 930, avg loss: 0.530634, loss: 0.336401, accuracy: 0.900000
Step: 940, avg loss: 0.528511, loss: 0.331075, accuracy: 0.800000
Step: 950, avg loss: 0.530174, loss: 0.686510, accuracy: 0.700000
Step: 960, avg loss: 0.530626, loss: 0.573552, accuracy: 0.800000
Step: 970, avg loss: 0.530709, loss: 0.538627, accuracy: 0.600000
Step: 980, avg loss: 0.528037, loss: 0.268899, accuracy: 1.000000
Step: 990, avg loss: 0.528924, loss: 0.615818, accuracy: 0.700000
Step: 1000, avg loss: 0.526133, loss: 0.249871, accuracy: 0.900000
Step: 1010, avg loss: 0.524663, loss: 0.377667, accuracy: 0.800000
Step: 1020, avg loss: 0.520204, loss: 0.069828, accuracy: 1.000000
Step: 1030, avg loss: 0.517391, loss: 0.230402, accuracy: 0.900000
Step: 1040, avg loss: 0.513205, loss: 0.082036, accuracy: 1.000000
Step: 1050, avg loss: 0.513971, loss: 0.593716, accuracy: 0.800000
Step: 1060, avg loss: 0.513227, loss: 0.435095, accuracy: 0.900000
Step: 1070, avg loss: 0.511567, loss: 0.335572, accuracy: 0.900000
Step: 1080, avg loss: 0.509224, loss: 0.258496, accuracy: 1.000000
Step: 1090, avg loss: 0.508088, loss: 0.385489, accuracy: 0.700000
Step: 1100, avg loss: 0.509693, loss: 0.684627, accuracy: 0.500000
Step: 1110, avg loss: 0.507811, loss: 0.300757, accuracy: 0.800000
Step: 1120, avg loss: 0.511205, loss: 0.887977, accuracy: 0.900000
Step: 1130, avg loss: 0.509530, loss: 0.321905, accuracy: 0.900000
Step: 1140, avg loss: 0.515415, loss: 1.180419, accuracy: 0.400000
Step: 1150, avg loss: 0.516711, loss: 0.664437, accuracy: 0.400000
Step: 1160, avg loss: 0.517702, loss: 0.631686, accuracy: 0.700000
Step: 1170, avg loss: 0.517439, loss: 0.486958, accuracy: 0.800000
Step: 1180, avg loss: 0.518917, loss: 0.691746, accuracy: 0.800000
Step: 1190, avg loss: 0.517943, loss: 0.403037, accuracy: 0.800000
Step: 1200, avg loss: 0.517758, loss: 0.495743, accuracy: 0.800000
Step: 1210, avg loss: 0.516988, loss: 0.424562, accuracy: 0.900000
Step: 1220, avg loss: 0.513711, loss: 0.117250, accuracy: 1.000000
Step: 1230, avg loss: 0.512977, loss: 0.423458, accuracy: 0.700000
Step: 1240, avg loss: 0.513846, loss: 0.620725, accuracy: 0.800000
Step: 1250, avg loss: 0.516298, loss: 0.820327, accuracy: 0.700000
Step: 1260, avg loss: 0.517053, loss: 0.611390, accuracy: 0.700000
Epoch 1 finished in loss: 0.516376 and accuracy: 0.763074
Step: 10, avg loss: 0.945975, loss: 0.945975, accuracy: 0.600000
Step: 20, avg loss: 0.703450, loss: 0.460924, accuracy: 0.800000
Step: 30, avg loss: 0.612070, loss: 0.429311, accuracy: 0.900000
Step: 40, avg loss: 0.608319, loss: 0.597066, accuracy: 0.700000
Step: 50, avg loss: 0.567366, loss: 0.403550, accuracy: 0.900000
Step: 60, avg loss: 0.540798, loss: 0.407960, accuracy: 0.800000
Step: 70, avg loss: 0.503006, loss: 0.276256, accuracy: 0.900000
Step: 80, avg loss: 0.469721, loss: 0.236723, accuracy: 0.900000
Step: 90, avg loss: 0.498253, loss: 0.726510, accuracy: 0.800000
Step: 100, avg loss: 0.505225, loss: 0.567975, accuracy: 0.800000
Step: 110, avg loss: 0.482753, loss: 0.258034, accuracy: 0.800000
Step: 120, avg loss: 0.529795, loss: 1.047250, accuracy: 0.400000
Step: 130, avg loss: 0.507958, loss: 0.245915, accuracy: 1.000000
Step: 140, avg loss: 0.485964, loss: 0.200043, accuracy: 0.900000
Step: 150, avg loss: 0.504963, loss: 0.770954, accuracy: 0.500000
Step: 160, avg loss: 0.479346, loss: 0.095091, accuracy: 1.000000
Step: 170, avg loss: 0.497665, loss: 0.790764, accuracy: 0.700000
Step: 180, avg loss: 0.505651, loss: 0.641408, accuracy: 0.800000
Step: 190, avg loss: 0.512541, loss: 0.636572, accuracy: 0.700000
Step: 200, avg loss: 0.517939, loss: 0.620502, accuracy: 0.500000
Step: 210, avg loss: 0.526195, loss: 0.691302, accuracy: 0.800000
Step: 220, avg loss: 0.528600, loss: 0.579108, accuracy: 0.600000
Step: 230, avg loss: 0.533487, loss: 0.641001, accuracy: 0.700000
Step: 240, avg loss: 0.527653, loss: 0.393489, accuracy: 0.800000
Step: 250, avg loss: 0.524698, loss: 0.453769, accuracy: 0.700000
Step: 260, avg loss: 0.516726, loss: 0.317429, accuracy: 0.800000
Step: 270, avg loss: 0.524470, loss: 0.725812, accuracy: 0.700000
Step: 280, avg loss: 0.515361, loss: 0.269401, accuracy: 0.800000
Step: 290, avg loss: 0.514308, loss: 0.484849, accuracy: 0.700000
Step: 300, avg loss: 0.504727, loss: 0.226868, accuracy: 0.900000
Step: 310, avg loss: 0.493018, loss: 0.141760, accuracy: 1.000000
Step: 320, avg loss: 0.483791, loss: 0.197755, accuracy: 0.800000
Step: 330, avg loss: 0.476012, loss: 0.227069, accuracy: 0.900000
Step: 340, avg loss: 0.489503, loss: 0.934719, accuracy: 0.600000
Step: 350, avg loss: 0.483598, loss: 0.282803, accuracy: 0.900000
Step: 360, avg loss: 0.477840, loss: 0.276307, accuracy: 0.900000
Step: 370, avg loss: 0.483604, loss: 0.691137, accuracy: 0.900000
Step: 380, avg loss: 0.496978, loss: 0.991804, accuracy: 0.600000
Step: 390, avg loss: 0.492048, loss: 0.304698, accuracy: 0.900000
Step: 400, avg loss: 0.485464, loss: 0.228683, accuracy: 0.900000
Step: 410, avg loss: 0.490635, loss: 0.697473, accuracy: 0.700000
Step: 420, avg loss: 0.488188, loss: 0.387880, accuracy: 0.900000
Step: 430, avg loss: 0.484147, loss: 0.314439, accuracy: 0.900000
Step: 440, avg loss: 0.491429, loss: 0.804520, accuracy: 0.700000
Step: 450, avg loss: 0.493737, loss: 0.595306, accuracy: 0.600000
Step: 460, avg loss: 0.490900, loss: 0.363227, accuracy: 0.800000
Step: 470, avg loss: 0.494865, loss: 0.677271, accuracy: 0.800000
Step: 480, avg loss: 0.497164, loss: 0.605203, accuracy: 0.800000
Step: 490, avg loss: 0.499903, loss: 0.631392, accuracy: 0.700000
Step: 500, avg loss: 0.500584, loss: 0.533965, accuracy: 0.700000
Step: 510, avg loss: 0.500294, loss: 0.485770, accuracy: 0.700000
Step: 520, avg loss: 0.492978, loss: 0.119845, accuracy: 1.000000
Step: 530, avg loss: 0.487329, loss: 0.193617, accuracy: 1.000000
Step: 540, avg loss: 0.480732, loss: 0.131066, accuracy: 1.000000
Step: 550, avg loss: 0.486301, loss: 0.787006, accuracy: 0.800000
Step: 560, avg loss: 0.487463, loss: 0.551422, accuracy: 0.800000
Step: 570, avg loss: 0.483988, loss: 0.289340, accuracy: 0.800000
Step: 580, avg loss: 0.484070, loss: 0.488785, accuracy: 0.600000
Step: 590, avg loss: 0.490249, loss: 0.848592, accuracy: 0.500000
Step: 600, avg loss: 0.487960, loss: 0.352922, accuracy: 0.800000
Step: 610, avg loss: 0.488887, loss: 0.544508, accuracy: 0.800000
Step: 620, avg loss: 0.485308, loss: 0.267010, accuracy: 0.900000
Step: 630, avg loss: 0.482673, loss: 0.319296, accuracy: 0.900000
Step: 640, avg loss: 0.484196, loss: 0.580145, accuracy: 0.700000
Step: 650, avg loss: 0.484233, loss: 0.486610, accuracy: 0.800000
Step: 660, avg loss: 0.482599, loss: 0.376350, accuracy: 0.800000
Step: 670, avg loss: 0.484202, loss: 0.590011, accuracy: 0.800000
Step: 680, avg loss: 0.485463, loss: 0.569997, accuracy: 0.800000
Step: 690, avg loss: 0.484169, loss: 0.396122, accuracy: 0.900000
Step: 700, avg loss: 0.487031, loss: 0.684551, accuracy: 0.700000
Step: 710, avg loss: 0.491597, loss: 0.811194, accuracy: 0.500000
Step: 720, avg loss: 0.491008, loss: 0.449204, accuracy: 0.800000
Step: 730, avg loss: 0.486465, loss: 0.159324, accuracy: 1.000000
Step: 740, avg loss: 0.489356, loss: 0.700456, accuracy: 0.800000
Step: 750, avg loss: 0.489009, loss: 0.463311, accuracy: 0.700000
Step: 760, avg loss: 0.484959, loss: 0.181192, accuracy: 0.900000
Step: 770, avg loss: 0.485129, loss: 0.498059, accuracy: 0.900000
Step: 780, avg loss: 0.487181, loss: 0.645157, accuracy: 0.800000
Step: 790, avg loss: 0.487680, loss: 0.526602, accuracy: 0.800000
Step: 800, avg loss: 0.486222, loss: 0.371104, accuracy: 0.800000
Step: 810, avg loss: 0.484199, loss: 0.322304, accuracy: 0.900000
Step: 820, avg loss: 0.486998, loss: 0.713703, accuracy: 0.800000
Step: 830, avg loss: 0.484793, loss: 0.304027, accuracy: 0.900000
Step: 840, avg loss: 0.487418, loss: 0.705282, accuracy: 0.600000
Step: 850, avg loss: 0.485714, loss: 0.342553, accuracy: 0.900000
Step: 860, avg loss: 0.489252, loss: 0.790042, accuracy: 0.600000
Step: 870, avg loss: 0.488838, loss: 0.453176, accuracy: 0.900000
Step: 880, avg loss: 0.487608, loss: 0.380664, accuracy: 0.800000
Step: 890, avg loss: 0.489762, loss: 0.679310, accuracy: 0.600000
Step: 900, avg loss: 0.488204, loss: 0.349495, accuracy: 0.900000
Step: 910, avg loss: 0.490558, loss: 0.702474, accuracy: 0.700000
Step: 920, avg loss: 0.489489, loss: 0.392195, accuracy: 0.800000
Step: 930, avg loss: 0.487337, loss: 0.289327, accuracy: 0.900000
Step: 940, avg loss: 0.484732, loss: 0.242450, accuracy: 1.000000
Step: 950, avg loss: 0.487234, loss: 0.722420, accuracy: 0.700000
Step: 960, avg loss: 0.487287, loss: 0.492364, accuracy: 0.800000
Step: 970, avg loss: 0.488349, loss: 0.590228, accuracy: 0.600000
Step: 980, avg loss: 0.485872, loss: 0.245658, accuracy: 0.900000
Step: 990, avg loss: 0.486932, loss: 0.590809, accuracy: 0.700000
Step: 1000, avg loss: 0.484364, loss: 0.230094, accuracy: 1.000000
Step: 1010, avg loss: 0.483299, loss: 0.376873, accuracy: 0.800000
Step: 1020, avg loss: 0.479256, loss: 0.070858, accuracy: 1.000000
Step: 1030, avg loss: 0.476604, loss: 0.206109, accuracy: 0.900000
Step: 1040, avg loss: 0.473481, loss: 0.151831, accuracy: 0.900000
Step: 1050, avg loss: 0.472600, loss: 0.380944, accuracy: 0.700000
Step: 1060, avg loss: 0.471617, loss: 0.368373, accuracy: 0.900000
Step: 1070, avg loss: 0.469681, loss: 0.264544, accuracy: 0.900000
Step: 1080, avg loss: 0.467375, loss: 0.220555, accuracy: 1.000000
Step: 1090, avg loss: 0.466630, loss: 0.386211, accuracy: 0.700000
Step: 1100, avg loss: 0.467226, loss: 0.532180, accuracy: 0.700000
Step: 1110, avg loss: 0.464880, loss: 0.206837, accuracy: 0.900000
Step: 1120, avg loss: 0.469191, loss: 0.947678, accuracy: 0.900000
Step: 1130, avg loss: 0.467882, loss: 0.321309, accuracy: 0.800000
Step: 1140, avg loss: 0.474189, loss: 1.186870, accuracy: 0.400000
Step: 1150, avg loss: 0.476413, loss: 0.729979, accuracy: 0.400000
Step: 1160, avg loss: 0.477212, loss: 0.569111, accuracy: 0.600000
Step: 1170, avg loss: 0.476841, loss: 0.433817, accuracy: 0.900000
Step: 1180, avg loss: 0.478749, loss: 0.701934, accuracy: 0.800000
Step: 1190, avg loss: 0.477644, loss: 0.347234, accuracy: 0.700000
Step: 1200, avg loss: 0.477825, loss: 0.499352, accuracy: 0.800000
Step: 1210, avg loss: 0.477057, loss: 0.384964, accuracy: 0.900000
Step: 1220, avg loss: 0.473860, loss: 0.087022, accuracy: 1.000000
Step: 1230, avg loss: 0.473010, loss: 0.369266, accuracy: 0.700000
Step: 1240, avg loss: 0.473547, loss: 0.539551, accuracy: 0.800000
Step: 1250, avg loss: 0.475564, loss: 0.725731, accuracy: 0.700000
Step: 1260, avg loss: 0.475860, loss: 0.512863, accuracy: 0.700000
Epoch 2 finished in loss: 0.475218 and accuracy: 0.790016
Step: 10, avg loss: 0.958933, loss: 0.958933, accuracy: 0.600000
Step: 20, avg loss: 0.684176, loss: 0.409418, accuracy: 0.800000
Step: 30, avg loss: 0.576731, loss: 0.361842, accuracy: 0.900000
Step: 40, avg loss: 0.572856, loss: 0.561232, accuracy: 0.700000
Step: 50, avg loss: 0.537813, loss: 0.397640, accuracy: 0.900000
Step: 60, avg loss: 0.507505, loss: 0.355963, accuracy: 0.900000
Step: 70, avg loss: 0.462505, loss: 0.192506, accuracy: 0.900000
Step: 80, avg loss: 0.429481, loss: 0.198317, accuracy: 0.900000
Step: 90, avg loss: 0.465292, loss: 0.751781, accuracy: 0.800000
Step: 100, avg loss: 0.473457, loss: 0.546942, accuracy: 0.800000
Step: 110, avg loss: 0.456640, loss: 0.288467, accuracy: 0.800000
Step: 120, avg loss: 0.506199, loss: 1.051350, accuracy: 0.500000
Step: 130, avg loss: 0.485695, loss: 0.239649, accuracy: 1.000000
Step: 140, avg loss: 0.463009, loss: 0.168080, accuracy: 0.900000
Step: 150, avg loss: 0.477387, loss: 0.678681, accuracy: 0.600000
Step: 160, avg loss: 0.452647, loss: 0.081557, accuracy: 1.000000
Step: 170, avg loss: 0.473359, loss: 0.804741, accuracy: 0.700000
Step: 180, avg loss: 0.482045, loss: 0.629714, accuracy: 0.800000
Step: 190, avg loss: 0.487056, loss: 0.577246, accuracy: 0.800000
Step: 200, avg loss: 0.492569, loss: 0.597322, accuracy: 0.600000
Step: 210, avg loss: 0.500693, loss: 0.663177, accuracy: 0.800000
Step: 220, avg loss: 0.505766, loss: 0.612300, accuracy: 0.700000
Step: 230, avg loss: 0.508062, loss: 0.558562, accuracy: 0.700000
Step: 240, avg loss: 0.501452, loss: 0.349423, accuracy: 0.700000
Step: 250, avg loss: 0.496340, loss: 0.373657, accuracy: 0.700000
Step: 260, avg loss: 0.489571, loss: 0.320352, accuracy: 0.900000
Step: 270, avg loss: 0.498419, loss: 0.728457, accuracy: 0.600000
Step: 280, avg loss: 0.487680, loss: 0.197735, accuracy: 1.000000
Step: 290, avg loss: 0.479906, loss: 0.262230, accuracy: 1.000000
Step: 300, avg loss: 0.470772, loss: 0.205892, accuracy: 0.900000
Step: 310, avg loss: 0.458425, loss: 0.088004, accuracy: 1.000000
Step: 320, avg loss: 0.448652, loss: 0.145706, accuracy: 1.000000
Step: 330, avg loss: 0.439587, loss: 0.149489, accuracy: 1.000000
Step: 340, avg loss: 0.454211, loss: 0.936816, accuracy: 0.600000
Step: 350, avg loss: 0.451386, loss: 0.355339, accuracy: 0.800000
Step: 360, avg loss: 0.449410, loss: 0.380241, accuracy: 0.900000
Step: 370, avg loss: 0.454192, loss: 0.626356, accuracy: 0.800000
Step: 380, avg loss: 0.465455, loss: 0.882181, accuracy: 0.600000
Step: 390, avg loss: 0.460432, loss: 0.269569, accuracy: 0.900000
Step: 400, avg loss: 0.454421, loss: 0.219968, accuracy: 1.000000
Step: 410, avg loss: 0.456906, loss: 0.556305, accuracy: 0.700000
Step: 420, avg loss: 0.453492, loss: 0.313531, accuracy: 0.900000
Step: 430, avg loss: 0.451423, loss: 0.364516, accuracy: 0.900000
Step: 440, avg loss: 0.459052, loss: 0.787104, accuracy: 0.700000
Step: 450, avg loss: 0.461770, loss: 0.581347, accuracy: 0.600000
Step: 460, avg loss: 0.459225, loss: 0.344709, accuracy: 0.900000
Step: 470, avg loss: 0.463090, loss: 0.640890, accuracy: 0.800000
Step: 480, avg loss: 0.466500, loss: 0.626769, accuracy: 0.800000
Step: 490, avg loss: 0.469192, loss: 0.598401, accuracy: 0.800000
Step: 500, avg loss: 0.468172, loss: 0.418179, accuracy: 0.800000
Step: 510, avg loss: 0.468557, loss: 0.487811, accuracy: 0.800000
Step: 520, avg loss: 0.461628, loss: 0.108285, accuracy: 1.000000
Step: 530, avg loss: 0.457384, loss: 0.236694, accuracy: 0.800000
Step: 540, avg loss: 0.450675, loss: 0.095088, accuracy: 1.000000
Step: 550, avg loss: 0.455904, loss: 0.738234, accuracy: 0.800000
Step: 560, avg loss: 0.456067, loss: 0.465071, accuracy: 0.800000
Step: 570, avg loss: 0.452785, loss: 0.268965, accuracy: 0.900000
Step: 580, avg loss: 0.454010, loss: 0.523866, accuracy: 0.700000
Step: 590, avg loss: 0.459842, loss: 0.798076, accuracy: 0.600000
Step: 600, avg loss: 0.455246, loss: 0.184080, accuracy: 1.000000
Step: 610, avg loss: 0.455434, loss: 0.466741, accuracy: 0.900000
Step: 620, avg loss: 0.449994, loss: 0.118116, accuracy: 1.000000
Step: 630, avg loss: 0.447859, loss: 0.315499, accuracy: 0.900000
Step: 640, avg loss: 0.448097, loss: 0.463091, accuracy: 0.700000
Step: 650, avg loss: 0.448111, loss: 0.449037, accuracy: 0.800000
Step: 660, avg loss: 0.446787, loss: 0.360700, accuracy: 0.800000
Step: 670, avg loss: 0.448581, loss: 0.566967, accuracy: 0.800000
Step: 680, avg loss: 0.449127, loss: 0.485730, accuracy: 0.800000
Step: 690, avg loss: 0.448510, loss: 0.406560, accuracy: 0.900000
Step: 700, avg loss: 0.451198, loss: 0.636675, accuracy: 0.800000
Step: 710, avg loss: 0.458165, loss: 0.945859, accuracy: 0.500000
Step: 720, avg loss: 0.458098, loss: 0.453300, accuracy: 0.800000
Step: 730, avg loss: 0.453670, loss: 0.134900, accuracy: 1.000000
Step: 740, avg loss: 0.456227, loss: 0.642843, accuracy: 0.700000
Step: 750, avg loss: 0.455913, loss: 0.432690, accuracy: 0.800000
Step: 760, avg loss: 0.452029, loss: 0.160749, accuracy: 0.900000
Step: 770, avg loss: 0.452391, loss: 0.479857, accuracy: 0.900000
Step: 780, avg loss: 0.453751, loss: 0.558507, accuracy: 0.800000
Step: 790, avg loss: 0.454588, loss: 0.519842, accuracy: 0.800000
Step: 800, avg loss: 0.453373, loss: 0.357411, accuracy: 0.800000
Step: 810, avg loss: 0.451344, loss: 0.289058, accuracy: 0.900000
Step: 820, avg loss: 0.455000, loss: 0.751089, accuracy: 0.700000
Step: 830, avg loss: 0.452656, loss: 0.260441, accuracy: 0.900000
Step: 840, avg loss: 0.455375, loss: 0.681072, accuracy: 0.600000
Step: 850, avg loss: 0.453056, loss: 0.258270, accuracy: 0.900000
Step: 860, avg loss: 0.457085, loss: 0.799557, accuracy: 0.700000
Step: 870, avg loss: 0.456412, loss: 0.398492, accuracy: 0.800000
Step: 880, avg loss: 0.454883, loss: 0.321930, accuracy: 0.800000
Step: 890, avg loss: 0.456844, loss: 0.629389, accuracy: 0.600000
Step: 900, avg loss: 0.454936, loss: 0.285112, accuracy: 1.000000
Step: 910, avg loss: 0.458147, loss: 0.747159, accuracy: 0.600000
Step: 920, avg loss: 0.457195, loss: 0.370545, accuracy: 0.800000
Step: 930, avg loss: 0.455098, loss: 0.262184, accuracy: 0.800000
Step: 940, avg loss: 0.452978, loss: 0.255848, accuracy: 1.000000
Step: 950, avg loss: 0.454598, loss: 0.606798, accuracy: 0.700000
Step: 960, avg loss: 0.456659, loss: 0.652511, accuracy: 0.800000
Step: 970, avg loss: 0.456963, loss: 0.486120, accuracy: 0.600000
Step: 980, avg loss: 0.454436, loss: 0.209340, accuracy: 1.000000
Step: 990, avg loss: 0.455679, loss: 0.577482, accuracy: 0.700000
Step: 1000, avg loss: 0.452546, loss: 0.142360, accuracy: 1.000000
Step: 1010, avg loss: 0.450873, loss: 0.283630, accuracy: 0.800000
Step: 1020, avg loss: 0.447404, loss: 0.096996, accuracy: 1.000000
Step: 1030, avg loss: 0.445053, loss: 0.205214, accuracy: 0.900000
Step: 1040, avg loss: 0.441277, loss: 0.052355, accuracy: 1.000000
Step: 1050, avg loss: 0.439904, loss: 0.297181, accuracy: 0.900000
Step: 1060, avg loss: 0.438653, loss: 0.307272, accuracy: 0.900000
Step: 1070, avg loss: 0.437030, loss: 0.264999, accuracy: 0.900000
Step: 1080, avg loss: 0.434560, loss: 0.170224, accuracy: 1.000000
Step: 1090, avg loss: 0.434462, loss: 0.423948, accuracy: 0.700000
Step: 1100, avg loss: 0.434280, loss: 0.414372, accuracy: 0.700000
Step: 1110, avg loss: 0.431750, loss: 0.153428, accuracy: 1.000000
Step: 1120, avg loss: 0.435111, loss: 0.808197, accuracy: 0.900000
Step: 1130, avg loss: 0.434649, loss: 0.382967, accuracy: 0.800000
Step: 1140, avg loss: 0.442114, loss: 1.285572, accuracy: 0.500000
Step: 1150, avg loss: 0.444417, loss: 0.707052, accuracy: 0.500000
Step: 1160, avg loss: 0.445125, loss: 0.526462, accuracy: 0.700000
Step: 1170, avg loss: 0.445052, loss: 0.436577, accuracy: 0.900000
Step: 1180, avg loss: 0.446696, loss: 0.639106, accuracy: 0.800000
Step: 1190, avg loss: 0.446351, loss: 0.405622, accuracy: 0.700000
Step: 1200, avg loss: 0.447076, loss: 0.533389, accuracy: 0.800000
Step: 1210, avg loss: 0.446416, loss: 0.367175, accuracy: 0.900000
Step: 1220, avg loss: 0.443390, loss: 0.077311, accuracy: 1.000000
Step: 1230, avg loss: 0.441793, loss: 0.246946, accuracy: 1.000000
Step: 1240, avg loss: 0.442187, loss: 0.490561, accuracy: 0.700000
Step: 1250, avg loss: 0.443788, loss: 0.642347, accuracy: 0.700000
Step: 1260, avg loss: 0.443022, loss: 0.347332, accuracy: 0.800000
Epoch 3 finished in loss: 0.442411 and accuracy: 0.814580
Step: 10, avg loss: 0.954646, loss: 0.954646, accuracy: 0.600000
Step: 20, avg loss: 0.680016, loss: 0.405386, accuracy: 0.900000
Step: 30, avg loss: 0.572765, loss: 0.358264, accuracy: 0.800000
Step: 40, avg loss: 0.549145, loss: 0.478283, accuracy: 0.700000
Step: 50, avg loss: 0.522867, loss: 0.417754, accuracy: 0.900000
Step: 60, avg loss: 0.491987, loss: 0.337592, accuracy: 0.900000
Step: 70, avg loss: 0.441293, loss: 0.137129, accuracy: 1.000000
Step: 80, avg loss: 0.403598, loss: 0.139730, accuracy: 0.900000
Step: 90, avg loss: 0.441777, loss: 0.747208, accuracy: 0.800000
Step: 100, avg loss: 0.452806, loss: 0.552070, accuracy: 0.800000
Step: 110, avg loss: 0.441263, loss: 0.325832, accuracy: 0.900000
Step: 120, avg loss: 0.495017, loss: 1.086307, accuracy: 0.600000
Step: 130, avg loss: 0.469805, loss: 0.167268, accuracy: 1.000000
Step: 140, avg loss: 0.445425, loss: 0.128482, accuracy: 1.000000
Step: 150, avg loss: 0.468423, loss: 0.790401, accuracy: 0.500000
Step: 160, avg loss: 0.444246, loss: 0.081588, accuracy: 1.000000
Step: 170, avg loss: 0.468925, loss: 0.863777, accuracy: 0.700000
Step: 180, avg loss: 0.475631, loss: 0.589635, accuracy: 0.800000
Step: 190, avg loss: 0.476358, loss: 0.489441, accuracy: 0.800000
Step: 200, avg loss: 0.481206, loss: 0.573324, accuracy: 0.800000
Step: 210, avg loss: 0.489044, loss: 0.645810, accuracy: 0.700000
Step: 220, avg loss: 0.493108, loss: 0.578440, accuracy: 0.600000
Step: 230, avg loss: 0.489532, loss: 0.410876, accuracy: 0.900000
Step: 240, avg loss: 0.481543, loss: 0.297787, accuracy: 0.800000
Step: 250, avg loss: 0.482802, loss: 0.513020, accuracy: 0.700000
Step: 260, avg loss: 0.477466, loss: 0.344074, accuracy: 0.900000
Step: 270, avg loss: 0.484466, loss: 0.666452, accuracy: 0.600000
Step: 280, avg loss: 0.473653, loss: 0.181699, accuracy: 1.000000
Step: 290, avg loss: 0.463493, loss: 0.179021, accuracy: 1.000000
Step: 300, avg loss: 0.455927, loss: 0.236526, accuracy: 0.900000
Step: 310, avg loss: 0.443436, loss: 0.068699, accuracy: 1.000000
Step: 320, avg loss: 0.433679, loss: 0.131214, accuracy: 0.900000
Step: 330, avg loss: 0.425919, loss: 0.177576, accuracy: 0.900000
Step: 340, avg loss: 0.432093, loss: 0.635838, accuracy: 0.900000
Step: 350, avg loss: 0.429252, loss: 0.332659, accuracy: 0.800000
Step: 360, avg loss: 0.427091, loss: 0.351478, accuracy: 0.900000
Step: 370, avg loss: 0.435573, loss: 0.740910, accuracy: 0.700000
Step: 380, avg loss: 0.448422, loss: 0.923832, accuracy: 0.700000
Step: 390, avg loss: 0.444407, loss: 0.291836, accuracy: 0.900000
Step: 400, avg loss: 0.438043, loss: 0.189845, accuracy: 1.000000
Step: 410, avg loss: 0.436176, loss: 0.361509, accuracy: 0.900000
Step: 420, avg loss: 0.433440, loss: 0.321262, accuracy: 0.900000
Step: 430, avg loss: 0.428183, loss: 0.207394, accuracy: 0.900000
Step: 440, avg loss: 0.437658, loss: 0.845076, accuracy: 0.800000
Step: 450, avg loss: 0.441530, loss: 0.611906, accuracy: 0.600000
Step: 460, avg loss: 0.437847, loss: 0.272121, accuracy: 0.900000
Step: 470, avg loss: 0.441379, loss: 0.603822, accuracy: 0.800000
Step: 480, avg loss: 0.444797, loss: 0.605445, accuracy: 0.800000
Step: 490, avg loss: 0.449877, loss: 0.693753, accuracy: 0.700000
Step: 500, avg loss: 0.448737, loss: 0.392839, accuracy: 0.900000
Step: 510, avg loss: 0.449150, loss: 0.469796, accuracy: 0.900000
Step: 520, avg loss: 0.442672, loss: 0.112291, accuracy: 1.000000
Step: 530, avg loss: 0.438734, loss: 0.233982, accuracy: 1.000000
Step: 540, avg loss: 0.432116, loss: 0.081371, accuracy: 1.000000
Step: 550, avg loss: 0.437493, loss: 0.727852, accuracy: 0.800000
Step: 560, avg loss: 0.436929, loss: 0.405921, accuracy: 0.900000
Step: 570, avg loss: 0.433378, loss: 0.234479, accuracy: 0.900000
Step: 580, avg loss: 0.428881, loss: 0.172558, accuracy: 1.000000
Step: 590, avg loss: 0.435768, loss: 0.835203, accuracy: 0.600000
Step: 600, avg loss: 0.430817, loss: 0.138744, accuracy: 1.000000
Step: 610, avg loss: 0.431238, loss: 0.456503, accuracy: 0.900000
Step: 620, avg loss: 0.425542, loss: 0.078069, accuracy: 1.000000
Step: 630, avg loss: 0.423482, loss: 0.295766, accuracy: 0.900000
Step: 640, avg loss: 0.424672, loss: 0.499652, accuracy: 0.800000
Step: 650, avg loss: 0.425357, loss: 0.469190, accuracy: 0.800000
Step: 660, avg loss: 0.423775, loss: 0.320917, accuracy: 0.900000
Step: 670, avg loss: 0.424789, loss: 0.491717, accuracy: 0.800000
Step: 680, avg loss: 0.425429, loss: 0.468338, accuracy: 0.800000
Step: 690, avg loss: 0.426077, loss: 0.470152, accuracy: 0.900000
Step: 700, avg loss: 0.428541, loss: 0.598547, accuracy: 0.700000
Step: 710, avg loss: 0.436799, loss: 1.014809, accuracy: 0.500000
Step: 720, avg loss: 0.435970, loss: 0.377180, accuracy: 0.900000
Step: 730, avg loss: 0.431765, loss: 0.128942, accuracy: 1.000000
Step: 740, avg loss: 0.434280, loss: 0.617870, accuracy: 0.800000
Step: 750, avg loss: 0.433786, loss: 0.397300, accuracy: 0.800000
Step: 760, avg loss: 0.429657, loss: 0.119977, accuracy: 0.900000
Step: 770, avg loss: 0.429656, loss: 0.429513, accuracy: 0.900000
Step: 780, avg loss: 0.430383, loss: 0.486409, accuracy: 0.800000
Step: 790, avg loss: 0.430687, loss: 0.454417, accuracy: 0.800000
Step: 800, avg loss: 0.428901, loss: 0.287805, accuracy: 0.800000
Step: 810, avg loss: 0.426145, loss: 0.205635, accuracy: 0.900000
Step: 820, avg loss: 0.430944, loss: 0.819656, accuracy: 0.600000
Step: 830, avg loss: 0.428362, loss: 0.216643, accuracy: 0.900000
Step: 840, avg loss: 0.431644, loss: 0.704083, accuracy: 0.600000
Step: 850, avg loss: 0.428801, loss: 0.189967, accuracy: 0.900000
Step: 860, avg loss: 0.433398, loss: 0.824121, accuracy: 0.800000
Step: 870, avg loss: 0.432846, loss: 0.385385, accuracy: 0.800000
Step: 880, avg loss: 0.432235, loss: 0.379067, accuracy: 0.800000
Step: 890, avg loss: 0.434597, loss: 0.642451, accuracy: 0.600000
Step: 900, avg loss: 0.433052, loss: 0.295575, accuracy: 0.900000
Step: 910, avg loss: 0.435047, loss: 0.614560, accuracy: 0.800000
Step: 920, avg loss: 0.434336, loss: 0.369646, accuracy: 0.800000
Step: 930, avg loss: 0.433662, loss: 0.371716, accuracy: 0.700000
Step: 940, avg loss: 0.431537, loss: 0.233887, accuracy: 1.000000
Step: 950, avg loss: 0.432383, loss: 0.511872, accuracy: 0.700000
Step: 960, avg loss: 0.433828, loss: 0.571083, accuracy: 0.800000
Step: 970, avg loss: 0.432718, loss: 0.326192, accuracy: 0.900000
Step: 980, avg loss: 0.429863, loss: 0.152923, accuracy: 1.000000
Step: 990, avg loss: 0.430601, loss: 0.502976, accuracy: 0.800000
Step: 1000, avg loss: 0.427068, loss: 0.077284, accuracy: 1.000000
Step: 1010, avg loss: 0.425913, loss: 0.310424, accuracy: 0.800000
Step: 1020, avg loss: 0.423093, loss: 0.138260, accuracy: 0.900000
Step: 1030, avg loss: 0.420522, loss: 0.158288, accuracy: 0.900000
Step: 1040, avg loss: 0.416904, loss: 0.044242, accuracy: 1.000000
Step: 1050, avg loss: 0.415151, loss: 0.232849, accuracy: 0.900000
Step: 1060, avg loss: 0.412512, loss: 0.135384, accuracy: 0.900000
Step: 1070, avg loss: 0.411176, loss: 0.269563, accuracy: 0.900000
Step: 1080, avg loss: 0.408894, loss: 0.164689, accuracy: 1.000000
Step: 1090, avg loss: 0.408689, loss: 0.386537, accuracy: 0.800000
Step: 1100, avg loss: 0.406680, loss: 0.187767, accuracy: 0.900000
Step: 1110, avg loss: 0.403834, loss: 0.090752, accuracy: 1.000000
Step: 1120, avg loss: 0.407060, loss: 0.765132, accuracy: 0.900000
Step: 1130, avg loss: 0.407453, loss: 0.451459, accuracy: 0.800000
Step: 1140, avg loss: 0.417821, loss: 1.589382, accuracy: 0.500000
Step: 1150, avg loss: 0.420410, loss: 0.715640, accuracy: 0.500000
Step: 1160, avg loss: 0.421173, loss: 0.508850, accuracy: 0.900000
Step: 1170, avg loss: 0.421291, loss: 0.434979, accuracy: 0.800000
Step: 1180, avg loss: 0.422786, loss: 0.597671, accuracy: 0.800000
Step: 1190, avg loss: 0.422840, loss: 0.429242, accuracy: 0.800000
Step: 1200, avg loss: 0.424042, loss: 0.567064, accuracy: 0.800000
Step: 1210, avg loss: 0.423414, loss: 0.348143, accuracy: 0.800000
Step: 1220, avg loss: 0.420560, loss: 0.075141, accuracy: 1.000000
Step: 1230, avg loss: 0.418789, loss: 0.202782, accuracy: 1.000000
Step: 1240, avg loss: 0.418836, loss: 0.424550, accuracy: 0.800000
Step: 1250, avg loss: 0.419738, loss: 0.531638, accuracy: 0.800000
Step: 1260, avg loss: 0.418477, loss: 0.260808, accuracy: 0.900000
Epoch 4 finished in loss: 0.417884 and accuracy: 0.838352
Step: 10, avg loss: 0.863344, loss: 0.863344, accuracy: 0.700000
Step: 20, avg loss: 0.601743, loss: 0.340142, accuracy: 0.900000
Step: 30, avg loss: 0.528321, loss: 0.381477, accuracy: 0.800000
Step: 40, avg loss: 0.518910, loss: 0.490676, accuracy: 0.700000
Step: 50, avg loss: 0.509265, loss: 0.470684, accuracy: 0.800000
Step: 60, avg loss: 0.483800, loss: 0.356478, accuracy: 0.800000
Step: 70, avg loss: 0.431327, loss: 0.116487, accuracy: 1.000000
Step: 80, avg loss: 0.392902, loss: 0.123928, accuracy: 0.900000
Step: 90, avg loss: 0.424099, loss: 0.673677, accuracy: 0.900000
Step: 100, avg loss: 0.433487, loss: 0.517975, accuracy: 0.800000
Step: 110, avg loss: 0.423623, loss: 0.324984, accuracy: 0.900000
Step: 120, avg loss: 0.467794, loss: 0.953673, accuracy: 0.700000
Step: 130, avg loss: 0.442708, loss: 0.141686, accuracy: 1.000000
Step: 140, avg loss: 0.417894, loss: 0.095312, accuracy: 1.000000
Step: 150, avg loss: 0.438404, loss: 0.725541, accuracy: 0.500000
Step: 160, avg loss: 0.415320, loss: 0.069058, accuracy: 1.000000
Step: 170, avg loss: 0.438325, loss: 0.806412, accuracy: 0.700000
Step: 180, avg loss: 0.445271, loss: 0.563354, accuracy: 0.800000
Step: 190, avg loss: 0.442973, loss: 0.401605, accuracy: 0.800000
Step: 200, avg loss: 0.448113, loss: 0.545773, accuracy: 0.800000
Step: 210, avg loss: 0.456607, loss: 0.626489, accuracy: 0.700000
Step: 220, avg loss: 0.460869, loss: 0.550372, accuracy: 0.600000
Step: 230, avg loss: 0.454557, loss: 0.315681, accuracy: 0.900000
Step: 240, avg loss: 0.446033, loss: 0.249976, accuracy: 0.800000
Step: 250, avg loss: 0.448180, loss: 0.499728, accuracy: 0.800000
Step: 260, avg loss: 0.446394, loss: 0.401741, accuracy: 0.900000
Step: 270, avg loss: 0.454998, loss: 0.678690, accuracy: 0.600000
Step: 280, avg loss: 0.443711, loss: 0.138965, accuracy: 1.000000
Step: 290, avg loss: 0.436125, loss: 0.223724, accuracy: 1.000000
Step: 300, avg loss: 0.427649, loss: 0.181849, accuracy: 0.900000
Step: 310, avg loss: 0.415454, loss: 0.049589, accuracy: 1.000000
Step: 320, avg loss: 0.405809, loss: 0.106810, accuracy: 1.000000
Step: 330, avg loss: 0.400675, loss: 0.236384, accuracy: 0.900000
Step: 340, avg loss: 0.412302, loss: 0.796017, accuracy: 0.800000
Step: 350, avg loss: 0.410112, loss: 0.335638, accuracy: 0.800000
Step: 360, avg loss: 0.409513, loss: 0.388537, accuracy: 0.900000
Step: 370, avg loss: 0.421013, loss: 0.835027, accuracy: 0.700000
Step: 380, avg loss: 0.430537, loss: 0.782911, accuracy: 0.700000
Step: 390, avg loss: 0.426847, loss: 0.286635, accuracy: 0.900000
Step: 400, avg loss: 0.421493, loss: 0.212681, accuracy: 0.900000
Step: 410, avg loss: 0.418702, loss: 0.307093, accuracy: 0.800000
Step: 420, avg loss: 0.415524, loss: 0.285217, accuracy: 0.900000
Step: 430, avg loss: 0.410685, loss: 0.207421, accuracy: 0.900000
Step: 440, avg loss: 0.418689, loss: 0.762859, accuracy: 0.700000
Step: 450, avg loss: 0.423899, loss: 0.653147, accuracy: 0.700000
Step: 460, avg loss: 0.421430, loss: 0.310335, accuracy: 0.800000
Step: 470, avg loss: 0.425027, loss: 0.590504, accuracy: 0.800000
Step: 480, avg loss: 0.428982, loss: 0.614865, accuracy: 0.800000
Step: 490, avg loss: 0.433781, loss: 0.664110, accuracy: 0.700000
Step: 500, avg loss: 0.431511, loss: 0.320268, accuracy: 0.900000
Step: 510, avg loss: 0.432734, loss: 0.493917, accuracy: 0.900000
Step: 520, avg loss: 0.426575, loss: 0.112438, accuracy: 1.000000
Step: 530, avg loss: 0.421925, loss: 0.180142, accuracy: 1.000000
Step: 540, avg loss: 0.415362, loss: 0.067547, accuracy: 1.000000
Step: 550, avg loss: 0.421338, loss: 0.744007, accuracy: 0.800000
Step: 560, avg loss: 0.419708, loss: 0.330068, accuracy: 0.900000
Step: 570, avg loss: 0.416611, loss: 0.243166, accuracy: 0.900000
Step: 580, avg loss: 0.411580, loss: 0.124833, accuracy: 1.000000
Step: 590, avg loss: 0.418427, loss: 0.815520, accuracy: 0.600000
Step: 600, avg loss: 0.413653, loss: 0.132032, accuracy: 1.000000
Step: 610, avg loss: 0.413933, loss: 0.430697, accuracy: 0.900000
Step: 620, avg loss: 0.408435, loss: 0.073099, accuracy: 1.000000
Step: 630, avg loss: 0.406635, loss: 0.295037, accuracy: 0.900000
Step: 640, avg loss: 0.405886, loss: 0.358653, accuracy: 0.900000
Step: 650, avg loss: 0.406658, loss: 0.456114, accuracy: 0.800000
Step: 660, avg loss: 0.405300, loss: 0.316987, accuracy: 0.900000
Step: 670, avg loss: 0.407186, loss: 0.531695, accuracy: 0.800000
Step: 680, avg loss: 0.407399, loss: 0.421646, accuracy: 0.900000
Step: 690, avg loss: 0.409104, loss: 0.525035, accuracy: 0.800000
Step: 700, avg loss: 0.410834, loss: 0.530224, accuracy: 0.800000
Step: 710, avg loss: 0.417963, loss: 0.917000, accuracy: 0.600000
Step: 720, avg loss: 0.417482, loss: 0.383284, accuracy: 0.900000
Step: 730, avg loss: 0.413394, loss: 0.119118, accuracy: 1.000000
Step: 740, avg loss: 0.414922, loss: 0.526472, accuracy: 0.900000
Step: 750, avg loss: 0.412757, loss: 0.252523, accuracy: 0.900000
Step: 760, avg loss: 0.408482, loss: 0.087865, accuracy: 1.000000
Step: 770, avg loss: 0.408775, loss: 0.431006, accuracy: 0.900000
Step: 780, avg loss: 0.409439, loss: 0.460602, accuracy: 0.900000
Step: 790, avg loss: 0.406424, loss: 0.171205, accuracy: 1.000000
Step: 800, avg loss: 0.402494, loss: 0.092095, accuracy: 1.000000
Step: 810, avg loss: 0.400591, loss: 0.248346, accuracy: 0.900000
Step: 820, avg loss: 0.407787, loss: 0.990597, accuracy: 0.600000
Step: 830, avg loss: 0.406789, loss: 0.324963, accuracy: 0.800000
Step: 840, avg loss: 0.409949, loss: 0.672210, accuracy: 0.600000
Step: 850, avg loss: 0.407585, loss: 0.209026, accuracy: 0.900000
Step: 860, avg loss: 0.412612, loss: 0.839935, accuracy: 0.700000
Step: 870, avg loss: 0.412750, loss: 0.424605, accuracy: 0.800000
Step: 880, avg loss: 0.411632, loss: 0.314404, accuracy: 0.900000
Step: 890, avg loss: 0.414675, loss: 0.682398, accuracy: 0.700000
Step: 900, avg loss: 0.413036, loss: 0.267178, accuracy: 0.900000
Step: 910, avg loss: 0.415475, loss: 0.635038, accuracy: 0.700000
Step: 920, avg loss: 0.414868, loss: 0.359552, accuracy: 0.800000
Step: 930, avg loss: 0.414345, loss: 0.366277, accuracy: 0.700000
Step: 940, avg loss: 0.412555, loss: 0.246053, accuracy: 0.900000
Step: 950, avg loss: 0.411572, loss: 0.319162, accuracy: 0.800000
Step: 960, avg loss: 0.413117, loss: 0.559938, accuracy: 0.800000
Step: 970, avg loss: 0.412355, loss: 0.339159, accuracy: 0.800000
Step: 980, avg loss: 0.410400, loss: 0.220813, accuracy: 0.900000
Step: 990, avg loss: 0.410644, loss: 0.434564, accuracy: 0.900000
Step: 1000, avg loss: 0.407374, loss: 0.083658, accuracy: 1.000000
Step: 1010, avg loss: 0.406390, loss: 0.307978, accuracy: 0.800000
Step: 1020, avg loss: 0.403427, loss: 0.104136, accuracy: 1.000000
Step: 1030, avg loss: 0.401290, loss: 0.183287, accuracy: 0.900000
Step: 1040, avg loss: 0.397777, loss: 0.035955, accuracy: 1.000000
Step: 1050, avg loss: 0.395808, loss: 0.191011, accuracy: 0.900000
Step: 1060, avg loss: 0.393808, loss: 0.183866, accuracy: 0.900000
Step: 1070, avg loss: 0.390899, loss: 0.082545, accuracy: 0.900000
Step: 1080, avg loss: 0.388754, loss: 0.159212, accuracy: 1.000000
Step: 1090, avg loss: 0.388365, loss: 0.346310, accuracy: 0.800000
Step: 1100, avg loss: 0.386210, loss: 0.151410, accuracy: 1.000000
Step: 1110, avg loss: 0.383267, loss: 0.059462, accuracy: 1.000000
Step: 1120, avg loss: 0.386493, loss: 0.744645, accuracy: 0.900000
Step: 1130, avg loss: 0.387941, loss: 0.550122, accuracy: 0.800000
Step: 1140, avg loss: 0.397023, loss: 1.423208, accuracy: 0.400000
Step: 1150, avg loss: 0.399735, loss: 0.708911, accuracy: 0.600000
Step: 1160, avg loss: 0.400476, loss: 0.485758, accuracy: 0.800000
Step: 1170, avg loss: 0.400996, loss: 0.461334, accuracy: 0.800000
Step: 1180, avg loss: 0.402611, loss: 0.591470, accuracy: 0.800000
Step: 1190, avg loss: 0.402258, loss: 0.360637, accuracy: 0.700000
Step: 1200, avg loss: 0.403623, loss: 0.566042, accuracy: 0.800000
Step: 1210, avg loss: 0.403032, loss: 0.332118, accuracy: 0.900000
Step: 1220, avg loss: 0.400338, loss: 0.074416, accuracy: 1.000000
Step: 1230, avg loss: 0.398432, loss: 0.165888, accuracy: 1.000000
Step: 1240, avg loss: 0.398615, loss: 0.421151, accuracy: 0.800000
Step: 1250, avg loss: 0.398968, loss: 0.442640, accuracy: 0.800000
Step: 1260, avg loss: 0.397491, loss: 0.212964, accuracy: 0.900000
Epoch 5 finished in loss: 0.396938 and accuracy: 0.845483
Step: 10, avg loss: 0.820345, loss: 0.820345, accuracy: 0.700000
Step: 20, avg loss: 0.542750, loss: 0.265156, accuracy: 0.900000
Step: 30, avg loss: 0.476922, loss: 0.345264, accuracy: 0.800000
Step: 40, avg loss: 0.460501, loss: 0.411238, accuracy: 0.700000
Step: 50, avg loss: 0.422034, loss: 0.268164, accuracy: 0.900000
Step: 60, avg loss: 0.403232, loss: 0.309225, accuracy: 0.900000
Step: 70, avg loss: 0.361985, loss: 0.114500, accuracy: 1.000000
Step: 80, avg loss: 0.327470, loss: 0.085871, accuracy: 1.000000
Step: 90, avg loss: 0.366240, loss: 0.676397, accuracy: 0.900000
Step: 100, avg loss: 0.369489, loss: 0.398732, accuracy: 0.900000
Step: 110, avg loss: 0.371543, loss: 0.392082, accuracy: 0.900000
Step: 120, avg loss: 0.411729, loss: 0.853775, accuracy: 0.700000
Step: 130, avg loss: 0.389495, loss: 0.122683, accuracy: 1.000000
Step: 140, avg loss: 0.365261, loss: 0.050224, accuracy: 1.000000
Step: 150, avg loss: 0.387612, loss: 0.700522, accuracy: 0.600000
Step: 160, avg loss: 0.367778, loss: 0.070267, accuracy: 1.000000
Step: 170, avg loss: 0.400011, loss: 0.915742, accuracy: 0.700000
Step: 180, avg loss: 0.410077, loss: 0.581201, accuracy: 0.800000
Step: 190, avg loss: 0.409299, loss: 0.395288, accuracy: 0.900000
Step: 200, avg loss: 0.414349, loss: 0.510305, accuracy: 0.700000
Step: 210, avg loss: 0.421812, loss: 0.571072, accuracy: 0.700000
Step: 220, avg loss: 0.429245, loss: 0.585336, accuracy: 0.600000
Step: 230, avg loss: 0.423187, loss: 0.289903, accuracy: 0.900000
Step: 240, avg loss: 0.417360, loss: 0.283339, accuracy: 0.800000
Step: 250, avg loss: 0.413890, loss: 0.330626, accuracy: 0.900000
Step: 260, avg loss: 0.408742, loss: 0.280023, accuracy: 0.900000
Step: 270, avg loss: 0.418898, loss: 0.682963, accuracy: 0.600000
Step: 280, avg loss: 0.408909, loss: 0.139209, accuracy: 1.000000
Step: 290, avg loss: 0.398833, loss: 0.116706, accuracy: 1.000000
Step: 300, avg loss: 0.394029, loss: 0.254711, accuracy: 0.900000
Step: 310, avg loss: 0.383077, loss: 0.054510, accuracy: 1.000000
Step: 320, avg loss: 0.373274, loss: 0.069378, accuracy: 1.000000
Step: 330, avg loss: 0.373911, loss: 0.394288, accuracy: 0.800000
Step: 340, avg loss: 0.377084, loss: 0.481814, accuracy: 0.900000
Step: 350, avg loss: 0.374866, loss: 0.299442, accuracy: 0.800000
Step: 360, avg loss: 0.370501, loss: 0.217740, accuracy: 0.800000
Step: 370, avg loss: 0.387108, loss: 0.984956, accuracy: 0.800000
Step: 380, avg loss: 0.399290, loss: 0.850018, accuracy: 0.800000
Step: 390, avg loss: 0.395527, loss: 0.252518, accuracy: 0.900000
Step: 400, avg loss: 0.389250, loss: 0.144477, accuracy: 1.000000
Step: 410, avg loss: 0.384763, loss: 0.205284, accuracy: 1.000000
Step: 420, avg loss: 0.381200, loss: 0.235120, accuracy: 0.900000
Step: 430, avg loss: 0.375096, loss: 0.118721, accuracy: 1.000000
Step: 440, avg loss: 0.383804, loss: 0.758254, accuracy: 0.700000
Step: 450, avg loss: 0.389059, loss: 0.620267, accuracy: 0.700000
Step: 460, avg loss: 0.386908, loss: 0.290114, accuracy: 0.900000
Step: 470, avg loss: 0.391171, loss: 0.587270, accuracy: 0.800000
Step: 480, avg loss: 0.394521, loss: 0.551976, accuracy: 0.900000
Step: 490, avg loss: 0.400355, loss: 0.680355, accuracy: 0.700000
Step: 500, avg loss: 0.397005, loss: 0.232893, accuracy: 0.900000
Step: 510, avg loss: 0.399933, loss: 0.546313, accuracy: 0.800000
Step: 520, avg loss: 0.394460, loss: 0.115354, accuracy: 1.000000
Step: 530, avg loss: 0.390328, loss: 0.175439, accuracy: 1.000000
Step: 540, avg loss: 0.383862, loss: 0.041158, accuracy: 1.000000
Step: 550, avg loss: 0.390794, loss: 0.765127, accuracy: 0.800000
Step: 560, avg loss: 0.389335, loss: 0.309100, accuracy: 0.900000
Step: 570, avg loss: 0.387431, loss: 0.280817, accuracy: 0.900000
Step: 580, avg loss: 0.382541, loss: 0.103799, accuracy: 1.000000
Step: 590, avg loss: 0.389130, loss: 0.771309, accuracy: 0.600000
Step: 600, avg loss: 0.384345, loss: 0.102008, accuracy: 1.000000
Step: 610, avg loss: 0.384825, loss: 0.413651, accuracy: 0.900000
Step: 620, avg loss: 0.379782, loss: 0.072137, accuracy: 1.000000
Step: 630, avg loss: 0.377518, loss: 0.237141, accuracy: 0.900000
Step: 640, avg loss: 0.373928, loss: 0.147771, accuracy: 1.000000
Step: 650, avg loss: 0.373850, loss: 0.368843, accuracy: 0.800000
Step: 660, avg loss: 0.371838, loss: 0.241090, accuracy: 0.900000
Step: 670, avg loss: 0.374615, loss: 0.557890, accuracy: 0.800000
Step: 680, avg loss: 0.374775, loss: 0.385472, accuracy: 0.900000
Step: 690, avg loss: 0.377717, loss: 0.577768, accuracy: 0.800000
Step: 700, avg loss: 0.379066, loss: 0.472147, accuracy: 0.800000
Step: 710, avg loss: 0.387992, loss: 1.012862, accuracy: 0.500000
Step: 720, avg loss: 0.387361, loss: 0.342544, accuracy: 0.900000
Step: 730, avg loss: 0.383668, loss: 0.117789, accuracy: 1.000000
Step: 740, avg loss: 0.386542, loss: 0.596287, accuracy: 0.800000
Step: 750, avg loss: 0.384568, loss: 0.238484, accuracy: 0.900000
Step: 760, avg loss: 0.380425, loss: 0.069713, accuracy: 1.000000
Step: 770, avg loss: 0.380795, loss: 0.408959, accuracy: 0.900000
Step: 780, avg loss: 0.381537, loss: 0.438639, accuracy: 0.900000
Step: 790, avg loss: 0.378784, loss: 0.164040, accuracy: 1.000000
Step: 800, avg loss: 0.374828, loss: 0.062298, accuracy: 1.000000
Step: 810, avg loss: 0.371365, loss: 0.094374, accuracy: 1.000000
Step: 820, avg loss: 0.377803, loss: 0.899268, accuracy: 0.700000
Step: 830, avg loss: 0.374639, loss: 0.115214, accuracy: 1.000000
Step: 840, avg loss: 0.378801, loss: 0.724238, accuracy: 0.600000
Step: 850, avg loss: 0.375242, loss: 0.076246, accuracy: 1.000000
Step: 860, avg loss: 0.381448, loss: 0.908996, accuracy: 0.700000
Step: 870, avg loss: 0.381434, loss: 0.380201, accuracy: 0.800000
Step: 880, avg loss: 0.379448, loss: 0.206639, accuracy: 0.900000
Step: 890, avg loss: 0.380495, loss: 0.472684, accuracy: 0.800000
Step: 900, avg loss: 0.379310, loss: 0.273801, accuracy: 0.900000
Step: 910, avg loss: 0.381652, loss: 0.592431, accuracy: 0.800000
Step: 920, avg loss: 0.381171, loss: 0.337437, accuracy: 0.800000
Step: 930, avg loss: 0.381410, loss: 0.403340, accuracy: 0.700000
Step: 940, avg loss: 0.379892, loss: 0.238794, accuracy: 1.000000
Step: 950, avg loss: 0.378778, loss: 0.274077, accuracy: 0.800000
Step: 960, avg loss: 0.380677, loss: 0.561033, accuracy: 0.800000
Step: 970, avg loss: 0.378596, loss: 0.178793, accuracy: 1.000000
Step: 980, avg loss: 0.375919, loss: 0.116304, accuracy: 1.000000
Step: 990, avg loss: 0.378072, loss: 0.588996, accuracy: 0.900000
Step: 1000, avg loss: 0.374911, loss: 0.061972, accuracy: 1.000000
Step: 1010, avg loss: 0.373562, loss: 0.238738, accuracy: 0.900000
Step: 1020, avg loss: 0.371136, loss: 0.126065, accuracy: 0.900000
Step: 1030, avg loss: 0.369132, loss: 0.164730, accuracy: 0.900000
Step: 1040, avg loss: 0.365700, loss: 0.012223, accuracy: 1.000000
Step: 1050, avg loss: 0.364061, loss: 0.193608, accuracy: 0.900000
Step: 1060, avg loss: 0.363007, loss: 0.252346, accuracy: 0.900000
Step: 1070, avg loss: 0.360309, loss: 0.074256, accuracy: 1.000000
Step: 1080, avg loss: 0.358824, loss: 0.199940, accuracy: 1.000000
Step: 1090, avg loss: 0.357932, loss: 0.261637, accuracy: 0.800000
Step: 1100, avg loss: 0.355901, loss: 0.134525, accuracy: 1.000000
Step: 1110, avg loss: 0.353123, loss: 0.047556, accuracy: 1.000000
Step: 1120, avg loss: 0.356595, loss: 0.741985, accuracy: 0.900000
Step: 1130, avg loss: 0.357861, loss: 0.499602, accuracy: 0.800000
Step: 1140, avg loss: 0.367490, loss: 1.455573, accuracy: 0.400000
Step: 1150, avg loss: 0.370216, loss: 0.681034, accuracy: 0.600000
Step: 1160, avg loss: 0.370798, loss: 0.437668, accuracy: 0.900000
Step: 1170, avg loss: 0.371439, loss: 0.445790, accuracy: 0.900000
Step: 1180, avg loss: 0.372938, loss: 0.548337, accuracy: 0.900000
Step: 1190, avg loss: 0.371859, loss: 0.244560, accuracy: 0.900000
Step: 1200, avg loss: 0.374094, loss: 0.639995, accuracy: 0.800000
Step: 1210, avg loss: 0.373052, loss: 0.248072, accuracy: 0.900000
Step: 1220, avg loss: 0.370557, loss: 0.068717, accuracy: 1.000000
Step: 1230, avg loss: 0.368496, loss: 0.116951, accuracy: 1.000000
Step: 1240, avg loss: 0.368410, loss: 0.357929, accuracy: 0.900000
Step: 1250, avg loss: 0.368021, loss: 0.319777, accuracy: 0.900000
Step: 1260, avg loss: 0.367022, loss: 0.242045, accuracy: 0.900000
Epoch 6 finished in loss: 0.366539 and accuracy: 0.869255
Step: 10, avg loss: 0.782234, loss: 0.782234, accuracy: 0.700000
Step: 20, avg loss: 0.496181, loss: 0.210129, accuracy: 0.900000
Step: 30, avg loss: 0.448792, loss: 0.354013, accuracy: 0.800000
Step: 40, avg loss: 0.433847, loss: 0.389013, accuracy: 0.800000
Step: 50, avg loss: 0.446427, loss: 0.496747, accuracy: 0.900000
Step: 60, avg loss: 0.432077, loss: 0.360327, accuracy: 0.900000
Step: 70, avg loss: 0.383140, loss: 0.089518, accuracy: 1.000000
Step: 80, avg loss: 0.346461, loss: 0.089705, accuracy: 1.000000
Step: 90, avg loss: 0.378051, loss: 0.630776, accuracy: 0.900000
Step: 100, avg loss: 0.369641, loss: 0.293947, accuracy: 0.900000
Step: 110, avg loss: 0.365275, loss: 0.321612, accuracy: 0.900000
Step: 120, avg loss: 0.394007, loss: 0.710064, accuracy: 0.700000
Step: 130, avg loss: 0.373022, loss: 0.121200, accuracy: 1.000000
Step: 140, avg loss: 0.349580, loss: 0.044836, accuracy: 1.000000
Step: 150, avg loss: 0.355243, loss: 0.434528, accuracy: 0.700000
Step: 160, avg loss: 0.337569, loss: 0.072458, accuracy: 1.000000
Step: 170, avg loss: 0.374709, loss: 0.968950, accuracy: 0.700000
Step: 180, avg loss: 0.392576, loss: 0.696305, accuracy: 0.700000
Step: 190, avg loss: 0.390003, loss: 0.343698, accuracy: 0.900000
Step: 200, avg loss: 0.394668, loss: 0.483305, accuracy: 0.800000
Step: 210, avg loss: 0.401779, loss: 0.543988, accuracy: 0.800000
Step: 220, avg loss: 0.408257, loss: 0.544309, accuracy: 0.700000
Step: 230, avg loss: 0.403253, loss: 0.293153, accuracy: 1.000000
Step: 240, avg loss: 0.395065, loss: 0.206750, accuracy: 0.900000
Step: 250, avg loss: 0.388973, loss: 0.242760, accuracy: 0.900000
Step: 260, avg loss: 0.383217, loss: 0.239314, accuracy: 0.900000
Step: 270, avg loss: 0.392143, loss: 0.624234, accuracy: 0.700000
Step: 280, avg loss: 0.381631, loss: 0.097784, accuracy: 1.000000
Step: 290, avg loss: 0.372067, loss: 0.104302, accuracy: 1.000000
Step: 300, avg loss: 0.365570, loss: 0.177134, accuracy: 0.900000
Step: 310, avg loss: 0.355328, loss: 0.048088, accuracy: 1.000000
Step: 320, avg loss: 0.345250, loss: 0.032835, accuracy: 1.000000
Step: 330, avg loss: 0.342813, loss: 0.264831, accuracy: 0.900000
Step: 340, avg loss: 0.353340, loss: 0.700701, accuracy: 0.800000
Step: 350, avg loss: 0.351117, loss: 0.275558, accuracy: 0.800000
Step: 360, avg loss: 0.352090, loss: 0.386135, accuracy: 0.800000
Step: 370, avg loss: 0.363191, loss: 0.762846, accuracy: 0.700000
Step: 380, avg loss: 0.375253, loss: 0.821530, accuracy: 0.800000
Step: 390, avg loss: 0.372193, loss: 0.255899, accuracy: 0.900000
Step: 400, avg loss: 0.369227, loss: 0.253564, accuracy: 0.900000
Step: 410, avg loss: 0.364488, loss: 0.174928, accuracy: 1.000000
Step: 420, avg loss: 0.361997, loss: 0.259863, accuracy: 0.800000
Step: 430, avg loss: 0.354961, loss: 0.059439, accuracy: 1.000000
Step: 440, avg loss: 0.362589, loss: 0.690626, accuracy: 0.700000
Step: 450, avg loss: 0.365938, loss: 0.513285, accuracy: 0.800000
Step: 460, avg loss: 0.362923, loss: 0.227248, accuracy: 0.900000
Step: 470, avg loss: 0.367769, loss: 0.590657, accuracy: 0.900000
Step: 480, avg loss: 0.372100, loss: 0.575656, accuracy: 0.900000
Step: 490, avg loss: 0.381282, loss: 0.822046, accuracy: 0.700000
Step: 500, avg loss: 0.378377, loss: 0.236050, accuracy: 1.000000
Step: 510, avg loss: 0.381361, loss: 0.530523, accuracy: 0.900000
Step: 520, avg loss: 0.376217, loss: 0.113897, accuracy: 1.000000
Step: 530, avg loss: 0.371181, loss: 0.109274, accuracy: 1.000000
Step: 540, avg loss: 0.365119, loss: 0.043834, accuracy: 1.000000
Step: 550, avg loss: 0.372388, loss: 0.764913, accuracy: 0.800000
Step: 560, avg loss: 0.371152, loss: 0.303217, accuracy: 0.900000
Step: 570, avg loss: 0.369823, loss: 0.295361, accuracy: 0.900000
Step: 580, avg loss: 0.365118, loss: 0.096955, accuracy: 1.000000
Step: 590, avg loss: 0.370038, loss: 0.655411, accuracy: 0.600000
Step: 600, avg loss: 0.365371, loss: 0.090025, accuracy: 1.000000
Step: 610, avg loss: 0.366389, loss: 0.427429, accuracy: 0.900000
Step: 620, avg loss: 0.361570, loss: 0.067618, accuracy: 1.000000
Step: 630, avg loss: 0.358269, loss: 0.153605, accuracy: 0.900000
Step: 640, avg loss: 0.355676, loss: 0.192325, accuracy: 0.900000
Step: 650, avg loss: 0.354038, loss: 0.249221, accuracy: 0.900000
Step: 660, avg loss: 0.351205, loss: 0.167037, accuracy: 0.900000
Step: 670, avg loss: 0.354561, loss: 0.576095, accuracy: 0.800000
Step: 680, avg loss: 0.354738, loss: 0.366572, accuracy: 0.900000
Step: 690, avg loss: 0.356392, loss: 0.468842, accuracy: 0.800000
Step: 700, avg loss: 0.357944, loss: 0.465041, accuracy: 0.800000
Step: 710, avg loss: 0.361548, loss: 0.613832, accuracy: 0.800000
Step: 720, avg loss: 0.361890, loss: 0.386203, accuracy: 0.900000
Step: 730, avg loss: 0.358526, loss: 0.116264, accuracy: 1.000000
Step: 740, avg loss: 0.361057, loss: 0.545852, accuracy: 0.800000
Step: 750, avg loss: 0.358838, loss: 0.194596, accuracy: 1.000000
Step: 760, avg loss: 0.355017, loss: 0.068463, accuracy: 1.000000
Step: 770, avg loss: 0.355635, loss: 0.402597, accuracy: 0.900000
Step: 780, avg loss: 0.357267, loss: 0.482975, accuracy: 0.800000
Step: 790, avg loss: 0.353734, loss: 0.078099, accuracy: 1.000000
Step: 800, avg loss: 0.350505, loss: 0.095446, accuracy: 1.000000
Step: 810, avg loss: 0.347706, loss: 0.123795, accuracy: 1.000000
Step: 820, avg loss: 0.353062, loss: 0.786896, accuracy: 0.700000
Step: 830, avg loss: 0.350287, loss: 0.122735, accuracy: 1.000000
Step: 840, avg loss: 0.353042, loss: 0.581665, accuracy: 0.700000
Step: 850, avg loss: 0.349311, loss: 0.035908, accuracy: 1.000000
Step: 860, avg loss: 0.355354, loss: 0.869063, accuracy: 0.700000
Step: 870, avg loss: 0.355189, loss: 0.341022, accuracy: 0.800000
Step: 880, avg loss: 0.353118, loss: 0.172932, accuracy: 1.000000
Step: 890, avg loss: 0.354953, loss: 0.516386, accuracy: 0.800000
Step: 900, avg loss: 0.353965, loss: 0.266087, accuracy: 0.800000
Step: 910, avg loss: 0.356397, loss: 0.575200, accuracy: 0.800000
Step: 920, avg loss: 0.355808, loss: 0.302220, accuracy: 0.800000
Step: 930, avg loss: 0.356106, loss: 0.383514, accuracy: 0.800000
Step: 940, avg loss: 0.355309, loss: 0.281249, accuracy: 0.900000
Step: 950, avg loss: 0.354242, loss: 0.253946, accuracy: 0.900000
Step: 960, avg loss: 0.355295, loss: 0.455293, accuracy: 0.800000
Step: 970, avg loss: 0.353194, loss: 0.151460, accuracy: 1.000000
Step: 980, avg loss: 0.351486, loss: 0.185874, accuracy: 0.900000
Step: 990, avg loss: 0.358121, loss: 1.008364, accuracy: 0.900000
Step: 1000, avg loss: 0.356433, loss: 0.189253, accuracy: 0.900000
Step: 1010, avg loss: 0.353927, loss: 0.103416, accuracy: 1.000000
Step: 1020, avg loss: 0.352355, loss: 0.193569, accuracy: 0.900000
Step: 1030, avg loss: 0.351471, loss: 0.261268, accuracy: 0.800000
Step: 1040, avg loss: 0.348349, loss: 0.026773, accuracy: 1.000000
Step: 1050, avg loss: 0.347572, loss: 0.266795, accuracy: 0.800000
Step: 1060, avg loss: 0.345692, loss: 0.148241, accuracy: 1.000000
Step: 1070, avg loss: 0.342999, loss: 0.057559, accuracy: 1.000000
Step: 1080, avg loss: 0.342542, loss: 0.293602, accuracy: 0.900000
Step: 1090, avg loss: 0.341927, loss: 0.275522, accuracy: 0.800000
Step: 1100, avg loss: 0.340075, loss: 0.138221, accuracy: 0.900000
Step: 1110, avg loss: 0.337412, loss: 0.044536, accuracy: 1.000000
Step: 1120, avg loss: 0.340196, loss: 0.649181, accuracy: 0.900000
Step: 1130, avg loss: 0.340925, loss: 0.422538, accuracy: 0.800000
Step: 1140, avg loss: 0.350289, loss: 1.408440, accuracy: 0.400000
Step: 1150, avg loss: 0.352826, loss: 0.642074, accuracy: 0.600000
Step: 1160, avg loss: 0.353473, loss: 0.427824, accuracy: 0.900000
Step: 1170, avg loss: 0.353966, loss: 0.411241, accuracy: 0.800000
Step: 1180, avg loss: 0.356037, loss: 0.598338, accuracy: 0.800000
Step: 1190, avg loss: 0.354889, loss: 0.219424, accuracy: 1.000000
Step: 1200, avg loss: 0.356865, loss: 0.591979, accuracy: 0.800000
Step: 1210, avg loss: 0.355923, loss: 0.242893, accuracy: 0.900000
Step: 1220, avg loss: 0.353572, loss: 0.069121, accuracy: 1.000000
Step: 1230, avg loss: 0.351561, loss: 0.106235, accuracy: 1.000000
Step: 1240, avg loss: 0.351512, loss: 0.345481, accuracy: 0.900000
Step: 1250, avg loss: 0.351031, loss: 0.291300, accuracy: 0.900000
Step: 1260, avg loss: 0.349531, loss: 0.162093, accuracy: 0.900000
Epoch 7 finished in loss: 0.349049 and accuracy: 0.875594
Step: 10, avg loss: 0.678312, loss: 0.678312, accuracy: 0.800000
Step: 20, avg loss: 0.451857, loss: 0.225403, accuracy: 0.900000
Step: 30, avg loss: 0.418842, loss: 0.352811, accuracy: 0.800000
Step: 40, avg loss: 0.409780, loss: 0.382594, accuracy: 0.800000
Step: 50, avg loss: 0.388500, loss: 0.303381, accuracy: 0.900000
Step: 60, avg loss: 0.358699, loss: 0.209696, accuracy: 0.800000
Step: 70, avg loss: 0.318975, loss: 0.080626, accuracy: 1.000000
Step: 80, avg loss: 0.287097, loss: 0.063954, accuracy: 1.000000
Step: 90, avg loss: 0.326802, loss: 0.644438, accuracy: 0.900000
Step: 100, avg loss: 0.304467, loss: 0.103454, accuracy: 1.000000
Step: 110, avg loss: 0.307121, loss: 0.333659, accuracy: 0.900000
Step: 120, avg loss: 0.334739, loss: 0.638544, accuracy: 0.800000
Step: 130, avg loss: 0.315835, loss: 0.088987, accuracy: 1.000000
Step: 140, avg loss: 0.295641, loss: 0.033109, accuracy: 1.000000
Step: 150, avg loss: 0.298465, loss: 0.338002, accuracy: 0.900000
Step: 160, avg loss: 0.283694, loss: 0.062136, accuracy: 1.000000
Step: 170, avg loss: 0.316626, loss: 0.843539, accuracy: 0.800000
Step: 180, avg loss: 0.336979, loss: 0.682973, accuracy: 0.800000
Step: 190, avg loss: 0.333405, loss: 0.269084, accuracy: 0.900000
Step: 200, avg loss: 0.343320, loss: 0.531693, accuracy: 0.800000
Step: 210, avg loss: 0.350815, loss: 0.500713, accuracy: 0.800000
Step: 220, avg loss: 0.358527, loss: 0.520496, accuracy: 0.800000
Step: 230, avg loss: 0.350793, loss: 0.180628, accuracy: 1.000000
Step: 240, avg loss: 0.341688, loss: 0.132291, accuracy: 1.000000
Step: 250, avg loss: 0.339244, loss: 0.280568, accuracy: 0.800000
Step: 260, avg loss: 0.329528, loss: 0.086650, accuracy: 1.000000
Step: 270, avg loss: 0.334314, loss: 0.458743, accuracy: 0.700000
Step: 280, avg loss: 0.325556, loss: 0.089096, accuracy: 1.000000
Step: 290, avg loss: 0.318169, loss: 0.111336, accuracy: 1.000000
Step: 300, avg loss: 0.311064, loss: 0.104998, accuracy: 0.900000
Step: 310, avg loss: 0.302638, loss: 0.049867, accuracy: 1.000000
Step: 320, avg loss: 0.294197, loss: 0.032508, accuracy: 1.000000
Step: 330, avg loss: 0.293280, loss: 0.263962, accuracy: 0.900000
Step: 340, avg loss: 0.287149, loss: 0.084828, accuracy: 1.000000
Step: 350, avg loss: 0.285117, loss: 0.216026, accuracy: 0.900000
Step: 360, avg loss: 0.296658, loss: 0.700569, accuracy: 0.800000
Step: 370, avg loss: 0.305482, loss: 0.623153, accuracy: 0.800000
Step: 380, avg loss: 0.324174, loss: 1.015790, accuracy: 0.800000
Step: 390, avg loss: 0.321672, loss: 0.226586, accuracy: 0.900000
Step: 400, avg loss: 0.320157, loss: 0.261077, accuracy: 0.900000
Step: 410, avg loss: 0.316354, loss: 0.164246, accuracy: 1.000000
Step: 420, avg loss: 0.314818, loss: 0.251837, accuracy: 0.800000
Step: 430, avg loss: 0.308825, loss: 0.057102, accuracy: 1.000000
Step: 440, avg loss: 0.317359, loss: 0.684321, accuracy: 0.800000
Step: 450, avg loss: 0.322283, loss: 0.538951, accuracy: 0.700000
Step: 460, avg loss: 0.320976, loss: 0.262160, accuracy: 0.900000
Step: 470, avg loss: 0.325722, loss: 0.544057, accuracy: 0.900000
Step: 480, avg loss: 0.329685, loss: 0.515920, accuracy: 0.900000
Step: 490, avg loss: 0.331664, loss: 0.426675, accuracy: 0.900000
Step: 500, avg loss: 0.329204, loss: 0.208640, accuracy: 0.900000
Step: 510, avg loss: 0.331802, loss: 0.461693, accuracy: 0.800000
Step: 520, avg loss: 0.327393, loss: 0.102566, accuracy: 1.000000
Step: 530, avg loss: 0.324507, loss: 0.174430, accuracy: 0.900000
Step: 540, avg loss: 0.319105, loss: 0.032800, accuracy: 1.000000
Step: 550, avg loss: 0.327721, loss: 0.792962, accuracy: 0.800000
Step: 560, avg loss: 0.325746, loss: 0.217135, accuracy: 0.900000
Step: 570, avg loss: 0.325074, loss: 0.287465, accuracy: 0.900000
Step: 580, avg loss: 0.320665, loss: 0.069313, accuracy: 1.000000
Step: 590, avg loss: 0.324555, loss: 0.550165, accuracy: 0.700000
Step: 600, avg loss: 0.320297, loss: 0.069113, accuracy: 1.000000
Step: 610, avg loss: 0.320976, loss: 0.361691, accuracy: 0.900000
Step: 620, avg loss: 0.317037, loss: 0.076757, accuracy: 1.000000
Step: 630, avg loss: 0.313670, loss: 0.104919, accuracy: 1.000000
Step: 640, avg loss: 0.312310, loss: 0.226632, accuracy: 0.900000
Step: 650, avg loss: 0.310116, loss: 0.169715, accuracy: 0.900000
Step: 660, avg loss: 0.307027, loss: 0.106268, accuracy: 1.000000
Step: 670, avg loss: 0.312109, loss: 0.647483, accuracy: 0.800000
Step: 680, avg loss: 0.312776, loss: 0.357443, accuracy: 0.900000
Step: 690, avg loss: 0.314473, loss: 0.429921, accuracy: 0.800000
Step: 700, avg loss: 0.315386, loss: 0.378324, accuracy: 0.900000
Step: 710, avg loss: 0.318697, loss: 0.550505, accuracy: 0.800000
Step: 720, avg loss: 0.320302, loss: 0.434235, accuracy: 0.900000
Step: 730, avg loss: 0.317708, loss: 0.130977, accuracy: 1.000000
Step: 740, avg loss: 0.319411, loss: 0.443723, accuracy: 0.900000
Step: 750, avg loss: 0.316854, loss: 0.127645, accuracy: 1.000000
Step: 760, avg loss: 0.313318, loss: 0.048100, accuracy: 1.000000
Step: 770, avg loss: 0.313929, loss: 0.360341, accuracy: 0.900000
Step: 780, avg loss: 0.315107, loss: 0.405807, accuracy: 0.900000
Step: 790, avg loss: 0.312364, loss: 0.098410, accuracy: 0.900000
Step: 800, avg loss: 0.310530, loss: 0.165683, accuracy: 0.900000
Step: 810, avg loss: 0.308120, loss: 0.115294, accuracy: 1.000000
Step: 820, avg loss: 0.312847, loss: 0.695715, accuracy: 0.800000
Step: 830, avg loss: 0.310954, loss: 0.155773, accuracy: 0.900000
Step: 840, avg loss: 0.314060, loss: 0.571834, accuracy: 0.900000
Step: 850, avg loss: 0.310802, loss: 0.037182, accuracy: 1.000000
Step: 860, avg loss: 0.316655, loss: 0.814129, accuracy: 0.700000
Step: 870, avg loss: 0.317710, loss: 0.408426, accuracy: 0.800000
Step: 880, avg loss: 0.315715, loss: 0.142171, accuracy: 1.000000
Step: 890, avg loss: 0.317031, loss: 0.432802, accuracy: 0.800000
Step: 900, avg loss: 0.315720, loss: 0.199037, accuracy: 0.900000
Step: 910, avg loss: 0.319091, loss: 0.622498, accuracy: 0.800000
Step: 920, avg loss: 0.318313, loss: 0.247544, accuracy: 0.800000
Step: 930, avg loss: 0.320502, loss: 0.521914, accuracy: 0.700000
Step: 940, avg loss: 0.319630, loss: 0.238477, accuracy: 0.900000
Step: 950, avg loss: 0.318809, loss: 0.241625, accuracy: 0.900000
Step: 960, avg loss: 0.319197, loss: 0.356125, accuracy: 0.900000
Step: 970, avg loss: 0.317310, loss: 0.136078, accuracy: 1.000000
Step: 980, avg loss: 0.315341, loss: 0.124400, accuracy: 1.000000
Step: 990, avg loss: 0.313320, loss: 0.115234, accuracy: 1.000000
Step: 1000, avg loss: 0.311436, loss: 0.124909, accuracy: 0.900000
Step: 1010, avg loss: 0.309351, loss: 0.100843, accuracy: 1.000000
Step: 1020, avg loss: 0.308436, loss: 0.216062, accuracy: 0.900000
Step: 1030, avg loss: 0.305766, loss: 0.033407, accuracy: 1.000000
Step: 1040, avg loss: 0.303142, loss: 0.032831, accuracy: 1.000000
Step: 1050, avg loss: 0.301651, loss: 0.146640, accuracy: 1.000000
Step: 1060, avg loss: 0.299621, loss: 0.086461, accuracy: 1.000000
Step: 1070, avg loss: 0.296926, loss: 0.011310, accuracy: 1.000000
Step: 1080, avg loss: 0.296332, loss: 0.232755, accuracy: 1.000000
Step: 1090, avg loss: 0.294361, loss: 0.081461, accuracy: 1.000000
Step: 1100, avg loss: 0.292081, loss: 0.043527, accuracy: 1.000000
Step: 1110, avg loss: 0.289918, loss: 0.051978, accuracy: 1.000000
Step: 1120, avg loss: 0.294054, loss: 0.753242, accuracy: 0.900000
Step: 1130, avg loss: 0.295184, loss: 0.421680, accuracy: 0.900000
Step: 1140, avg loss: 0.314947, loss: 2.548197, accuracy: 0.400000
Step: 1150, avg loss: 0.317772, loss: 0.639781, accuracy: 0.700000
Step: 1160, avg loss: 0.318250, loss: 0.373273, accuracy: 0.900000
Step: 1170, avg loss: 0.318667, loss: 0.367073, accuracy: 0.900000
Step: 1180, avg loss: 0.320092, loss: 0.486713, accuracy: 0.900000
Step: 1190, avg loss: 0.319041, loss: 0.195059, accuracy: 1.000000
Step: 1200, avg loss: 0.321646, loss: 0.631593, accuracy: 0.800000
Step: 1210, avg loss: 0.320624, loss: 0.198047, accuracy: 0.900000
Step: 1220, avg loss: 0.318562, loss: 0.069007, accuracy: 1.000000
Step: 1230, avg loss: 0.316740, loss: 0.094460, accuracy: 1.000000
Step: 1240, avg loss: 0.317542, loss: 0.416191, accuracy: 0.800000
Step: 1250, avg loss: 0.316160, loss: 0.144837, accuracy: 0.900000
Step: 1260, avg loss: 0.314115, loss: 0.058483, accuracy: 1.000000
Epoch 8 finished in loss: 0.313718 and accuracy: 0.900951
Step: 10, avg loss: 0.918456, loss: 0.918456, accuracy: 0.600000
Step: 20, avg loss: 0.659131, loss: 0.399806, accuracy: 0.800000
Step: 30, avg loss: 0.531576, loss: 0.276464, accuracy: 0.800000
Step: 40, avg loss: 0.479783, loss: 0.324403, accuracy: 0.800000
Step: 50, avg loss: 0.420465, loss: 0.183194, accuracy: 0.900000
Step: 60, avg loss: 0.382550, loss: 0.192976, accuracy: 0.900000
Step: 70, avg loss: 0.333162, loss: 0.036835, accuracy: 1.000000
Step: 80, avg loss: 0.296930, loss: 0.043302, accuracy: 1.000000
Step: 90, avg loss: 0.334169, loss: 0.632087, accuracy: 0.900000
Step: 100, avg loss: 0.329620, loss: 0.288673, accuracy: 0.900000
Step: 110, avg loss: 0.322042, loss: 0.246268, accuracy: 0.900000
Step: 120, avg loss: 0.332735, loss: 0.450353, accuracy: 0.900000
Step: 130, avg loss: 0.313453, loss: 0.082064, accuracy: 1.000000
Step: 140, avg loss: 0.293247, loss: 0.030582, accuracy: 1.000000
Step: 150, avg loss: 0.300528, loss: 0.402462, accuracy: 0.800000
Step: 160, avg loss: 0.285216, loss: 0.055537, accuracy: 1.000000
Step: 170, avg loss: 0.301551, loss: 0.562900, accuracy: 0.800000
Step: 180, avg loss: 0.312710, loss: 0.502422, accuracy: 0.900000
Step: 190, avg loss: 0.307270, loss: 0.209347, accuracy: 0.900000
Step: 200, avg loss: 0.311784, loss: 0.397556, accuracy: 0.800000
Step: 210, avg loss: 0.319608, loss: 0.476074, accuracy: 0.900000
Step: 220, avg loss: 0.323903, loss: 0.414098, accuracy: 0.700000
Step: 230, avg loss: 0.317128, loss: 0.168082, accuracy: 0.900000
Step: 240, avg loss: 0.306834, loss: 0.070076, accuracy: 1.000000
Step: 250, avg loss: 0.302084, loss: 0.188077, accuracy: 0.900000
Step: 260, avg loss: 0.292150, loss: 0.043799, accuracy: 1.000000
Step: 270, avg loss: 0.294147, loss: 0.346075, accuracy: 0.700000
Step: 280, avg loss: 0.285573, loss: 0.054076, accuracy: 1.000000
Step: 290, avg loss: 0.279327, loss: 0.104450, accuracy: 1.000000
Step: 300, avg loss: 0.273768, loss: 0.112555, accuracy: 0.900000
Step: 310, avg loss: 0.266698, loss: 0.054597, accuracy: 1.000000
Step: 320, avg loss: 0.259393, loss: 0.032924, accuracy: 1.000000
Step: 330, avg loss: 0.258807, loss: 0.240064, accuracy: 0.900000
Step: 340, avg loss: 0.253254, loss: 0.070000, accuracy: 1.000000
Step: 350, avg loss: 0.248784, loss: 0.096803, accuracy: 1.000000
Step: 360, avg loss: 0.247848, loss: 0.215090, accuracy: 0.900000
Step: 370, avg loss: 0.254619, loss: 0.498391, accuracy: 0.900000
Step: 380, avg loss: 0.277461, loss: 1.122608, accuracy: 0.800000
Step: 390, avg loss: 0.275849, loss: 0.214589, accuracy: 0.900000
Step: 400, avg loss: 0.271143, loss: 0.087623, accuracy: 1.000000
Step: 410, avg loss: 0.267604, loss: 0.126045, accuracy: 1.000000
Step: 420, avg loss: 0.266509, loss: 0.221585, accuracy: 0.800000
Step: 430, avg loss: 0.261367, loss: 0.045427, accuracy: 1.000000
Step: 440, avg loss: 0.267738, loss: 0.541680, accuracy: 0.800000
Step: 450, avg loss: 0.292023, loss: 1.360561, accuracy: 0.800000
Step: 460, avg loss: 0.294805, loss: 0.420000, accuracy: 0.800000
Step: 470, avg loss: 0.304887, loss: 0.768647, accuracy: 0.700000
Step: 480, avg loss: 0.308051, loss: 0.456774, accuracy: 0.900000
Step: 490, avg loss: 0.310189, loss: 0.412795, accuracy: 0.900000
Step: 500, avg loss: 0.307371, loss: 0.169322, accuracy: 1.000000
Step: 510, avg loss: 0.309601, loss: 0.421083, accuracy: 0.800000
Step: 520, avg loss: 0.305981, loss: 0.121367, accuracy: 1.000000
Step: 530, avg loss: 0.302633, loss: 0.128543, accuracy: 1.000000
Step: 540, avg loss: 0.297652, loss: 0.033653, accuracy: 1.000000
Step: 550, avg loss: 0.306427, loss: 0.780277, accuracy: 0.800000
Step: 560, avg loss: 0.304016, loss: 0.171427, accuracy: 1.000000
Step: 570, avg loss: 0.307452, loss: 0.499851, accuracy: 0.900000
Step: 580, avg loss: 0.303215, loss: 0.061679, accuracy: 1.000000
Step: 590, avg loss: 0.306475, loss: 0.495595, accuracy: 0.800000
Step: 600, avg loss: 0.302396, loss: 0.061716, accuracy: 1.000000
Step: 610, avg loss: 0.304700, loss: 0.442906, accuracy: 0.800000
Step: 620, avg loss: 0.300783, loss: 0.061866, accuracy: 1.000000
Step: 630, avg loss: 0.297835, loss: 0.115092, accuracy: 0.900000
Step: 640, avg loss: 0.294821, loss: 0.104916, accuracy: 1.000000
Step: 650, avg loss: 0.292461, loss: 0.141428, accuracy: 1.000000
Step: 660, avg loss: 0.288927, loss: 0.059215, accuracy: 1.000000
Step: 670, avg loss: 0.295502, loss: 0.729449, accuracy: 0.800000
Step: 680, avg loss: 0.295909, loss: 0.323188, accuracy: 0.900000
Step: 690, avg loss: 0.297757, loss: 0.423411, accuracy: 0.800000
Step: 700, avg loss: 0.299226, loss: 0.400557, accuracy: 0.900000
Step: 710, avg loss: 0.299305, loss: 0.304826, accuracy: 0.800000
Step: 720, avg loss: 0.300928, loss: 0.416209, accuracy: 0.800000
Step: 730, avg loss: 0.298416, loss: 0.117515, accuracy: 1.000000
Step: 740, avg loss: 0.301686, loss: 0.540418, accuracy: 0.800000
Step: 750, avg loss: 0.301641, loss: 0.298331, accuracy: 0.900000
Step: 760, avg loss: 0.298385, loss: 0.054133, accuracy: 1.000000
Step: 770, avg loss: 0.298322, loss: 0.293588, accuracy: 0.900000
Step: 780, avg loss: 0.298289, loss: 0.295701, accuracy: 0.900000
Step: 790, avg loss: 0.295770, loss: 0.099284, accuracy: 1.000000
Step: 800, avg loss: 0.292793, loss: 0.057622, accuracy: 1.000000
Step: 810, avg loss: 0.297172, loss: 0.647523, accuracy: 0.900000
Step: 820, avg loss: 0.300085, loss: 0.536046, accuracy: 0.900000
Step: 830, avg loss: 0.297675, loss: 0.100017, accuracy: 1.000000
Step: 840, avg loss: 0.303131, loss: 0.756039, accuracy: 0.800000
Step: 850, avg loss: 0.301409, loss: 0.156680, accuracy: 0.900000
Step: 860, avg loss: 0.305256, loss: 0.632303, accuracy: 0.700000
Step: 870, avg loss: 0.304793, loss: 0.264943, accuracy: 0.900000
Step: 880, avg loss: 0.302575, loss: 0.109640, accuracy: 1.000000
Step: 890, avg loss: 0.307698, loss: 0.758541, accuracy: 0.700000
Step: 900, avg loss: 0.306354, loss: 0.186716, accuracy: 1.000000
Step: 910, avg loss: 0.309131, loss: 0.559078, accuracy: 0.800000
Step: 920, avg loss: 0.308238, loss: 0.226925, accuracy: 0.900000
Step: 930, avg loss: 0.309878, loss: 0.460774, accuracy: 0.700000
Step: 940, avg loss: 0.308573, loss: 0.187252, accuracy: 0.900000
Step: 950, avg loss: 0.306753, loss: 0.135674, accuracy: 0.900000
Step: 960, avg loss: 0.306318, loss: 0.264915, accuracy: 0.900000
Step: 970, avg loss: 0.304113, loss: 0.092464, accuracy: 1.000000
Step: 980, avg loss: 0.302030, loss: 0.100026, accuracy: 1.000000
Step: 990, avg loss: 0.302052, loss: 0.304152, accuracy: 0.900000
Step: 1000, avg loss: 0.299337, loss: 0.030555, accuracy: 1.000000
Step: 1010, avg loss: 0.297103, loss: 0.073727, accuracy: 1.000000
Step: 1020, avg loss: 0.294940, loss: 0.076498, accuracy: 1.000000
Step: 1030, avg loss: 0.292765, loss: 0.070900, accuracy: 1.000000
Step: 1040, avg loss: 0.290002, loss: 0.005410, accuracy: 1.000000
Step: 1050, avg loss: 0.288276, loss: 0.108794, accuracy: 1.000000
Step: 1060, avg loss: 0.286334, loss: 0.082371, accuracy: 1.000000
Step: 1070, avg loss: 0.283764, loss: 0.011418, accuracy: 1.000000
Step: 1080, avg loss: 0.282127, loss: 0.106866, accuracy: 1.000000
Step: 1090, avg loss: 0.281280, loss: 0.189825, accuracy: 0.900000
Step: 1100, avg loss: 0.278830, loss: 0.011785, accuracy: 1.000000
Step: 1110, avg loss: 0.276420, loss: 0.011301, accuracy: 1.000000
Step: 1120, avg loss: 0.280130, loss: 0.691957, accuracy: 0.900000
Step: 1130, avg loss: 0.280574, loss: 0.330346, accuracy: 0.900000
Step: 1140, avg loss: 0.301518, loss: 2.668132, accuracy: 0.600000
Step: 1150, avg loss: 0.304936, loss: 0.694606, accuracy: 0.600000
Step: 1160, avg loss: 0.306135, loss: 0.444004, accuracy: 0.900000
Step: 1170, avg loss: 0.305848, loss: 0.272637, accuracy: 0.900000
Step: 1180, avg loss: 0.308183, loss: 0.581302, accuracy: 0.800000
Step: 1190, avg loss: 0.307438, loss: 0.219542, accuracy: 1.000000
Step: 1200, avg loss: 0.310422, loss: 0.665527, accuracy: 0.700000
Step: 1210, avg loss: 0.309037, loss: 0.142889, accuracy: 1.000000
Step: 1220, avg loss: 0.306981, loss: 0.058183, accuracy: 1.000000
Step: 1230, avg loss: 0.305263, loss: 0.095634, accuracy: 1.000000
Step: 1240, avg loss: 0.307600, loss: 0.595016, accuracy: 0.800000
Step: 1250, avg loss: 0.306054, loss: 0.114429, accuracy: 1.000000
Step: 1260, avg loss: 0.304213, loss: 0.074061, accuracy: 1.000000
Epoch 9 finished in loss: 0.303818 and accuracy: 0.904913
Step: 10, avg loss: 0.642067, loss: 0.642067, accuracy: 0.700000
Step: 20, avg loss: 0.410903, loss: 0.179738, accuracy: 0.900000
Step: 30, avg loss: 0.485736, loss: 0.635404, accuracy: 0.700000
Step: 40, avg loss: 0.540472, loss: 0.704677, accuracy: 0.700000
Step: 50, avg loss: 0.472453, loss: 0.200381, accuracy: 1.000000
Step: 60, avg loss: 0.424385, loss: 0.184043, accuracy: 1.000000
Step: 70, avg loss: 0.376824, loss: 0.091457, accuracy: 1.000000
Step: 80, avg loss: 0.335666, loss: 0.047561, accuracy: 1.000000
Step: 90, avg loss: 0.359357, loss: 0.548881, accuracy: 0.900000
Step: 100, avg loss: 0.336264, loss: 0.128433, accuracy: 0.900000
Step: 110, avg loss: 0.326894, loss: 0.233188, accuracy: 0.900000
Step: 120, avg loss: 0.334699, loss: 0.420555, accuracy: 0.900000
Step: 130, avg loss: 0.316199, loss: 0.094198, accuracy: 1.000000
Step: 140, avg loss: 0.295205, loss: 0.022279, accuracy: 1.000000
Step: 150, avg loss: 0.302918, loss: 0.410907, accuracy: 0.800000
Step: 160, avg loss: 0.287472, loss: 0.055775, accuracy: 1.000000
Step: 170, avg loss: 0.303650, loss: 0.562505, accuracy: 0.700000
Step: 180, avg loss: 0.314431, loss: 0.497700, accuracy: 0.900000
Step: 190, avg loss: 0.310899, loss: 0.247324, accuracy: 0.900000
Step: 200, avg loss: 0.312626, loss: 0.345444, accuracy: 0.800000
Step: 210, avg loss: 0.322878, loss: 0.527921, accuracy: 0.800000
Step: 220, avg loss: 0.326202, loss: 0.396009, accuracy: 0.700000
Step: 230, avg loss: 0.317024, loss: 0.115104, accuracy: 1.000000
Step: 240, avg loss: 0.306557, loss: 0.065818, accuracy: 1.000000
Step: 250, avg loss: 0.300290, loss: 0.149883, accuracy: 0.900000
Step: 260, avg loss: 0.292922, loss: 0.108716, accuracy: 0.900000
Step: 270, avg loss: 0.289426, loss: 0.198541, accuracy: 1.000000
Step: 280, avg loss: 0.280353, loss: 0.035364, accuracy: 1.000000
Step: 290, avg loss: 0.272532, loss: 0.053559, accuracy: 1.000000
Step: 300, avg loss: 0.264775, loss: 0.039822, accuracy: 1.000000
Step: 310, avg loss: 0.257415, loss: 0.036624, accuracy: 1.000000
Step: 320, avg loss: 0.250157, loss: 0.025133, accuracy: 1.000000
Step: 330, avg loss: 0.249088, loss: 0.214884, accuracy: 0.900000
Step: 340, avg loss: 0.243401, loss: 0.055743, accuracy: 1.000000
Step: 350, avg loss: 0.238891, loss: 0.085529, accuracy: 1.000000
Step: 360, avg loss: 0.234700, loss: 0.088047, accuracy: 1.000000
Step: 370, avg loss: 0.248108, loss: 0.730797, accuracy: 0.800000
Step: 380, avg loss: 0.261918, loss: 0.772890, accuracy: 0.900000
Step: 390, avg loss: 0.259153, loss: 0.154051, accuracy: 0.900000
Step: 400, avg loss: 0.254653, loss: 0.079179, accuracy: 1.000000
Step: 410, avg loss: 0.251452, loss: 0.123405, accuracy: 1.000000
Step: 420, avg loss: 0.249594, loss: 0.173423, accuracy: 0.900000
Step: 430, avg loss: 0.244906, loss: 0.048007, accuracy: 1.000000
Step: 440, avg loss: 0.254903, loss: 0.684771, accuracy: 0.800000
Step: 450, avg loss: 0.260167, loss: 0.491773, accuracy: 0.700000
Step: 460, avg loss: 0.258650, loss: 0.190394, accuracy: 0.900000
Step: 470, avg loss: 0.265468, loss: 0.579092, accuracy: 0.800000
Step: 480, avg loss: 0.270021, loss: 0.483994, accuracy: 0.900000
Step: 490, avg loss: 0.273894, loss: 0.459804, accuracy: 0.800000
Step: 500, avg loss: 0.277432, loss: 0.450785, accuracy: 0.800000
Step: 510, avg loss: 0.282362, loss: 0.528859, accuracy: 0.800000
Step: 520, avg loss: 0.280028, loss: 0.161003, accuracy: 0.900000
Step: 530, avg loss: 0.277847, loss: 0.164455, accuracy: 0.900000
Step: 540, avg loss: 0.273582, loss: 0.047558, accuracy: 1.000000
Step: 550, avg loss: 0.282171, loss: 0.745942, accuracy: 0.800000
Step: 560, avg loss: 0.280496, loss: 0.188387, accuracy: 1.000000
Step: 570, avg loss: 0.276934, loss: 0.077431, accuracy: 1.000000
Step: 580, avg loss: 0.273242, loss: 0.062841, accuracy: 1.000000
Step: 590, avg loss: 0.276515, loss: 0.466313, accuracy: 0.800000
Step: 600, avg loss: 0.272978, loss: 0.064319, accuracy: 1.000000
Step: 610, avg loss: 0.277432, loss: 0.544671, accuracy: 0.800000
Step: 620, avg loss: 0.274001, loss: 0.064714, accuracy: 1.000000
Step: 630, avg loss: 0.271732, loss: 0.131025, accuracy: 1.000000
Step: 640, avg loss: 0.272048, loss: 0.291958, accuracy: 0.900000
Step: 650, avg loss: 0.269217, loss: 0.088080, accuracy: 1.000000
Step: 660, avg loss: 0.266490, loss: 0.089200, accuracy: 1.000000
Step: 670, avg loss: 0.272157, loss: 0.646182, accuracy: 0.800000
Step: 680, avg loss: 0.273136, loss: 0.338759, accuracy: 0.900000
Step: 690, avg loss: 0.274839, loss: 0.390589, accuracy: 0.800000
Step: 700, avg loss: 0.276215, loss: 0.371220, accuracy: 0.900000
Step: 710, avg loss: 0.276456, loss: 0.293289, accuracy: 0.800000
Step: 720, avg loss: 0.276786, loss: 0.300202, accuracy: 0.900000
Step: 730, avg loss: 0.274222, loss: 0.089601, accuracy: 1.000000
Step: 740, avg loss: 0.276566, loss: 0.447700, accuracy: 0.800000
Step: 750, avg loss: 0.273854, loss: 0.073161, accuracy: 1.000000
Step: 760, avg loss: 0.270638, loss: 0.029420, accuracy: 1.000000
Step: 770, avg loss: 0.269624, loss: 0.192605, accuracy: 0.900000
Step: 780, avg loss: 0.269884, loss: 0.289882, accuracy: 0.900000
Step: 790, avg loss: 0.267085, loss: 0.048808, accuracy: 1.000000
Step: 800, avg loss: 0.264491, loss: 0.059556, accuracy: 1.000000
Step: 810, avg loss: 0.265080, loss: 0.312177, accuracy: 0.900000
Step: 820, avg loss: 0.268531, loss: 0.548079, accuracy: 0.800000
Step: 830, avg loss: 0.266039, loss: 0.061700, accuracy: 1.000000
Step: 840, avg loss: 0.276586, loss: 1.151941, accuracy: 0.600000
Step: 850, avg loss: 0.273795, loss: 0.039334, accuracy: 1.000000
Step: 860, avg loss: 0.279737, loss: 0.784872, accuracy: 0.800000
Step: 870, avg loss: 0.278421, loss: 0.165211, accuracy: 1.000000
Step: 880, avg loss: 0.276133, loss: 0.077114, accuracy: 1.000000
Step: 890, avg loss: 0.280151, loss: 0.633682, accuracy: 0.800000
Step: 900, avg loss: 0.279185, loss: 0.193238, accuracy: 1.000000
Step: 910, avg loss: 0.282057, loss: 0.540512, accuracy: 0.800000
Step: 920, avg loss: 0.281641, loss: 0.243761, accuracy: 0.900000
Step: 930, avg loss: 0.282710, loss: 0.381132, accuracy: 0.700000
Step: 940, avg loss: 0.281003, loss: 0.122201, accuracy: 1.000000
Step: 950, avg loss: 0.278591, loss: 0.051856, accuracy: 1.000000
Step: 960, avg loss: 0.278503, loss: 0.270132, accuracy: 0.900000
Step: 970, avg loss: 0.276528, loss: 0.086990, accuracy: 1.000000
Step: 980, avg loss: 0.274649, loss: 0.092317, accuracy: 1.000000
Step: 990, avg loss: 0.272422, loss: 0.054240, accuracy: 1.000000
Step: 1000, avg loss: 0.270606, loss: 0.090836, accuracy: 1.000000
Step: 1010, avg loss: 0.269256, loss: 0.134246, accuracy: 1.000000
Step: 1020, avg loss: 0.267001, loss: 0.039240, accuracy: 1.000000
Step: 1030, avg loss: 0.264652, loss: 0.025001, accuracy: 1.000000
Step: 1040, avg loss: 0.262746, loss: 0.066485, accuracy: 1.000000
Step: 1050, avg loss: 0.260655, loss: 0.043198, accuracy: 1.000000
Step: 1060, avg loss: 0.259085, loss: 0.094197, accuracy: 1.000000
Step: 1070, avg loss: 0.256782, loss: 0.012619, accuracy: 1.000000
Step: 1080, avg loss: 0.255543, loss: 0.123020, accuracy: 1.000000
Step: 1090, avg loss: 0.256914, loss: 0.404935, accuracy: 0.900000
Step: 1100, avg loss: 0.254862, loss: 0.031276, accuracy: 1.000000
Step: 1110, avg loss: 0.252870, loss: 0.033720, accuracy: 1.000000
Step: 1120, avg loss: 0.256787, loss: 0.691621, accuracy: 0.900000
Step: 1130, avg loss: 0.256509, loss: 0.225331, accuracy: 0.900000
Step: 1140, avg loss: 0.276494, loss: 2.534743, accuracy: 0.600000
Step: 1150, avg loss: 0.279750, loss: 0.650989, accuracy: 0.700000
Step: 1160, avg loss: 0.282465, loss: 0.594700, accuracy: 0.800000
Step: 1170, avg loss: 0.282490, loss: 0.285321, accuracy: 0.900000
Step: 1180, avg loss: 0.284345, loss: 0.501379, accuracy: 0.900000
Step: 1190, avg loss: 0.285576, loss: 0.430941, accuracy: 0.900000
Step: 1200, avg loss: 0.287856, loss: 0.559156, accuracy: 0.800000
Step: 1210, avg loss: 0.286562, loss: 0.131211, accuracy: 1.000000
Step: 1220, avg loss: 0.284814, loss: 0.073383, accuracy: 1.000000
Step: 1230, avg loss: 0.283332, loss: 0.102528, accuracy: 1.000000
Step: 1240, avg loss: 0.282539, loss: 0.184948, accuracy: 0.900000
Step: 1250, avg loss: 0.281462, loss: 0.147869, accuracy: 0.900000
Step: 1260, avg loss: 0.279676, loss: 0.056456, accuracy: 1.000000
Epoch 10 finished in loss: 0.279343 and accuracy: 0.912837
Step: 10, avg loss: 0.658759, loss: 0.658759, accuracy: 0.700000
Step: 20, avg loss: 0.493614, loss: 0.328469, accuracy: 0.900000
Step: 30, avg loss: 0.364218, loss: 0.105426, accuracy: 1.000000
Step: 40, avg loss: 0.379884, loss: 0.426882, accuracy: 0.800000
Step: 50, avg loss: 0.323617, loss: 0.098550, accuracy: 1.000000
Step: 60, avg loss: 0.296319, loss: 0.159826, accuracy: 0.900000
Step: 70, avg loss: 0.256203, loss: 0.015512, accuracy: 1.000000
Step: 80, avg loss: 0.229199, loss: 0.040171, accuracy: 1.000000
Step: 90, avg loss: 0.275067, loss: 0.642011, accuracy: 0.900000
Step: 100, avg loss: 0.273067, loss: 0.255068, accuracy: 0.900000
Step: 110, avg loss: 0.266112, loss: 0.196562, accuracy: 0.900000
Step: 120, avg loss: 0.281889, loss: 0.455435, accuracy: 0.900000
Step: 130, avg loss: 0.264815, loss: 0.059920, accuracy: 1.000000
Step: 140, avg loss: 0.248002, loss: 0.029442, accuracy: 1.000000
Step: 150, avg loss: 0.239808, loss: 0.125090, accuracy: 1.000000
Step: 160, avg loss: 0.227455, loss: 0.042148, accuracy: 1.000000
Step: 170, avg loss: 0.238420, loss: 0.413874, accuracy: 0.800000
Step: 180, avg loss: 0.251013, loss: 0.465089, accuracy: 0.900000
Step: 190, avg loss: 0.249316, loss: 0.218773, accuracy: 0.900000
Step: 200, avg loss: 0.254209, loss: 0.347180, accuracy: 0.800000
Step: 210, avg loss: 0.264132, loss: 0.462575, accuracy: 0.900000
Step: 220, avg loss: 0.271481, loss: 0.425814, accuracy: 0.700000
Step: 230, avg loss: 0.263972, loss: 0.098770, accuracy: 1.000000
Step: 240, avg loss: 0.255263, loss: 0.054966, accuracy: 1.000000
Step: 250, avg loss: 0.247929, loss: 0.071923, accuracy: 1.000000
Step: 260, avg loss: 0.239654, loss: 0.032754, accuracy: 1.000000
Step: 270, avg loss: 0.234201, loss: 0.092434, accuracy: 1.000000
Step: 280, avg loss: 0.226259, loss: 0.011830, accuracy: 1.000000
Step: 290, avg loss: 0.221909, loss: 0.100110, accuracy: 1.000000
Step: 300, avg loss: 0.215776, loss: 0.037916, accuracy: 1.000000
Step: 310, avg loss: 0.210059, loss: 0.038560, accuracy: 1.000000
Step: 320, avg loss: 0.204246, loss: 0.024031, accuracy: 1.000000
Step: 330, avg loss: 0.203042, loss: 0.164518, accuracy: 0.900000
Step: 340, avg loss: 0.199440, loss: 0.080557, accuracy: 1.000000
Step: 350, avg loss: 0.194729, loss: 0.034559, accuracy: 1.000000
Step: 360, avg loss: 0.190662, loss: 0.048317, accuracy: 1.000000
Step: 370, avg loss: 0.219566, loss: 1.260129, accuracy: 0.700000
Step: 380, avg loss: 0.234698, loss: 0.794567, accuracy: 0.900000
Step: 390, avg loss: 0.233560, loss: 0.190336, accuracy: 0.900000
Step: 400, avg loss: 0.229361, loss: 0.065596, accuracy: 1.000000
Step: 410, avg loss: 0.226969, loss: 0.131259, accuracy: 1.000000
Step: 420, avg loss: 0.228327, loss: 0.284008, accuracy: 0.900000
Step: 430, avg loss: 0.224071, loss: 0.045334, accuracy: 1.000000
Step: 440, avg loss: 0.227922, loss: 0.393497, accuracy: 0.900000
Step: 450, avg loss: 0.226990, loss: 0.185984, accuracy: 0.900000
Step: 460, avg loss: 0.228174, loss: 0.281466, accuracy: 0.900000
Step: 470, avg loss: 0.236642, loss: 0.626162, accuracy: 0.800000
Step: 480, avg loss: 0.245693, loss: 0.671085, accuracy: 0.800000
Step: 490, avg loss: 0.249188, loss: 0.416940, accuracy: 0.900000
Step: 500, avg loss: 0.248130, loss: 0.196296, accuracy: 1.000000
Step: 510, avg loss: 0.249928, loss: 0.339823, accuracy: 0.900000
Step: 520, avg loss: 0.246786, loss: 0.086570, accuracy: 1.000000
Step: 530, avg loss: 0.244426, loss: 0.121679, accuracy: 1.000000
Step: 540, avg loss: 0.240491, loss: 0.031933, accuracy: 1.000000
Step: 550, avg loss: 0.249691, loss: 0.746531, accuracy: 0.800000
Step: 560, avg loss: 0.247736, loss: 0.140216, accuracy: 1.000000
Step: 570, avg loss: 0.245018, loss: 0.092762, accuracy: 1.000000
Step: 580, avg loss: 0.241819, loss: 0.059501, accuracy: 1.000000
Step: 590, avg loss: 0.240489, loss: 0.163357, accuracy: 1.000000
Step: 600, avg loss: 0.237400, loss: 0.055154, accuracy: 1.000000
Step: 610, avg loss: 0.240132, loss: 0.404060, accuracy: 0.900000
Step: 620, avg loss: 0.240352, loss: 0.253735, accuracy: 0.900000
Step: 630, avg loss: 0.238233, loss: 0.106904, accuracy: 1.000000
Step: 640, avg loss: 0.236119, loss: 0.102930, accuracy: 1.000000
Step: 650, avg loss: 0.233884, loss: 0.090837, accuracy: 1.000000
Step: 660, avg loss: 0.232340, loss: 0.131970, accuracy: 0.900000
Step: 670, avg loss: 0.237325, loss: 0.566353, accuracy: 0.900000
Step: 680, avg loss: 0.237724, loss: 0.264428, accuracy: 0.900000
Step: 690, avg loss: 0.240776, loss: 0.448331, accuracy: 0.900000
Step: 700, avg loss: 0.242788, loss: 0.381608, accuracy: 0.900000
Step: 710, avg loss: 0.242395, loss: 0.214892, accuracy: 0.800000
Step: 720, avg loss: 0.242756, loss: 0.268386, accuracy: 0.900000
Step: 730, avg loss: 0.240505, loss: 0.078385, accuracy: 1.000000
Step: 740, avg loss: 0.240715, loss: 0.256115, accuracy: 0.900000
Step: 750, avg loss: 0.238305, loss: 0.059925, accuracy: 1.000000
Step: 760, avg loss: 0.235561, loss: 0.029798, accuracy: 1.000000
Step: 770, avg loss: 0.234410, loss: 0.146904, accuracy: 0.900000
Step: 780, avg loss: 0.234416, loss: 0.234863, accuracy: 0.900000
Step: 790, avg loss: 0.240336, loss: 0.702143, accuracy: 0.800000
Step: 800, avg loss: 0.241538, loss: 0.336496, accuracy: 0.900000
Step: 810, avg loss: 0.240900, loss: 0.189789, accuracy: 0.900000
Step: 820, avg loss: 0.244480, loss: 0.534490, accuracy: 0.800000
Step: 830, avg loss: 0.242781, loss: 0.103462, accuracy: 1.000000
Step: 840, avg loss: 0.244410, loss: 0.379590, accuracy: 0.900000
Step: 850, avg loss: 0.242090, loss: 0.047265, accuracy: 1.000000
Step: 860, avg loss: 0.249914, loss: 0.914972, accuracy: 0.800000
Step: 870, avg loss: 0.249718, loss: 0.232862, accuracy: 0.900000
Step: 880, avg loss: 0.247650, loss: 0.067679, accuracy: 1.000000
Step: 890, avg loss: 0.250545, loss: 0.505311, accuracy: 0.800000
Step: 900, avg loss: 0.248763, loss: 0.090211, accuracy: 1.000000
Step: 910, avg loss: 0.252642, loss: 0.601761, accuracy: 0.900000
Step: 920, avg loss: 0.251993, loss: 0.192873, accuracy: 0.900000
Step: 930, avg loss: 0.251878, loss: 0.241279, accuracy: 0.900000
Step: 940, avg loss: 0.250638, loss: 0.135398, accuracy: 1.000000
Step: 950, avg loss: 0.248571, loss: 0.054185, accuracy: 1.000000
Step: 960, avg loss: 0.248629, loss: 0.254195, accuracy: 0.900000
Step: 970, avg loss: 0.246844, loss: 0.075487, accuracy: 1.000000
Step: 980, avg loss: 0.245557, loss: 0.120732, accuracy: 1.000000
Step: 990, avg loss: 0.243452, loss: 0.037155, accuracy: 1.000000
Step: 1000, avg loss: 0.243023, loss: 0.200555, accuracy: 0.900000
Step: 1010, avg loss: 0.241583, loss: 0.097568, accuracy: 1.000000
Step: 1020, avg loss: 0.240109, loss: 0.091223, accuracy: 1.000000
Step: 1030, avg loss: 0.238667, loss: 0.091558, accuracy: 1.000000
Step: 1040, avg loss: 0.236446, loss: 0.007761, accuracy: 1.000000
Step: 1050, avg loss: 0.235092, loss: 0.094263, accuracy: 1.000000
Step: 1060, avg loss: 0.233549, loss: 0.071525, accuracy: 1.000000
Step: 1070, avg loss: 0.231473, loss: 0.011418, accuracy: 1.000000
Step: 1080, avg loss: 0.230326, loss: 0.107543, accuracy: 1.000000
Step: 1090, avg loss: 0.229912, loss: 0.185208, accuracy: 0.900000
Step: 1100, avg loss: 0.227973, loss: 0.016661, accuracy: 1.000000
Step: 1110, avg loss: 0.226281, loss: 0.040111, accuracy: 1.000000
Step: 1120, avg loss: 0.230177, loss: 0.662710, accuracy: 0.900000
Step: 1130, avg loss: 0.228628, loss: 0.055071, accuracy: 1.000000
Step: 1140, avg loss: 0.248282, loss: 2.469162, accuracy: 0.600000
Step: 1150, avg loss: 0.250594, loss: 0.514178, accuracy: 0.700000
Step: 1160, avg loss: 0.256108, loss: 0.890254, accuracy: 0.900000
Step: 1170, avg loss: 0.256550, loss: 0.307779, accuracy: 0.900000
Step: 1180, avg loss: 0.261074, loss: 0.790419, accuracy: 0.800000
Step: 1190, avg loss: 0.261482, loss: 0.309634, accuracy: 0.900000
Step: 1200, avg loss: 0.264390, loss: 0.610432, accuracy: 0.800000
Step: 1210, avg loss: 0.263438, loss: 0.149233, accuracy: 1.000000
Step: 1220, avg loss: 0.262596, loss: 0.160650, accuracy: 0.900000
Step: 1230, avg loss: 0.261118, loss: 0.080830, accuracy: 1.000000
Step: 1240, avg loss: 0.260358, loss: 0.166855, accuracy: 0.900000
Step: 1250, avg loss: 0.259441, loss: 0.145797, accuracy: 1.000000
Step: 1260, avg loss: 0.257759, loss: 0.047475, accuracy: 1.000000
Epoch 11 finished in loss: 0.257543 and accuracy: 0.931062
Step: 10, avg loss: 0.368371, loss: 0.368371, accuracy: 0.800000
Step: 20, avg loss: 0.323548, loss: 0.278726, accuracy: 0.900000
Step: 30, avg loss: 0.267941, loss: 0.156728, accuracy: 0.900000
Step: 40, avg loss: 0.251891, loss: 0.203739, accuracy: 0.900000
Step: 50, avg loss: 0.213718, loss: 0.061026, accuracy: 1.000000
Step: 60, avg loss: 0.185509, loss: 0.044465, accuracy: 1.000000
Step: 70, avg loss: 0.161969, loss: 0.020729, accuracy: 1.000000
Step: 80, avg loss: 0.147533, loss: 0.046482, accuracy: 1.000000
Step: 90, avg loss: 0.214162, loss: 0.747195, accuracy: 0.900000
Step: 100, avg loss: 0.197695, loss: 0.049485, accuracy: 1.000000
Step: 110, avg loss: 0.187761, loss: 0.088421, accuracy: 1.000000
Step: 120, avg loss: 0.209883, loss: 0.453229, accuracy: 0.900000
Step: 130, avg loss: 0.198032, loss: 0.055821, accuracy: 1.000000
Step: 140, avg loss: 0.185562, loss: 0.023445, accuracy: 1.000000
Step: 150, avg loss: 0.205478, loss: 0.484314, accuracy: 0.800000
Step: 160, avg loss: 0.196071, loss: 0.054957, accuracy: 1.000000
Step: 170, avg loss: 0.199367, loss: 0.252114, accuracy: 0.800000
Step: 180, avg loss: 0.217284, loss: 0.521865, accuracy: 0.900000
Step: 190, avg loss: 0.217978, loss: 0.230468, accuracy: 0.900000
Step: 200, avg loss: 0.216652, loss: 0.191469, accuracy: 1.000000
Step: 210, avg loss: 0.232491, loss: 0.549258, accuracy: 0.800000
Step: 220, avg loss: 0.239466, loss: 0.385946, accuracy: 0.800000
Step: 230, avg loss: 0.231232, loss: 0.050079, accuracy: 1.000000
Step: 240, avg loss: 0.223853, loss: 0.054135, accuracy: 1.000000
Step: 250, avg loss: 0.219035, loss: 0.103405, accuracy: 1.000000
Step: 260, avg loss: 0.211755, loss: 0.029771, accuracy: 1.000000
Step: 270, avg loss: 0.206984, loss: 0.082924, accuracy: 1.000000
Step: 280, avg loss: 0.200118, loss: 0.014745, accuracy: 1.000000
Step: 290, avg loss: 0.195177, loss: 0.056819, accuracy: 1.000000
Step: 300, avg loss: 0.189434, loss: 0.022880, accuracy: 1.000000
Step: 310, avg loss: 0.184526, loss: 0.037307, accuracy: 1.000000
Step: 320, avg loss: 0.179476, loss: 0.022911, accuracy: 1.000000
Step: 330, avg loss: 0.177557, loss: 0.116152, accuracy: 1.000000
Step: 340, avg loss: 0.174271, loss: 0.065828, accuracy: 1.000000
Step: 350, avg loss: 0.170869, loss: 0.055220, accuracy: 1.000000
Step: 360, avg loss: 0.167974, loss: 0.066622, accuracy: 1.000000
Step: 370, avg loss: 0.166320, loss: 0.106805, accuracy: 1.000000
Step: 380, avg loss: 0.183508, loss: 0.819439, accuracy: 0.900000
Step: 390, avg loss: 0.184912, loss: 0.238291, accuracy: 0.900000
Step: 400, avg loss: 0.181861, loss: 0.062847, accuracy: 1.000000
Step: 410, avg loss: 0.180604, loss: 0.130342, accuracy: 1.000000
Step: 420, avg loss: 0.179026, loss: 0.114317, accuracy: 1.000000
Step: 430, avg loss: 0.175946, loss: 0.046594, accuracy: 1.000000
Step: 440, avg loss: 0.179218, loss: 0.319886, accuracy: 0.900000
Step: 450, avg loss: 0.181542, loss: 0.283818, accuracy: 0.900000
Step: 460, avg loss: 0.179575, loss: 0.091081, accuracy: 1.000000
Step: 470, avg loss: 0.190850, loss: 0.709486, accuracy: 0.800000
Step: 480, avg loss: 0.196375, loss: 0.456046, accuracy: 0.900000
Step: 490, avg loss: 0.200921, loss: 0.419112, accuracy: 0.900000
Step: 500, avg loss: 0.199328, loss: 0.121278, accuracy: 1.000000
Step: 510, avg loss: 0.201432, loss: 0.306643, accuracy: 0.900000
Step: 520, avg loss: 0.199669, loss: 0.109728, accuracy: 1.000000
Step: 530, avg loss: 0.198132, loss: 0.118252, accuracy: 1.000000
Step: 540, avg loss: 0.195071, loss: 0.032822, accuracy: 1.000000
Step: 550, avg loss: 0.205231, loss: 0.753881, accuracy: 0.800000
Step: 560, avg loss: 0.205984, loss: 0.247380, accuracy: 0.900000
Step: 570, avg loss: 0.204117, loss: 0.099568, accuracy: 1.000000
Step: 580, avg loss: 0.202576, loss: 0.114722, accuracy: 1.000000
Step: 590, avg loss: 0.202889, loss: 0.221074, accuracy: 0.900000
Step: 600, avg loss: 0.200654, loss: 0.068801, accuracy: 1.000000
Step: 610, avg loss: 0.202975, loss: 0.342238, accuracy: 0.900000
Step: 620, avg loss: 0.200405, loss: 0.043576, accuracy: 1.000000
Step: 630, avg loss: 0.197972, loss: 0.047141, accuracy: 1.000000
Step: 640, avg loss: 0.197463, loss: 0.165419, accuracy: 0.900000
Step: 650, avg loss: 0.194993, loss: 0.036885, accuracy: 1.000000
Step: 660, avg loss: 0.193066, loss: 0.067804, accuracy: 1.000000
Step: 670, avg loss: 0.199709, loss: 0.638202, accuracy: 0.800000
Step: 680, avg loss: 0.200917, loss: 0.281837, accuracy: 0.900000
Step: 690, avg loss: 0.199605, loss: 0.110344, accuracy: 1.000000
Step: 700, avg loss: 0.201526, loss: 0.334084, accuracy: 0.900000
Step: 710, avg loss: 0.202849, loss: 0.295515, accuracy: 0.800000
Step: 720, avg loss: 0.205931, loss: 0.424706, accuracy: 0.700000
Step: 730, avg loss: 0.204563, loss: 0.106073, accuracy: 1.000000
Step: 740, avg loss: 0.204292, loss: 0.184530, accuracy: 0.900000
Step: 750, avg loss: 0.203088, loss: 0.113947, accuracy: 0.900000
Step: 760, avg loss: 0.200680, loss: 0.020089, accuracy: 1.000000
Step: 770, avg loss: 0.198780, loss: 0.054370, accuracy: 1.000000
Step: 780, avg loss: 0.199276, loss: 0.237472, accuracy: 0.900000
Step: 790, avg loss: 0.197042, loss: 0.022802, accuracy: 1.000000
Step: 800, avg loss: 0.195148, loss: 0.045539, accuracy: 1.000000
Step: 810, avg loss: 0.194169, loss: 0.115860, accuracy: 0.900000
Step: 820, avg loss: 0.198206, loss: 0.525187, accuracy: 0.900000
Step: 830, avg loss: 0.196832, loss: 0.084184, accuracy: 1.000000
Step: 840, avg loss: 0.201468, loss: 0.586282, accuracy: 0.700000
Step: 850, avg loss: 0.199234, loss: 0.011568, accuracy: 1.000000
Step: 860, avg loss: 0.203293, loss: 0.548238, accuracy: 0.900000
Step: 870, avg loss: 0.201617, loss: 0.057514, accuracy: 1.000000
Step: 880, avg loss: 0.199920, loss: 0.052286, accuracy: 1.000000
Step: 890, avg loss: 0.202805, loss: 0.456674, accuracy: 0.700000
Step: 900, avg loss: 0.201540, loss: 0.088954, accuracy: 1.000000
Step: 910, avg loss: 0.205885, loss: 0.596975, accuracy: 0.800000
Step: 920, avg loss: 0.205556, loss: 0.175621, accuracy: 0.900000
Step: 930, avg loss: 0.206395, loss: 0.283593, accuracy: 0.800000
Step: 940, avg loss: 0.206534, loss: 0.219387, accuracy: 0.900000
Step: 950, avg loss: 0.205023, loss: 0.062978, accuracy: 1.000000
Step: 960, avg loss: 0.205581, loss: 0.258607, accuracy: 0.900000
Step: 970, avg loss: 0.205152, loss: 0.163954, accuracy: 0.900000
Step: 980, avg loss: 0.204026, loss: 0.094811, accuracy: 1.000000
Step: 990, avg loss: 0.202747, loss: 0.077400, accuracy: 1.000000
Step: 1000, avg loss: 0.201338, loss: 0.061935, accuracy: 1.000000
Step: 1010, avg loss: 0.199819, loss: 0.047909, accuracy: 1.000000
Step: 1020, avg loss: 0.198288, loss: 0.043656, accuracy: 1.000000
Step: 1030, avg loss: 0.196678, loss: 0.032375, accuracy: 1.000000
Step: 1040, avg loss: 0.194837, loss: 0.005273, accuracy: 1.000000
Step: 1050, avg loss: 0.194611, loss: 0.171118, accuracy: 0.900000
Step: 1060, avg loss: 0.193331, loss: 0.058921, accuracy: 1.000000
Step: 1070, avg loss: 0.191624, loss: 0.010635, accuracy: 1.000000
Step: 1080, avg loss: 0.190744, loss: 0.096658, accuracy: 1.000000
Step: 1090, avg loss: 0.190197, loss: 0.131131, accuracy: 0.900000
Step: 1100, avg loss: 0.188634, loss: 0.018221, accuracy: 1.000000
Step: 1110, avg loss: 0.187101, loss: 0.018471, accuracy: 1.000000
Step: 1120, avg loss: 0.191283, loss: 0.655479, accuracy: 0.900000
Step: 1130, avg loss: 0.190413, loss: 0.093011, accuracy: 0.900000
Step: 1140, avg loss: 0.208498, loss: 2.252019, accuracy: 0.500000
Step: 1150, avg loss: 0.210099, loss: 0.392630, accuracy: 0.800000
Step: 1160, avg loss: 0.214801, loss: 0.755589, accuracy: 0.800000
Step: 1170, avg loss: 0.215501, loss: 0.296725, accuracy: 0.900000
Step: 1180, avg loss: 0.220757, loss: 0.835688, accuracy: 0.800000
Step: 1190, avg loss: 0.223168, loss: 0.507577, accuracy: 0.900000
Step: 1200, avg loss: 0.226381, loss: 0.608843, accuracy: 0.800000
Step: 1210, avg loss: 0.225919, loss: 0.170463, accuracy: 1.000000
Step: 1220, avg loss: 0.224637, loss: 0.069471, accuracy: 1.000000
Step: 1230, avg loss: 0.223333, loss: 0.064278, accuracy: 1.000000
Step: 1240, avg loss: 0.222712, loss: 0.146270, accuracy: 1.000000
Step: 1250, avg loss: 0.221342, loss: 0.051439, accuracy: 1.000000
Step: 1260, avg loss: 0.220090, loss: 0.063670, accuracy: 1.000000
Epoch 12 finished in loss: 0.219794 and accuracy: 0.936609
Step: 10, avg loss: 0.332391, loss: 0.332391, accuracy: 0.900000
Step: 20, avg loss: 0.211687, loss: 0.090983, accuracy: 1.000000
Step: 30, avg loss: 0.164880, loss: 0.071266, accuracy: 1.000000
Step: 40, avg loss: 0.185756, loss: 0.248385, accuracy: 0.900000
Step: 50, avg loss: 0.160457, loss: 0.059258, accuracy: 1.000000
Step: 60, avg loss: 0.139357, loss: 0.033857, accuracy: 1.000000
Step: 70, avg loss: 0.121174, loss: 0.012078, accuracy: 1.000000
Step: 80, avg loss: 0.111099, loss: 0.040577, accuracy: 1.000000
Step: 90, avg loss: 0.176944, loss: 0.703703, accuracy: 0.900000
Step: 100, avg loss: 0.167105, loss: 0.078551, accuracy: 1.000000
Step: 110, avg loss: 0.158291, loss: 0.070155, accuracy: 1.000000
Step: 120, avg loss: 0.176814, loss: 0.380560, accuracy: 0.900000
Step: 130, avg loss: 0.167718, loss: 0.058564, accuracy: 1.000000
Step: 140, avg loss: 0.157181, loss: 0.020201, accuracy: 1.000000
Step: 150, avg loss: 0.166152, loss: 0.291758, accuracy: 0.800000
Step: 160, avg loss: 0.158780, loss: 0.048193, accuracy: 1.000000
Step: 170, avg loss: 0.170913, loss: 0.365047, accuracy: 0.800000
Step: 180, avg loss: 0.189094, loss: 0.498159, accuracy: 0.900000
Step: 190, avg loss: 0.184565, loss: 0.103055, accuracy: 1.000000
Step: 200, avg loss: 0.189275, loss: 0.278754, accuracy: 0.900000
Step: 210, avg loss: 0.201916, loss: 0.454733, accuracy: 0.900000
Step: 220, avg loss: 0.202876, loss: 0.223046, accuracy: 0.900000
Step: 230, avg loss: 0.196152, loss: 0.048217, accuracy: 1.000000
Step: 240, avg loss: 0.189683, loss: 0.040900, accuracy: 1.000000
Step: 250, avg loss: 0.184152, loss: 0.051418, accuracy: 1.000000
Step: 260, avg loss: 0.178107, loss: 0.026971, accuracy: 1.000000
Step: 270, avg loss: 0.173366, loss: 0.050093, accuracy: 1.000000
Step: 280, avg loss: 0.167684, loss: 0.014286, accuracy: 1.000000
Step: 290, avg loss: 0.163800, loss: 0.055036, accuracy: 1.000000
Step: 300, avg loss: 0.159133, loss: 0.023784, accuracy: 1.000000
Step: 310, avg loss: 0.155513, loss: 0.046912, accuracy: 1.000000
Step: 320, avg loss: 0.151414, loss: 0.024370, accuracy: 1.000000
Step: 330, avg loss: 0.154323, loss: 0.247405, accuracy: 0.900000
Step: 340, avg loss: 0.152275, loss: 0.084672, accuracy: 1.000000
Step: 350, avg loss: 0.149141, loss: 0.042594, accuracy: 1.000000
Step: 360, avg loss: 0.146430, loss: 0.051548, accuracy: 1.000000
Step: 370, avg loss: 0.145529, loss: 0.113104, accuracy: 1.000000
Step: 380, avg loss: 0.159394, loss: 0.672382, accuracy: 0.900000
Step: 390, avg loss: 0.157082, loss: 0.069246, accuracy: 1.000000
Step: 400, avg loss: 0.154619, loss: 0.058567, accuracy: 1.000000
Step: 410, avg loss: 0.154068, loss: 0.132001, accuracy: 1.000000
Step: 420, avg loss: 0.151386, loss: 0.041437, accuracy: 1.000000
Step: 430, avg loss: 0.148964, loss: 0.047225, accuracy: 1.000000
Step: 440, avg loss: 0.157445, loss: 0.522118, accuracy: 0.900000
Step: 450, avg loss: 0.157238, loss: 0.148149, accuracy: 0.900000
Step: 460, avg loss: 0.156891, loss: 0.141258, accuracy: 1.000000
Step: 470, avg loss: 0.166135, loss: 0.591398, accuracy: 0.800000
Step: 480, avg loss: 0.171474, loss: 0.422405, accuracy: 0.900000
Step: 490, avg loss: 0.175830, loss: 0.384877, accuracy: 0.900000
Step: 500, avg loss: 0.174844, loss: 0.126541, accuracy: 1.000000
Step: 510, avg loss: 0.179184, loss: 0.396196, accuracy: 0.800000
Step: 520, avg loss: 0.177288, loss: 0.080578, accuracy: 1.000000
Step: 530, avg loss: 0.175809, loss: 0.098932, accuracy: 1.000000
Step: 540, avg loss: 0.173157, loss: 0.032576, accuracy: 1.000000
Step: 550, avg loss: 0.183496, loss: 0.741812, accuracy: 0.800000
Step: 560, avg loss: 0.181916, loss: 0.095035, accuracy: 1.000000
Step: 570, avg loss: 0.180163, loss: 0.081973, accuracy: 1.000000
Step: 580, avg loss: 0.178028, loss: 0.056359, accuracy: 1.000000
Step: 590, avg loss: 0.181408, loss: 0.377399, accuracy: 0.900000
Step: 600, avg loss: 0.179535, loss: 0.069068, accuracy: 1.000000
Step: 610, avg loss: 0.180929, loss: 0.264532, accuracy: 0.900000
Step: 620, avg loss: 0.178825, loss: 0.050501, accuracy: 1.000000
Step: 630, avg loss: 0.176533, loss: 0.034403, accuracy: 1.000000
Step: 640, avg loss: 0.176597, loss: 0.180646, accuracy: 0.900000
Step: 650, avg loss: 0.174569, loss: 0.044778, accuracy: 1.000000
Step: 660, avg loss: 0.172783, loss: 0.056683, accuracy: 1.000000
Step: 670, avg loss: 0.182540, loss: 0.826519, accuracy: 0.800000
Step: 680, avg loss: 0.182081, loss: 0.151344, accuracy: 0.900000
Step: 690, avg loss: 0.181384, loss: 0.133992, accuracy: 0.900000
Step: 700, avg loss: 0.181601, loss: 0.196538, accuracy: 0.900000
Step: 710, avg loss: 0.180468, loss: 0.101170, accuracy: 1.000000
Step: 720, avg loss: 0.179767, loss: 0.130016, accuracy: 1.000000
Step: 730, avg loss: 0.178024, loss: 0.052485, accuracy: 1.000000
Step: 740, avg loss: 0.178872, loss: 0.240815, accuracy: 0.900000
Step: 750, avg loss: 0.177113, loss: 0.046945, accuracy: 1.000000
Step: 760, avg loss: 0.175051, loss: 0.020430, accuracy: 1.000000
Step: 770, avg loss: 0.173231, loss: 0.034860, accuracy: 1.000000
Step: 780, avg loss: 0.174188, loss: 0.247900, accuracy: 0.800000
Step: 790, avg loss: 0.172197, loss: 0.016860, accuracy: 1.000000
Step: 800, avg loss: 0.170231, loss: 0.014945, accuracy: 1.000000
Step: 810, avg loss: 0.168760, loss: 0.051059, accuracy: 1.000000
Step: 820, avg loss: 0.173163, loss: 0.529835, accuracy: 0.900000
Step: 830, avg loss: 0.171695, loss: 0.051336, accuracy: 1.000000
Step: 840, avg loss: 0.171563, loss: 0.160601, accuracy: 1.000000
Step: 850, avg loss: 0.169686, loss: 0.011980, accuracy: 1.000000
Step: 860, avg loss: 0.175511, loss: 0.670697, accuracy: 0.900000
Step: 870, avg loss: 0.173884, loss: 0.033892, accuracy: 1.000000
Step: 880, avg loss: 0.172374, loss: 0.041068, accuracy: 1.000000
Step: 890, avg loss: 0.174497, loss: 0.361282, accuracy: 0.900000
Step: 900, avg loss: 0.172991, loss: 0.038948, accuracy: 1.000000
Step: 910, avg loss: 0.177118, loss: 0.548606, accuracy: 0.900000
Step: 920, avg loss: 0.176873, loss: 0.154508, accuracy: 0.900000
Step: 930, avg loss: 0.176788, loss: 0.169017, accuracy: 0.900000
Step: 940, avg loss: 0.176799, loss: 0.177797, accuracy: 0.900000
Step: 950, avg loss: 0.175934, loss: 0.094658, accuracy: 1.000000
Step: 960, avg loss: 0.175116, loss: 0.097325, accuracy: 1.000000
Step: 970, avg loss: 0.173908, loss: 0.057987, accuracy: 1.000000
Step: 980, avg loss: 0.173258, loss: 0.110212, accuracy: 1.000000
Step: 990, avg loss: 0.171568, loss: 0.005954, accuracy: 1.000000
Step: 1000, avg loss: 0.170138, loss: 0.028600, accuracy: 1.000000
Step: 1010, avg loss: 0.168926, loss: 0.047709, accuracy: 1.000000
Step: 1020, avg loss: 0.167558, loss: 0.029370, accuracy: 1.000000
Step: 1030, avg loss: 0.166289, loss: 0.036866, accuracy: 1.000000
Step: 1040, avg loss: 0.164721, loss: 0.003244, accuracy: 1.000000
Step: 1050, avg loss: 0.163768, loss: 0.064587, accuracy: 1.000000
Step: 1060, avg loss: 0.162921, loss: 0.074040, accuracy: 1.000000
Step: 1070, avg loss: 0.162008, loss: 0.065243, accuracy: 1.000000
Step: 1080, avg loss: 0.161471, loss: 0.103921, accuracy: 1.000000
Step: 1090, avg loss: 0.160724, loss: 0.080055, accuracy: 1.000000
Step: 1100, avg loss: 0.159409, loss: 0.016161, accuracy: 1.000000
Step: 1110, avg loss: 0.158043, loss: 0.007699, accuracy: 1.000000
Step: 1120, avg loss: 0.160282, loss: 0.408850, accuracy: 0.900000
Step: 1130, avg loss: 0.159071, loss: 0.023382, accuracy: 1.000000
Step: 1140, avg loss: 0.170782, loss: 1.494192, accuracy: 0.700000
Step: 1150, avg loss: 0.173828, loss: 0.521062, accuracy: 0.900000
Step: 1160, avg loss: 0.180119, loss: 0.903588, accuracy: 0.800000
Step: 1170, avg loss: 0.181247, loss: 0.312089, accuracy: 0.900000
Step: 1180, avg loss: 0.184435, loss: 0.557483, accuracy: 0.900000
Step: 1190, avg loss: 0.184951, loss: 0.245736, accuracy: 0.900000
Step: 1200, avg loss: 0.189060, loss: 0.678050, accuracy: 0.800000
Step: 1210, avg loss: 0.189309, loss: 0.219264, accuracy: 0.900000
Step: 1220, avg loss: 0.188248, loss: 0.059865, accuracy: 1.000000
Step: 1230, avg loss: 0.187140, loss: 0.051927, accuracy: 1.000000
Step: 1240, avg loss: 0.186465, loss: 0.103401, accuracy: 1.000000
Step: 1250, avg loss: 0.185431, loss: 0.057220, accuracy: 1.000000
Step: 1260, avg loss: 0.184479, loss: 0.065452, accuracy: 1.000000
Epoch 13 finished in loss: 0.184212 and accuracy: 0.956418
Step: 10, avg loss: 0.306486, loss: 0.306486, accuracy: 0.900000
Step: 20, avg loss: 0.179455, loss: 0.052425, accuracy: 1.000000
Step: 30, avg loss: 0.151965, loss: 0.096984, accuracy: 1.000000
Step: 40, avg loss: 0.161545, loss: 0.190284, accuracy: 0.900000
Step: 50, avg loss: 0.143769, loss: 0.072666, accuracy: 1.000000
Step: 60, avg loss: 0.127944, loss: 0.048822, accuracy: 1.000000
Step: 70, avg loss: 0.117156, loss: 0.052423, accuracy: 1.000000
Step: 80, avg loss: 0.106978, loss: 0.035731, accuracy: 1.000000
Step: 90, avg loss: 0.182438, loss: 0.786116, accuracy: 0.800000
Step: 100, avg loss: 0.165976, loss: 0.017826, accuracy: 1.000000
Step: 110, avg loss: 0.158033, loss: 0.078594, accuracy: 1.000000
Step: 120, avg loss: 0.173639, loss: 0.345310, accuracy: 0.900000
Step: 130, avg loss: 0.167029, loss: 0.087713, accuracy: 1.000000
Step: 140, avg loss: 0.156384, loss: 0.018001, accuracy: 1.000000
Step: 150, avg loss: 0.159497, loss: 0.203072, accuracy: 0.900000
Step: 160, avg loss: 0.151586, loss: 0.032929, accuracy: 1.000000
Step: 170, avg loss: 0.164236, loss: 0.366634, accuracy: 0.800000
Step: 180, avg loss: 0.184205, loss: 0.523677, accuracy: 0.900000
Step: 190, avg loss: 0.195633, loss: 0.401332, accuracy: 0.900000
Step: 200, avg loss: 0.192543, loss: 0.133837, accuracy: 1.000000
Step: 210, avg loss: 0.214673, loss: 0.657275, accuracy: 0.800000
Step: 220, avg loss: 0.215525, loss: 0.233422, accuracy: 1.000000
Step: 230, avg loss: 0.209175, loss: 0.069458, accuracy: 1.000000
Step: 240, avg loss: 0.202677, loss: 0.053223, accuracy: 1.000000
Step: 250, avg loss: 0.198354, loss: 0.094602, accuracy: 1.000000
Step: 260, avg loss: 0.191913, loss: 0.030907, accuracy: 1.000000
Step: 270, avg loss: 0.188464, loss: 0.098790, accuracy: 1.000000
Step: 280, avg loss: 0.182249, loss: 0.014430, accuracy: 1.000000
Step: 290, avg loss: 0.178140, loss: 0.063104, accuracy: 1.000000
Step: 300, avg loss: 0.173095, loss: 0.026768, accuracy: 1.000000
Step: 310, avg loss: 0.169013, loss: 0.046552, accuracy: 1.000000
Step: 320, avg loss: 0.164453, loss: 0.023099, accuracy: 1.000000
Step: 330, avg loss: 0.161626, loss: 0.071177, accuracy: 1.000000
Step: 340, avg loss: 0.158554, loss: 0.057179, accuracy: 1.000000
Step: 350, avg loss: 0.155225, loss: 0.042012, accuracy: 1.000000
Step: 360, avg loss: 0.152392, loss: 0.053245, accuracy: 1.000000
Step: 370, avg loss: 0.150717, loss: 0.090426, accuracy: 1.000000
Step: 380, avg loss: 0.166283, loss: 0.742206, accuracy: 0.900000
Step: 390, avg loss: 0.166981, loss: 0.193509, accuracy: 0.900000
Step: 400, avg loss: 0.164410, loss: 0.064164, accuracy: 1.000000
Step: 410, avg loss: 0.162739, loss: 0.095872, accuracy: 1.000000
Step: 420, avg loss: 0.159746, loss: 0.037037, accuracy: 1.000000
Step: 430, avg loss: 0.157113, loss: 0.046523, accuracy: 1.000000
Step: 440, avg loss: 0.163781, loss: 0.450541, accuracy: 0.800000
Step: 450, avg loss: 0.170137, loss: 0.449796, accuracy: 0.900000
Step: 460, avg loss: 0.168201, loss: 0.081085, accuracy: 1.000000
Step: 470, avg loss: 0.177303, loss: 0.595972, accuracy: 0.900000
Step: 480, avg loss: 0.182734, loss: 0.437982, accuracy: 0.900000
Step: 490, avg loss: 0.187244, loss: 0.403759, accuracy: 0.900000
Step: 500, avg loss: 0.185917, loss: 0.120882, accuracy: 1.000000
Step: 510, avg loss: 0.186631, loss: 0.222320, accuracy: 0.900000
Step: 520, avg loss: 0.186527, loss: 0.181199, accuracy: 0.900000
Step: 530, avg loss: 0.185231, loss: 0.117863, accuracy: 1.000000
Step: 540, avg loss: 0.182334, loss: 0.028787, accuracy: 1.000000
Step: 550, avg loss: 0.195297, loss: 0.895325, accuracy: 0.700000
Step: 560, avg loss: 0.193745, loss: 0.108367, accuracy: 1.000000
Step: 570, avg loss: 0.192105, loss: 0.100266, accuracy: 1.000000
Step: 580, avg loss: 0.189815, loss: 0.059290, accuracy: 1.000000
Step: 590, avg loss: 0.189501, loss: 0.171259, accuracy: 0.900000
Step: 600, avg loss: 0.187137, loss: 0.047665, accuracy: 1.000000
Step: 610, avg loss: 0.187607, loss: 0.215813, accuracy: 0.900000
Step: 620, avg loss: 0.185488, loss: 0.056235, accuracy: 1.000000
Step: 630, avg loss: 0.183032, loss: 0.030780, accuracy: 1.000000
Step: 640, avg loss: 0.185410, loss: 0.335217, accuracy: 0.900000
Step: 650, avg loss: 0.183082, loss: 0.034080, accuracy: 1.000000
Step: 660, avg loss: 0.180886, loss: 0.038124, accuracy: 1.000000
Step: 670, avg loss: 0.187024, loss: 0.592146, accuracy: 0.900000
Step: 680, avg loss: 0.188797, loss: 0.307597, accuracy: 0.900000
Step: 690, avg loss: 0.187465, loss: 0.096874, accuracy: 1.000000
Step: 700, avg loss: 0.188110, loss: 0.232614, accuracy: 0.900000
Step: 710, avg loss: 0.186551, loss: 0.077456, accuracy: 1.000000
Step: 720, avg loss: 0.184825, loss: 0.062294, accuracy: 1.000000
Step: 730, avg loss: 0.182853, loss: 0.040830, accuracy: 1.000000
Step: 740, avg loss: 0.181832, loss: 0.107291, accuracy: 1.000000
Step: 750, avg loss: 0.179936, loss: 0.039620, accuracy: 1.000000
Step: 760, avg loss: 0.177784, loss: 0.016375, accuracy: 1.000000
Step: 770, avg loss: 0.175848, loss: 0.028728, accuracy: 1.000000
Step: 780, avg loss: 0.175632, loss: 0.159051, accuracy: 1.000000
Step: 790, avg loss: 0.173598, loss: 0.014918, accuracy: 1.000000
Step: 800, avg loss: 0.171823, loss: 0.031577, accuracy: 1.000000
Step: 810, avg loss: 0.170113, loss: 0.033316, accuracy: 1.000000
Step: 820, avg loss: 0.174442, loss: 0.525078, accuracy: 0.900000
Step: 830, avg loss: 0.172873, loss: 0.044272, accuracy: 1.000000
Step: 840, avg loss: 0.171861, loss: 0.087838, accuracy: 1.000000
Step: 850, avg loss: 0.170174, loss: 0.028504, accuracy: 1.000000
Step: 860, avg loss: 0.175372, loss: 0.617189, accuracy: 0.900000
Step: 870, avg loss: 0.173634, loss: 0.024163, accuracy: 1.000000
Step: 880, avg loss: 0.172678, loss: 0.089492, accuracy: 1.000000
Step: 890, avg loss: 0.172086, loss: 0.119963, accuracy: 0.900000
Step: 900, avg loss: 0.173055, loss: 0.259303, accuracy: 0.900000
Step: 910, avg loss: 0.176717, loss: 0.506291, accuracy: 0.900000
Step: 920, avg loss: 0.175849, loss: 0.096863, accuracy: 1.000000
Step: 930, avg loss: 0.178166, loss: 0.391370, accuracy: 0.800000
Step: 940, avg loss: 0.177178, loss: 0.085303, accuracy: 1.000000
Step: 950, avg loss: 0.175884, loss: 0.054234, accuracy: 1.000000
Step: 960, avg loss: 0.174666, loss: 0.058913, accuracy: 1.000000
Step: 970, avg loss: 0.173408, loss: 0.052689, accuracy: 1.000000
Step: 980, avg loss: 0.172453, loss: 0.079820, accuracy: 1.000000
Step: 990, avg loss: 0.170787, loss: 0.007478, accuracy: 1.000000
Step: 1000, avg loss: 0.169262, loss: 0.018288, accuracy: 1.000000
Step: 1010, avg loss: 0.167948, loss: 0.036519, accuracy: 1.000000
Step: 1020, avg loss: 0.166504, loss: 0.020726, accuracy: 1.000000
Step: 1030, avg loss: 0.165225, loss: 0.034761, accuracy: 1.000000
Step: 1040, avg loss: 0.163662, loss: 0.002676, accuracy: 1.000000
Step: 1050, avg loss: 0.162925, loss: 0.086210, accuracy: 1.000000
Step: 1060, avg loss: 0.161843, loss: 0.048251, accuracy: 1.000000
Step: 1070, avg loss: 0.160453, loss: 0.013178, accuracy: 1.000000
Step: 1080, avg loss: 0.159945, loss: 0.105600, accuracy: 1.000000
Step: 1090, avg loss: 0.158862, loss: 0.041842, accuracy: 1.000000
Step: 1100, avg loss: 0.157506, loss: 0.009704, accuracy: 1.000000
Step: 1110, avg loss: 0.156838, loss: 0.083377, accuracy: 0.900000
Step: 1120, avg loss: 0.160292, loss: 0.543644, accuracy: 0.900000
Step: 1130, avg loss: 0.159202, loss: 0.037204, accuracy: 1.000000
Step: 1140, avg loss: 0.167525, loss: 1.107998, accuracy: 0.800000
Step: 1150, avg loss: 0.168794, loss: 0.313447, accuracy: 0.900000
Step: 1160, avg loss: 0.172924, loss: 0.647862, accuracy: 0.800000
Step: 1170, avg loss: 0.173337, loss: 0.221260, accuracy: 0.900000
Step: 1180, avg loss: 0.177190, loss: 0.627973, accuracy: 0.900000
Step: 1190, avg loss: 0.179770, loss: 0.484237, accuracy: 0.900000
Step: 1200, avg loss: 0.183089, loss: 0.577973, accuracy: 0.900000
Step: 1210, avg loss: 0.183878, loss: 0.278586, accuracy: 0.900000
Step: 1220, avg loss: 0.182862, loss: 0.059981, accuracy: 1.000000
Step: 1230, avg loss: 0.181817, loss: 0.054248, accuracy: 1.000000
Step: 1240, avg loss: 0.180907, loss: 0.069036, accuracy: 1.000000
Step: 1250, avg loss: 0.179698, loss: 0.029764, accuracy: 1.000000
Step: 1260, avg loss: 0.178739, loss: 0.058850, accuracy: 1.000000
Epoch 14 finished in loss: 0.178475 and accuracy: 0.960380
Step: 10, avg loss: 0.408213, loss: 0.408213, accuracy: 0.800000
Step: 20, avg loss: 0.225645, loss: 0.043078, accuracy: 1.000000
Step: 30, avg loss: 0.176131, loss: 0.077102, accuracy: 1.000000
Step: 40, avg loss: 0.166088, loss: 0.135958, accuracy: 0.900000
Step: 50, avg loss: 0.141406, loss: 0.042679, accuracy: 1.000000
Step: 60, avg loss: 0.122357, loss: 0.027112, accuracy: 1.000000
Step: 70, avg loss: 0.109538, loss: 0.032627, accuracy: 1.000000
Step: 80, avg loss: 0.100867, loss: 0.040166, accuracy: 1.000000
Step: 90, avg loss: 0.166380, loss: 0.690489, accuracy: 0.900000
Step: 100, avg loss: 0.153602, loss: 0.038595, accuracy: 1.000000
Step: 110, avg loss: 0.145860, loss: 0.068437, accuracy: 1.000000
Step: 120, avg loss: 0.151184, loss: 0.209757, accuracy: 0.900000
Step: 130, avg loss: 0.147561, loss: 0.104077, accuracy: 0.900000
Step: 140, avg loss: 0.138138, loss: 0.015649, accuracy: 1.000000
Step: 150, avg loss: 0.136168, loss: 0.108581, accuracy: 1.000000
Step: 160, avg loss: 0.129801, loss: 0.034300, accuracy: 1.000000
Step: 170, avg loss: 0.133020, loss: 0.184521, accuracy: 0.900000
Step: 180, avg loss: 0.156480, loss: 0.555292, accuracy: 0.900000
Step: 190, avg loss: 0.151977, loss: 0.070931, accuracy: 1.000000
Step: 200, avg loss: 0.147838, loss: 0.069187, accuracy: 1.000000
Step: 210, avg loss: 0.172161, loss: 0.658638, accuracy: 0.800000
Step: 220, avg loss: 0.169272, loss: 0.108589, accuracy: 1.000000
Step: 230, avg loss: 0.173400, loss: 0.264232, accuracy: 0.900000
Step: 240, avg loss: 0.167948, loss: 0.042548, accuracy: 1.000000
Step: 250, avg loss: 0.164258, loss: 0.075694, accuracy: 1.000000
Step: 260, avg loss: 0.159202, loss: 0.032795, accuracy: 1.000000
Step: 270, avg loss: 0.156160, loss: 0.077065, accuracy: 1.000000
Step: 280, avg loss: 0.151134, loss: 0.015445, accuracy: 1.000000
Step: 290, avg loss: 0.148224, loss: 0.066741, accuracy: 1.000000
Step: 300, avg loss: 0.144255, loss: 0.029156, accuracy: 1.000000
Step: 310, avg loss: 0.140994, loss: 0.043165, accuracy: 1.000000
Step: 320, avg loss: 0.137326, loss: 0.023601, accuracy: 1.000000
Step: 330, avg loss: 0.138216, loss: 0.166716, accuracy: 0.900000
Step: 340, avg loss: 0.135933, loss: 0.060589, accuracy: 1.000000
Step: 350, avg loss: 0.133419, loss: 0.047930, accuracy: 1.000000
Step: 360, avg loss: 0.132806, loss: 0.111359, accuracy: 1.000000
Step: 370, avg loss: 0.131203, loss: 0.073495, accuracy: 1.000000
Step: 380, avg loss: 0.147035, loss: 0.732802, accuracy: 0.900000
Step: 390, avg loss: 0.148156, loss: 0.190769, accuracy: 0.900000
Step: 400, avg loss: 0.145629, loss: 0.047075, accuracy: 1.000000
Step: 410, avg loss: 0.144471, loss: 0.098173, accuracy: 1.000000
Step: 420, avg loss: 0.144885, loss: 0.161832, accuracy: 0.900000
Step: 430, avg loss: 0.143332, loss: 0.078116, accuracy: 1.000000
Step: 440, avg loss: 0.144409, loss: 0.190708, accuracy: 0.900000
Step: 450, avg loss: 0.142256, loss: 0.047531, accuracy: 1.000000
Step: 460, avg loss: 0.140757, loss: 0.073299, accuracy: 1.000000
Step: 470, avg loss: 0.149682, loss: 0.560259, accuracy: 0.900000
Step: 480, avg loss: 0.155731, loss: 0.439996, accuracy: 0.900000
Step: 490, avg loss: 0.160750, loss: 0.401659, accuracy: 0.900000
Step: 500, avg loss: 0.159832, loss: 0.114886, accuracy: 1.000000
Step: 510, avg loss: 0.162076, loss: 0.274282, accuracy: 0.800000
Step: 520, avg loss: 0.160737, loss: 0.092412, accuracy: 1.000000
Step: 530, avg loss: 0.159190, loss: 0.078780, accuracy: 1.000000
Step: 540, avg loss: 0.156793, loss: 0.029705, accuracy: 1.000000
Step: 550, avg loss: 0.167905, loss: 0.767958, accuracy: 0.800000
Step: 560, avg loss: 0.166552, loss: 0.092177, accuracy: 1.000000
Step: 570, avg loss: 0.165086, loss: 0.082988, accuracy: 1.000000
Step: 580, avg loss: 0.163414, loss: 0.068122, accuracy: 1.000000
Step: 590, avg loss: 0.161909, loss: 0.074573, accuracy: 1.000000
Step: 600, avg loss: 0.166934, loss: 0.463407, accuracy: 0.900000
Step: 610, avg loss: 0.164977, loss: 0.047547, accuracy: 1.000000
Step: 620, avg loss: 0.162971, loss: 0.040635, accuracy: 1.000000
Step: 630, avg loss: 0.160991, loss: 0.038211, accuracy: 1.000000
Step: 640, avg loss: 0.159162, loss: 0.043942, accuracy: 1.000000
Step: 650, avg loss: 0.164541, loss: 0.508835, accuracy: 0.900000
Step: 660, avg loss: 0.162674, loss: 0.041272, accuracy: 1.000000
Step: 670, avg loss: 0.169017, loss: 0.587694, accuracy: 0.900000
Step: 680, avg loss: 0.169239, loss: 0.184091, accuracy: 0.900000
Step: 690, avg loss: 0.167657, loss: 0.060087, accuracy: 1.000000
Step: 700, avg loss: 0.166228, loss: 0.067624, accuracy: 1.000000
Step: 710, avg loss: 0.164403, loss: 0.036640, accuracy: 1.000000
Step: 720, avg loss: 0.162759, loss: 0.046066, accuracy: 1.000000
Step: 730, avg loss: 0.160971, loss: 0.032206, accuracy: 1.000000
Step: 740, avg loss: 0.159725, loss: 0.068780, accuracy: 1.000000
Step: 750, avg loss: 0.158133, loss: 0.040331, accuracy: 1.000000
Step: 760, avg loss: 0.159844, loss: 0.288133, accuracy: 0.900000
Step: 770, avg loss: 0.158273, loss: 0.038872, accuracy: 1.000000
Step: 780, avg loss: 0.157578, loss: 0.104066, accuracy: 1.000000
Step: 790, avg loss: 0.160643, loss: 0.399713, accuracy: 0.900000
Step: 800, avg loss: 0.158733, loss: 0.007894, accuracy: 1.000000
Step: 810, avg loss: 0.157191, loss: 0.033805, accuracy: 1.000000
Step: 820, avg loss: 0.164170, loss: 0.729436, accuracy: 0.800000
Step: 830, avg loss: 0.162710, loss: 0.043036, accuracy: 1.000000
Step: 840, avg loss: 0.162645, loss: 0.157230, accuracy: 0.900000
Step: 850, avg loss: 0.161716, loss: 0.083726, accuracy: 1.000000
Step: 860, avg loss: 0.165401, loss: 0.478609, accuracy: 0.900000
Step: 870, avg loss: 0.164639, loss: 0.099089, accuracy: 0.900000
Step: 880, avg loss: 0.163587, loss: 0.072029, accuracy: 1.000000
Step: 890, avg loss: 0.162276, loss: 0.046919, accuracy: 1.000000
Step: 900, avg loss: 0.160916, loss: 0.039881, accuracy: 1.000000
Step: 910, avg loss: 0.166892, loss: 0.704760, accuracy: 0.800000
Step: 920, avg loss: 0.166252, loss: 0.108002, accuracy: 1.000000
Step: 930, avg loss: 0.164936, loss: 0.043853, accuracy: 1.000000
Step: 940, avg loss: 0.164411, loss: 0.115643, accuracy: 1.000000
Step: 950, avg loss: 0.163747, loss: 0.101292, accuracy: 1.000000
Step: 960, avg loss: 0.162469, loss: 0.041087, accuracy: 1.000000
Step: 970, avg loss: 0.161293, loss: 0.048336, accuracy: 1.000000
Step: 980, avg loss: 0.160190, loss: 0.053207, accuracy: 1.000000
Step: 990, avg loss: 0.158637, loss: 0.006453, accuracy: 1.000000
Step: 1000, avg loss: 0.157262, loss: 0.021180, accuracy: 1.000000
Step: 1010, avg loss: 0.156210, loss: 0.050972, accuracy: 1.000000
Step: 1020, avg loss: 0.154830, loss: 0.015436, accuracy: 1.000000
Step: 1030, avg loss: 0.153621, loss: 0.030372, accuracy: 1.000000
Step: 1040, avg loss: 0.152153, loss: 0.000932, accuracy: 1.000000
Step: 1050, avg loss: 0.152923, loss: 0.232936, accuracy: 0.900000
Step: 1060, avg loss: 0.151880, loss: 0.042449, accuracy: 1.000000
Step: 1070, avg loss: 0.153174, loss: 0.290331, accuracy: 0.900000
Step: 1080, avg loss: 0.152537, loss: 0.084296, accuracy: 1.000000
Step: 1090, avg loss: 0.151507, loss: 0.040311, accuracy: 1.000000
Step: 1100, avg loss: 0.150211, loss: 0.008923, accuracy: 1.000000
Step: 1110, avg loss: 0.148894, loss: 0.004074, accuracy: 1.000000
Step: 1120, avg loss: 0.149655, loss: 0.234061, accuracy: 0.900000
Step: 1130, avg loss: 0.148642, loss: 0.035267, accuracy: 1.000000
Step: 1140, avg loss: 0.149735, loss: 0.273199, accuracy: 0.900000
Step: 1150, avg loss: 0.151394, loss: 0.340554, accuracy: 0.800000
Step: 1160, avg loss: 0.153232, loss: 0.364557, accuracy: 0.900000
Step: 1170, avg loss: 0.153611, loss: 0.197612, accuracy: 0.900000
Step: 1180, avg loss: 0.157967, loss: 0.667577, accuracy: 0.800000
Step: 1190, avg loss: 0.159614, loss: 0.353937, accuracy: 0.900000
Step: 1200, avg loss: 0.162736, loss: 0.534342, accuracy: 0.900000
Step: 1210, avg loss: 0.162832, loss: 0.174319, accuracy: 0.900000
Step: 1220, avg loss: 0.161881, loss: 0.046834, accuracy: 1.000000
Step: 1230, avg loss: 0.161064, loss: 0.061405, accuracy: 1.000000
Step: 1240, avg loss: 0.160218, loss: 0.056131, accuracy: 1.000000
Step: 1250, avg loss: 0.159025, loss: 0.011019, accuracy: 1.000000
Step: 1260, avg loss: 0.158096, loss: 0.042049, accuracy: 1.000000
Epoch 15 finished in loss: 0.157864 and accuracy: 0.961173
Step: 10, avg loss: 0.193070, loss: 0.193070, accuracy: 0.900000
Step: 20, avg loss: 0.117545, loss: 0.042019, accuracy: 1.000000
Step: 30, avg loss: 0.094865, loss: 0.049507, accuracy: 1.000000
Step: 40, avg loss: 0.087319, loss: 0.064678, accuracy: 1.000000
Step: 50, avg loss: 0.079642, loss: 0.048933, accuracy: 1.000000
Step: 60, avg loss: 0.071794, loss: 0.032556, accuracy: 1.000000
Step: 70, avg loss: 0.065804, loss: 0.029861, accuracy: 1.000000
Step: 80, avg loss: 0.062098, loss: 0.036156, accuracy: 1.000000
Step: 90, avg loss: 0.130304, loss: 0.675958, accuracy: 0.900000
Step: 100, avg loss: 0.119119, loss: 0.018449, accuracy: 1.000000
Step: 110, avg loss: 0.114643, loss: 0.069888, accuracy: 1.000000
Step: 120, avg loss: 0.110345, loss: 0.063067, accuracy: 1.000000
Step: 130, avg loss: 0.105448, loss: 0.046686, accuracy: 1.000000
Step: 140, avg loss: 0.099092, loss: 0.016460, accuracy: 1.000000
Step: 150, avg loss: 0.096703, loss: 0.063254, accuracy: 1.000000
Step: 160, avg loss: 0.096274, loss: 0.089839, accuracy: 1.000000
Step: 170, avg loss: 0.092564, loss: 0.033199, accuracy: 1.000000
Step: 180, avg loss: 0.122015, loss: 0.622688, accuracy: 0.900000
Step: 190, avg loss: 0.120575, loss: 0.094664, accuracy: 1.000000
Step: 200, avg loss: 0.120372, loss: 0.116505, accuracy: 1.000000
Step: 210, avg loss: 0.141891, loss: 0.572266, accuracy: 0.800000
Step: 220, avg loss: 0.137865, loss: 0.053331, accuracy: 1.000000
Step: 230, avg loss: 0.132999, loss: 0.025937, accuracy: 1.000000
Step: 240, avg loss: 0.128807, loss: 0.032403, accuracy: 1.000000
Step: 250, avg loss: 0.125426, loss: 0.044281, accuracy: 1.000000
Step: 260, avg loss: 0.121831, loss: 0.031946, accuracy: 1.000000
Step: 270, avg loss: 0.119650, loss: 0.062960, accuracy: 1.000000
Step: 280, avg loss: 0.115862, loss: 0.013564, accuracy: 1.000000
Step: 290, avg loss: 0.113976, loss: 0.061168, accuracy: 1.000000
Step: 300, avg loss: 0.111204, loss: 0.030817, accuracy: 1.000000
Step: 310, avg loss: 0.109137, loss: 0.047140, accuracy: 1.000000
Step: 320, avg loss: 0.106588, loss: 0.027568, accuracy: 1.000000
Step: 330, avg loss: 0.112535, loss: 0.302852, accuracy: 0.900000
Step: 340, avg loss: 0.111018, loss: 0.060956, accuracy: 1.000000
Step: 350, avg loss: 0.109114, loss: 0.044378, accuracy: 1.000000
Step: 360, avg loss: 0.107698, loss: 0.058120, accuracy: 1.000000
Step: 370, avg loss: 0.110795, loss: 0.222308, accuracy: 0.900000
Step: 380, avg loss: 0.128534, loss: 0.784844, accuracy: 0.900000
Step: 390, avg loss: 0.129508, loss: 0.166546, accuracy: 0.900000
Step: 400, avg loss: 0.127651, loss: 0.055233, accuracy: 1.000000
Step: 410, avg loss: 0.126765, loss: 0.091296, accuracy: 1.000000
Step: 420, avg loss: 0.124429, loss: 0.028658, accuracy: 1.000000
Step: 430, avg loss: 0.122562, loss: 0.044147, accuracy: 1.000000
Step: 440, avg loss: 0.125843, loss: 0.266940, accuracy: 0.800000
Step: 450, avg loss: 0.125858, loss: 0.126493, accuracy: 0.900000
Step: 460, avg loss: 0.124785, loss: 0.076536, accuracy: 1.000000
Step: 470, avg loss: 0.134742, loss: 0.592736, accuracy: 0.900000
Step: 480, avg loss: 0.140925, loss: 0.431558, accuracy: 0.900000
Step: 490, avg loss: 0.146089, loss: 0.393927, accuracy: 0.900000
Step: 500, avg loss: 0.145593, loss: 0.121326, accuracy: 1.000000
Step: 510, avg loss: 0.143785, loss: 0.053350, accuracy: 1.000000
Step: 520, avg loss: 0.142849, loss: 0.095102, accuracy: 1.000000
Step: 530, avg loss: 0.141411, loss: 0.066655, accuracy: 1.000000
Step: 540, avg loss: 0.139282, loss: 0.026424, accuracy: 1.000000
Step: 550, avg loss: 0.150198, loss: 0.739662, accuracy: 0.800000
Step: 560, avg loss: 0.148680, loss: 0.065236, accuracy: 1.000000
Step: 570, avg loss: 0.149982, loss: 0.222895, accuracy: 0.900000
Step: 580, avg loss: 0.148510, loss: 0.064576, accuracy: 1.000000
Step: 590, avg loss: 0.147045, loss: 0.062110, accuracy: 1.000000
Step: 600, avg loss: 0.146438, loss: 0.110581, accuracy: 1.000000
Step: 610, avg loss: 0.145001, loss: 0.058792, accuracy: 1.000000
Step: 620, avg loss: 0.143261, loss: 0.037107, accuracy: 1.000000
Step: 630, avg loss: 0.141395, loss: 0.025691, accuracy: 1.000000
Step: 640, avg loss: 0.139919, loss: 0.046943, accuracy: 1.000000
Step: 650, avg loss: 0.138528, loss: 0.049504, accuracy: 1.000000
Step: 660, avg loss: 0.136992, loss: 0.037150, accuracy: 1.000000
Step: 670, avg loss: 0.144019, loss: 0.607818, accuracy: 0.900000
Step: 680, avg loss: 0.144475, loss: 0.174997, accuracy: 0.900000
Step: 690, avg loss: 0.143455, loss: 0.074145, accuracy: 1.000000
Step: 700, avg loss: 0.142743, loss: 0.093614, accuracy: 0.900000
Step: 710, avg loss: 0.141222, loss: 0.034733, accuracy: 1.000000
Step: 720, avg loss: 0.140149, loss: 0.063935, accuracy: 1.000000
Step: 730, avg loss: 0.138587, loss: 0.026153, accuracy: 1.000000
Step: 740, avg loss: 0.137628, loss: 0.067621, accuracy: 1.000000
Step: 750, avg loss: 0.136317, loss: 0.039286, accuracy: 1.000000
Step: 760, avg loss: 0.134717, loss: 0.014767, accuracy: 1.000000
Step: 770, avg loss: 0.133289, loss: 0.024741, accuracy: 1.000000
Step: 780, avg loss: 0.132904, loss: 0.103259, accuracy: 1.000000
Step: 790, avg loss: 0.131411, loss: 0.014949, accuracy: 1.000000
Step: 800, avg loss: 0.129806, loss: 0.003040, accuracy: 1.000000
Step: 810, avg loss: 0.128928, loss: 0.058639, accuracy: 1.000000
Step: 820, avg loss: 0.132800, loss: 0.446434, accuracy: 0.900000
Step: 830, avg loss: 0.131668, loss: 0.038849, accuracy: 1.000000
Step: 840, avg loss: 0.130900, loss: 0.067190, accuracy: 1.000000
Step: 850, avg loss: 0.129587, loss: 0.019308, accuracy: 1.000000
Step: 860, avg loss: 0.133242, loss: 0.443918, accuracy: 0.900000
Step: 870, avg loss: 0.132493, loss: 0.068002, accuracy: 1.000000
Step: 880, avg loss: 0.135255, loss: 0.375608, accuracy: 0.900000
Step: 890, avg loss: 0.134055, loss: 0.028402, accuracy: 1.000000
Step: 900, avg loss: 0.133511, loss: 0.085168, accuracy: 1.000000
Step: 910, avg loss: 0.138526, loss: 0.589847, accuracy: 0.900000
Step: 920, avg loss: 0.137631, loss: 0.056162, accuracy: 1.000000
Step: 930, avg loss: 0.137541, loss: 0.129305, accuracy: 0.900000
Step: 940, avg loss: 0.137089, loss: 0.095046, accuracy: 1.000000
Step: 950, avg loss: 0.136230, loss: 0.055492, accuracy: 1.000000
Step: 960, avg loss: 0.135190, loss: 0.036369, accuracy: 1.000000
Step: 970, avg loss: 0.134277, loss: 0.046638, accuracy: 1.000000
Step: 980, avg loss: 0.133559, loss: 0.063861, accuracy: 1.000000
Step: 990, avg loss: 0.132703, loss: 0.048876, accuracy: 1.000000
Step: 1000, avg loss: 0.131670, loss: 0.029367, accuracy: 1.000000
Step: 1010, avg loss: 0.136588, loss: 0.628430, accuracy: 0.900000
Step: 1020, avg loss: 0.138158, loss: 0.296703, accuracy: 0.900000
Step: 1030, avg loss: 0.137087, loss: 0.027847, accuracy: 1.000000
Step: 1040, avg loss: 0.135839, loss: 0.007282, accuracy: 1.000000
Step: 1050, avg loss: 0.135039, loss: 0.051813, accuracy: 1.000000
Step: 1060, avg loss: 0.135115, loss: 0.143153, accuracy: 0.900000
Step: 1070, avg loss: 0.133998, loss: 0.015520, accuracy: 1.000000
Step: 1080, avg loss: 0.133767, loss: 0.109133, accuracy: 1.000000
Step: 1090, avg loss: 0.136975, loss: 0.483434, accuracy: 0.900000
Step: 1100, avg loss: 0.135987, loss: 0.028212, accuracy: 1.000000
Step: 1110, avg loss: 0.135799, loss: 0.115182, accuracy: 0.900000
Step: 1120, avg loss: 0.135152, loss: 0.063276, accuracy: 1.000000
Step: 1130, avg loss: 0.134231, loss: 0.031129, accuracy: 1.000000
Step: 1140, avg loss: 0.134676, loss: 0.184959, accuracy: 0.900000
Step: 1150, avg loss: 0.135037, loss: 0.176133, accuracy: 0.900000
Step: 1160, avg loss: 0.137347, loss: 0.403027, accuracy: 0.800000
Step: 1170, avg loss: 0.138674, loss: 0.292584, accuracy: 0.900000
Step: 1180, avg loss: 0.143068, loss: 0.657234, accuracy: 0.900000
Step: 1190, avg loss: 0.147038, loss: 0.615502, accuracy: 0.800000
Step: 1200, avg loss: 0.151445, loss: 0.675803, accuracy: 0.800000
Step: 1210, avg loss: 0.151596, loss: 0.169730, accuracy: 1.000000
Step: 1220, avg loss: 0.150742, loss: 0.047475, accuracy: 1.000000
Step: 1230, avg loss: 0.149891, loss: 0.045997, accuracy: 1.000000
Step: 1240, avg loss: 0.149152, loss: 0.058257, accuracy: 1.000000
Step: 1250, avg loss: 0.148161, loss: 0.025320, accuracy: 1.000000
Step: 1260, avg loss: 0.147433, loss: 0.056426, accuracy: 1.000000
Epoch 16 finished in loss: 0.147234 and accuracy: 0.967512
Step: 10, avg loss: 0.181458, loss: 0.181458, accuracy: 0.900000
Step: 20, avg loss: 0.159230, loss: 0.137003, accuracy: 0.900000
Step: 30, avg loss: 0.202325, loss: 0.288514, accuracy: 0.900000
Step: 40, avg loss: 0.177942, loss: 0.104795, accuracy: 1.000000
Step: 50, avg loss: 0.149298, loss: 0.034721, accuracy: 1.000000
Step: 60, avg loss: 0.129930, loss: 0.033088, accuracy: 1.000000
Step: 70, avg loss: 0.114162, loss: 0.019555, accuracy: 1.000000
Step: 80, avg loss: 0.103159, loss: 0.026138, accuracy: 1.000000
Step: 90, avg loss: 0.163189, loss: 0.643435, accuracy: 0.900000
Step: 100, avg loss: 0.151298, loss: 0.044275, accuracy: 1.000000
Step: 110, avg loss: 0.143398, loss: 0.064395, accuracy: 1.000000
Step: 120, avg loss: 0.133983, loss: 0.030418, accuracy: 1.000000
Step: 130, avg loss: 0.128049, loss: 0.056843, accuracy: 1.000000
Step: 140, avg loss: 0.120130, loss: 0.017186, accuracy: 1.000000
Step: 150, avg loss: 0.119845, loss: 0.115850, accuracy: 1.000000
Step: 160, avg loss: 0.115185, loss: 0.045283, accuracy: 1.000000
Step: 170, avg loss: 0.109370, loss: 0.016334, accuracy: 1.000000
Step: 180, avg loss: 0.137215, loss: 0.610572, accuracy: 0.900000
Step: 190, avg loss: 0.134023, loss: 0.076580, accuracy: 1.000000
Step: 200, avg loss: 0.129044, loss: 0.034442, accuracy: 1.000000
Step: 210, avg loss: 0.149023, loss: 0.548597, accuracy: 0.800000
Step: 220, avg loss: 0.144947, loss: 0.059359, accuracy: 1.000000
Step: 230, avg loss: 0.140418, loss: 0.040775, accuracy: 1.000000
Step: 240, avg loss: 0.136592, loss: 0.048584, accuracy: 1.000000
Step: 250, avg loss: 0.136686, loss: 0.138961, accuracy: 1.000000
Step: 260, avg loss: 0.132533, loss: 0.028690, accuracy: 1.000000
Step: 270, avg loss: 0.129437, loss: 0.048943, accuracy: 1.000000
Step: 280, avg loss: 0.125103, loss: 0.008081, accuracy: 1.000000
Step: 290, avg loss: 0.122770, loss: 0.057460, accuracy: 1.000000
Step: 300, avg loss: 0.119633, loss: 0.028655, accuracy: 1.000000
Step: 310, avg loss: 0.117628, loss: 0.057479, accuracy: 1.000000
Step: 320, avg loss: 0.114740, loss: 0.025223, accuracy: 1.000000
Step: 330, avg loss: 0.113205, loss: 0.064068, accuracy: 1.000000
Step: 340, avg loss: 0.112700, loss: 0.096054, accuracy: 1.000000
Step: 350, avg loss: 0.110701, loss: 0.042707, accuracy: 1.000000
Step: 360, avg loss: 0.108972, loss: 0.048487, accuracy: 1.000000
Step: 370, avg loss: 0.120491, loss: 0.535146, accuracy: 0.900000
Step: 380, avg loss: 0.140866, loss: 0.894748, accuracy: 0.700000
Step: 390, avg loss: 0.138687, loss: 0.055878, accuracy: 1.000000
Step: 400, avg loss: 0.136474, loss: 0.050182, accuracy: 1.000000
Step: 410, avg loss: 0.135104, loss: 0.080289, accuracy: 1.000000
Step: 420, avg loss: 0.137744, loss: 0.246012, accuracy: 0.900000
Step: 430, avg loss: 0.135624, loss: 0.046556, accuracy: 1.000000
Step: 440, avg loss: 0.134291, loss: 0.076996, accuracy: 1.000000
Step: 450, avg loss: 0.132173, loss: 0.038949, accuracy: 1.000000
Step: 460, avg loss: 0.131000, loss: 0.078232, accuracy: 1.000000
Step: 470, avg loss: 0.140479, loss: 0.576499, accuracy: 0.900000
Step: 480, avg loss: 0.146572, loss: 0.432951, accuracy: 0.900000
Step: 490, avg loss: 0.157056, loss: 0.660297, accuracy: 0.800000
Step: 500, avg loss: 0.156259, loss: 0.117189, accuracy: 1.000000
Step: 510, avg loss: 0.154803, loss: 0.082036, accuracy: 1.000000
Step: 520, avg loss: 0.153339, loss: 0.078659, accuracy: 1.000000
Step: 530, avg loss: 0.151864, loss: 0.075143, accuracy: 1.000000
Step: 540, avg loss: 0.149652, loss: 0.032416, accuracy: 1.000000
Step: 550, avg loss: 0.160386, loss: 0.740046, accuracy: 0.800000
Step: 560, avg loss: 0.159197, loss: 0.093799, accuracy: 1.000000
Step: 570, avg loss: 0.157670, loss: 0.072142, accuracy: 1.000000
Step: 580, avg loss: 0.156041, loss: 0.063182, accuracy: 1.000000
Step: 590, avg loss: 0.154426, loss: 0.060750, accuracy: 1.000000
Step: 600, avg loss: 0.152719, loss: 0.052028, accuracy: 1.000000
Step: 610, avg loss: 0.150737, loss: 0.031819, accuracy: 1.000000
Step: 620, avg loss: 0.148927, loss: 0.038506, accuracy: 1.000000
Step: 630, avg loss: 0.146902, loss: 0.021344, accuracy: 1.000000
Step: 640, avg loss: 0.145392, loss: 0.050276, accuracy: 1.000000
Step: 650, avg loss: 0.143596, loss: 0.028679, accuracy: 1.000000
Step: 660, avg loss: 0.141976, loss: 0.036681, accuracy: 1.000000
Step: 670, avg loss: 0.149082, loss: 0.618080, accuracy: 0.900000
Step: 680, avg loss: 0.148021, loss: 0.076913, accuracy: 1.000000
Step: 690, avg loss: 0.146489, loss: 0.042328, accuracy: 1.000000
Step: 700, avg loss: 0.144645, loss: 0.017400, accuracy: 1.000000
Step: 710, avg loss: 0.143004, loss: 0.028155, accuracy: 1.000000
Step: 720, avg loss: 0.145125, loss: 0.295664, accuracy: 0.900000
Step: 730, avg loss: 0.143518, loss: 0.027857, accuracy: 1.000000
Step: 740, avg loss: 0.145009, loss: 0.253806, accuracy: 0.900000
Step: 750, avg loss: 0.143535, loss: 0.034500, accuracy: 1.000000
Step: 760, avg loss: 0.141888, loss: 0.018375, accuracy: 1.000000
Step: 770, avg loss: 0.140366, loss: 0.024665, accuracy: 1.000000
Step: 780, avg loss: 0.139568, loss: 0.078138, accuracy: 1.000000
Step: 790, avg loss: 0.137982, loss: 0.014258, accuracy: 1.000000
Step: 800, avg loss: 0.136741, loss: 0.038725, accuracy: 1.000000
Step: 810, avg loss: 0.135466, loss: 0.033447, accuracy: 1.000000
Step: 820, avg loss: 0.136996, loss: 0.260914, accuracy: 0.900000
Step: 830, avg loss: 0.135805, loss: 0.038174, accuracy: 1.000000
Step: 840, avg loss: 0.134688, loss: 0.041985, accuracy: 1.000000
Step: 850, avg loss: 0.133892, loss: 0.067018, accuracy: 1.000000
Step: 860, avg loss: 0.137066, loss: 0.406857, accuracy: 0.900000
Step: 870, avg loss: 0.135796, loss: 0.026532, accuracy: 1.000000
Step: 880, avg loss: 0.134579, loss: 0.028702, accuracy: 1.000000
Step: 890, avg loss: 0.133912, loss: 0.075270, accuracy: 1.000000
Step: 900, avg loss: 0.132622, loss: 0.017741, accuracy: 1.000000
Step: 910, avg loss: 0.138739, loss: 0.689298, accuracy: 0.900000
Step: 920, avg loss: 0.137706, loss: 0.043710, accuracy: 1.000000
Step: 930, avg loss: 0.136564, loss: 0.031503, accuracy: 1.000000
Step: 940, avg loss: 0.136032, loss: 0.086514, accuracy: 1.000000
Step: 950, avg loss: 0.135545, loss: 0.089796, accuracy: 1.000000
Step: 960, avg loss: 0.134693, loss: 0.053795, accuracy: 1.000000
Step: 970, avg loss: 0.133752, loss: 0.043399, accuracy: 1.000000
Step: 980, avg loss: 0.133047, loss: 0.064666, accuracy: 1.000000
Step: 990, avg loss: 0.131746, loss: 0.004277, accuracy: 1.000000
Step: 1000, avg loss: 0.130694, loss: 0.026487, accuracy: 1.000000
Step: 1010, avg loss: 0.133217, loss: 0.385568, accuracy: 0.900000
Step: 1020, avg loss: 0.132124, loss: 0.021738, accuracy: 1.000000
Step: 1030, avg loss: 0.131084, loss: 0.025003, accuracy: 1.000000
Step: 1040, avg loss: 0.129848, loss: 0.002523, accuracy: 1.000000
Step: 1050, avg loss: 0.129468, loss: 0.089960, accuracy: 1.000000
Step: 1060, avg loss: 0.130406, loss: 0.228857, accuracy: 0.900000
Step: 1070, avg loss: 0.130056, loss: 0.092936, accuracy: 0.900000
Step: 1080, avg loss: 0.129843, loss: 0.107119, accuracy: 1.000000
Step: 1090, avg loss: 0.131627, loss: 0.324227, accuracy: 0.900000
Step: 1100, avg loss: 0.132660, loss: 0.245330, accuracy: 0.900000
Step: 1110, avg loss: 0.131977, loss: 0.056759, accuracy: 1.000000
Step: 1120, avg loss: 0.131035, loss: 0.026478, accuracy: 1.000000
Step: 1130, avg loss: 0.130392, loss: 0.058434, accuracy: 1.000000
Step: 1140, avg loss: 0.130165, loss: 0.104488, accuracy: 1.000000
Step: 1150, avg loss: 0.130411, loss: 0.158425, accuracy: 0.900000
Step: 1160, avg loss: 0.131453, loss: 0.251303, accuracy: 0.900000
Step: 1170, avg loss: 0.133557, loss: 0.377618, accuracy: 0.800000
Step: 1180, avg loss: 0.138184, loss: 0.679506, accuracy: 0.900000
Step: 1190, avg loss: 0.137875, loss: 0.101483, accuracy: 1.000000
Step: 1200, avg loss: 0.141494, loss: 0.572163, accuracy: 0.900000
Step: 1210, avg loss: 0.141879, loss: 0.188015, accuracy: 0.900000
Step: 1220, avg loss: 0.141031, loss: 0.038465, accuracy: 1.000000
Step: 1230, avg loss: 0.140108, loss: 0.027452, accuracy: 1.000000
Step: 1240, avg loss: 0.139528, loss: 0.068293, accuracy: 1.000000
Step: 1250, avg loss: 0.138506, loss: 0.011663, accuracy: 1.000000
Step: 1260, avg loss: 0.137746, loss: 0.042747, accuracy: 1.000000
Epoch 17 finished in loss: 0.137544 and accuracy: 0.971474
Step: 10, avg loss: 0.111763, loss: 0.111763, accuracy: 1.000000
Step: 20, avg loss: 0.074846, loss: 0.037929, accuracy: 1.000000
Step: 30, avg loss: 0.064776, loss: 0.044637, accuracy: 1.000000
Step: 40, avg loss: 0.062451, loss: 0.055475, accuracy: 1.000000
Step: 50, avg loss: 0.056088, loss: 0.030637, accuracy: 1.000000
Step: 60, avg loss: 0.051957, loss: 0.031303, accuracy: 1.000000
Step: 70, avg loss: 0.045253, loss: 0.005031, accuracy: 1.000000
Step: 80, avg loss: 0.043350, loss: 0.030025, accuracy: 1.000000
Step: 90, avg loss: 0.111552, loss: 0.657173, accuracy: 0.900000
Step: 100, avg loss: 0.102731, loss: 0.023343, accuracy: 1.000000
Step: 110, avg loss: 0.098644, loss: 0.057771, accuracy: 1.000000
Step: 120, avg loss: 0.091134, loss: 0.008522, accuracy: 1.000000
Step: 130, avg loss: 0.087064, loss: 0.038230, accuracy: 1.000000
Step: 140, avg loss: 0.082136, loss: 0.018073, accuracy: 1.000000
Step: 150, avg loss: 0.080966, loss: 0.064581, accuracy: 1.000000
Step: 160, avg loss: 0.078247, loss: 0.037461, accuracy: 1.000000
Step: 170, avg loss: 0.075058, loss: 0.024041, accuracy: 1.000000
Step: 180, avg loss: 0.105305, loss: 0.619504, accuracy: 0.900000
Step: 190, avg loss: 0.103732, loss: 0.075405, accuracy: 1.000000
Step: 200, avg loss: 0.100298, loss: 0.035057, accuracy: 1.000000
Step: 210, avg loss: 0.119217, loss: 0.497607, accuracy: 0.900000
Step: 220, avg loss: 0.116398, loss: 0.057193, accuracy: 1.000000
Step: 230, avg loss: 0.112642, loss: 0.030011, accuracy: 1.000000
Step: 240, avg loss: 0.109571, loss: 0.038935, accuracy: 1.000000
Step: 250, avg loss: 0.107923, loss: 0.068368, accuracy: 1.000000
Step: 260, avg loss: 0.104930, loss: 0.030108, accuracy: 1.000000
Step: 270, avg loss: 0.102766, loss: 0.046512, accuracy: 1.000000
Step: 280, avg loss: 0.099327, loss: 0.006452, accuracy: 1.000000
Step: 290, avg loss: 0.097872, loss: 0.057152, accuracy: 1.000000
Step: 300, avg loss: 0.095684, loss: 0.032234, accuracy: 1.000000
Step: 310, avg loss: 0.093972, loss: 0.042603, accuracy: 1.000000
Step: 320, avg loss: 0.097152, loss: 0.195723, accuracy: 0.900000
Step: 330, avg loss: 0.096450, loss: 0.073978, accuracy: 1.000000
Step: 340, avg loss: 0.095449, loss: 0.062423, accuracy: 1.000000
Step: 350, avg loss: 0.093986, loss: 0.044245, accuracy: 1.000000
Step: 360, avg loss: 0.092630, loss: 0.045170, accuracy: 1.000000
Step: 370, avg loss: 0.091983, loss: 0.068696, accuracy: 1.000000
Step: 380, avg loss: 0.107760, loss: 0.691521, accuracy: 0.900000
Step: 390, avg loss: 0.106568, loss: 0.061279, accuracy: 1.000000
Step: 400, avg loss: 0.105135, loss: 0.049242, accuracy: 1.000000
Step: 410, avg loss: 0.104587, loss: 0.082660, accuracy: 1.000000
Step: 420, avg loss: 0.102648, loss: 0.023144, accuracy: 1.000000
Step: 430, avg loss: 0.101353, loss: 0.046948, accuracy: 1.000000
Step: 440, avg loss: 0.103167, loss: 0.181177, accuracy: 0.900000
Step: 450, avg loss: 0.102181, loss: 0.058784, accuracy: 1.000000
Step: 460, avg loss: 0.101544, loss: 0.072910, accuracy: 1.000000
Step: 470, avg loss: 0.111711, loss: 0.579367, accuracy: 0.900000
Step: 480, avg loss: 0.118215, loss: 0.423902, accuracy: 0.900000
Step: 490, avg loss: 0.123502, loss: 0.377300, accuracy: 0.900000
Step: 500, avg loss: 0.123473, loss: 0.122037, accuracy: 1.000000
Step: 510, avg loss: 0.122500, loss: 0.073883, accuracy: 1.000000
Step: 520, avg loss: 0.121498, loss: 0.070399, accuracy: 1.000000
Step: 530, avg loss: 0.121036, loss: 0.096965, accuracy: 1.000000
Step: 540, avg loss: 0.119985, loss: 0.064319, accuracy: 1.000000
Step: 550, avg loss: 0.132019, loss: 0.781847, accuracy: 0.800000
Step: 560, avg loss: 0.130839, loss: 0.065928, accuracy: 1.000000
Step: 570, avg loss: 0.131766, loss: 0.183702, accuracy: 0.900000
Step: 580, avg loss: 0.131717, loss: 0.128932, accuracy: 0.900000
Step: 590, avg loss: 0.131454, loss: 0.116194, accuracy: 1.000000
Step: 600, avg loss: 0.130059, loss: 0.047760, accuracy: 1.000000
Step: 610, avg loss: 0.129247, loss: 0.080525, accuracy: 1.000000
Step: 620, avg loss: 0.127936, loss: 0.047910, accuracy: 1.000000
Step: 630, avg loss: 0.126274, loss: 0.023255, accuracy: 1.000000
Step: 640, avg loss: 0.128378, loss: 0.260938, accuracy: 0.900000
Step: 650, avg loss: 0.131508, loss: 0.331802, accuracy: 0.900000
Step: 660, avg loss: 0.130499, loss: 0.064926, accuracy: 1.000000
Step: 670, avg loss: 0.136413, loss: 0.526775, accuracy: 0.900000
Step: 680, avg loss: 0.135456, loss: 0.071335, accuracy: 1.000000
Step: 690, avg loss: 0.134197, loss: 0.048536, accuracy: 1.000000
Step: 700, avg loss: 0.132669, loss: 0.027278, accuracy: 1.000000
Step: 710, avg loss: 0.131210, loss: 0.029031, accuracy: 1.000000
Step: 720, avg loss: 0.129768, loss: 0.027416, accuracy: 1.000000
Step: 730, avg loss: 0.128494, loss: 0.036798, accuracy: 1.000000
Step: 740, avg loss: 0.129269, loss: 0.185842, accuracy: 0.900000
Step: 750, avg loss: 0.128075, loss: 0.039723, accuracy: 1.000000
Step: 760, avg loss: 0.126663, loss: 0.020763, accuracy: 1.000000
Step: 770, avg loss: 0.125347, loss: 0.025327, accuracy: 1.000000
Step: 780, avg loss: 0.124558, loss: 0.063812, accuracy: 1.000000
Step: 790, avg loss: 0.123690, loss: 0.055944, accuracy: 1.000000
Step: 800, avg loss: 0.122323, loss: 0.014365, accuracy: 1.000000
Step: 810, avg loss: 0.121312, loss: 0.040394, accuracy: 1.000000
Step: 820, avg loss: 0.124574, loss: 0.388809, accuracy: 0.900000
Step: 830, avg loss: 0.123538, loss: 0.038578, accuracy: 1.000000
Step: 840, avg loss: 0.123935, loss: 0.156929, accuracy: 0.900000
Step: 850, avg loss: 0.125555, loss: 0.261638, accuracy: 0.800000
Step: 860, avg loss: 0.128393, loss: 0.369585, accuracy: 0.900000
Step: 870, avg loss: 0.127086, loss: 0.014645, accuracy: 1.000000
Step: 880, avg loss: 0.125953, loss: 0.027400, accuracy: 1.000000
Step: 890, avg loss: 0.124815, loss: 0.024674, accuracy: 1.000000
Step: 900, avg loss: 0.124354, loss: 0.083382, accuracy: 1.000000
Step: 910, avg loss: 0.129718, loss: 0.612436, accuracy: 0.900000
Step: 920, avg loss: 0.128934, loss: 0.057544, accuracy: 1.000000
Step: 930, avg loss: 0.127693, loss: 0.013580, accuracy: 1.000000
Step: 940, avg loss: 0.127144, loss: 0.076084, accuracy: 1.000000
Step: 950, avg loss: 0.126368, loss: 0.053460, accuracy: 1.000000
Step: 960, avg loss: 0.125437, loss: 0.036982, accuracy: 1.000000
Step: 970, avg loss: 0.124597, loss: 0.043920, accuracy: 1.000000
Step: 980, avg loss: 0.123975, loss: 0.063679, accuracy: 1.000000
Step: 990, avg loss: 0.122775, loss: 0.005160, accuracy: 1.000000
Step: 1000, avg loss: 0.121741, loss: 0.019305, accuracy: 1.000000
Step: 1010, avg loss: 0.120942, loss: 0.041090, accuracy: 1.000000
Step: 1020, avg loss: 0.120175, loss: 0.042725, accuracy: 1.000000
Step: 1030, avg loss: 0.119266, loss: 0.026565, accuracy: 1.000000
Step: 1040, avg loss: 0.118158, loss: 0.003954, accuracy: 1.000000
Step: 1050, avg loss: 0.117476, loss: 0.046558, accuracy: 1.000000
Step: 1060, avg loss: 0.116866, loss: 0.052806, accuracy: 1.000000
Step: 1070, avg loss: 0.115907, loss: 0.014310, accuracy: 1.000000
Step: 1080, avg loss: 0.115864, loss: 0.111283, accuracy: 1.000000
Step: 1090, avg loss: 0.116840, loss: 0.222225, accuracy: 0.900000
Step: 1100, avg loss: 0.115931, loss: 0.016847, accuracy: 1.000000
Step: 1110, avg loss: 0.114937, loss: 0.005548, accuracy: 1.000000
Step: 1120, avg loss: 0.114120, loss: 0.023490, accuracy: 1.000000
Step: 1130, avg loss: 0.113520, loss: 0.046304, accuracy: 1.000000
Step: 1140, avg loss: 0.113501, loss: 0.111371, accuracy: 1.000000
Step: 1150, avg loss: 0.114665, loss: 0.247352, accuracy: 0.900000
Step: 1160, avg loss: 0.114752, loss: 0.124782, accuracy: 1.000000
Step: 1170, avg loss: 0.115504, loss: 0.202703, accuracy: 0.900000
Step: 1180, avg loss: 0.120255, loss: 0.676160, accuracy: 0.900000
Step: 1190, avg loss: 0.121228, loss: 0.235948, accuracy: 0.900000
Step: 1200, avg loss: 0.124776, loss: 0.547014, accuracy: 0.900000
Step: 1210, avg loss: 0.128028, loss: 0.518286, accuracy: 0.900000
Step: 1220, avg loss: 0.127400, loss: 0.051457, accuracy: 1.000000
Step: 1230, avg loss: 0.126581, loss: 0.026633, accuracy: 1.000000
Step: 1240, avg loss: 0.126094, loss: 0.066191, accuracy: 1.000000
Step: 1250, avg loss: 0.125185, loss: 0.012525, accuracy: 1.000000
Step: 1260, avg loss: 0.124652, loss: 0.058012, accuracy: 1.000000
Epoch 18 finished in loss: 0.124474 and accuracy: 0.976228
Step: 10, avg loss: 0.066870, loss: 0.066870, accuracy: 1.000000
Step: 20, avg loss: 0.052480, loss: 0.038091, accuracy: 1.000000
Step: 30, avg loss: 0.048953, loss: 0.041897, accuracy: 1.000000
Step: 40, avg loss: 0.045308, loss: 0.034372, accuracy: 1.000000
Step: 50, avg loss: 0.041556, loss: 0.026549, accuracy: 1.000000
Step: 60, avg loss: 0.039832, loss: 0.031210, accuracy: 1.000000
Step: 70, avg loss: 0.035006, loss: 0.006052, accuracy: 1.000000
Step: 80, avg loss: 0.034271, loss: 0.029131, accuracy: 1.000000
Step: 90, avg loss: 0.104460, loss: 0.665964, accuracy: 0.900000
Step: 100, avg loss: 0.096195, loss: 0.021810, accuracy: 1.000000
Step: 110, avg loss: 0.092668, loss: 0.057406, accuracy: 1.000000
Step: 120, avg loss: 0.085512, loss: 0.006791, accuracy: 1.000000
Step: 130, avg loss: 0.080634, loss: 0.022100, accuracy: 1.000000
Step: 140, avg loss: 0.076301, loss: 0.019970, accuracy: 1.000000
Step: 150, avg loss: 0.075542, loss: 0.064918, accuracy: 1.000000
Step: 160, avg loss: 0.073014, loss: 0.035088, accuracy: 1.000000
Step: 170, avg loss: 0.069703, loss: 0.016733, accuracy: 1.000000
Step: 180, avg loss: 0.100396, loss: 0.622176, accuracy: 0.900000
Step: 190, avg loss: 0.098235, loss: 0.059337, accuracy: 1.000000
Step: 200, avg loss: 0.118191, loss: 0.497347, accuracy: 0.900000
Step: 210, avg loss: 0.135066, loss: 0.472584, accuracy: 0.900000
Step: 220, avg loss: 0.139566, loss: 0.234055, accuracy: 0.900000
Step: 230, avg loss: 0.135333, loss: 0.042198, accuracy: 1.000000
Step: 240, avg loss: 0.131289, loss: 0.038296, accuracy: 1.000000
Step: 250, avg loss: 0.128917, loss: 0.071974, accuracy: 1.000000
Step: 260, avg loss: 0.125132, loss: 0.030517, accuracy: 1.000000
Step: 270, avg loss: 0.122461, loss: 0.053009, accuracy: 1.000000
Step: 280, avg loss: 0.119222, loss: 0.031765, accuracy: 1.000000
Step: 290, avg loss: 0.117148, loss: 0.059080, accuracy: 1.000000
Step: 300, avg loss: 0.114116, loss: 0.026189, accuracy: 1.000000
Step: 310, avg loss: 0.112131, loss: 0.052577, accuracy: 1.000000
Step: 320, avg loss: 0.109407, loss: 0.024965, accuracy: 1.000000
Step: 330, avg loss: 0.108950, loss: 0.094326, accuracy: 1.000000
Step: 340, avg loss: 0.107589, loss: 0.062687, accuracy: 1.000000
Step: 350, avg loss: 0.105862, loss: 0.047137, accuracy: 1.000000
Step: 360, avg loss: 0.104382, loss: 0.052569, accuracy: 1.000000
Step: 370, avg loss: 0.112428, loss: 0.402085, accuracy: 0.900000
Step: 380, avg loss: 0.126821, loss: 0.659360, accuracy: 0.900000
Step: 390, avg loss: 0.124768, loss: 0.046767, accuracy: 1.000000
Step: 400, avg loss: 0.123093, loss: 0.057755, accuracy: 1.000000
Step: 410, avg loss: 0.122079, loss: 0.081545, accuracy: 1.000000
Step: 420, avg loss: 0.119703, loss: 0.022279, accuracy: 1.000000
Step: 430, avg loss: 0.117969, loss: 0.045139, accuracy: 1.000000
Step: 440, avg loss: 0.122610, loss: 0.322180, accuracy: 0.900000
Step: 450, avg loss: 0.120732, loss: 0.038081, accuracy: 1.000000
Step: 460, avg loss: 0.119546, loss: 0.066181, accuracy: 1.000000
Step: 470, avg loss: 0.129114, loss: 0.569266, accuracy: 0.900000
Step: 480, avg loss: 0.135260, loss: 0.424081, accuracy: 0.900000
Step: 490, avg loss: 0.140405, loss: 0.387375, accuracy: 0.900000
Step: 500, avg loss: 0.139976, loss: 0.118968, accuracy: 1.000000
Step: 510, avg loss: 0.138281, loss: 0.053509, accuracy: 1.000000
Step: 520, avg loss: 0.137289, loss: 0.086738, accuracy: 1.000000
Step: 530, avg loss: 0.135735, loss: 0.054915, accuracy: 1.000000
Step: 540, avg loss: 0.133665, loss: 0.023932, accuracy: 1.000000
Step: 550, avg loss: 0.144938, loss: 0.753719, accuracy: 0.800000
Step: 560, avg loss: 0.143497, loss: 0.064191, accuracy: 1.000000
Step: 570, avg loss: 0.142076, loss: 0.062524, accuracy: 1.000000
Step: 580, avg loss: 0.140576, loss: 0.055096, accuracy: 1.000000
Step: 590, avg loss: 0.139256, loss: 0.062669, accuracy: 1.000000
Step: 600, avg loss: 0.137871, loss: 0.056172, accuracy: 1.000000
Step: 610, avg loss: 0.136630, loss: 0.062159, accuracy: 1.000000
Step: 620, avg loss: 0.135081, loss: 0.040622, accuracy: 1.000000
Step: 630, avg loss: 0.133275, loss: 0.021293, accuracy: 1.000000
Step: 640, avg loss: 0.133757, loss: 0.164108, accuracy: 0.900000
Step: 650, avg loss: 0.132048, loss: 0.022691, accuracy: 1.000000
Step: 660, avg loss: 0.130491, loss: 0.029241, accuracy: 1.000000
Step: 670, avg loss: 0.139142, loss: 0.710163, accuracy: 0.800000
Step: 680, avg loss: 0.138071, loss: 0.066306, accuracy: 1.000000
Step: 690, avg loss: 0.137046, loss: 0.067340, accuracy: 1.000000
Step: 700, avg loss: 0.135666, loss: 0.040420, accuracy: 1.000000
Step: 710, avg loss: 0.134097, loss: 0.024243, accuracy: 1.000000
Step: 720, avg loss: 0.132635, loss: 0.028855, accuracy: 1.000000
Step: 730, avg loss: 0.131107, loss: 0.021113, accuracy: 1.000000
Step: 740, avg loss: 0.130375, loss: 0.076904, accuracy: 1.000000
Step: 750, avg loss: 0.129105, loss: 0.035114, accuracy: 1.000000
Step: 760, avg loss: 0.127591, loss: 0.014057, accuracy: 1.000000
Step: 770, avg loss: 0.126213, loss: 0.021520, accuracy: 1.000000
Step: 780, avg loss: 0.125471, loss: 0.068332, accuracy: 1.000000
Step: 790, avg loss: 0.124063, loss: 0.014206, accuracy: 1.000000
Step: 800, avg loss: 0.122542, loss: 0.002375, accuracy: 1.000000
Step: 810, avg loss: 0.121379, loss: 0.028336, accuracy: 1.000000
Step: 820, avg loss: 0.123555, loss: 0.299834, accuracy: 0.900000
Step: 830, avg loss: 0.122697, loss: 0.052320, accuracy: 1.000000
Step: 840, avg loss: 0.121621, loss: 0.032302, accuracy: 1.000000
Step: 850, avg loss: 0.120368, loss: 0.015148, accuracy: 1.000000
Step: 860, avg loss: 0.122048, loss: 0.264890, accuracy: 0.900000
Step: 870, avg loss: 0.121428, loss: 0.068092, accuracy: 1.000000
Step: 880, avg loss: 0.120323, loss: 0.024142, accuracy: 1.000000
Step: 890, avg loss: 0.119177, loss: 0.018315, accuracy: 1.000000
Step: 900, avg loss: 0.118037, loss: 0.016618, accuracy: 1.000000
Step: 910, avg loss: 0.124875, loss: 0.740251, accuracy: 0.900000
Step: 920, avg loss: 0.124190, loss: 0.061933, accuracy: 1.000000
Step: 930, avg loss: 0.123983, loss: 0.104889, accuracy: 1.000000
Step: 940, avg loss: 0.123477, loss: 0.076447, accuracy: 1.000000
Step: 950, avg loss: 0.122636, loss: 0.043564, accuracy: 1.000000
Step: 960, avg loss: 0.122621, loss: 0.121217, accuracy: 0.900000
Step: 970, avg loss: 0.121760, loss: 0.039129, accuracy: 1.000000
Step: 980, avg loss: 0.121046, loss: 0.051725, accuracy: 1.000000
Step: 990, avg loss: 0.119859, loss: 0.003604, accuracy: 1.000000
Step: 1000, avg loss: 0.118824, loss: 0.016297, accuracy: 1.000000
Step: 1010, avg loss: 0.118026, loss: 0.038239, accuracy: 1.000000
Step: 1020, avg loss: 0.117137, loss: 0.027308, accuracy: 1.000000
Step: 1030, avg loss: 0.116332, loss: 0.034298, accuracy: 1.000000
Step: 1040, avg loss: 0.115270, loss: 0.005888, accuracy: 1.000000
Step: 1050, avg loss: 0.114624, loss: 0.047363, accuracy: 1.000000
Step: 1060, avg loss: 0.113887, loss: 0.036490, accuracy: 1.000000
Step: 1070, avg loss: 0.112942, loss: 0.012790, accuracy: 1.000000
Step: 1080, avg loss: 0.112839, loss: 0.101823, accuracy: 1.000000
Step: 1090, avg loss: 0.112163, loss: 0.039208, accuracy: 1.000000
Step: 1100, avg loss: 0.111179, loss: 0.003873, accuracy: 1.000000
Step: 1110, avg loss: 0.110209, loss: 0.003530, accuracy: 1.000000
Step: 1120, avg loss: 0.109442, loss: 0.024266, accuracy: 1.000000
Step: 1130, avg loss: 0.108634, loss: 0.018192, accuracy: 1.000000
Step: 1140, avg loss: 0.108611, loss: 0.105964, accuracy: 1.000000
Step: 1150, avg loss: 0.112715, loss: 0.580636, accuracy: 0.800000
Step: 1160, avg loss: 0.115535, loss: 0.439786, accuracy: 0.900000
Step: 1170, avg loss: 0.115568, loss: 0.119360, accuracy: 1.000000
Step: 1180, avg loss: 0.120678, loss: 0.718583, accuracy: 0.900000
Step: 1190, avg loss: 0.120786, loss: 0.133538, accuracy: 1.000000
Step: 1200, avg loss: 0.124354, loss: 0.548979, accuracy: 0.900000
Step: 1210, avg loss: 0.124076, loss: 0.090738, accuracy: 1.000000
Step: 1220, avg loss: 0.123400, loss: 0.041541, accuracy: 1.000000
Step: 1230, avg loss: 0.122589, loss: 0.023617, accuracy: 1.000000
Step: 1240, avg loss: 0.122058, loss: 0.056747, accuracy: 1.000000
Step: 1250, avg loss: 0.121176, loss: 0.011841, accuracy: 1.000000
Step: 1260, avg loss: 0.120518, loss: 0.038283, accuracy: 1.000000
Epoch 19 finished in loss: 0.120344 and accuracy: 0.980190
Step: 10, avg loss: 0.415498, loss: 0.415498, accuracy: 0.900000
Step: 20, avg loss: 0.227537, loss: 0.039576, accuracy: 1.000000
Step: 30, avg loss: 0.164826, loss: 0.039405, accuracy: 1.000000
Step: 40, avg loss: 0.134652, loss: 0.044130, accuracy: 1.000000
Step: 50, avg loss: 0.134322, loss: 0.133004, accuracy: 0.900000
Step: 60, avg loss: 0.117869, loss: 0.035602, accuracy: 1.000000
Step: 70, avg loss: 0.101746, loss: 0.005011, accuracy: 1.000000
Step: 80, avg loss: 0.092821, loss: 0.030341, accuracy: 1.000000
Step: 90, avg loss: 0.155880, loss: 0.660352, accuracy: 0.900000
Step: 100, avg loss: 0.142243, loss: 0.019510, accuracy: 1.000000
Step: 110, avg loss: 0.133995, loss: 0.051518, accuracy: 1.000000
Step: 120, avg loss: 0.123553, loss: 0.008686, accuracy: 1.000000
Step: 130, avg loss: 0.115806, loss: 0.022843, accuracy: 1.000000
Step: 140, avg loss: 0.108902, loss: 0.019150, accuracy: 1.000000
Step: 150, avg loss: 0.112262, loss: 0.159301, accuracy: 0.900000
Step: 160, avg loss: 0.107404, loss: 0.034531, accuracy: 1.000000
Step: 170, avg loss: 0.101812, loss: 0.012351, accuracy: 1.000000
Step: 180, avg loss: 0.127953, loss: 0.572354, accuracy: 0.900000
Step: 190, avg loss: 0.124308, loss: 0.058692, accuracy: 1.000000
Step: 200, avg loss: 0.119671, loss: 0.031556, accuracy: 1.000000
Step: 210, avg loss: 0.138055, loss: 0.505754, accuracy: 0.900000
Step: 220, avg loss: 0.133774, loss: 0.043870, accuracy: 1.000000
Step: 230, avg loss: 0.138583, loss: 0.244369, accuracy: 0.900000
Step: 240, avg loss: 0.134761, loss: 0.046864, accuracy: 1.000000
Step: 250, avg loss: 0.131469, loss: 0.052454, accuracy: 1.000000
Step: 260, avg loss: 0.127596, loss: 0.030783, accuracy: 1.000000
Step: 270, avg loss: 0.124399, loss: 0.041270, accuracy: 1.000000
Step: 280, avg loss: 0.120564, loss: 0.017019, accuracy: 1.000000
Step: 290, avg loss: 0.118365, loss: 0.056792, accuracy: 1.000000
Step: 300, avg loss: 0.115343, loss: 0.027708, accuracy: 1.000000
Step: 310, avg loss: 0.112922, loss: 0.040292, accuracy: 1.000000
Step: 320, avg loss: 0.110187, loss: 0.025400, accuracy: 1.000000
Step: 330, avg loss: 0.111129, loss: 0.141280, accuracy: 0.900000
Step: 340, avg loss: 0.110213, loss: 0.079987, accuracy: 1.000000
Step: 350, avg loss: 0.109102, loss: 0.071303, accuracy: 1.000000
Step: 360, avg loss: 0.107274, loss: 0.043308, accuracy: 1.000000
Step: 370, avg loss: 0.109952, loss: 0.206349, accuracy: 0.900000
Step: 380, avg loss: 0.127590, loss: 0.780189, accuracy: 0.900000
Step: 390, avg loss: 0.125700, loss: 0.053886, accuracy: 1.000000
Step: 400, avg loss: 0.123707, loss: 0.045979, accuracy: 1.000000
Step: 410, avg loss: 0.122668, loss: 0.081105, accuracy: 1.000000
Step: 420, avg loss: 0.120231, loss: 0.020341, accuracy: 1.000000
Step: 430, avg loss: 0.118465, loss: 0.044263, accuracy: 1.000000
Step: 440, avg loss: 0.117999, loss: 0.097977, accuracy: 1.000000
Step: 450, avg loss: 0.123062, loss: 0.345842, accuracy: 0.900000
Step: 460, avg loss: 0.121668, loss: 0.058912, accuracy: 1.000000
Step: 470, avg loss: 0.131114, loss: 0.565668, accuracy: 0.900000
Step: 480, avg loss: 0.137008, loss: 0.413991, accuracy: 0.900000
Step: 490, avg loss: 0.142093, loss: 0.386196, accuracy: 0.900000
Step: 500, avg loss: 0.141290, loss: 0.101915, accuracy: 1.000000
Step: 510, avg loss: 0.139248, loss: 0.037192, accuracy: 1.000000
Step: 520, avg loss: 0.138214, loss: 0.085432, accuracy: 1.000000
Step: 530, avg loss: 0.136764, loss: 0.061408, accuracy: 1.000000
Step: 540, avg loss: 0.134677, loss: 0.024045, accuracy: 1.000000
Step: 550, avg loss: 0.143395, loss: 0.614167, accuracy: 0.800000
Step: 560, avg loss: 0.141749, loss: 0.051210, accuracy: 1.000000
Step: 570, avg loss: 0.140093, loss: 0.047379, accuracy: 1.000000
Step: 580, avg loss: 0.138738, loss: 0.061503, accuracy: 1.000000
Step: 590, avg loss: 0.137420, loss: 0.060938, accuracy: 1.000000
Step: 600, avg loss: 0.135919, loss: 0.047380, accuracy: 1.000000
Step: 610, avg loss: 0.134207, loss: 0.031498, accuracy: 1.000000
Step: 620, avg loss: 0.132564, loss: 0.032309, accuracy: 1.000000
Step: 630, avg loss: 0.130732, loss: 0.017205, accuracy: 1.000000
Step: 640, avg loss: 0.129282, loss: 0.037921, accuracy: 1.000000
Step: 650, avg loss: 0.127811, loss: 0.033677, accuracy: 1.000000
Step: 660, avg loss: 0.126318, loss: 0.029270, accuracy: 1.000000
Step: 670, avg loss: 0.134342, loss: 0.663898, accuracy: 0.900000
Step: 680, avg loss: 0.133285, loss: 0.062469, accuracy: 1.000000
Step: 690, avg loss: 0.132064, loss: 0.049043, accuracy: 1.000000
Step: 700, avg loss: 0.130378, loss: 0.014055, accuracy: 1.000000
Step: 710, avg loss: 0.128828, loss: 0.020303, accuracy: 1.000000
Step: 720, avg loss: 0.127411, loss: 0.026846, accuracy: 1.000000
Step: 730, avg loss: 0.125911, loss: 0.017898, accuracy: 1.000000
Step: 740, avg loss: 0.125038, loss: 0.061288, accuracy: 1.000000
Step: 750, avg loss: 0.124538, loss: 0.087532, accuracy: 1.000000
Step: 760, avg loss: 0.123063, loss: 0.012450, accuracy: 1.000000
Step: 770, avg loss: 0.121737, loss: 0.020919, accuracy: 1.000000
Step: 780, avg loss: 0.121546, loss: 0.106899, accuracy: 1.000000
Step: 790, avg loss: 0.120183, loss: 0.013851, accuracy: 1.000000
Step: 800, avg loss: 0.118710, loss: 0.002297, accuracy: 1.000000
Step: 810, avg loss: 0.117564, loss: 0.025903, accuracy: 1.000000
Step: 820, avg loss: 0.120512, loss: 0.359307, accuracy: 0.900000
Step: 830, avg loss: 0.119429, loss: 0.030639, accuracy: 1.000000
Step: 840, avg loss: 0.118805, loss: 0.066969, accuracy: 1.000000
Step: 850, avg loss: 0.117621, loss: 0.018190, accuracy: 1.000000
Step: 860, avg loss: 0.118186, loss: 0.166216, accuracy: 0.900000
Step: 870, avg loss: 0.116958, loss: 0.011362, accuracy: 1.000000
Step: 880, avg loss: 0.115888, loss: 0.022813, accuracy: 1.000000
Step: 890, avg loss: 0.116954, loss: 0.210701, accuracy: 0.900000
Step: 900, avg loss: 0.119408, loss: 0.337868, accuracy: 0.900000
Step: 910, avg loss: 0.126839, loss: 0.795611, accuracy: 0.800000
Step: 920, avg loss: 0.125830, loss: 0.034033, accuracy: 1.000000
Step: 930, avg loss: 0.124697, loss: 0.020493, accuracy: 1.000000
Step: 940, avg loss: 0.127906, loss: 0.426279, accuracy: 0.900000
Step: 950, avg loss: 0.126985, loss: 0.040400, accuracy: 1.000000
Step: 960, avg loss: 0.125978, loss: 0.030333, accuracy: 1.000000
Step: 970, avg loss: 0.125073, loss: 0.038159, accuracy: 1.000000
Step: 980, avg loss: 0.124406, loss: 0.059760, accuracy: 1.000000
Step: 990, avg loss: 0.123192, loss: 0.004238, accuracy: 1.000000
Step: 1000, avg loss: 0.122195, loss: 0.023512, accuracy: 1.000000
Step: 1010, avg loss: 0.121336, loss: 0.035367, accuracy: 1.000000
Step: 1020, avg loss: 0.120271, loss: 0.012737, accuracy: 1.000000
Step: 1030, avg loss: 0.119313, loss: 0.021548, accuracy: 1.000000
Step: 1040, avg loss: 0.118204, loss: 0.004009, accuracy: 1.000000
Step: 1050, avg loss: 0.117559, loss: 0.050532, accuracy: 1.000000
Step: 1060, avg loss: 0.117231, loss: 0.082723, accuracy: 1.000000
Step: 1070, avg loss: 0.116823, loss: 0.073555, accuracy: 1.000000
Step: 1080, avg loss: 0.116662, loss: 0.099456, accuracy: 1.000000
Step: 1090, avg loss: 0.116006, loss: 0.045177, accuracy: 1.000000
Step: 1100, avg loss: 0.116465, loss: 0.166517, accuracy: 0.900000
Step: 1110, avg loss: 0.115435, loss: 0.002121, accuracy: 1.000000
Step: 1120, avg loss: 0.114541, loss: 0.015261, accuracy: 1.000000
Step: 1130, avg loss: 0.113702, loss: 0.019763, accuracy: 1.000000
Step: 1140, avg loss: 0.113077, loss: 0.042504, accuracy: 1.000000
Step: 1150, avg loss: 0.113188, loss: 0.125840, accuracy: 0.900000
Step: 1160, avg loss: 0.113194, loss: 0.113874, accuracy: 1.000000
Step: 1170, avg loss: 0.112739, loss: 0.059979, accuracy: 1.000000
Step: 1180, avg loss: 0.117737, loss: 0.702487, accuracy: 0.900000
Step: 1190, avg loss: 0.117424, loss: 0.080447, accuracy: 1.000000
Step: 1200, avg loss: 0.120932, loss: 0.538362, accuracy: 0.900000
Step: 1210, avg loss: 0.120747, loss: 0.098634, accuracy: 1.000000
Step: 1220, avg loss: 0.120074, loss: 0.038581, accuracy: 1.000000
Step: 1230, avg loss: 0.119327, loss: 0.028249, accuracy: 1.000000
Step: 1240, avg loss: 0.118765, loss: 0.049631, accuracy: 1.000000
Step: 1250, avg loss: 0.117933, loss: 0.014777, accuracy: 1.000000
Step: 1260, avg loss: 0.117346, loss: 0.043935, accuracy: 1.000000
Epoch 20 finished in loss: 0.117176 and accuracy: 0.977813
Step: 10, avg loss: 0.053418, loss: 0.053418, accuracy: 1.000000
Step: 20, avg loss: 0.040214, loss: 0.027010, accuracy: 1.000000
Step: 30, avg loss: 0.049897, loss: 0.069264, accuracy: 1.000000
Step: 40, avg loss: 0.044091, loss: 0.026674, accuracy: 1.000000
Step: 50, avg loss: 0.040045, loss: 0.023858, accuracy: 1.000000
Step: 60, avg loss: 0.039038, loss: 0.034006, accuracy: 1.000000
Step: 70, avg loss: 0.033842, loss: 0.002665, accuracy: 1.000000
Step: 80, avg loss: 0.033101, loss: 0.027910, accuracy: 1.000000
Step: 90, avg loss: 0.105135, loss: 0.681407, accuracy: 0.900000
Step: 100, avg loss: 0.096684, loss: 0.020627, accuracy: 1.000000
Step: 110, avg loss: 0.092492, loss: 0.050572, accuracy: 1.000000
Step: 120, avg loss: 0.085433, loss: 0.007779, accuracy: 1.000000
Step: 130, avg loss: 0.080376, loss: 0.019703, accuracy: 1.000000
Step: 140, avg loss: 0.075893, loss: 0.017608, accuracy: 1.000000
Step: 150, avg loss: 0.075133, loss: 0.064497, accuracy: 1.000000
Step: 160, avg loss: 0.072604, loss: 0.034667, accuracy: 1.000000
Step: 170, avg loss: 0.069343, loss: 0.017166, accuracy: 1.000000
Step: 180, avg loss: 0.098880, loss: 0.601013, accuracy: 0.900000
Step: 190, avg loss: 0.096772, loss: 0.058825, accuracy: 1.000000
Step: 200, avg loss: 0.093483, loss: 0.030983, accuracy: 1.000000
Step: 210, avg loss: 0.114039, loss: 0.525173, accuracy: 0.900000
Step: 220, avg loss: 0.111075, loss: 0.048830, accuracy: 1.000000
Step: 230, avg loss: 0.107273, loss: 0.023616, accuracy: 1.000000
Step: 240, avg loss: 0.104420, loss: 0.038808, accuracy: 1.000000
Step: 250, avg loss: 0.115192, loss: 0.373729, accuracy: 0.900000
Step: 260, avg loss: 0.111973, loss: 0.031490, accuracy: 1.000000
Step: 270, avg loss: 0.109569, loss: 0.047063, accuracy: 1.000000
Step: 280, avg loss: 0.105998, loss: 0.009596, accuracy: 1.000000
Step: 290, avg loss: 0.104273, loss: 0.055945, accuracy: 1.000000
Step: 300, avg loss: 0.101728, loss: 0.027934, accuracy: 1.000000
Step: 310, avg loss: 0.099704, loss: 0.038987, accuracy: 1.000000
Step: 320, avg loss: 0.097295, loss: 0.022629, accuracy: 1.000000
Step: 330, avg loss: 0.096341, loss: 0.065805, accuracy: 1.000000
Step: 340, avg loss: 0.098694, loss: 0.176346, accuracy: 0.900000
Step: 350, avg loss: 0.097363, loss: 0.052115, accuracy: 1.000000
Step: 360, avg loss: 0.095782, loss: 0.040431, accuracy: 1.000000
Step: 370, avg loss: 0.095528, loss: 0.086397, accuracy: 1.000000
Step: 380, avg loss: 0.112678, loss: 0.747235, accuracy: 0.900000
Step: 390, avg loss: 0.115431, loss: 0.220025, accuracy: 0.900000
Step: 400, avg loss: 0.113902, loss: 0.054291, accuracy: 1.000000
Step: 410, avg loss: 0.113130, loss: 0.082241, accuracy: 1.000000
Step: 420, avg loss: 0.111031, loss: 0.024960, accuracy: 1.000000
Step: 430, avg loss: 0.109563, loss: 0.047914, accuracy: 1.000000
Step: 440, avg loss: 0.109781, loss: 0.119133, accuracy: 1.000000
Step: 450, avg loss: 0.108277, loss: 0.042109, accuracy: 1.000000
Step: 460, avg loss: 0.107163, loss: 0.057055, accuracy: 1.000000
Step: 470, avg loss: 0.116930, loss: 0.566212, accuracy: 0.900000
Step: 480, avg loss: 0.123371, loss: 0.426088, accuracy: 0.900000
Step: 490, avg loss: 0.128670, loss: 0.383016, accuracy: 0.900000
Step: 500, avg loss: 0.128231, loss: 0.106737, accuracy: 1.000000
Step: 510, avg loss: 0.126391, loss: 0.034395, accuracy: 1.000000
Step: 520, avg loss: 0.125198, loss: 0.064344, accuracy: 1.000000
Step: 530, avg loss: 0.131086, loss: 0.437266, accuracy: 0.900000
Step: 540, avg loss: 0.129089, loss: 0.023236, accuracy: 1.000000
Step: 550, avg loss: 0.137995, loss: 0.618907, accuracy: 0.800000
Step: 560, avg loss: 0.136429, loss: 0.050330, accuracy: 1.000000
Step: 570, avg loss: 0.134913, loss: 0.050017, accuracy: 1.000000
Step: 580, avg loss: 0.133342, loss: 0.043750, accuracy: 1.000000
Step: 590, avg loss: 0.132086, loss: 0.059289, accuracy: 1.000000
Step: 600, avg loss: 0.130714, loss: 0.049731, accuracy: 1.000000
Step: 610, avg loss: 0.129065, loss: 0.030148, accuracy: 1.000000
Step: 620, avg loss: 0.127570, loss: 0.036375, accuracy: 1.000000
Step: 630, avg loss: 0.128733, loss: 0.200853, accuracy: 0.900000
Step: 640, avg loss: 0.127158, loss: 0.027879, accuracy: 1.000000
Step: 650, avg loss: 0.127999, loss: 0.181862, accuracy: 0.900000
Step: 660, avg loss: 0.126493, loss: 0.028607, accuracy: 1.000000
Step: 670, avg loss: 0.133632, loss: 0.604778, accuracy: 0.900000
Step: 680, avg loss: 0.132395, loss: 0.049502, accuracy: 1.000000
Step: 690, avg loss: 0.131037, loss: 0.038717, accuracy: 1.000000
Step: 700, avg loss: 0.129516, loss: 0.024552, accuracy: 1.000000
Step: 710, avg loss: 0.127968, loss: 0.019659, accuracy: 1.000000
Step: 720, avg loss: 0.126661, loss: 0.033815, accuracy: 1.000000
Step: 730, avg loss: 0.125166, loss: 0.017554, accuracy: 1.000000
Step: 740, avg loss: 0.124463, loss: 0.073152, accuracy: 1.000000
Step: 750, avg loss: 0.123351, loss: 0.041023, accuracy: 1.000000
Step: 760, avg loss: 0.122386, loss: 0.050014, accuracy: 1.000000
Step: 770, avg loss: 0.121024, loss: 0.017557, accuracy: 1.000000
Step: 780, avg loss: 0.120143, loss: 0.052292, accuracy: 1.000000
Step: 790, avg loss: 0.120233, loss: 0.127275, accuracy: 0.900000
Step: 800, avg loss: 0.118768, loss: 0.002999, accuracy: 1.000000
Step: 810, avg loss: 0.117637, loss: 0.027130, accuracy: 1.000000
Step: 820, avg loss: 0.117579, loss: 0.112939, accuracy: 0.900000
Step: 830, avg loss: 0.116626, loss: 0.038487, accuracy: 1.000000
Step: 840, avg loss: 0.115672, loss: 0.036454, accuracy: 1.000000
Step: 850, avg loss: 0.114475, loss: 0.013910, accuracy: 1.000000
Step: 860, avg loss: 0.118378, loss: 0.450117, accuracy: 0.900000
Step: 870, avg loss: 0.117131, loss: 0.009940, accuracy: 1.000000
Step: 880, avg loss: 0.116072, loss: 0.023905, accuracy: 1.000000
Step: 890, avg loss: 0.115062, loss: 0.026206, accuracy: 1.000000
Step: 900, avg loss: 0.114016, loss: 0.020930, accuracy: 1.000000
Step: 910, avg loss: 0.119856, loss: 0.645451, accuracy: 0.900000
Step: 920, avg loss: 0.118936, loss: 0.035164, accuracy: 1.000000
Step: 930, avg loss: 0.117804, loss: 0.013696, accuracy: 1.000000
Step: 940, avg loss: 0.117310, loss: 0.071346, accuracy: 1.000000
Step: 950, avg loss: 0.116696, loss: 0.059037, accuracy: 1.000000
Step: 960, avg loss: 0.115795, loss: 0.030183, accuracy: 1.000000
Step: 970, avg loss: 0.114978, loss: 0.036531, accuracy: 1.000000
Step: 980, avg loss: 0.114324, loss: 0.050902, accuracy: 1.000000
Step: 990, avg loss: 0.113218, loss: 0.004792, accuracy: 1.000000
Step: 1000, avg loss: 0.112245, loss: 0.015893, accuracy: 1.000000
Step: 1010, avg loss: 0.111607, loss: 0.047889, accuracy: 1.000000
Step: 1020, avg loss: 0.110543, loss: 0.003082, accuracy: 1.000000
Step: 1030, avg loss: 0.109701, loss: 0.023785, accuracy: 1.000000
Step: 1040, avg loss: 0.108674, loss: 0.002842, accuracy: 1.000000
Step: 1050, avg loss: 0.108106, loss: 0.049078, accuracy: 1.000000
Step: 1060, avg loss: 0.107399, loss: 0.033150, accuracy: 1.000000
Step: 1070, avg loss: 0.106523, loss: 0.013692, accuracy: 1.000000
Step: 1080, avg loss: 0.106364, loss: 0.089356, accuracy: 1.000000
Step: 1090, avg loss: 0.105688, loss: 0.032641, accuracy: 1.000000
Step: 1100, avg loss: 0.106111, loss: 0.152216, accuracy: 0.900000
Step: 1110, avg loss: 0.105175, loss: 0.002255, accuracy: 1.000000
Step: 1120, avg loss: 0.104376, loss: 0.015720, accuracy: 1.000000
Step: 1130, avg loss: 0.103584, loss: 0.014812, accuracy: 1.000000
Step: 1140, avg loss: 0.105970, loss: 0.375579, accuracy: 0.800000
Step: 1150, avg loss: 0.105241, loss: 0.022154, accuracy: 1.000000
Step: 1160, avg loss: 0.105413, loss: 0.125152, accuracy: 1.000000
Step: 1170, avg loss: 0.105066, loss: 0.064902, accuracy: 1.000000
Step: 1180, avg loss: 0.110327, loss: 0.725850, accuracy: 0.900000
Step: 1190, avg loss: 0.109988, loss: 0.069948, accuracy: 1.000000
Step: 1200, avg loss: 0.113834, loss: 0.571554, accuracy: 0.900000
Step: 1210, avg loss: 0.113923, loss: 0.124560, accuracy: 1.000000
Step: 1220, avg loss: 0.113238, loss: 0.030376, accuracy: 1.000000
Step: 1230, avg loss: 0.112495, loss: 0.021830, accuracy: 1.000000
Step: 1240, avg loss: 0.112033, loss: 0.055252, accuracy: 1.000000
Step: 1250, avg loss: 0.111188, loss: 0.006362, accuracy: 1.000000
Step: 1260, avg loss: 0.110611, loss: 0.038513, accuracy: 1.000000
Epoch 21 finished in loss: 0.110451 and accuracy: 0.980190
Step: 10, avg loss: 0.041797, loss: 0.041797, accuracy: 1.000000
Step: 20, avg loss: 0.037538, loss: 0.033279, accuracy: 1.000000
Step: 30, avg loss: 0.038247, loss: 0.039665, accuracy: 1.000000
Step: 40, avg loss: 0.035062, loss: 0.025505, accuracy: 1.000000
Step: 50, avg loss: 0.033456, loss: 0.027032, accuracy: 1.000000
Step: 60, avg loss: 0.032379, loss: 0.026997, accuracy: 1.000000
Step: 70, avg loss: 0.028130, loss: 0.002636, accuracy: 1.000000
Step: 80, avg loss: 0.028214, loss: 0.028800, accuracy: 1.000000
Step: 90, avg loss: 0.107187, loss: 0.738968, accuracy: 0.900000
Step: 100, avg loss: 0.098079, loss: 0.016112, accuracy: 1.000000
Step: 110, avg loss: 0.093719, loss: 0.050115, accuracy: 1.000000
Step: 120, avg loss: 0.088843, loss: 0.035206, accuracy: 1.000000
Step: 130, avg loss: 0.083593, loss: 0.020591, accuracy: 1.000000
Step: 140, avg loss: 0.078670, loss: 0.014681, accuracy: 1.000000
Step: 150, avg loss: 0.077198, loss: 0.056577, accuracy: 1.000000
Step: 160, avg loss: 0.074300, loss: 0.030832, accuracy: 1.000000
Step: 170, avg loss: 0.070746, loss: 0.013887, accuracy: 1.000000
Step: 180, avg loss: 0.101639, loss: 0.626821, accuracy: 0.900000
Step: 190, avg loss: 0.099427, loss: 0.059609, accuracy: 1.000000
Step: 200, avg loss: 0.096400, loss: 0.038891, accuracy: 1.000000
Step: 210, avg loss: 0.114119, loss: 0.468490, accuracy: 0.900000
Step: 220, avg loss: 0.123166, loss: 0.313152, accuracy: 0.900000
Step: 230, avg loss: 0.130693, loss: 0.296304, accuracy: 0.900000
Step: 240, avg loss: 0.127274, loss: 0.048617, accuracy: 1.000000
Step: 250, avg loss: 0.124219, loss: 0.050896, accuracy: 1.000000
Step: 260, avg loss: 0.120545, loss: 0.028702, accuracy: 1.000000
Step: 270, avg loss: 0.117651, loss: 0.042402, accuracy: 1.000000
Step: 280, avg loss: 0.113964, loss: 0.014420, accuracy: 1.000000
Step: 290, avg loss: 0.113218, loss: 0.092343, accuracy: 1.000000
Step: 300, avg loss: 0.113118, loss: 0.110204, accuracy: 0.900000
Step: 310, avg loss: 0.110800, loss: 0.041251, accuracy: 1.000000
Step: 320, avg loss: 0.108419, loss: 0.034632, accuracy: 1.000000
Step: 330, avg loss: 0.106951, loss: 0.059969, accuracy: 1.000000
Step: 340, avg loss: 0.105719, loss: 0.065071, accuracy: 1.000000
Step: 350, avg loss: 0.104031, loss: 0.046627, accuracy: 1.000000
Step: 360, avg loss: 0.102243, loss: 0.039680, accuracy: 1.000000
Step: 370, avg loss: 0.101231, loss: 0.064775, accuracy: 1.000000
Step: 380, avg loss: 0.117251, loss: 0.709982, accuracy: 0.900000
Step: 390, avg loss: 0.115216, loss: 0.037889, accuracy: 1.000000
Step: 400, avg loss: 0.113514, loss: 0.047136, accuracy: 1.000000
Step: 410, avg loss: 0.112709, loss: 0.080520, accuracy: 1.000000
Step: 420, avg loss: 0.110484, loss: 0.019244, accuracy: 1.000000
Step: 430, avg loss: 0.108903, loss: 0.042504, accuracy: 1.000000
Step: 440, avg loss: 0.111583, loss: 0.226839, accuracy: 0.900000
Step: 450, avg loss: 0.109985, loss: 0.039674, accuracy: 1.000000
Step: 460, avg loss: 0.108923, loss: 0.061135, accuracy: 1.000000
Step: 470, avg loss: 0.118993, loss: 0.582231, accuracy: 0.900000
Step: 480, avg loss: 0.125659, loss: 0.438927, accuracy: 0.900000
Step: 490, avg loss: 0.131032, loss: 0.388940, accuracy: 0.900000
Step: 500, avg loss: 0.130479, loss: 0.103367, accuracy: 1.000000
Step: 510, avg loss: 0.128722, loss: 0.040878, accuracy: 1.000000
Step: 520, avg loss: 0.127513, loss: 0.065853, accuracy: 1.000000
Step: 530, avg loss: 0.126273, loss: 0.061811, accuracy: 1.000000
Step: 540, avg loss: 0.124363, loss: 0.023133, accuracy: 1.000000
Step: 550, avg loss: 0.130354, loss: 0.453881, accuracy: 0.800000
Step: 560, avg loss: 0.128717, loss: 0.038648, accuracy: 1.000000
Step: 570, avg loss: 0.127220, loss: 0.043407, accuracy: 1.000000
Step: 580, avg loss: 0.130816, loss: 0.335817, accuracy: 0.900000
Step: 590, avg loss: 0.129632, loss: 0.060954, accuracy: 1.000000
Step: 600, avg loss: 0.128260, loss: 0.047309, accuracy: 1.000000
Step: 610, avg loss: 0.126676, loss: 0.031595, accuracy: 1.000000
Step: 620, avg loss: 0.125221, loss: 0.036504, accuracy: 1.000000
Step: 630, avg loss: 0.123508, loss: 0.017300, accuracy: 1.000000
Step: 640, avg loss: 0.122175, loss: 0.038177, accuracy: 1.000000
Step: 650, avg loss: 0.120553, loss: 0.016755, accuracy: 1.000000
Step: 660, avg loss: 0.126954, loss: 0.543040, accuracy: 0.900000
Step: 670, avg loss: 0.132407, loss: 0.492252, accuracy: 0.900000
Step: 680, avg loss: 0.131378, loss: 0.062456, accuracy: 1.000000
Step: 690, avg loss: 0.132985, loss: 0.242291, accuracy: 0.900000
Step: 700, avg loss: 0.131361, loss: 0.019281, accuracy: 1.000000
Step: 710, avg loss: 0.129847, loss: 0.023895, accuracy: 1.000000
Step: 720, avg loss: 0.128465, loss: 0.030338, accuracy: 1.000000
Step: 730, avg loss: 0.127072, loss: 0.026769, accuracy: 1.000000
Step: 740, avg loss: 0.126111, loss: 0.055928, accuracy: 1.000000
Step: 750, avg loss: 0.124929, loss: 0.037498, accuracy: 1.000000
Step: 760, avg loss: 0.123518, loss: 0.017643, accuracy: 1.000000
Step: 770, avg loss: 0.122391, loss: 0.036781, accuracy: 1.000000
Step: 780, avg loss: 0.121991, loss: 0.091200, accuracy: 1.000000
Step: 790, avg loss: 0.120609, loss: 0.012817, accuracy: 1.000000
Step: 800, avg loss: 0.119217, loss: 0.009256, accuracy: 1.000000
Step: 810, avg loss: 0.118105, loss: 0.029150, accuracy: 1.000000
Step: 820, avg loss: 0.117000, loss: 0.027442, accuracy: 1.000000
Step: 830, avg loss: 0.116633, loss: 0.086594, accuracy: 1.000000
Step: 840, avg loss: 0.115596, loss: 0.029489, accuracy: 1.000000
Step: 850, avg loss: 0.114396, loss: 0.013582, accuracy: 1.000000
Step: 860, avg loss: 0.113668, loss: 0.051782, accuracy: 1.000000
Step: 870, avg loss: 0.112373, loss: 0.001063, accuracy: 1.000000
Step: 880, avg loss: 0.111336, loss: 0.021051, accuracy: 1.000000
Step: 890, avg loss: 0.110126, loss: 0.003671, accuracy: 1.000000
Step: 900, avg loss: 0.109129, loss: 0.020391, accuracy: 1.000000
Step: 910, avg loss: 0.116510, loss: 0.780766, accuracy: 0.900000
Step: 920, avg loss: 0.115548, loss: 0.028039, accuracy: 1.000000
Step: 930, avg loss: 0.114391, loss: 0.007905, accuracy: 1.000000
Step: 940, avg loss: 0.113872, loss: 0.065680, accuracy: 1.000000
Step: 950, avg loss: 0.114806, loss: 0.202547, accuracy: 0.900000
Step: 960, avg loss: 0.113887, loss: 0.026624, accuracy: 1.000000
Step: 970, avg loss: 0.113075, loss: 0.035074, accuracy: 1.000000
Step: 980, avg loss: 0.112406, loss: 0.047522, accuracy: 1.000000
Step: 990, avg loss: 0.111296, loss: 0.002581, accuracy: 1.000000
Step: 1000, avg loss: 0.110320, loss: 0.013613, accuracy: 1.000000
Step: 1010, avg loss: 0.109581, loss: 0.035701, accuracy: 1.000000
Step: 1020, avg loss: 0.108552, loss: 0.004644, accuracy: 1.000000
Step: 1030, avg loss: 0.107693, loss: 0.020058, accuracy: 1.000000
Step: 1040, avg loss: 0.106689, loss: 0.003314, accuracy: 1.000000
Step: 1050, avg loss: 0.106111, loss: 0.045976, accuracy: 1.000000
Step: 1060, avg loss: 0.105369, loss: 0.027443, accuracy: 1.000000
Step: 1070, avg loss: 0.104486, loss: 0.010894, accuracy: 1.000000
Step: 1080, avg loss: 0.104558, loss: 0.112286, accuracy: 1.000000
Step: 1090, avg loss: 0.103860, loss: 0.028431, accuracy: 1.000000
Step: 1100, avg loss: 0.103011, loss: 0.010543, accuracy: 1.000000
Step: 1110, avg loss: 0.102100, loss: 0.001844, accuracy: 1.000000
Step: 1120, avg loss: 0.101339, loss: 0.016846, accuracy: 1.000000
Step: 1130, avg loss: 0.100935, loss: 0.055677, accuracy: 1.000000
Step: 1140, avg loss: 0.100981, loss: 0.106216, accuracy: 0.900000
Step: 1150, avg loss: 0.100285, loss: 0.020963, accuracy: 1.000000
Step: 1160, avg loss: 0.102786, loss: 0.390354, accuracy: 0.900000
Step: 1170, avg loss: 0.102390, loss: 0.056502, accuracy: 1.000000
Step: 1180, avg loss: 0.107079, loss: 0.655654, accuracy: 0.900000
Step: 1190, avg loss: 0.106819, loss: 0.076209, accuracy: 1.000000
Step: 1200, avg loss: 0.109753, loss: 0.458883, accuracy: 0.900000
Step: 1210, avg loss: 0.109501, loss: 0.079270, accuracy: 1.000000
Step: 1220, avg loss: 0.108885, loss: 0.034247, accuracy: 1.000000
Step: 1230, avg loss: 0.108206, loss: 0.025476, accuracy: 1.000000
Step: 1240, avg loss: 0.107686, loss: 0.043634, accuracy: 1.000000
Step: 1250, avg loss: 0.106900, loss: 0.009416, accuracy: 1.000000
Step: 1260, avg loss: 0.106453, loss: 0.050591, accuracy: 1.000000
Epoch 22 finished in loss: 0.106298 and accuracy: 0.981775
Step: 10, avg loss: 0.071379, loss: 0.071379, accuracy: 1.000000
Step: 20, avg loss: 0.070373, loss: 0.069367, accuracy: 1.000000
Step: 30, avg loss: 0.060011, loss: 0.039286, accuracy: 1.000000
Step: 40, avg loss: 0.052625, loss: 0.030468, accuracy: 1.000000
Step: 50, avg loss: 0.046129, loss: 0.020145, accuracy: 1.000000
Step: 60, avg loss: 0.043204, loss: 0.028580, accuracy: 1.000000
Step: 70, avg loss: 0.037578, loss: 0.003819, accuracy: 1.000000
Step: 80, avg loss: 0.035974, loss: 0.024751, accuracy: 1.000000
Step: 90, avg loss: 0.111758, loss: 0.718030, accuracy: 0.900000
Step: 100, avg loss: 0.102342, loss: 0.017597, accuracy: 1.000000
Step: 110, avg loss: 0.097450, loss: 0.048528, accuracy: 1.000000
Step: 120, avg loss: 0.089661, loss: 0.003983, accuracy: 1.000000
Step: 130, avg loss: 0.084217, loss: 0.018893, accuracy: 1.000000
Step: 140, avg loss: 0.079254, loss: 0.014732, accuracy: 1.000000
Step: 150, avg loss: 0.077751, loss: 0.056703, accuracy: 1.000000
Step: 160, avg loss: 0.075174, loss: 0.036523, accuracy: 1.000000
Step: 170, avg loss: 0.071428, loss: 0.011493, accuracy: 1.000000
Step: 180, avg loss: 0.101848, loss: 0.618988, accuracy: 0.900000
Step: 190, avg loss: 0.099288, loss: 0.053215, accuracy: 1.000000
Step: 200, avg loss: 0.095798, loss: 0.029482, accuracy: 1.000000
Step: 210, avg loss: 0.113591, loss: 0.469446, accuracy: 0.900000
Step: 220, avg loss: 0.118014, loss: 0.210895, accuracy: 0.900000
Step: 230, avg loss: 0.113765, loss: 0.020293, accuracy: 1.000000
Step: 240, avg loss: 0.110831, loss: 0.043349, accuracy: 1.000000
Step: 250, avg loss: 0.108331, loss: 0.048321, accuracy: 1.000000
Step: 260, avg loss: 0.105203, loss: 0.027006, accuracy: 1.000000
Step: 270, avg loss: 0.103195, loss: 0.050989, accuracy: 1.000000
Step: 280, avg loss: 0.099919, loss: 0.011458, accuracy: 1.000000
Step: 290, avg loss: 0.098335, loss: 0.054009, accuracy: 1.000000
Step: 300, avg loss: 0.095878, loss: 0.024621, accuracy: 1.000000
Step: 310, avg loss: 0.094012, loss: 0.038018, accuracy: 1.000000
Step: 320, avg loss: 0.091815, loss: 0.023721, accuracy: 1.000000
Step: 330, avg loss: 0.090992, loss: 0.064645, accuracy: 1.000000
Step: 340, avg loss: 0.090111, loss: 0.061056, accuracy: 1.000000
Step: 350, avg loss: 0.088753, loss: 0.042561, accuracy: 1.000000
Step: 360, avg loss: 0.087987, loss: 0.061169, accuracy: 1.000000
Step: 370, avg loss: 0.087366, loss: 0.065015, accuracy: 1.000000
Step: 380, avg loss: 0.105073, loss: 0.760235, accuracy: 0.900000
Step: 390, avg loss: 0.106165, loss: 0.147686, accuracy: 0.900000
Step: 400, avg loss: 0.104760, loss: 0.049935, accuracy: 1.000000
Step: 410, avg loss: 0.104045, loss: 0.075468, accuracy: 1.000000
Step: 420, avg loss: 0.102032, loss: 0.019500, accuracy: 1.000000
Step: 430, avg loss: 0.100610, loss: 0.040860, accuracy: 1.000000
Step: 440, avg loss: 0.099815, loss: 0.065657, accuracy: 1.000000
Step: 450, avg loss: 0.099560, loss: 0.088336, accuracy: 1.000000
Step: 460, avg loss: 0.098697, loss: 0.059875, accuracy: 1.000000
Step: 470, avg loss: 0.109181, loss: 0.591440, accuracy: 0.900000
Step: 480, avg loss: 0.116361, loss: 0.453799, accuracy: 0.900000
Step: 490, avg loss: 0.122554, loss: 0.419806, accuracy: 0.900000
Step: 500, avg loss: 0.121989, loss: 0.094328, accuracy: 1.000000
Step: 510, avg loss: 0.121531, loss: 0.098602, accuracy: 1.000000
Step: 520, avg loss: 0.120516, loss: 0.068789, accuracy: 1.000000
Step: 530, avg loss: 0.119611, loss: 0.072544, accuracy: 1.000000
Step: 540, avg loss: 0.117849, loss: 0.024445, accuracy: 1.000000
Step: 550, avg loss: 0.119249, loss: 0.194883, accuracy: 0.900000
Step: 560, avg loss: 0.117618, loss: 0.027878, accuracy: 1.000000
Step: 570, avg loss: 0.116205, loss: 0.037107, accuracy: 1.000000
Step: 580, avg loss: 0.115349, loss: 0.066520, accuracy: 1.000000
Step: 590, avg loss: 0.114221, loss: 0.048834, accuracy: 1.000000
Step: 600, avg loss: 0.113194, loss: 0.052583, accuracy: 1.000000
Step: 610, avg loss: 0.111800, loss: 0.028156, accuracy: 1.000000
Step: 620, avg loss: 0.110526, loss: 0.032810, accuracy: 1.000000
Step: 630, avg loss: 0.109015, loss: 0.015365, accuracy: 1.000000
Step: 640, avg loss: 0.107920, loss: 0.038890, accuracy: 1.000000
Step: 650, avg loss: 0.106493, loss: 0.015191, accuracy: 1.000000
Step: 660, avg loss: 0.105296, loss: 0.027481, accuracy: 1.000000
Step: 670, avg loss: 0.113145, loss: 0.631196, accuracy: 0.900000
Step: 680, avg loss: 0.112223, loss: 0.050398, accuracy: 1.000000
Step: 690, avg loss: 0.111128, loss: 0.036698, accuracy: 1.000000
Step: 700, avg loss: 0.109669, loss: 0.009003, accuracy: 1.000000
Step: 710, avg loss: 0.108380, loss: 0.018124, accuracy: 1.000000
Step: 720, avg loss: 0.107173, loss: 0.021510, accuracy: 1.000000
Step: 730, avg loss: 0.105919, loss: 0.015639, accuracy: 1.000000
Step: 740, avg loss: 0.105303, loss: 0.060300, accuracy: 1.000000
Step: 750, avg loss: 0.104328, loss: 0.032209, accuracy: 1.000000
Step: 760, avg loss: 0.103154, loss: 0.015060, accuracy: 1.000000
Step: 770, avg loss: 0.102019, loss: 0.015820, accuracy: 1.000000
Step: 780, avg loss: 0.102639, loss: 0.150320, accuracy: 0.900000
Step: 790, avg loss: 0.101488, loss: 0.011772, accuracy: 1.000000
Step: 800, avg loss: 0.100245, loss: 0.002030, accuracy: 1.000000
Step: 810, avg loss: 0.099320, loss: 0.025303, accuracy: 1.000000
Step: 820, avg loss: 0.098399, loss: 0.023763, accuracy: 1.000000
Step: 830, avg loss: 0.097689, loss: 0.039504, accuracy: 1.000000
Step: 840, avg loss: 0.096958, loss: 0.036303, accuracy: 1.000000
Step: 850, avg loss: 0.095826, loss: 0.000745, accuracy: 1.000000
Step: 860, avg loss: 0.095218, loss: 0.043525, accuracy: 1.000000
Step: 870, avg loss: 0.094920, loss: 0.069277, accuracy: 1.000000
Step: 880, avg loss: 0.094079, loss: 0.020955, accuracy: 1.000000
Step: 890, avg loss: 0.093094, loss: 0.006331, accuracy: 1.000000
Step: 900, avg loss: 0.092252, loss: 0.017316, accuracy: 1.000000
Step: 910, avg loss: 0.099678, loss: 0.768041, accuracy: 0.900000
Step: 920, avg loss: 0.098867, loss: 0.025084, accuracy: 1.000000
Step: 930, avg loss: 0.097858, loss: 0.005019, accuracy: 1.000000
Step: 940, avg loss: 0.097535, loss: 0.067538, accuracy: 1.000000
Step: 950, avg loss: 0.096963, loss: 0.043197, accuracy: 1.000000
Step: 960, avg loss: 0.096388, loss: 0.041761, accuracy: 1.000000
Step: 970, avg loss: 0.095736, loss: 0.033147, accuracy: 1.000000
Step: 980, avg loss: 0.095186, loss: 0.041790, accuracy: 1.000000
Step: 990, avg loss: 0.094267, loss: 0.004218, accuracy: 1.000000
Step: 1000, avg loss: 0.093474, loss: 0.014970, accuracy: 1.000000
Step: 1010, avg loss: 0.092894, loss: 0.034856, accuracy: 1.000000
Step: 1020, avg loss: 0.092184, loss: 0.020535, accuracy: 1.000000
Step: 1030, avg loss: 0.091494, loss: 0.021109, accuracy: 1.000000
Step: 1040, avg loss: 0.090631, loss: 0.001682, accuracy: 1.000000
Step: 1050, avg loss: 0.090202, loss: 0.045636, accuracy: 1.000000
Step: 1060, avg loss: 0.089642, loss: 0.030852, accuracy: 1.000000
Step: 1070, avg loss: 0.088902, loss: 0.010409, accuracy: 1.000000
Step: 1080, avg loss: 0.088994, loss: 0.098883, accuracy: 1.000000
Step: 1090, avg loss: 0.088437, loss: 0.028251, accuracy: 1.000000
Step: 1100, avg loss: 0.087680, loss: 0.005135, accuracy: 1.000000
Step: 1110, avg loss: 0.086902, loss: 0.001368, accuracy: 1.000000
Step: 1120, avg loss: 0.086348, loss: 0.024848, accuracy: 1.000000
Step: 1130, avg loss: 0.085701, loss: 0.013206, accuracy: 1.000000
Step: 1140, avg loss: 0.085286, loss: 0.038454, accuracy: 1.000000
Step: 1150, avg loss: 0.084718, loss: 0.019891, accuracy: 1.000000
Step: 1160, avg loss: 0.084648, loss: 0.076688, accuracy: 1.000000
Step: 1170, avg loss: 0.084375, loss: 0.052652, accuracy: 1.000000
Step: 1180, avg loss: 0.089037, loss: 0.634546, accuracy: 0.900000
Step: 1190, avg loss: 0.089065, loss: 0.092291, accuracy: 1.000000
Step: 1200, avg loss: 0.091830, loss: 0.420871, accuracy: 0.900000
Step: 1210, avg loss: 0.091839, loss: 0.092943, accuracy: 1.000000
Step: 1220, avg loss: 0.091355, loss: 0.032833, accuracy: 1.000000
Step: 1230, avg loss: 0.090847, loss: 0.028831, accuracy: 1.000000
Step: 1240, avg loss: 0.090517, loss: 0.049936, accuracy: 1.000000
Step: 1250, avg loss: 0.089849, loss: 0.007055, accuracy: 1.000000
Step: 1260, avg loss: 0.089380, loss: 0.030755, accuracy: 1.000000
Epoch 23 finished in loss: 0.089252 and accuracy: 0.988114
Step: 10, avg loss: 0.199301, loss: 0.199301, accuracy: 0.900000
Step: 20, avg loss: 0.115889, loss: 0.032477, accuracy: 1.000000
Step: 30, avg loss: 0.089158, loss: 0.035695, accuracy: 1.000000
Step: 40, avg loss: 0.073648, loss: 0.027118, accuracy: 1.000000
Step: 50, avg loss: 0.062565, loss: 0.018234, accuracy: 1.000000
Step: 60, avg loss: 0.060185, loss: 0.048284, accuracy: 1.000000
Step: 70, avg loss: 0.051914, loss: 0.002289, accuracy: 1.000000
Step: 80, avg loss: 0.048576, loss: 0.025207, accuracy: 1.000000
Step: 90, avg loss: 0.126500, loss: 0.749891, accuracy: 0.900000
Step: 100, avg loss: 0.115604, loss: 0.017547, accuracy: 1.000000
Step: 110, avg loss: 0.109432, loss: 0.047711, accuracy: 1.000000
Step: 120, avg loss: 0.100672, loss: 0.004309, accuracy: 1.000000
Step: 130, avg loss: 0.094372, loss: 0.018775, accuracy: 1.000000
Step: 140, avg loss: 0.088667, loss: 0.014497, accuracy: 1.000000
Step: 150, avg loss: 0.086394, loss: 0.054574, accuracy: 1.000000
Step: 160, avg loss: 0.083028, loss: 0.032536, accuracy: 1.000000
Step: 170, avg loss: 0.078784, loss: 0.010879, accuracy: 1.000000
Step: 180, avg loss: 0.109387, loss: 0.629647, accuracy: 0.900000
Step: 190, avg loss: 0.106464, loss: 0.053835, accuracy: 1.000000
Step: 200, avg loss: 0.105027, loss: 0.077735, accuracy: 1.000000
Step: 210, avg loss: 0.117452, loss: 0.365953, accuracy: 0.900000
Step: 220, avg loss: 0.113685, loss: 0.034584, accuracy: 1.000000
Step: 230, avg loss: 0.118803, loss: 0.231401, accuracy: 0.900000
Step: 240, avg loss: 0.117031, loss: 0.076271, accuracy: 1.000000
Step: 250, avg loss: 0.114584, loss: 0.055840, accuracy: 1.000000
Step: 260, avg loss: 0.111287, loss: 0.028880, accuracy: 1.000000
Step: 270, avg loss: 0.108547, loss: 0.037285, accuracy: 1.000000
Step: 280, avg loss: 0.105718, loss: 0.029341, accuracy: 1.000000
Step: 290, avg loss: 0.103975, loss: 0.055177, accuracy: 1.000000
Step: 300, avg loss: 0.101528, loss: 0.030565, accuracy: 1.000000
Step: 310, avg loss: 0.099652, loss: 0.043364, accuracy: 1.000000
Step: 320, avg loss: 0.097248, loss: 0.022741, accuracy: 1.000000
Step: 330, avg loss: 0.096097, loss: 0.059265, accuracy: 1.000000
Step: 340, avg loss: 0.094895, loss: 0.055214, accuracy: 1.000000
Step: 350, avg loss: 0.093004, loss: 0.028711, accuracy: 1.000000
Step: 360, avg loss: 0.091479, loss: 0.038093, accuracy: 1.000000
Step: 370, avg loss: 0.090750, loss: 0.064523, accuracy: 1.000000
Step: 380, avg loss: 0.108081, loss: 0.749310, accuracy: 0.900000
Step: 390, avg loss: 0.106276, loss: 0.037686, accuracy: 1.000000
Step: 400, avg loss: 0.104794, loss: 0.047004, accuracy: 1.000000
Step: 410, avg loss: 0.104193, loss: 0.080143, accuracy: 1.000000
Step: 420, avg loss: 0.102102, loss: 0.016393, accuracy: 1.000000
Step: 430, avg loss: 0.100715, loss: 0.042474, accuracy: 1.000000
Step: 440, avg loss: 0.100654, loss: 0.098007, accuracy: 1.000000
Step: 450, avg loss: 0.099108, loss: 0.031074, accuracy: 1.000000
Step: 460, avg loss: 0.098351, loss: 0.064319, accuracy: 1.000000
Step: 470, avg loss: 0.109602, loss: 0.627144, accuracy: 0.900000
Step: 480, avg loss: 0.116997, loss: 0.464571, accuracy: 0.900000
Step: 490, avg loss: 0.123281, loss: 0.424911, accuracy: 0.900000
Step: 500, avg loss: 0.122747, loss: 0.096557, accuracy: 1.000000
Step: 510, avg loss: 0.120979, loss: 0.032562, accuracy: 1.000000
Step: 520, avg loss: 0.119780, loss: 0.058666, accuracy: 1.000000
Step: 530, avg loss: 0.118700, loss: 0.062544, accuracy: 1.000000
Step: 540, avg loss: 0.116936, loss: 0.023445, accuracy: 1.000000
Step: 550, avg loss: 0.117952, loss: 0.172787, accuracy: 0.900000
Step: 560, avg loss: 0.116254, loss: 0.022849, accuracy: 1.000000
Step: 570, avg loss: 0.114879, loss: 0.037929, accuracy: 1.000000
Step: 580, avg loss: 0.113849, loss: 0.055111, accuracy: 1.000000
Step: 590, avg loss: 0.112818, loss: 0.053002, accuracy: 1.000000
Step: 600, avg loss: 0.111669, loss: 0.043888, accuracy: 1.000000
Step: 610, avg loss: 0.110275, loss: 0.026652, accuracy: 1.000000
Step: 620, avg loss: 0.109097, loss: 0.037246, accuracy: 1.000000
Step: 630, avg loss: 0.107584, loss: 0.013794, accuracy: 1.000000
Step: 640, avg loss: 0.106520, loss: 0.039427, accuracy: 1.000000
Step: 650, avg loss: 0.105114, loss: 0.015194, accuracy: 1.000000
Step: 660, avg loss: 0.103948, loss: 0.028133, accuracy: 1.000000
Step: 670, avg loss: 0.112211, loss: 0.657580, accuracy: 0.900000
Step: 680, avg loss: 0.111269, loss: 0.048147, accuracy: 1.000000
Step: 690, avg loss: 0.111583, loss: 0.132909, accuracy: 0.900000
Step: 700, avg loss: 0.110119, loss: 0.009102, accuracy: 1.000000
Step: 710, avg loss: 0.108820, loss: 0.017897, accuracy: 1.000000
Step: 720, avg loss: 0.107605, loss: 0.021380, accuracy: 1.000000
Step: 730, avg loss: 0.106354, loss: 0.016237, accuracy: 1.000000
Step: 740, avg loss: 0.105657, loss: 0.054760, accuracy: 1.000000
Step: 750, avg loss: 0.104608, loss: 0.027021, accuracy: 1.000000
Step: 760, avg loss: 0.103425, loss: 0.014712, accuracy: 1.000000
Step: 770, avg loss: 0.102265, loss: 0.014076, accuracy: 1.000000
Step: 780, avg loss: 0.101725, loss: 0.060166, accuracy: 1.000000
Step: 790, avg loss: 0.100600, loss: 0.012847, accuracy: 1.000000
Step: 800, avg loss: 0.100195, loss: 0.068210, accuracy: 1.000000
Step: 810, avg loss: 0.099307, loss: 0.028266, accuracy: 1.000000
Step: 820, avg loss: 0.098486, loss: 0.031967, accuracy: 1.000000
Step: 830, avg loss: 0.097819, loss: 0.043098, accuracy: 1.000000
Step: 840, avg loss: 0.096980, loss: 0.027331, accuracy: 1.000000
Step: 850, avg loss: 0.095848, loss: 0.000769, accuracy: 1.000000
Step: 860, avg loss: 0.095261, loss: 0.045394, accuracy: 1.000000
Step: 870, avg loss: 0.094264, loss: 0.008509, accuracy: 1.000000
Step: 880, avg loss: 0.093446, loss: 0.022334, accuracy: 1.000000
Step: 890, avg loss: 0.093278, loss: 0.078426, accuracy: 1.000000
Step: 900, avg loss: 0.098865, loss: 0.596172, accuracy: 0.900000
Step: 910, avg loss: 0.106694, loss: 0.811259, accuracy: 0.900000
Step: 920, avg loss: 0.105853, loss: 0.029297, accuracy: 1.000000
Step: 930, avg loss: 0.104770, loss: 0.005131, accuracy: 1.000000
Step: 940, avg loss: 0.104365, loss: 0.066736, accuracy: 1.000000
Step: 950, avg loss: 0.103729, loss: 0.043911, accuracy: 1.000000
Step: 960, avg loss: 0.102941, loss: 0.028142, accuracy: 1.000000
Step: 970, avg loss: 0.102199, loss: 0.030944, accuracy: 1.000000
Step: 980, avg loss: 0.101586, loss: 0.042101, accuracy: 1.000000
Step: 990, avg loss: 0.100599, loss: 0.003868, accuracy: 1.000000
Step: 1000, avg loss: 0.099725, loss: 0.013254, accuracy: 1.000000
Step: 1010, avg loss: 0.099071, loss: 0.033673, accuracy: 1.000000
Step: 1020, avg loss: 0.098123, loss: 0.002386, accuracy: 1.000000
Step: 1030, avg loss: 0.097283, loss: 0.011587, accuracy: 1.000000
Step: 1040, avg loss: 0.096379, loss: 0.003282, accuracy: 1.000000
Step: 1050, avg loss: 0.096074, loss: 0.064271, accuracy: 1.000000
Step: 1060, avg loss: 0.095449, loss: 0.029919, accuracy: 1.000000
Step: 1070, avg loss: 0.095254, loss: 0.074533, accuracy: 0.900000
Step: 1080, avg loss: 0.095161, loss: 0.085217, accuracy: 1.000000
Step: 1090, avg loss: 0.094810, loss: 0.056879, accuracy: 1.000000
Step: 1100, avg loss: 0.094156, loss: 0.022900, accuracy: 1.000000
Step: 1110, avg loss: 0.093321, loss: 0.001465, accuracy: 1.000000
Step: 1120, avg loss: 0.092632, loss: 0.016189, accuracy: 1.000000
Step: 1130, avg loss: 0.091957, loss: 0.016368, accuracy: 1.000000
Step: 1140, avg loss: 0.092211, loss: 0.120851, accuracy: 0.900000
Step: 1150, avg loss: 0.091682, loss: 0.031364, accuracy: 1.000000
Step: 1160, avg loss: 0.091698, loss: 0.093595, accuracy: 1.000000
Step: 1170, avg loss: 0.091309, loss: 0.046191, accuracy: 1.000000
Step: 1180, avg loss: 0.095431, loss: 0.577663, accuracy: 0.900000
Step: 1190, avg loss: 0.095273, loss: 0.076654, accuracy: 1.000000
Step: 1200, avg loss: 0.097355, loss: 0.345100, accuracy: 0.900000
Step: 1210, avg loss: 0.097231, loss: 0.082316, accuracy: 1.000000
Step: 1220, avg loss: 0.096681, loss: 0.030131, accuracy: 1.000000
Step: 1230, avg loss: 0.096089, loss: 0.023914, accuracy: 1.000000
Step: 1240, avg loss: 0.095703, loss: 0.048209, accuracy: 1.000000
Step: 1250, avg loss: 0.095002, loss: 0.008066, accuracy: 1.000000
Step: 1260, avg loss: 0.094501, loss: 0.031830, accuracy: 1.000000
Epoch 24 finished in loss: 0.094378 and accuracy: 0.985737
Step: 10, avg loss: 0.053658, loss: 0.053658, accuracy: 1.000000
Step: 20, avg loss: 0.041783, loss: 0.029908, accuracy: 1.000000
Step: 30, avg loss: 0.040245, loss: 0.037170, accuracy: 1.000000
Step: 40, avg loss: 0.040250, loss: 0.040264, accuracy: 1.000000
Step: 50, avg loss: 0.034716, loss: 0.012579, accuracy: 1.000000
Step: 60, avg loss: 0.033770, loss: 0.029042, accuracy: 1.000000
Step: 70, avg loss: 0.029400, loss: 0.003182, accuracy: 1.000000
Step: 80, avg loss: 0.028779, loss: 0.024426, accuracy: 1.000000
Step: 90, avg loss: 0.112174, loss: 0.779339, accuracy: 0.900000
Step: 100, avg loss: 0.102601, loss: 0.016446, accuracy: 1.000000
Step: 110, avg loss: 0.097483, loss: 0.046294, accuracy: 1.000000
Step: 120, avg loss: 0.089735, loss: 0.004511, accuracy: 1.000000
Step: 130, avg loss: 0.084236, loss: 0.018243, accuracy: 1.000000
Step: 140, avg loss: 0.079286, loss: 0.014949, accuracy: 1.000000
Step: 150, avg loss: 0.078277, loss: 0.064140, accuracy: 1.000000
Step: 160, avg loss: 0.075153, loss: 0.028297, accuracy: 1.000000
Step: 170, avg loss: 0.070834, loss: 0.001739, accuracy: 1.000000
Step: 180, avg loss: 0.103122, loss: 0.652013, accuracy: 0.900000
Step: 190, avg loss: 0.100613, loss: 0.055445, accuracy: 1.000000
Step: 200, avg loss: 0.096836, loss: 0.025084, accuracy: 1.000000
Step: 210, avg loss: 0.111044, loss: 0.395199, accuracy: 0.900000
Step: 220, avg loss: 0.107842, loss: 0.040595, accuracy: 1.000000
Step: 230, avg loss: 0.103855, loss: 0.016152, accuracy: 1.000000
Step: 240, avg loss: 0.101254, loss: 0.041414, accuracy: 1.000000
Step: 250, avg loss: 0.105326, loss: 0.203053, accuracy: 0.900000
Step: 260, avg loss: 0.102306, loss: 0.026816, accuracy: 1.000000
Step: 270, avg loss: 0.100089, loss: 0.042445, accuracy: 1.000000
Step: 280, avg loss: 0.096837, loss: 0.009046, accuracy: 1.000000
Step: 290, avg loss: 0.095378, loss: 0.054505, accuracy: 1.000000
Step: 300, avg loss: 0.093156, loss: 0.028724, accuracy: 1.000000
Step: 310, avg loss: 0.091588, loss: 0.044560, accuracy: 1.000000
Step: 320, avg loss: 0.089749, loss: 0.032737, accuracy: 1.000000
Step: 330, avg loss: 0.088947, loss: 0.063270, accuracy: 1.000000
Step: 340, avg loss: 0.087991, loss: 0.056453, accuracy: 1.000000
Step: 350, avg loss: 0.086739, loss: 0.044155, accuracy: 1.000000
Step: 360, avg loss: 0.092546, loss: 0.295788, accuracy: 0.900000
Step: 370, avg loss: 0.097133, loss: 0.262291, accuracy: 0.900000
Step: 380, avg loss: 0.114494, loss: 0.756823, accuracy: 0.900000
Step: 390, avg loss: 0.112754, loss: 0.046648, accuracy: 1.000000
Step: 400, avg loss: 0.110993, loss: 0.042313, accuracy: 1.000000
Step: 410, avg loss: 0.110355, loss: 0.084836, accuracy: 1.000000
Step: 420, avg loss: 0.108486, loss: 0.031843, accuracy: 1.000000
Step: 430, avg loss: 0.106893, loss: 0.039985, accuracy: 1.000000
Step: 440, avg loss: 0.105915, loss: 0.063872, accuracy: 1.000000
Step: 450, avg loss: 0.105572, loss: 0.090508, accuracy: 1.000000
Step: 460, avg loss: 0.104593, loss: 0.060504, accuracy: 1.000000
Step: 470, avg loss: 0.115394, loss: 0.612246, accuracy: 0.900000
Step: 480, avg loss: 0.123002, loss: 0.480610, accuracy: 0.900000
Step: 490, avg loss: 0.129290, loss: 0.431085, accuracy: 0.900000
Step: 500, avg loss: 0.128458, loss: 0.087721, accuracy: 1.000000
Step: 510, avg loss: 0.126511, loss: 0.029157, accuracy: 1.000000
Step: 520, avg loss: 0.125317, loss: 0.064426, accuracy: 1.000000
Step: 530, avg loss: 0.124102, loss: 0.060898, accuracy: 1.000000
Step: 540, avg loss: 0.122259, loss: 0.024585, accuracy: 1.000000
Step: 550, avg loss: 0.120392, loss: 0.019544, accuracy: 1.000000
Step: 560, avg loss: 0.118825, loss: 0.032683, accuracy: 1.000000
Step: 570, avg loss: 0.117264, loss: 0.029838, accuracy: 1.000000
Step: 580, avg loss: 0.116135, loss: 0.051790, accuracy: 1.000000
Step: 590, avg loss: 0.115187, loss: 0.060173, accuracy: 1.000000
Step: 600, avg loss: 0.114190, loss: 0.055406, accuracy: 1.000000
Step: 610, avg loss: 0.112754, loss: 0.026588, accuracy: 1.000000
Step: 620, avg loss: 0.111474, loss: 0.033403, accuracy: 1.000000
Step: 630, avg loss: 0.109944, loss: 0.015076, accuracy: 1.000000
Step: 640, avg loss: 0.109051, loss: 0.052786, accuracy: 1.000000
Step: 650, avg loss: 0.107575, loss: 0.013083, accuracy: 1.000000
Step: 660, avg loss: 0.106360, loss: 0.027414, accuracy: 1.000000
Step: 670, avg loss: 0.114644, loss: 0.661396, accuracy: 0.900000
Step: 680, avg loss: 0.113684, loss: 0.049314, accuracy: 1.000000
Step: 690, avg loss: 0.112469, loss: 0.029852, accuracy: 1.000000
Step: 700, avg loss: 0.110992, loss: 0.009069, accuracy: 1.000000
Step: 710, avg loss: 0.109703, loss: 0.019504, accuracy: 1.000000
Step: 720, avg loss: 0.108539, loss: 0.025930, accuracy: 1.000000
Step: 730, avg loss: 0.107272, loss: 0.016040, accuracy: 1.000000
Step: 740, avg loss: 0.106736, loss: 0.067574, accuracy: 1.000000
Step: 750, avg loss: 0.105885, loss: 0.042936, accuracy: 1.000000
Step: 760, avg loss: 0.104920, loss: 0.032555, accuracy: 1.000000
Step: 770, avg loss: 0.103761, loss: 0.015636, accuracy: 1.000000
Step: 780, avg loss: 0.103296, loss: 0.067544, accuracy: 1.000000
Step: 790, avg loss: 0.102506, loss: 0.040886, accuracy: 1.000000
Step: 800, avg loss: 0.101264, loss: 0.003091, accuracy: 1.000000
Step: 810, avg loss: 0.100374, loss: 0.029218, accuracy: 1.000000
Step: 820, avg loss: 0.099413, loss: 0.021547, accuracy: 1.000000
Step: 830, avg loss: 0.098671, loss: 0.037830, accuracy: 1.000000
Step: 840, avg loss: 0.097813, loss: 0.026577, accuracy: 1.000000
Step: 850, avg loss: 0.096673, loss: 0.000945, accuracy: 1.000000
Step: 860, avg loss: 0.096925, loss: 0.118361, accuracy: 1.000000
Step: 870, avg loss: 0.095955, loss: 0.012545, accuracy: 1.000000
Step: 880, avg loss: 0.095118, loss: 0.022284, accuracy: 1.000000
Step: 890, avg loss: 0.094327, loss: 0.024668, accuracy: 1.000000
Step: 900, avg loss: 0.093437, loss: 0.014234, accuracy: 1.000000
Step: 910, avg loss: 0.100654, loss: 0.750191, accuracy: 0.900000
Step: 920, avg loss: 0.099852, loss: 0.026881, accuracy: 1.000000
Step: 930, avg loss: 0.098857, loss: 0.007275, accuracy: 1.000000
Step: 940, avg loss: 0.098526, loss: 0.067798, accuracy: 1.000000
Step: 950, avg loss: 0.097969, loss: 0.045575, accuracy: 1.000000
Step: 960, avg loss: 0.097207, loss: 0.024857, accuracy: 1.000000
Step: 970, avg loss: 0.096525, loss: 0.031049, accuracy: 1.000000
Step: 980, avg loss: 0.095966, loss: 0.041745, accuracy: 1.000000
Step: 990, avg loss: 0.095046, loss: 0.004880, accuracy: 1.000000
Step: 1000, avg loss: 0.094229, loss: 0.013340, accuracy: 1.000000
Step: 1010, avg loss: 0.093858, loss: 0.056797, accuracy: 1.000000
Step: 1020, avg loss: 0.092969, loss: 0.003167, accuracy: 1.000000
Step: 1030, avg loss: 0.092257, loss: 0.019613, accuracy: 1.000000
Step: 1040, avg loss: 0.091404, loss: 0.003564, accuracy: 1.000000
Step: 1050, avg loss: 0.090966, loss: 0.045362, accuracy: 1.000000
Step: 1060, avg loss: 0.090386, loss: 0.029483, accuracy: 1.000000
Step: 1070, avg loss: 0.089662, loss: 0.012960, accuracy: 1.000000
Step: 1080, avg loss: 0.089547, loss: 0.077231, accuracy: 1.000000
Step: 1090, avg loss: 0.089108, loss: 0.041644, accuracy: 1.000000
Step: 1100, avg loss: 0.088330, loss: 0.003548, accuracy: 1.000000
Step: 1110, avg loss: 0.087558, loss: 0.002641, accuracy: 1.000000
Step: 1120, avg loss: 0.086908, loss: 0.014787, accuracy: 1.000000
Step: 1130, avg loss: 0.086261, loss: 0.013775, accuracy: 1.000000
Step: 1140, avg loss: 0.085986, loss: 0.054904, accuracy: 1.000000
Step: 1150, avg loss: 0.085473, loss: 0.027003, accuracy: 1.000000
Step: 1160, avg loss: 0.085401, loss: 0.077191, accuracy: 1.000000
Step: 1170, avg loss: 0.085026, loss: 0.041465, accuracy: 1.000000
Step: 1180, avg loss: 0.087789, loss: 0.411110, accuracy: 0.900000
Step: 1190, avg loss: 0.097268, loss: 1.215781, accuracy: 0.900000
Step: 1200, avg loss: 0.098905, loss: 0.293692, accuracy: 0.900000
Step: 1210, avg loss: 0.098802, loss: 0.086431, accuracy: 1.000000
Step: 1220, avg loss: 0.098222, loss: 0.028069, accuracy: 1.000000
Step: 1230, avg loss: 0.097631, loss: 0.025516, accuracy: 1.000000
Step: 1240, avg loss: 0.097180, loss: 0.041718, accuracy: 1.000000
Step: 1250, avg loss: 0.096475, loss: 0.008984, accuracy: 1.000000
Step: 1260, avg loss: 0.095952, loss: 0.030680, accuracy: 1.000000
Epoch 25 finished in loss: 0.095815 and accuracy: 0.988114
Step: 10, avg loss: 0.049254, loss: 0.049254, accuracy: 1.000000
Step: 20, avg loss: 0.039127, loss: 0.028999, accuracy: 1.000000
Step: 30, avg loss: 0.101879, loss: 0.227382, accuracy: 0.900000
Step: 40, avg loss: 0.084239, loss: 0.031322, accuracy: 1.000000
Step: 50, avg loss: 0.072996, loss: 0.028020, accuracy: 1.000000
Step: 60, avg loss: 0.065440, loss: 0.027659, accuracy: 1.000000
Step: 70, avg loss: 0.056482, loss: 0.002734, accuracy: 1.000000
Step: 80, avg loss: 0.052430, loss: 0.024070, accuracy: 1.000000
Step: 90, avg loss: 0.150506, loss: 0.935116, accuracy: 0.900000
Step: 100, avg loss: 0.136864, loss: 0.014087, accuracy: 1.000000
Step: 110, avg loss: 0.128520, loss: 0.045072, accuracy: 1.000000
Step: 120, avg loss: 0.118154, loss: 0.004126, accuracy: 1.000000
Step: 130, avg loss: 0.110250, loss: 0.015407, accuracy: 1.000000
Step: 140, avg loss: 0.103277, loss: 0.012623, accuracy: 1.000000
Step: 150, avg loss: 0.099853, loss: 0.051922, accuracy: 1.000000
Step: 160, avg loss: 0.095440, loss: 0.029247, accuracy: 1.000000
Step: 170, avg loss: 0.090344, loss: 0.008812, accuracy: 1.000000
Step: 180, avg loss: 0.127937, loss: 0.767008, accuracy: 0.900000
Step: 190, avg loss: 0.123840, loss: 0.050096, accuracy: 1.000000
Step: 200, avg loss: 0.118906, loss: 0.025165, accuracy: 1.000000
Step: 210, avg loss: 0.129004, loss: 0.330968, accuracy: 0.900000
Step: 220, avg loss: 0.124375, loss: 0.027157, accuracy: 1.000000
Step: 230, avg loss: 0.120594, loss: 0.037421, accuracy: 1.000000
Step: 240, avg loss: 0.117053, loss: 0.035604, accuracy: 1.000000
Step: 250, avg loss: 0.113871, loss: 0.037497, accuracy: 1.000000
Step: 260, avg loss: 0.110673, loss: 0.030742, accuracy: 1.000000
Step: 270, avg loss: 0.107799, loss: 0.033067, accuracy: 1.000000
Step: 280, avg loss: 0.104381, loss: 0.012084, accuracy: 1.000000
Step: 290, avg loss: 0.102483, loss: 0.049337, accuracy: 1.000000
Step: 300, avg loss: 0.099951, loss: 0.026520, accuracy: 1.000000
Step: 310, avg loss: 0.098127, loss: 0.043411, accuracy: 1.000000
Step: 320, avg loss: 0.095856, loss: 0.025455, accuracy: 1.000000
Step: 330, avg loss: 0.094824, loss: 0.061803, accuracy: 1.000000
Step: 340, avg loss: 0.093647, loss: 0.054797, accuracy: 1.000000
Step: 350, avg loss: 0.092044, loss: 0.037550, accuracy: 1.000000
Step: 360, avg loss: 0.090582, loss: 0.039405, accuracy: 1.000000
Step: 370, avg loss: 0.089827, loss: 0.062648, accuracy: 1.000000
Step: 380, avg loss: 0.108358, loss: 0.794005, accuracy: 0.900000
Step: 390, avg loss: 0.106472, loss: 0.034813, accuracy: 1.000000
Step: 400, avg loss: 0.104893, loss: 0.043311, accuracy: 1.000000
Step: 410, avg loss: 0.104296, loss: 0.080407, accuracy: 1.000000
Step: 420, avg loss: 0.102216, loss: 0.016936, accuracy: 1.000000
Step: 430, avg loss: 0.100811, loss: 0.041817, accuracy: 1.000000
Step: 440, avg loss: 0.100093, loss: 0.069218, accuracy: 1.000000
Step: 450, avg loss: 0.098565, loss: 0.031349, accuracy: 1.000000
Step: 460, avg loss: 0.097850, loss: 0.065661, accuracy: 1.000000
Step: 470, avg loss: 0.109544, loss: 0.647477, accuracy: 0.900000
Step: 480, avg loss: 0.117062, loss: 0.470388, accuracy: 0.900000
Step: 490, avg loss: 0.123389, loss: 0.427092, accuracy: 0.900000
Step: 500, avg loss: 0.122808, loss: 0.094331, accuracy: 1.000000
Step: 510, avg loss: 0.121723, loss: 0.067460, accuracy: 1.000000
Step: 520, avg loss: 0.120714, loss: 0.069271, accuracy: 1.000000
Step: 530, avg loss: 0.119465, loss: 0.054545, accuracy: 1.000000
Step: 540, avg loss: 0.117636, loss: 0.020702, accuracy: 1.000000
Step: 550, avg loss: 0.115836, loss: 0.018596, accuracy: 1.000000
Step: 560, avg loss: 0.114147, loss: 0.021269, accuracy: 1.000000
Step: 570, avg loss: 0.113418, loss: 0.072575, accuracy: 1.000000
Step: 580, avg loss: 0.112168, loss: 0.040934, accuracy: 1.000000
Step: 590, avg loss: 0.111052, loss: 0.046315, accuracy: 1.000000
Step: 600, avg loss: 0.109976, loss: 0.046522, accuracy: 1.000000
Step: 610, avg loss: 0.108570, loss: 0.024201, accuracy: 1.000000
Step: 620, avg loss: 0.107329, loss: 0.031631, accuracy: 1.000000
Step: 630, avg loss: 0.105845, loss: 0.013852, accuracy: 1.000000
Step: 640, avg loss: 0.104795, loss: 0.038605, accuracy: 1.000000
Step: 650, avg loss: 0.103377, loss: 0.012609, accuracy: 1.000000
Step: 660, avg loss: 0.102215, loss: 0.026695, accuracy: 1.000000
Step: 670, avg loss: 0.110752, loss: 0.674240, accuracy: 0.900000
Step: 680, avg loss: 0.109854, loss: 0.049666, accuracy: 1.000000
Step: 690, avg loss: 0.108709, loss: 0.030813, accuracy: 1.000000
Step: 700, avg loss: 0.107262, loss: 0.007450, accuracy: 1.000000
Step: 710, avg loss: 0.105957, loss: 0.014629, accuracy: 1.000000
Step: 720, avg loss: 0.104872, loss: 0.027787, accuracy: 1.000000
Step: 730, avg loss: 0.103641, loss: 0.015048, accuracy: 1.000000
Step: 740, avg loss: 0.103012, loss: 0.057060, accuracy: 1.000000
Step: 750, avg loss: 0.101991, loss: 0.026471, accuracy: 1.000000
Step: 760, avg loss: 0.100907, loss: 0.019609, accuracy: 1.000000
Step: 770, avg loss: 0.099783, loss: 0.014324, accuracy: 1.000000
Step: 780, avg loss: 0.099155, loss: 0.050788, accuracy: 1.000000
Step: 790, avg loss: 0.098058, loss: 0.012563, accuracy: 1.000000
Step: 800, avg loss: 0.096867, loss: 0.002736, accuracy: 1.000000
Step: 810, avg loss: 0.096004, loss: 0.027001, accuracy: 1.000000
Step: 820, avg loss: 0.095093, loss: 0.021309, accuracy: 1.000000
Step: 830, avg loss: 0.094406, loss: 0.038034, accuracy: 1.000000
Step: 840, avg loss: 0.093636, loss: 0.029754, accuracy: 1.000000
Step: 850, avg loss: 0.092545, loss: 0.000901, accuracy: 1.000000
Step: 860, avg loss: 0.093553, loss: 0.179201, accuracy: 0.900000
Step: 870, avg loss: 0.092506, loss: 0.002445, accuracy: 1.000000
Step: 880, avg loss: 0.091931, loss: 0.041962, accuracy: 1.000000
Step: 890, avg loss: 0.090945, loss: 0.004116, accuracy: 1.000000
Step: 900, avg loss: 0.090124, loss: 0.017071, accuracy: 1.000000
Step: 910, avg loss: 0.097627, loss: 0.772915, accuracy: 0.900000
Step: 920, avg loss: 0.096881, loss: 0.029029, accuracy: 1.000000
Step: 930, avg loss: 0.095884, loss: 0.004088, accuracy: 1.000000
Step: 940, avg loss: 0.095577, loss: 0.067062, accuracy: 1.000000
Step: 950, avg loss: 0.095107, loss: 0.050912, accuracy: 1.000000
Step: 960, avg loss: 0.094357, loss: 0.023152, accuracy: 1.000000
Step: 970, avg loss: 0.093694, loss: 0.030056, accuracy: 1.000000
Step: 980, avg loss: 0.093032, loss: 0.028781, accuracy: 1.000000
Step: 990, avg loss: 0.092122, loss: 0.002928, accuracy: 1.000000
Step: 1000, avg loss: 0.091337, loss: 0.013605, accuracy: 1.000000
Step: 1010, avg loss: 0.090763, loss: 0.033380, accuracy: 1.000000
Step: 1020, avg loss: 0.089899, loss: 0.002661, accuracy: 1.000000
Step: 1030, avg loss: 0.089233, loss: 0.021295, accuracy: 1.000000
Step: 1040, avg loss: 0.088426, loss: 0.005287, accuracy: 1.000000
Step: 1050, avg loss: 0.087999, loss: 0.043646, accuracy: 1.000000
Step: 1060, avg loss: 0.087445, loss: 0.029199, accuracy: 1.000000
Step: 1070, avg loss: 0.086747, loss: 0.012751, accuracy: 1.000000
Step: 1080, avg loss: 0.087356, loss: 0.152501, accuracy: 0.900000
Step: 1090, avg loss: 0.086811, loss: 0.028043, accuracy: 1.000000
Step: 1100, avg loss: 0.086064, loss: 0.004570, accuracy: 1.000000
Step: 1110, avg loss: 0.085305, loss: 0.001887, accuracy: 1.000000
Step: 1120, avg loss: 0.084705, loss: 0.018101, accuracy: 1.000000
Step: 1130, avg loss: 0.084109, loss: 0.017303, accuracy: 1.000000
Step: 1140, avg loss: 0.083659, loss: 0.032819, accuracy: 1.000000
Step: 1150, avg loss: 0.083427, loss: 0.056960, accuracy: 1.000000
Step: 1160, avg loss: 0.083384, loss: 0.078448, accuracy: 1.000000
Step: 1170, avg loss: 0.083039, loss: 0.043028, accuracy: 1.000000
Step: 1180, avg loss: 0.084952, loss: 0.308780, accuracy: 0.900000
Step: 1190, avg loss: 0.084901, loss: 0.078830, accuracy: 1.000000
Step: 1200, avg loss: 0.086190, loss: 0.239603, accuracy: 0.900000
Step: 1210, avg loss: 0.086119, loss: 0.077625, accuracy: 1.000000
Step: 1220, avg loss: 0.085648, loss: 0.028640, accuracy: 1.000000
Step: 1230, avg loss: 0.085141, loss: 0.023342, accuracy: 1.000000
Step: 1240, avg loss: 0.084774, loss: 0.039546, accuracy: 1.000000
Step: 1250, avg loss: 0.084297, loss: 0.025173, accuracy: 1.000000
Step: 1260, avg loss: 0.083870, loss: 0.030505, accuracy: 1.000000
Epoch 26 finished in loss: 0.083757 and accuracy: 0.988906
Step: 10, avg loss: 0.044184, loss: 0.044184, accuracy: 1.000000
Step: 20, avg loss: 0.038573, loss: 0.032961, accuracy: 1.000000
Step: 30, avg loss: 0.038440, loss: 0.038174, accuracy: 1.000000
Step: 40, avg loss: 0.035137, loss: 0.025229, accuracy: 1.000000
Step: 50, avg loss: 0.032363, loss: 0.021266, accuracy: 1.000000
Step: 60, avg loss: 0.031808, loss: 0.029032, accuracy: 1.000000
Step: 70, avg loss: 0.027544, loss: 0.001964, accuracy: 1.000000
Step: 80, avg loss: 0.027223, loss: 0.024976, accuracy: 1.000000
Step: 90, avg loss: 0.123314, loss: 0.892041, accuracy: 0.900000
Step: 100, avg loss: 0.112476, loss: 0.014934, accuracy: 1.000000
Step: 110, avg loss: 0.106231, loss: 0.043778, accuracy: 1.000000
Step: 120, avg loss: 0.097735, loss: 0.004286, accuracy: 1.000000
Step: 130, avg loss: 0.091493, loss: 0.016577, accuracy: 1.000000
Step: 140, avg loss: 0.085825, loss: 0.012150, accuracy: 1.000000
Step: 150, avg loss: 0.083601, loss: 0.052465, accuracy: 1.000000
Step: 160, avg loss: 0.080697, loss: 0.037138, accuracy: 1.000000
Step: 170, avg loss: 0.076894, loss: 0.016045, accuracy: 1.000000
Step: 180, avg loss: 0.113775, loss: 0.740742, accuracy: 0.900000
Step: 190, avg loss: 0.110512, loss: 0.051783, accuracy: 1.000000
Step: 200, avg loss: 0.106944, loss: 0.039151, accuracy: 1.000000
Step: 210, avg loss: 0.124331, loss: 0.472077, accuracy: 0.800000
Step: 220, avg loss: 0.120104, loss: 0.031335, accuracy: 1.000000
Step: 230, avg loss: 0.115680, loss: 0.018354, accuracy: 1.000000
Step: 240, avg loss: 0.112508, loss: 0.039557, accuracy: 1.000000
Step: 250, avg loss: 0.111058, loss: 0.076247, accuracy: 1.000000
Step: 260, avg loss: 0.108124, loss: 0.034771, accuracy: 1.000000
Step: 270, avg loss: 0.105586, loss: 0.039593, accuracy: 1.000000
Step: 280, avg loss: 0.102328, loss: 0.014365, accuracy: 1.000000
Step: 290, avg loss: 0.100583, loss: 0.051732, accuracy: 1.000000
Step: 300, avg loss: 0.098005, loss: 0.023255, accuracy: 1.000000
Step: 310, avg loss: 0.096422, loss: 0.048916, accuracy: 1.000000
Step: 320, avg loss: 0.094212, loss: 0.025706, accuracy: 1.000000
Step: 330, avg loss: 0.097806, loss: 0.212802, accuracy: 0.900000
Step: 340, avg loss: 0.096451, loss: 0.051752, accuracy: 1.000000
Step: 350, avg loss: 0.094614, loss: 0.032149, accuracy: 1.000000
Step: 360, avg loss: 0.093032, loss: 0.037655, accuracy: 1.000000
Step: 370, avg loss: 0.093670, loss: 0.116660, accuracy: 1.000000
Step: 380, avg loss: 0.112014, loss: 0.790721, accuracy: 0.900000
Step: 390, avg loss: 0.109997, loss: 0.033369, accuracy: 1.000000
Step: 400, avg loss: 0.108157, loss: 0.036382, accuracy: 1.000000
Step: 410, avg loss: 0.107401, loss: 0.077149, accuracy: 1.000000
Step: 420, avg loss: 0.105206, loss: 0.015235, accuracy: 1.000000
Step: 430, avg loss: 0.103807, loss: 0.045058, accuracy: 1.000000
Step: 440, avg loss: 0.102939, loss: 0.065585, accuracy: 1.000000
Step: 450, avg loss: 0.101547, loss: 0.040334, accuracy: 1.000000
Step: 460, avg loss: 0.100749, loss: 0.064810, accuracy: 1.000000
Step: 470, avg loss: 0.112381, loss: 0.647457, accuracy: 0.900000
Step: 480, avg loss: 0.119687, loss: 0.463095, accuracy: 0.900000
Step: 490, avg loss: 0.125722, loss: 0.415403, accuracy: 0.900000
Step: 500, avg loss: 0.125078, loss: 0.093520, accuracy: 1.000000
Step: 510, avg loss: 0.123642, loss: 0.051835, accuracy: 1.000000
Step: 520, avg loss: 0.122494, loss: 0.063912, accuracy: 1.000000
Step: 530, avg loss: 0.121202, loss: 0.054062, accuracy: 1.000000
Step: 540, avg loss: 0.119719, loss: 0.041082, accuracy: 1.000000
Step: 550, avg loss: 0.117894, loss: 0.019356, accuracy: 1.000000
Step: 560, avg loss: 0.116080, loss: 0.016326, accuracy: 1.000000
Step: 570, avg loss: 0.114563, loss: 0.029572, accuracy: 1.000000
Step: 580, avg loss: 0.113273, loss: 0.039796, accuracy: 1.000000
Step: 590, avg loss: 0.112244, loss: 0.052507, accuracy: 1.000000
Step: 600, avg loss: 0.111127, loss: 0.045246, accuracy: 1.000000
Step: 610, avg loss: 0.109729, loss: 0.025870, accuracy: 1.000000
Step: 620, avg loss: 0.108471, loss: 0.031734, accuracy: 1.000000
Step: 630, avg loss: 0.106979, loss: 0.014490, accuracy: 1.000000
Step: 640, avg loss: 0.108558, loss: 0.208036, accuracy: 0.900000
Step: 650, avg loss: 0.107084, loss: 0.012741, accuracy: 1.000000
Step: 660, avg loss: 0.105836, loss: 0.024693, accuracy: 1.000000
Step: 670, avg loss: 0.114507, loss: 0.686779, accuracy: 0.900000
Step: 680, avg loss: 0.113506, loss: 0.046439, accuracy: 1.000000
Step: 690, avg loss: 0.112307, loss: 0.030762, accuracy: 1.000000
Step: 700, avg loss: 0.110798, loss: 0.006687, accuracy: 1.000000
Step: 710, avg loss: 0.109453, loss: 0.015322, accuracy: 1.000000
Step: 720, avg loss: 0.108200, loss: 0.019221, accuracy: 1.000000
Step: 730, avg loss: 0.106927, loss: 0.015250, accuracy: 1.000000
Step: 740, avg loss: 0.106225, loss: 0.055005, accuracy: 1.000000
Step: 750, avg loss: 0.105387, loss: 0.043397, accuracy: 1.000000
Step: 760, avg loss: 0.104212, loss: 0.016043, accuracy: 1.000000
Step: 770, avg loss: 0.103031, loss: 0.013287, accuracy: 1.000000
Step: 780, avg loss: 0.102235, loss: 0.040935, accuracy: 1.000000
Step: 790, avg loss: 0.101093, loss: 0.012071, accuracy: 1.000000
Step: 800, avg loss: 0.099859, loss: 0.002359, accuracy: 1.000000
Step: 810, avg loss: 0.098962, loss: 0.027169, accuracy: 1.000000
Step: 820, avg loss: 0.098097, loss: 0.028052, accuracy: 1.000000
Step: 830, avg loss: 0.097325, loss: 0.034017, accuracy: 1.000000
Step: 840, avg loss: 0.096445, loss: 0.023373, accuracy: 1.000000
Step: 850, avg loss: 0.095325, loss: 0.001286, accuracy: 1.000000
Step: 860, avg loss: 0.094764, loss: 0.047113, accuracy: 1.000000
Step: 870, avg loss: 0.093764, loss: 0.007722, accuracy: 1.000000
Step: 880, avg loss: 0.092935, loss: 0.020853, accuracy: 1.000000
Step: 890, avg loss: 0.091993, loss: 0.009066, accuracy: 1.000000
Step: 900, avg loss: 0.091179, loss: 0.018683, accuracy: 1.000000
Step: 910, avg loss: 0.099381, loss: 0.837573, accuracy: 0.900000
Step: 920, avg loss: 0.098618, loss: 0.029224, accuracy: 1.000000
Step: 930, avg loss: 0.097616, loss: 0.005422, accuracy: 1.000000
Step: 940, avg loss: 0.097280, loss: 0.066028, accuracy: 1.000000
Step: 950, avg loss: 0.096682, loss: 0.040519, accuracy: 1.000000
Step: 960, avg loss: 0.095935, loss: 0.024882, accuracy: 1.000000
Step: 970, avg loss: 0.095270, loss: 0.031504, accuracy: 1.000000
Step: 980, avg loss: 0.094734, loss: 0.042728, accuracy: 1.000000
Step: 990, avg loss: 0.093808, loss: 0.003050, accuracy: 1.000000
Step: 1000, avg loss: 0.092991, loss: 0.012089, accuracy: 1.000000
Step: 1010, avg loss: 0.092401, loss: 0.033425, accuracy: 1.000000
Step: 1020, avg loss: 0.091531, loss: 0.003638, accuracy: 1.000000
Step: 1030, avg loss: 0.090843, loss: 0.020714, accuracy: 1.000000
Step: 1040, avg loss: 0.089992, loss: 0.002286, accuracy: 1.000000
Step: 1050, avg loss: 0.089515, loss: 0.039929, accuracy: 1.000000
Step: 1060, avg loss: 0.088946, loss: 0.029186, accuracy: 1.000000
Step: 1070, avg loss: 0.088231, loss: 0.012486, accuracy: 1.000000
Step: 1080, avg loss: 0.088049, loss: 0.068547, accuracy: 1.000000
Step: 1090, avg loss: 0.087485, loss: 0.026593, accuracy: 1.000000
Step: 1100, avg loss: 0.086768, loss: 0.008556, accuracy: 1.000000
Step: 1110, avg loss: 0.085995, loss: 0.001029, accuracy: 1.000000
Step: 1120, avg loss: 0.085362, loss: 0.015101, accuracy: 1.000000
Step: 1130, avg loss: 0.084710, loss: 0.011704, accuracy: 1.000000
Step: 1140, avg loss: 0.084261, loss: 0.033426, accuracy: 1.000000
Step: 1150, avg loss: 0.083726, loss: 0.022840, accuracy: 1.000000
Step: 1160, avg loss: 0.083754, loss: 0.086915, accuracy: 1.000000
Step: 1170, avg loss: 0.083374, loss: 0.039296, accuracy: 1.000000
Step: 1180, avg loss: 0.085355, loss: 0.317151, accuracy: 0.900000
Step: 1190, avg loss: 0.085200, loss: 0.066845, accuracy: 1.000000
Step: 1200, avg loss: 0.086311, loss: 0.218543, accuracy: 0.900000
Step: 1210, avg loss: 0.086279, loss: 0.082467, accuracy: 1.000000
Step: 1220, avg loss: 0.085820, loss: 0.030320, accuracy: 1.000000
Step: 1230, avg loss: 0.085261, loss: 0.017048, accuracy: 1.000000
Step: 1240, avg loss: 0.084943, loss: 0.045787, accuracy: 1.000000
Step: 1250, avg loss: 0.084334, loss: 0.008872, accuracy: 1.000000
Step: 1260, avg loss: 0.083900, loss: 0.029565, accuracy: 1.000000
Epoch 27 finished in loss: 0.083774 and accuracy: 0.988906
Step: 10, avg loss: 0.043281, loss: 0.043281, accuracy: 1.000000
Step: 20, avg loss: 0.034022, loss: 0.024763, accuracy: 1.000000
Step: 30, avg loss: 0.035050, loss: 0.037106, accuracy: 1.000000
Step: 40, avg loss: 0.033718, loss: 0.029721, accuracy: 1.000000
Step: 50, avg loss: 0.029807, loss: 0.014162, accuracy: 1.000000
Step: 60, avg loss: 0.029671, loss: 0.028994, accuracy: 1.000000
Step: 70, avg loss: 0.025842, loss: 0.002864, accuracy: 1.000000
Step: 80, avg loss: 0.025694, loss: 0.024663, accuracy: 1.000000
Step: 90, avg loss: 0.123833, loss: 0.908945, accuracy: 0.900000
Step: 100, avg loss: 0.113001, loss: 0.015509, accuracy: 1.000000
Step: 110, avg loss: 0.106834, loss: 0.045163, accuracy: 1.000000
Step: 120, avg loss: 0.098287, loss: 0.004273, accuracy: 1.000000
Step: 130, avg loss: 0.091928, loss: 0.015618, accuracy: 1.000000
Step: 140, avg loss: 0.086239, loss: 0.012278, accuracy: 1.000000
Step: 150, avg loss: 0.083638, loss: 0.047230, accuracy: 1.000000
Step: 160, avg loss: 0.080191, loss: 0.028491, accuracy: 1.000000
Step: 170, avg loss: 0.075579, loss: 0.001774, accuracy: 1.000000
Step: 180, avg loss: 0.110559, loss: 0.705226, accuracy: 0.900000
Step: 190, avg loss: 0.107284, loss: 0.048326, accuracy: 1.000000
Step: 200, avg loss: 0.103052, loss: 0.022647, accuracy: 1.000000
Step: 210, avg loss: 0.106719, loss: 0.180074, accuracy: 0.900000
Step: 220, avg loss: 0.103638, loss: 0.038937, accuracy: 1.000000
Step: 230, avg loss: 0.099504, loss: 0.008536, accuracy: 1.000000
Step: 240, avg loss: 0.097444, loss: 0.050071, accuracy: 1.000000
Step: 250, avg loss: 0.099796, loss: 0.156258, accuracy: 0.900000
Step: 260, avg loss: 0.097034, loss: 0.027975, accuracy: 1.000000
Step: 270, avg loss: 0.094745, loss: 0.035241, accuracy: 1.000000
Step: 280, avg loss: 0.091647, loss: 0.007978, accuracy: 1.000000
Step: 290, avg loss: 0.090390, loss: 0.055212, accuracy: 1.000000
Step: 300, avg loss: 0.088253, loss: 0.026263, accuracy: 1.000000
Step: 310, avg loss: 0.086701, loss: 0.040146, accuracy: 1.000000
Step: 320, avg loss: 0.084641, loss: 0.020774, accuracy: 1.000000
Step: 330, avg loss: 0.083872, loss: 0.059271, accuracy: 1.000000
Step: 340, avg loss: 0.083008, loss: 0.054503, accuracy: 1.000000
Step: 350, avg loss: 0.081551, loss: 0.032027, accuracy: 1.000000
Step: 360, avg loss: 0.085139, loss: 0.210697, accuracy: 0.900000
Step: 370, avg loss: 0.087575, loss: 0.175263, accuracy: 0.900000
Step: 380, avg loss: 0.107077, loss: 0.828663, accuracy: 0.900000
Step: 390, avg loss: 0.105145, loss: 0.031721, accuracy: 1.000000
Step: 400, avg loss: 0.103446, loss: 0.037189, accuracy: 1.000000
Step: 410, avg loss: 0.102786, loss: 0.076412, accuracy: 1.000000
Step: 420, avg loss: 0.100679, loss: 0.014262, accuracy: 1.000000
Step: 430, avg loss: 0.099273, loss: 0.040249, accuracy: 1.000000
Step: 440, avg loss: 0.098962, loss: 0.085585, accuracy: 1.000000
Step: 450, avg loss: 0.097496, loss: 0.032983, accuracy: 1.000000
Step: 460, avg loss: 0.096723, loss: 0.061921, accuracy: 1.000000
Step: 470, avg loss: 0.108754, loss: 0.662187, accuracy: 0.900000
Step: 480, avg loss: 0.116425, loss: 0.476989, accuracy: 0.900000
Step: 490, avg loss: 0.122847, loss: 0.431086, accuracy: 0.900000
Step: 500, avg loss: 0.122245, loss: 0.092746, accuracy: 1.000000
Step: 510, avg loss: 0.120462, loss: 0.031297, accuracy: 1.000000
Step: 520, avg loss: 0.119305, loss: 0.060330, accuracy: 1.000000
Step: 530, avg loss: 0.118149, loss: 0.058040, accuracy: 1.000000
Step: 540, avg loss: 0.116369, loss: 0.022020, accuracy: 1.000000
Step: 550, avg loss: 0.114563, loss: 0.017019, accuracy: 1.000000
Step: 560, avg loss: 0.112903, loss: 0.021630, accuracy: 1.000000
Step: 570, avg loss: 0.111431, loss: 0.028956, accuracy: 1.000000
Step: 580, avg loss: 0.110121, loss: 0.035471, accuracy: 1.000000
Step: 590, avg loss: 0.109236, loss: 0.057902, accuracy: 1.000000
Step: 600, avg loss: 0.108279, loss: 0.051803, accuracy: 1.000000
Step: 610, avg loss: 0.106953, loss: 0.027407, accuracy: 1.000000
Step: 620, avg loss: 0.105732, loss: 0.031261, accuracy: 1.000000
Step: 630, avg loss: 0.104287, loss: 0.014722, accuracy: 1.000000
Step: 640, avg loss: 0.103234, loss: 0.036846, accuracy: 1.000000
Step: 650, avg loss: 0.101823, loss: 0.011521, accuracy: 1.000000
Step: 660, avg loss: 0.100724, loss: 0.029325, accuracy: 1.000000
Step: 670, avg loss: 0.110316, loss: 0.743344, accuracy: 0.900000
Step: 680, avg loss: 0.109444, loss: 0.051055, accuracy: 1.000000
Step: 690, avg loss: 0.108308, loss: 0.031023, accuracy: 1.000000
Step: 700, avg loss: 0.106950, loss: 0.013289, accuracy: 1.000000
Step: 710, avg loss: 0.105667, loss: 0.015810, accuracy: 1.000000
Step: 720, avg loss: 0.104454, loss: 0.018332, accuracy: 1.000000
Step: 730, avg loss: 0.103224, loss: 0.014675, accuracy: 1.000000
Step: 740, avg loss: 0.102547, loss: 0.053140, accuracy: 1.000000
Step: 750, avg loss: 0.101473, loss: 0.021976, accuracy: 1.000000
Step: 760, avg loss: 0.100327, loss: 0.014369, accuracy: 1.000000
Step: 770, avg loss: 0.099186, loss: 0.012546, accuracy: 1.000000
Step: 780, avg loss: 0.098636, loss: 0.056223, accuracy: 1.000000
Step: 790, avg loss: 0.097532, loss: 0.011471, accuracy: 1.000000
Step: 800, avg loss: 0.096342, loss: 0.002311, accuracy: 1.000000
Step: 810, avg loss: 0.095465, loss: 0.025272, accuracy: 1.000000
Step: 820, avg loss: 0.094552, loss: 0.020658, accuracy: 1.000000
Step: 830, avg loss: 0.093860, loss: 0.037068, accuracy: 1.000000
Step: 840, avg loss: 0.093053, loss: 0.026129, accuracy: 1.000000
Step: 850, avg loss: 0.091995, loss: 0.003115, accuracy: 1.000000
Step: 860, avg loss: 0.091327, loss: 0.034483, accuracy: 1.000000
Step: 870, avg loss: 0.090285, loss: 0.000704, accuracy: 1.000000
Step: 880, avg loss: 0.089507, loss: 0.021808, accuracy: 1.000000
Step: 890, avg loss: 0.088526, loss: 0.002239, accuracy: 1.000000
Step: 900, avg loss: 0.087778, loss: 0.021173, accuracy: 1.000000
Step: 910, avg loss: 0.096233, loss: 0.857220, accuracy: 0.900000
Step: 920, avg loss: 0.095514, loss: 0.030054, accuracy: 1.000000
Step: 930, avg loss: 0.094523, loss: 0.003359, accuracy: 1.000000
Step: 940, avg loss: 0.094236, loss: 0.067559, accuracy: 1.000000
Step: 950, avg loss: 0.100953, loss: 0.732372, accuracy: 0.900000
Step: 960, avg loss: 0.100148, loss: 0.023642, accuracy: 1.000000
Step: 970, avg loss: 0.099417, loss: 0.029214, accuracy: 1.000000
Step: 980, avg loss: 0.098798, loss: 0.038744, accuracy: 1.000000
Step: 990, avg loss: 0.097827, loss: 0.002657, accuracy: 1.000000
Step: 1000, avg loss: 0.096982, loss: 0.013376, accuracy: 1.000000
Step: 1010, avg loss: 0.096336, loss: 0.031691, accuracy: 1.000000
Step: 1020, avg loss: 0.095425, loss: 0.003480, accuracy: 1.000000
Step: 1030, avg loss: 0.095383, loss: 0.091049, accuracy: 0.900000
Step: 1040, avg loss: 0.094494, loss: 0.002947, accuracy: 1.000000
Step: 1050, avg loss: 0.093866, loss: 0.028534, accuracy: 1.000000
Step: 1060, avg loss: 0.093239, loss: 0.027396, accuracy: 1.000000
Step: 1070, avg loss: 0.092472, loss: 0.011186, accuracy: 1.000000
Step: 1080, avg loss: 0.092458, loss: 0.090953, accuracy: 1.000000
Step: 1090, avg loss: 0.091859, loss: 0.027131, accuracy: 1.000000
Step: 1100, avg loss: 0.091042, loss: 0.001996, accuracy: 1.000000
Step: 1110, avg loss: 0.090233, loss: 0.001280, accuracy: 1.000000
Step: 1120, avg loss: 0.089698, loss: 0.030294, accuracy: 1.000000
Step: 1130, avg loss: 0.089003, loss: 0.011198, accuracy: 1.000000
Step: 1140, avg loss: 0.088570, loss: 0.039673, accuracy: 1.000000
Step: 1150, avg loss: 0.088761, loss: 0.110455, accuracy: 0.900000
Step: 1160, avg loss: 0.093588, loss: 0.648678, accuracy: 0.900000
Step: 1170, avg loss: 0.093168, loss: 0.044461, accuracy: 1.000000
Step: 1180, avg loss: 0.095705, loss: 0.392545, accuracy: 0.900000
Step: 1190, avg loss: 0.095420, loss: 0.061789, accuracy: 1.000000
Step: 1200, avg loss: 0.095606, loss: 0.117815, accuracy: 1.000000
Step: 1210, avg loss: 0.097567, loss: 0.332881, accuracy: 0.900000
Step: 1220, avg loss: 0.096998, loss: 0.028053, accuracy: 1.000000
Step: 1230, avg loss: 0.096342, loss: 0.016426, accuracy: 1.000000
Step: 1240, avg loss: 0.095883, loss: 0.039364, accuracy: 1.000000
Step: 1250, avg loss: 0.095190, loss: 0.009262, accuracy: 1.000000
Step: 1260, avg loss: 0.094671, loss: 0.029741, accuracy: 1.000000
Epoch 28 finished in loss: 0.094531 and accuracy: 0.985737
Step: 10, avg loss: 0.047986, loss: 0.047986, accuracy: 1.000000
Step: 20, avg loss: 0.038506, loss: 0.029026, accuracy: 1.000000
Step: 30, avg loss: 0.038085, loss: 0.037244, accuracy: 1.000000
Step: 40, avg loss: 0.033786, loss: 0.020889, accuracy: 1.000000
Step: 50, avg loss: 0.052660, loss: 0.128154, accuracy: 0.900000
Step: 60, avg loss: 0.048394, loss: 0.027066, accuracy: 1.000000
Step: 70, avg loss: 0.042048, loss: 0.003971, accuracy: 1.000000
Step: 80, avg loss: 0.039228, loss: 0.019489, accuracy: 1.000000
Step: 90, avg loss: 0.126527, loss: 0.824922, accuracy: 0.900000
Step: 100, avg loss: 0.115374, loss: 0.014990, accuracy: 1.000000
Step: 110, avg loss: 0.108956, loss: 0.044776, accuracy: 1.000000
Step: 120, avg loss: 0.100252, loss: 0.004505, accuracy: 1.000000
Step: 130, avg loss: 0.093687, loss: 0.014909, accuracy: 1.000000
Step: 140, avg loss: 0.087903, loss: 0.012717, accuracy: 1.000000
Step: 150, avg loss: 0.085060, loss: 0.045257, accuracy: 1.000000
Step: 160, avg loss: 0.081744, loss: 0.031996, accuracy: 1.000000
Step: 170, avg loss: 0.078958, loss: 0.034379, accuracy: 1.000000
Step: 180, avg loss: 0.110900, loss: 0.653925, accuracy: 0.900000
Step: 190, avg loss: 0.107965, loss: 0.055139, accuracy: 1.000000
Step: 200, avg loss: 0.103798, loss: 0.024626, accuracy: 1.000000
Step: 210, avg loss: 0.103351, loss: 0.094394, accuracy: 0.900000
Step: 220, avg loss: 0.100001, loss: 0.029661, accuracy: 1.000000
Step: 230, avg loss: 0.097597, loss: 0.044713, accuracy: 1.000000
Step: 240, avg loss: 0.095001, loss: 0.035281, accuracy: 1.000000
Step: 250, avg loss: 0.092616, loss: 0.035375, accuracy: 1.000000
Step: 260, avg loss: 0.093480, loss: 0.115082, accuracy: 0.900000
Step: 270, avg loss: 0.091399, loss: 0.037308, accuracy: 1.000000
Step: 280, avg loss: 0.088511, loss: 0.010534, accuracy: 1.000000
Step: 290, avg loss: 0.087328, loss: 0.054190, accuracy: 1.000000
Step: 300, avg loss: 0.085284, loss: 0.026013, accuracy: 1.000000
Step: 310, avg loss: 0.083985, loss: 0.045004, accuracy: 1.000000
Step: 320, avg loss: 0.082174, loss: 0.026035, accuracy: 1.000000
Step: 330, avg loss: 0.081500, loss: 0.059938, accuracy: 1.000000
Step: 340, avg loss: 0.080746, loss: 0.055883, accuracy: 1.000000
Step: 350, avg loss: 0.079410, loss: 0.033971, accuracy: 1.000000
Step: 360, avg loss: 0.078200, loss: 0.035844, accuracy: 1.000000
Step: 370, avg loss: 0.077733, loss: 0.060929, accuracy: 1.000000
Step: 380, avg loss: 0.096134, loss: 0.776988, accuracy: 0.900000
Step: 390, avg loss: 0.096035, loss: 0.092252, accuracy: 1.000000
Step: 400, avg loss: 0.094553, loss: 0.036747, accuracy: 1.000000
Step: 410, avg loss: 0.094168, loss: 0.078788, accuracy: 1.000000
Step: 420, avg loss: 0.092287, loss: 0.015167, accuracy: 1.000000
Step: 430, avg loss: 0.091114, loss: 0.041858, accuracy: 1.000000
Step: 440, avg loss: 0.090452, loss: 0.061946, accuracy: 1.000000
Step: 450, avg loss: 0.089067, loss: 0.028139, accuracy: 1.000000
Step: 460, avg loss: 0.088447, loss: 0.060546, accuracy: 1.000000
Step: 470, avg loss: 0.099883, loss: 0.625959, accuracy: 0.900000
Step: 480, avg loss: 0.106913, loss: 0.437330, accuracy: 0.900000
Step: 490, avg loss: 0.112793, loss: 0.395019, accuracy: 0.900000
Step: 500, avg loss: 0.112526, loss: 0.099433, accuracy: 1.000000
Step: 510, avg loss: 0.110801, loss: 0.024562, accuracy: 1.000000
Step: 520, avg loss: 0.109690, loss: 0.053027, accuracy: 1.000000
Step: 530, avg loss: 0.108719, loss: 0.058209, accuracy: 1.000000
Step: 540, avg loss: 0.107096, loss: 0.021107, accuracy: 1.000000
Step: 550, avg loss: 0.105448, loss: 0.016442, accuracy: 1.000000
Step: 560, avg loss: 0.103916, loss: 0.019667, accuracy: 1.000000
Step: 570, avg loss: 0.102597, loss: 0.028699, accuracy: 1.000000
Step: 580, avg loss: 0.101450, loss: 0.036078, accuracy: 1.000000
Step: 590, avg loss: 0.100515, loss: 0.046295, accuracy: 1.000000
Step: 600, avg loss: 0.099610, loss: 0.046246, accuracy: 1.000000
Step: 610, avg loss: 0.098414, loss: 0.026628, accuracy: 1.000000
Step: 620, avg loss: 0.097303, loss: 0.029538, accuracy: 1.000000
Step: 630, avg loss: 0.095977, loss: 0.013743, accuracy: 1.000000
Step: 640, avg loss: 0.095063, loss: 0.037471, accuracy: 1.000000
Step: 650, avg loss: 0.093902, loss: 0.019646, accuracy: 1.000000
Step: 660, avg loss: 0.092906, loss: 0.028126, accuracy: 1.000000
Step: 670, avg loss: 0.102768, loss: 0.753679, accuracy: 0.900000
Step: 680, avg loss: 0.102043, loss: 0.053474, accuracy: 1.000000
Step: 690, avg loss: 0.100977, loss: 0.028491, accuracy: 1.000000
Step: 700, avg loss: 0.099744, loss: 0.014631, accuracy: 1.000000
Step: 710, avg loss: 0.098561, loss: 0.015808, accuracy: 1.000000
Step: 720, avg loss: 0.097429, loss: 0.017036, accuracy: 1.000000
Step: 730, avg loss: 0.096297, loss: 0.014752, accuracy: 1.000000
Step: 740, avg loss: 0.095693, loss: 0.051666, accuracy: 1.000000
Step: 750, avg loss: 0.094713, loss: 0.022185, accuracy: 1.000000
Step: 760, avg loss: 0.093655, loss: 0.014280, accuracy: 1.000000
Step: 770, avg loss: 0.092600, loss: 0.012424, accuracy: 1.000000
Step: 780, avg loss: 0.092034, loss: 0.048413, accuracy: 1.000000
Step: 790, avg loss: 0.091029, loss: 0.012676, accuracy: 1.000000
Step: 800, avg loss: 0.089983, loss: 0.007332, accuracy: 1.000000
Step: 810, avg loss: 0.089165, loss: 0.023734, accuracy: 1.000000
Step: 820, avg loss: 0.088331, loss: 0.020825, accuracy: 1.000000
Step: 830, avg loss: 0.087670, loss: 0.033461, accuracy: 1.000000
Step: 840, avg loss: 0.086949, loss: 0.027059, accuracy: 1.000000
Step: 850, avg loss: 0.085941, loss: 0.001293, accuracy: 1.000000
Step: 860, avg loss: 0.085355, loss: 0.035562, accuracy: 1.000000
Step: 870, avg loss: 0.084382, loss: 0.000669, accuracy: 1.000000
Step: 880, avg loss: 0.083618, loss: 0.017146, accuracy: 1.000000
Step: 890, avg loss: 0.082709, loss: 0.002719, accuracy: 1.000000
Step: 900, avg loss: 0.082142, loss: 0.031713, accuracy: 1.000000
Step: 910, avg loss: 0.091179, loss: 0.904444, accuracy: 0.900000
Step: 920, avg loss: 0.090458, loss: 0.024870, accuracy: 1.000000
Step: 930, avg loss: 0.089570, loss: 0.007855, accuracy: 1.000000
Step: 940, avg loss: 0.092610, loss: 0.375320, accuracy: 0.900000
Step: 950, avg loss: 0.092108, loss: 0.044986, accuracy: 1.000000
Step: 960, avg loss: 0.091398, loss: 0.023887, accuracy: 1.000000
Step: 970, avg loss: 0.090794, loss: 0.032845, accuracy: 1.000000
Step: 980, avg loss: 0.090170, loss: 0.029691, accuracy: 1.000000
Step: 990, avg loss: 0.089279, loss: 0.001935, accuracy: 1.000000
Step: 1000, avg loss: 0.088509, loss: 0.012301, accuracy: 1.000000
Step: 1010, avg loss: 0.087929, loss: 0.029932, accuracy: 1.000000
Step: 1020, avg loss: 0.087104, loss: 0.003691, accuracy: 1.000000
Step: 1030, avg loss: 0.086459, loss: 0.020728, accuracy: 1.000000
Step: 1040, avg loss: 0.085814, loss: 0.019343, accuracy: 1.000000
Step: 1050, avg loss: 0.085365, loss: 0.038662, accuracy: 1.000000
Step: 1060, avg loss: 0.084803, loss: 0.025834, accuracy: 1.000000
Step: 1070, avg loss: 0.084125, loss: 0.012274, accuracy: 1.000000
Step: 1080, avg loss: 0.084612, loss: 0.136719, accuracy: 1.000000
Step: 1090, avg loss: 0.084078, loss: 0.026361, accuracy: 1.000000
Step: 1100, avg loss: 0.083416, loss: 0.011238, accuracy: 1.000000
Step: 1110, avg loss: 0.082685, loss: 0.002345, accuracy: 1.000000
Step: 1120, avg loss: 0.082089, loss: 0.015868, accuracy: 1.000000
Step: 1130, avg loss: 0.081488, loss: 0.014223, accuracy: 1.000000
Step: 1140, avg loss: 0.081088, loss: 0.035931, accuracy: 1.000000
Step: 1150, avg loss: 0.080838, loss: 0.052303, accuracy: 1.000000
Step: 1160, avg loss: 0.080763, loss: 0.072127, accuracy: 1.000000
Step: 1170, avg loss: 0.080453, loss: 0.044516, accuracy: 1.000000
Step: 1180, avg loss: 0.081920, loss: 0.253494, accuracy: 0.900000
Step: 1190, avg loss: 0.084019, loss: 0.331699, accuracy: 0.900000
Step: 1200, avg loss: 0.084637, loss: 0.158156, accuracy: 0.900000
Step: 1210, avg loss: 0.084632, loss: 0.084137, accuracy: 1.000000
Step: 1220, avg loss: 0.084164, loss: 0.027532, accuracy: 1.000000
Step: 1230, avg loss: 0.083626, loss: 0.017941, accuracy: 1.000000
Step: 1240, avg loss: 0.083271, loss: 0.039599, accuracy: 1.000000
Step: 1250, avg loss: 0.082661, loss: 0.006975, accuracy: 1.000000
Step: 1260, avg loss: 0.082237, loss: 0.029236, accuracy: 1.000000
Epoch 29 finished in loss: 0.082114 and accuracy: 0.988114
Step: 10, avg loss: 0.045415, loss: 0.045415, accuracy: 1.000000
Step: 20, avg loss: 0.037010, loss: 0.028604, accuracy: 1.000000
Step: 30, avg loss: 0.037557, loss: 0.038652, accuracy: 1.000000
Step: 40, avg loss: 0.033986, loss: 0.023272, accuracy: 1.000000
Step: 50, avg loss: 0.029991, loss: 0.014011, accuracy: 1.000000
Step: 60, avg loss: 0.029342, loss: 0.026096, accuracy: 1.000000
Step: 70, avg loss: 0.025443, loss: 0.002049, accuracy: 1.000000
Step: 80, avg loss: 0.024309, loss: 0.016369, accuracy: 1.000000
Step: 90, avg loss: 0.128792, loss: 0.964659, accuracy: 0.900000
Step: 100, avg loss: 0.117932, loss: 0.020197, accuracy: 1.000000
Step: 110, avg loss: 0.111195, loss: 0.043821, accuracy: 1.000000
Step: 120, avg loss: 0.102219, loss: 0.003487, accuracy: 1.000000
Step: 130, avg loss: 0.095498, loss: 0.014848, accuracy: 1.000000
Step: 140, avg loss: 0.089489, loss: 0.011373, accuracy: 1.000000
Step: 150, avg loss: 0.086533, loss: 0.045147, accuracy: 1.000000
Step: 160, avg loss: 0.083145, loss: 0.032324, accuracy: 1.000000
Step: 170, avg loss: 0.078337, loss: 0.001412, accuracy: 1.000000
Step: 180, avg loss: 0.114232, loss: 0.724445, accuracy: 0.900000
Step: 190, avg loss: 0.111004, loss: 0.052902, accuracy: 1.000000
Step: 200, avg loss: 0.106523, loss: 0.021378, accuracy: 1.000000
Step: 210, avg loss: 0.107738, loss: 0.132033, accuracy: 0.900000
Step: 220, avg loss: 0.104140, loss: 0.028595, accuracy: 1.000000
Step: 230, avg loss: 0.109024, loss: 0.216470, accuracy: 0.900000
Step: 240, avg loss: 0.106229, loss: 0.041932, accuracy: 1.000000
Step: 250, avg loss: 0.103489, loss: 0.037744, accuracy: 1.000000
Step: 260, avg loss: 0.101383, loss: 0.048733, accuracy: 1.000000
Step: 270, avg loss: 0.099158, loss: 0.041301, accuracy: 1.000000
Step: 280, avg loss: 0.095936, loss: 0.008940, accuracy: 1.000000
Step: 290, avg loss: 0.094282, loss: 0.047966, accuracy: 1.000000
Step: 300, avg loss: 0.092198, loss: 0.031765, accuracy: 1.000000
Step: 310, avg loss: 0.090680, loss: 0.045139, accuracy: 1.000000
Step: 320, avg loss: 0.088654, loss: 0.025833, accuracy: 1.000000
Step: 330, avg loss: 0.087744, loss: 0.058639, accuracy: 1.000000
Step: 340, avg loss: 0.087572, loss: 0.081910, accuracy: 1.000000
Step: 350, avg loss: 0.086289, loss: 0.042647, accuracy: 1.000000
Step: 360, avg loss: 0.084811, loss: 0.033086, accuracy: 1.000000
Step: 370, avg loss: 0.089399, loss: 0.254576, accuracy: 0.900000
Step: 380, avg loss: 0.106194, loss: 0.727599, accuracy: 0.900000
Step: 390, avg loss: 0.104377, loss: 0.035317, accuracy: 1.000000
Step: 400, avg loss: 0.102776, loss: 0.040362, accuracy: 1.000000
Step: 410, avg loss: 0.102238, loss: 0.080708, accuracy: 1.000000
Step: 420, avg loss: 0.100183, loss: 0.015926, accuracy: 1.000000
Step: 430, avg loss: 0.098828, loss: 0.041905, accuracy: 1.000000
Step: 440, avg loss: 0.097919, loss: 0.058832, accuracy: 1.000000
Step: 450, avg loss: 0.096522, loss: 0.035058, accuracy: 1.000000
Step: 460, avg loss: 0.095685, loss: 0.058015, accuracy: 1.000000
Step: 470, avg loss: 0.106974, loss: 0.626302, accuracy: 0.900000
Step: 480, avg loss: 0.114013, loss: 0.444848, accuracy: 0.900000
Step: 490, avg loss: 0.119863, loss: 0.400624, accuracy: 0.900000
Step: 500, avg loss: 0.119352, loss: 0.094324, accuracy: 1.000000
Step: 510, avg loss: 0.117485, loss: 0.024135, accuracy: 1.000000
Step: 520, avg loss: 0.116237, loss: 0.052620, accuracy: 1.000000
Step: 530, avg loss: 0.115050, loss: 0.053307, accuracy: 1.000000
Step: 540, avg loss: 0.113345, loss: 0.022980, accuracy: 1.000000
Step: 550, avg loss: 0.111565, loss: 0.015436, accuracy: 1.000000
Step: 560, avg loss: 0.109898, loss: 0.018219, accuracy: 1.000000
Step: 570, avg loss: 0.108478, loss: 0.028943, accuracy: 1.000000
Step: 580, avg loss: 0.107185, loss: 0.033492, accuracy: 1.000000
Step: 590, avg loss: 0.106177, loss: 0.047701, accuracy: 1.000000
Step: 600, avg loss: 0.105146, loss: 0.044341, accuracy: 1.000000
Step: 610, avg loss: 0.103818, loss: 0.024109, accuracy: 1.000000
Step: 620, avg loss: 0.102960, loss: 0.050651, accuracy: 1.000000
Step: 630, avg loss: 0.101530, loss: 0.012863, accuracy: 1.000000
Step: 640, avg loss: 0.100553, loss: 0.038988, accuracy: 1.000000
Step: 650, avg loss: 0.099173, loss: 0.010887, accuracy: 1.000000
Step: 660, avg loss: 0.098072, loss: 0.026454, accuracy: 1.000000
Step: 670, avg loss: 0.107048, loss: 0.699475, accuracy: 0.900000
Step: 680, avg loss: 0.106186, loss: 0.048440, accuracy: 1.000000
Step: 690, avg loss: 0.105033, loss: 0.026664, accuracy: 1.000000
Step: 700, avg loss: 0.103616, loss: 0.005825, accuracy: 1.000000
Step: 710, avg loss: 0.102402, loss: 0.017410, accuracy: 1.000000
Step: 720, avg loss: 0.101216, loss: 0.017031, accuracy: 1.000000
Step: 730, avg loss: 0.100033, loss: 0.014808, accuracy: 1.000000
Step: 740, avg loss: 0.099411, loss: 0.054039, accuracy: 1.000000
Step: 750, avg loss: 0.098363, loss: 0.020782, accuracy: 1.000000
Step: 760, avg loss: 0.097251, loss: 0.013844, accuracy: 1.000000
Step: 770, avg loss: 0.096156, loss: 0.013000, accuracy: 1.000000
Step: 780, avg loss: 0.095527, loss: 0.047052, accuracy: 1.000000
Step: 790, avg loss: 0.094465, loss: 0.011605, accuracy: 1.000000
Step: 800, avg loss: 0.093305, loss: 0.001736, accuracy: 1.000000
Step: 810, avg loss: 0.092468, loss: 0.025456, accuracy: 1.000000
Step: 820, avg loss: 0.091679, loss: 0.027811, accuracy: 1.000000
Step: 830, avg loss: 0.091236, loss: 0.054879, accuracy: 1.000000
Step: 840, avg loss: 0.090450, loss: 0.025192, accuracy: 1.000000
Step: 850, avg loss: 0.089415, loss: 0.002474, accuracy: 1.000000
Step: 860, avg loss: 0.088804, loss: 0.036929, accuracy: 1.000000
Step: 870, avg loss: 0.087951, loss: 0.014590, accuracy: 1.000000
Step: 880, avg loss: 0.087210, loss: 0.022705, accuracy: 1.000000
Step: 890, avg loss: 0.086346, loss: 0.010364, accuracy: 1.000000
Step: 900, avg loss: 0.085574, loss: 0.016812, accuracy: 1.000000
Step: 910, avg loss: 0.094104, loss: 0.861773, accuracy: 0.900000
Step: 920, avg loss: 0.093392, loss: 0.028617, accuracy: 1.000000
Step: 930, avg loss: 0.092432, loss: 0.004151, accuracy: 1.000000
Step: 940, avg loss: 0.092151, loss: 0.066012, accuracy: 1.000000
Step: 950, avg loss: 0.091566, loss: 0.036565, accuracy: 1.000000
Step: 960, avg loss: 0.090877, loss: 0.025448, accuracy: 1.000000
Step: 970, avg loss: 0.090237, loss: 0.028776, accuracy: 1.000000
Step: 980, avg loss: 0.089588, loss: 0.026621, accuracy: 1.000000
Step: 990, avg loss: 0.088714, loss: 0.003083, accuracy: 1.000000
Step: 1000, avg loss: 0.087967, loss: 0.014043, accuracy: 1.000000
Step: 1010, avg loss: 0.087400, loss: 0.030666, accuracy: 1.000000
Step: 1020, avg loss: 0.086564, loss: 0.002140, accuracy: 1.000000
Step: 1030, avg loss: 0.085930, loss: 0.021246, accuracy: 1.000000
Step: 1040, avg loss: 0.085130, loss: 0.002714, accuracy: 1.000000
Step: 1050, avg loss: 0.084611, loss: 0.030692, accuracy: 1.000000
Step: 1060, avg loss: 0.084070, loss: 0.027224, accuracy: 1.000000
Step: 1070, avg loss: 0.083379, loss: 0.010183, accuracy: 1.000000
Step: 1080, avg loss: 0.083207, loss: 0.064704, accuracy: 1.000000
Step: 1090, avg loss: 0.082686, loss: 0.026466, accuracy: 1.000000
Step: 1100, avg loss: 0.081957, loss: 0.002451, accuracy: 1.000000
Step: 1110, avg loss: 0.081232, loss: 0.001546, accuracy: 1.000000
Step: 1120, avg loss: 0.080641, loss: 0.015077, accuracy: 1.000000
Step: 1130, avg loss: 0.080024, loss: 0.010842, accuracy: 1.000000
Step: 1140, avg loss: 0.079647, loss: 0.037016, accuracy: 1.000000
Step: 1150, avg loss: 0.079101, loss: 0.016933, accuracy: 1.000000
Step: 1160, avg loss: 0.079078, loss: 0.076455, accuracy: 1.000000
Step: 1170, avg loss: 0.078754, loss: 0.041074, accuracy: 1.000000
Step: 1180, avg loss: 0.079175, loss: 0.128513, accuracy: 0.900000
Step: 1190, avg loss: 0.079056, loss: 0.065025, accuracy: 1.000000
Step: 1200, avg loss: 0.079662, loss: 0.151750, accuracy: 0.900000
Step: 1210, avg loss: 0.079591, loss: 0.071012, accuracy: 1.000000
Step: 1220, avg loss: 0.079170, loss: 0.028293, accuracy: 1.000000
Step: 1230, avg loss: 0.078650, loss: 0.015143, accuracy: 1.000000
Step: 1240, avg loss: 0.078307, loss: 0.036133, accuracy: 1.000000
Step: 1250, avg loss: 0.077727, loss: 0.005821, accuracy: 1.000000
Step: 1260, avg loss: 0.077330, loss: 0.027685, accuracy: 1.000000
Epoch 30 finished in loss: 0.077214 and accuracy: 0.989699
Step: 10, avg loss: 0.281112, loss: 0.281112, accuracy: 0.900000
Step: 20, avg loss: 0.157334, loss: 0.033555, accuracy: 1.000000
Step: 30, avg loss: 0.117086, loss: 0.036592, accuracy: 1.000000
Step: 40, avg loss: 0.093733, loss: 0.023672, accuracy: 1.000000
Step: 50, avg loss: 0.078022, loss: 0.015177, accuracy: 1.000000
Step: 60, avg loss: 0.070178, loss: 0.030958, accuracy: 1.000000
Step: 70, avg loss: 0.060431, loss: 0.001949, accuracy: 1.000000
Step: 80, avg loss: 0.055476, loss: 0.020792, accuracy: 1.000000
Step: 90, avg loss: 0.155042, loss: 0.951569, accuracy: 0.900000
Step: 100, avg loss: 0.141275, loss: 0.017373, accuracy: 1.000000
Step: 110, avg loss: 0.132471, loss: 0.044433, accuracy: 1.000000
Step: 120, avg loss: 0.121716, loss: 0.003407, accuracy: 1.000000
Step: 130, avg loss: 0.113453, loss: 0.014299, accuracy: 1.000000
Step: 140, avg loss: 0.106195, loss: 0.011836, accuracy: 1.000000
Step: 150, avg loss: 0.102192, loss: 0.046161, accuracy: 1.000000
Step: 160, avg loss: 0.097788, loss: 0.031726, accuracy: 1.000000
Step: 170, avg loss: 0.092164, loss: 0.002172, accuracy: 1.000000
Step: 180, avg loss: 0.129067, loss: 0.756415, accuracy: 0.900000
Step: 190, avg loss: 0.124576, loss: 0.043747, accuracy: 1.000000
Step: 200, avg loss: 0.119372, loss: 0.020492, accuracy: 1.000000
Step: 210, avg loss: 0.116934, loss: 0.068173, accuracy: 1.000000
Step: 220, avg loss: 0.112816, loss: 0.026353, accuracy: 1.000000
Step: 230, avg loss: 0.108173, loss: 0.006020, accuracy: 1.000000
Step: 240, avg loss: 0.105210, loss: 0.037051, accuracy: 1.000000
Step: 250, avg loss: 0.102408, loss: 0.035173, accuracy: 1.000000
Step: 260, avg loss: 0.099621, loss: 0.029953, accuracy: 1.000000
Step: 270, avg loss: 0.097532, loss: 0.043214, accuracy: 1.000000
Step: 280, avg loss: 0.094268, loss: 0.006137, accuracy: 1.000000
Step: 290, avg loss: 0.092934, loss: 0.055587, accuracy: 1.000000
Step: 300, avg loss: 0.090700, loss: 0.025904, accuracy: 1.000000
Step: 310, avg loss: 0.089118, loss: 0.041653, accuracy: 1.000000
Step: 320, avg loss: 0.086962, loss: 0.020145, accuracy: 1.000000
Step: 330, avg loss: 0.086158, loss: 0.060431, accuracy: 1.000000
Step: 340, avg loss: 0.085239, loss: 0.054892, accuracy: 1.000000
Step: 350, avg loss: 0.083702, loss: 0.031444, accuracy: 1.000000
Step: 360, avg loss: 0.082528, loss: 0.041430, accuracy: 1.000000
Step: 370, avg loss: 0.082335, loss: 0.075404, accuracy: 1.000000
Step: 380, avg loss: 0.103689, loss: 0.893786, accuracy: 0.900000
Step: 390, avg loss: 0.102011, loss: 0.038228, accuracy: 1.000000
Step: 400, avg loss: 0.100612, loss: 0.046047, accuracy: 1.000000
Step: 410, avg loss: 0.100018, loss: 0.076270, accuracy: 1.000000
Step: 420, avg loss: 0.098000, loss: 0.015290, accuracy: 1.000000
Step: 430, avg loss: 0.096639, loss: 0.039446, accuracy: 1.000000
Step: 440, avg loss: 0.096006, loss: 0.068811, accuracy: 1.000000
Step: 450, avg loss: 0.096530, loss: 0.119551, accuracy: 0.900000
Step: 460, avg loss: 0.095743, loss: 0.060353, accuracy: 1.000000
Step: 470, avg loss: 0.106860, loss: 0.618249, accuracy: 0.900000
Step: 480, avg loss: 0.114083, loss: 0.453530, accuracy: 0.900000
Step: 490, avg loss: 0.119781, loss: 0.393316, accuracy: 0.900000
Step: 500, avg loss: 0.124628, loss: 0.362134, accuracy: 0.900000
Step: 510, avg loss: 0.122592, loss: 0.020778, accuracy: 1.000000
Step: 520, avg loss: 0.121283, loss: 0.054537, accuracy: 1.000000
Step: 530, avg loss: 0.120144, loss: 0.060917, accuracy: 1.000000
Step: 540, avg loss: 0.118327, loss: 0.022002, accuracy: 1.000000
Step: 550, avg loss: 0.116447, loss: 0.014939, accuracy: 1.000000
Step: 560, avg loss: 0.114649, loss: 0.015761, accuracy: 1.000000
Step: 570, avg loss: 0.113133, loss: 0.028256, accuracy: 1.000000
Step: 580, avg loss: 0.111764, loss: 0.033731, accuracy: 1.000000
Step: 590, avg loss: 0.110685, loss: 0.048113, accuracy: 1.000000
Step: 600, avg loss: 0.109541, loss: 0.042015, accuracy: 1.000000
Step: 610, avg loss: 0.108160, loss: 0.025274, accuracy: 1.000000
Step: 620, avg loss: 0.106863, loss: 0.027803, accuracy: 1.000000
Step: 630, avg loss: 0.105371, loss: 0.012830, accuracy: 1.000000
Step: 640, avg loss: 0.104318, loss: 0.038010, accuracy: 1.000000
Step: 650, avg loss: 0.102888, loss: 0.011348, accuracy: 1.000000
Step: 660, avg loss: 0.101721, loss: 0.025892, accuracy: 1.000000
Step: 670, avg loss: 0.110960, loss: 0.720679, accuracy: 0.900000
Step: 680, avg loss: 0.110042, loss: 0.048569, accuracy: 1.000000
Step: 690, avg loss: 0.108854, loss: 0.028097, accuracy: 1.000000
Step: 700, avg loss: 0.107737, loss: 0.030641, accuracy: 1.000000
Step: 710, avg loss: 0.106434, loss: 0.015234, accuracy: 1.000000
Step: 720, avg loss: 0.105200, loss: 0.017551, accuracy: 1.000000
Step: 730, avg loss: 0.103973, loss: 0.015632, accuracy: 1.000000
Step: 740, avg loss: 0.103247, loss: 0.050250, accuracy: 1.000000
Step: 750, avg loss: 0.102092, loss: 0.016601, accuracy: 1.000000
Step: 760, avg loss: 0.100936, loss: 0.014251, accuracy: 1.000000
Step: 770, avg loss: 0.099780, loss: 0.011907, accuracy: 1.000000
Step: 780, avg loss: 0.099009, loss: 0.039679, accuracy: 1.000000
Step: 790, avg loss: 0.097896, loss: 0.011064, accuracy: 1.000000
Step: 800, avg loss: 0.096692, loss: 0.001599, accuracy: 1.000000
Step: 810, avg loss: 0.095806, loss: 0.024891, accuracy: 1.000000
Step: 820, avg loss: 0.094902, loss: 0.021691, accuracy: 1.000000
Step: 830, avg loss: 0.094538, loss: 0.064675, accuracy: 1.000000
Step: 840, avg loss: 0.093705, loss: 0.024631, accuracy: 1.000000
Step: 850, avg loss: 0.092791, loss: 0.015939, accuracy: 1.000000
Step: 860, avg loss: 0.092122, loss: 0.035337, accuracy: 1.000000
Step: 870, avg loss: 0.091181, loss: 0.010173, accuracy: 1.000000
Step: 880, avg loss: 0.090393, loss: 0.021872, accuracy: 1.000000
Step: 890, avg loss: 0.089495, loss: 0.010513, accuracy: 1.000000
Step: 900, avg loss: 0.088725, loss: 0.020156, accuracy: 1.000000
Step: 910, avg loss: 0.096651, loss: 0.809979, accuracy: 0.900000
Step: 920, avg loss: 0.095918, loss: 0.029245, accuracy: 1.000000
Step: 930, avg loss: 0.094931, loss: 0.004075, accuracy: 1.000000
Step: 940, avg loss: 0.094640, loss: 0.067604, accuracy: 1.000000
Step: 950, avg loss: 0.093915, loss: 0.025807, accuracy: 1.000000
Step: 960, avg loss: 0.093173, loss: 0.022634, accuracy: 1.000000
Step: 970, avg loss: 0.092494, loss: 0.027346, accuracy: 1.000000
Step: 980, avg loss: 0.091835, loss: 0.027899, accuracy: 1.000000
Step: 990, avg loss: 0.090932, loss: 0.002412, accuracy: 1.000000
Step: 1000, avg loss: 0.090148, loss: 0.012506, accuracy: 1.000000
Step: 1010, avg loss: 0.089545, loss: 0.029250, accuracy: 1.000000
Step: 1020, avg loss: 0.088688, loss: 0.002190, accuracy: 1.000000
Step: 1030, avg loss: 0.088023, loss: 0.020156, accuracy: 1.000000
Step: 1040, avg loss: 0.087202, loss: 0.002652, accuracy: 1.000000
Step: 1050, avg loss: 0.086628, loss: 0.026970, accuracy: 1.000000
Step: 1060, avg loss: 0.086066, loss: 0.026972, accuracy: 1.000000
Step: 1070, avg loss: 0.085362, loss: 0.010735, accuracy: 1.000000
Step: 1080, avg loss: 0.085156, loss: 0.063174, accuracy: 1.000000
Step: 1090, avg loss: 0.084597, loss: 0.024273, accuracy: 1.000000
Step: 1100, avg loss: 0.083858, loss: 0.003299, accuracy: 1.000000
Step: 1110, avg loss: 0.083114, loss: 0.001203, accuracy: 1.000000
Step: 1120, avg loss: 0.082492, loss: 0.013476, accuracy: 1.000000
Step: 1130, avg loss: 0.081856, loss: 0.010645, accuracy: 1.000000
Step: 1140, avg loss: 0.081486, loss: 0.039626, accuracy: 1.000000
Step: 1150, avg loss: 0.080929, loss: 0.017509, accuracy: 1.000000
Step: 1160, avg loss: 0.080883, loss: 0.075485, accuracy: 1.000000
Step: 1170, avg loss: 0.080559, loss: 0.043054, accuracy: 1.000000
Step: 1180, avg loss: 0.080681, loss: 0.094989, accuracy: 1.000000
Step: 1190, avg loss: 0.080523, loss: 0.061773, accuracy: 1.000000
Step: 1200, avg loss: 0.080585, loss: 0.087955, accuracy: 1.000000
Step: 1210, avg loss: 0.080739, loss: 0.099221, accuracy: 1.000000
Step: 1220, avg loss: 0.080312, loss: 0.028750, accuracy: 1.000000
Step: 1230, avg loss: 0.079796, loss: 0.016774, accuracy: 1.000000
Step: 1240, avg loss: 0.079427, loss: 0.034049, accuracy: 1.000000
Step: 1250, avg loss: 0.078816, loss: 0.003042, accuracy: 1.000000
Step: 1260, avg loss: 0.078427, loss: 0.029836, accuracy: 1.000000
Epoch 31 finished in loss: 0.078310 and accuracy: 0.991284
Step: 10, avg loss: 0.042573, loss: 0.042573, accuracy: 1.000000
Step: 20, avg loss: 0.034917, loss: 0.027261, accuracy: 1.000000
Step: 30, avg loss: 0.035679, loss: 0.037203, accuracy: 1.000000
Step: 40, avg loss: 0.032260, loss: 0.022004, accuracy: 1.000000
Step: 50, avg loss: 0.028728, loss: 0.014598, accuracy: 1.000000
Step: 60, avg loss: 0.028229, loss: 0.025735, accuracy: 1.000000
Step: 70, avg loss: 0.024312, loss: 0.000810, accuracy: 1.000000
Step: 80, avg loss: 0.024183, loss: 0.023281, accuracy: 1.000000
Step: 90, avg loss: 0.128997, loss: 0.967507, accuracy: 0.900000
Step: 100, avg loss: 0.117752, loss: 0.016545, accuracy: 1.000000
Step: 110, avg loss: 0.111118, loss: 0.044778, accuracy: 1.000000
Step: 120, avg loss: 0.102166, loss: 0.003691, accuracy: 1.000000
Step: 130, avg loss: 0.095339, loss: 0.013422, accuracy: 1.000000
Step: 140, avg loss: 0.089388, loss: 0.012024, accuracy: 1.000000
Step: 150, avg loss: 0.086529, loss: 0.046496, accuracy: 1.000000
Step: 160, avg loss: 0.082886, loss: 0.028251, accuracy: 1.000000
Step: 170, avg loss: 0.078090, loss: 0.001343, accuracy: 1.000000
Step: 180, avg loss: 0.113616, loss: 0.717569, accuracy: 0.900000
Step: 190, avg loss: 0.110465, loss: 0.053752, accuracy: 1.000000
Step: 200, avg loss: 0.105985, loss: 0.020857, accuracy: 1.000000
Step: 210, avg loss: 0.102603, loss: 0.034965, accuracy: 1.000000
Step: 220, avg loss: 0.099178, loss: 0.027252, accuracy: 1.000000
Step: 230, avg loss: 0.095535, loss: 0.015391, accuracy: 1.000000
Step: 240, avg loss: 0.093048, loss: 0.035836, accuracy: 1.000000
Step: 250, avg loss: 0.090502, loss: 0.029407, accuracy: 1.000000
Step: 260, avg loss: 0.088068, loss: 0.027218, accuracy: 1.000000
Step: 270, avg loss: 0.086231, loss: 0.038466, accuracy: 1.000000
Step: 280, avg loss: 0.083363, loss: 0.005936, accuracy: 1.000000
Step: 290, avg loss: 0.082417, loss: 0.055928, accuracy: 1.000000
Step: 300, avg loss: 0.080290, loss: 0.018603, accuracy: 1.000000
Step: 310, avg loss: 0.079026, loss: 0.041110, accuracy: 1.000000
Step: 320, avg loss: 0.077311, loss: 0.024141, accuracy: 1.000000
Step: 330, avg loss: 0.076708, loss: 0.057421, accuracy: 1.000000
Step: 340, avg loss: 0.075952, loss: 0.051000, accuracy: 1.000000
Step: 350, avg loss: 0.075158, loss: 0.048167, accuracy: 1.000000
Step: 360, avg loss: 0.074133, loss: 0.038230, accuracy: 1.000000
Step: 370, avg loss: 0.073848, loss: 0.063592, accuracy: 1.000000
Step: 380, avg loss: 0.092563, loss: 0.785028, accuracy: 0.900000
Step: 390, avg loss: 0.091146, loss: 0.037319, accuracy: 1.000000
Step: 400, avg loss: 0.089842, loss: 0.038986, accuracy: 1.000000
Step: 410, avg loss: 0.089585, loss: 0.079279, accuracy: 1.000000
Step: 420, avg loss: 0.087805, loss: 0.014816, accuracy: 1.000000
Step: 430, avg loss: 0.086739, loss: 0.042004, accuracy: 1.000000
Step: 440, avg loss: 0.086062, loss: 0.056921, accuracy: 1.000000
Step: 450, avg loss: 0.084951, loss: 0.036059, accuracy: 1.000000
Step: 460, avg loss: 0.084337, loss: 0.056704, accuracy: 1.000000
Step: 470, avg loss: 0.096322, loss: 0.647633, accuracy: 0.900000
Step: 480, avg loss: 0.103771, loss: 0.453904, accuracy: 0.900000
Step: 490, avg loss: 0.109888, loss: 0.403488, accuracy: 0.900000
Step: 500, avg loss: 0.109449, loss: 0.087934, accuracy: 1.000000
Step: 510, avg loss: 0.107692, loss: 0.019830, accuracy: 1.000000
Step: 520, avg loss: 0.106632, loss: 0.052581, accuracy: 1.000000
Step: 530, avg loss: 0.105510, loss: 0.047167, accuracy: 1.000000
Step: 540, avg loss: 0.103904, loss: 0.018797, accuracy: 1.000000
Step: 550, avg loss: 0.103135, loss: 0.061627, accuracy: 1.000000
Step: 560, avg loss: 0.104901, loss: 0.201987, accuracy: 0.900000
Step: 570, avg loss: 0.103579, loss: 0.029559, accuracy: 1.000000
Step: 580, avg loss: 0.102422, loss: 0.036466, accuracy: 1.000000
Step: 590, avg loss: 0.101475, loss: 0.046595, accuracy: 1.000000
Step: 600, avg loss: 0.100485, loss: 0.042022, accuracy: 1.000000
Step: 610, avg loss: 0.099251, loss: 0.025234, accuracy: 1.000000
Step: 620, avg loss: 0.098112, loss: 0.028627, accuracy: 1.000000
Step: 630, avg loss: 0.096763, loss: 0.013154, accuracy: 1.000000
Step: 640, avg loss: 0.095862, loss: 0.039103, accuracy: 1.000000
Step: 650, avg loss: 0.094579, loss: 0.012472, accuracy: 1.000000
Step: 660, avg loss: 0.093531, loss: 0.025403, accuracy: 1.000000
Step: 670, avg loss: 0.101926, loss: 0.655998, accuracy: 0.900000
Step: 680, avg loss: 0.101151, loss: 0.049184, accuracy: 1.000000
Step: 690, avg loss: 0.100117, loss: 0.029840, accuracy: 1.000000
Step: 700, avg loss: 0.098833, loss: 0.010207, accuracy: 1.000000
Step: 710, avg loss: 0.097651, loss: 0.014946, accuracy: 1.000000
Step: 720, avg loss: 0.096664, loss: 0.026570, accuracy: 1.000000
Step: 730, avg loss: 0.095555, loss: 0.015720, accuracy: 1.000000
Step: 740, avg loss: 0.094938, loss: 0.049902, accuracy: 1.000000
Step: 750, avg loss: 0.093867, loss: 0.014602, accuracy: 1.000000
Step: 760, avg loss: 0.092799, loss: 0.012684, accuracy: 1.000000
Step: 770, avg loss: 0.091760, loss: 0.012791, accuracy: 1.000000
Step: 780, avg loss: 0.091080, loss: 0.038694, accuracy: 1.000000
Step: 790, avg loss: 0.090075, loss: 0.011701, accuracy: 1.000000
Step: 800, avg loss: 0.088971, loss: 0.001779, accuracy: 1.000000
Step: 810, avg loss: 0.088175, loss: 0.024510, accuracy: 1.000000
Step: 820, avg loss: 0.087349, loss: 0.020434, accuracy: 1.000000
Step: 830, avg loss: 0.086787, loss: 0.040729, accuracy: 1.000000
Step: 840, avg loss: 0.086116, loss: 0.030398, accuracy: 1.000000
Step: 850, avg loss: 0.085163, loss: 0.005112, accuracy: 1.000000
Step: 860, avg loss: 0.084633, loss: 0.039602, accuracy: 1.000000
Step: 870, avg loss: 0.083667, loss: 0.000537, accuracy: 1.000000
Step: 880, avg loss: 0.082992, loss: 0.024275, accuracy: 1.000000
Step: 890, avg loss: 0.082085, loss: 0.002272, accuracy: 1.000000
Step: 900, avg loss: 0.081354, loss: 0.016339, accuracy: 1.000000
Step: 910, avg loss: 0.089686, loss: 0.839575, accuracy: 0.900000
Step: 920, avg loss: 0.089010, loss: 0.027440, accuracy: 1.000000
Step: 930, avg loss: 0.088098, loss: 0.004211, accuracy: 1.000000
Step: 940, avg loss: 0.087843, loss: 0.064163, accuracy: 1.000000
Step: 950, avg loss: 0.087147, loss: 0.021664, accuracy: 1.000000
Step: 960, avg loss: 0.086481, loss: 0.023225, accuracy: 1.000000
Step: 970, avg loss: 0.085876, loss: 0.027831, accuracy: 1.000000
Step: 980, avg loss: 0.085350, loss: 0.034269, accuracy: 1.000000
Step: 990, avg loss: 0.084582, loss: 0.009311, accuracy: 1.000000
Step: 1000, avg loss: 0.083858, loss: 0.012195, accuracy: 1.000000
Step: 1010, avg loss: 0.083269, loss: 0.024396, accuracy: 1.000000
Step: 1020, avg loss: 0.082468, loss: 0.001602, accuracy: 1.000000
Step: 1030, avg loss: 0.081783, loss: 0.011925, accuracy: 1.000000
Step: 1040, avg loss: 0.081017, loss: 0.002047, accuracy: 1.000000
Step: 1050, avg loss: 0.080518, loss: 0.028669, accuracy: 1.000000
Step: 1060, avg loss: 0.079998, loss: 0.025426, accuracy: 1.000000
Step: 1070, avg loss: 0.079350, loss: 0.010584, accuracy: 1.000000
Step: 1080, avg loss: 0.079143, loss: 0.057006, accuracy: 1.000000
Step: 1090, avg loss: 0.078788, loss: 0.040457, accuracy: 1.000000
Step: 1100, avg loss: 0.078104, loss: 0.003528, accuracy: 1.000000
Step: 1110, avg loss: 0.077413, loss: 0.001461, accuracy: 1.000000
Step: 1120, avg loss: 0.076866, loss: 0.016098, accuracy: 1.000000
Step: 1130, avg loss: 0.076277, loss: 0.010318, accuracy: 1.000000
Step: 1140, avg loss: 0.075900, loss: 0.033271, accuracy: 1.000000
Step: 1150, avg loss: 0.075379, loss: 0.016001, accuracy: 1.000000
Step: 1160, avg loss: 0.075348, loss: 0.071819, accuracy: 1.000000
Step: 1170, avg loss: 0.075042, loss: 0.039534, accuracy: 1.000000
Step: 1180, avg loss: 0.074972, loss: 0.066817, accuracy: 1.000000
Step: 1190, avg loss: 0.074858, loss: 0.061312, accuracy: 1.000000
Step: 1200, avg loss: 0.074723, loss: 0.058679, accuracy: 1.000000
Step: 1210, avg loss: 0.074845, loss: 0.089545, accuracy: 1.000000
Step: 1220, avg loss: 0.074440, loss: 0.025450, accuracy: 1.000000
Step: 1230, avg loss: 0.073942, loss: 0.013160, accuracy: 1.000000
Step: 1240, avg loss: 0.073661, loss: 0.039089, accuracy: 1.000000
Step: 1250, avg loss: 0.073100, loss: 0.003528, accuracy: 1.000000
Step: 1260, avg loss: 0.072740, loss: 0.027800, accuracy: 1.000000
Epoch 32 finished in loss: 0.072630 and accuracy: 0.992868
Step: 10, avg loss: 0.044930, loss: 0.044930, accuracy: 1.000000
Step: 20, avg loss: 0.036046, loss: 0.027161, accuracy: 1.000000
Step: 30, avg loss: 0.036387, loss: 0.037071, accuracy: 1.000000
Step: 40, avg loss: 0.032373, loss: 0.020330, accuracy: 1.000000
Step: 50, avg loss: 0.027481, loss: 0.007912, accuracy: 1.000000
Step: 60, avg loss: 0.028070, loss: 0.031018, accuracy: 1.000000
Step: 70, avg loss: 0.024166, loss: 0.000738, accuracy: 1.000000
Step: 80, avg loss: 0.023864, loss: 0.021751, accuracy: 1.000000
Step: 90, avg loss: 0.131774, loss: 0.995059, accuracy: 0.900000
Step: 100, avg loss: 0.120146, loss: 0.015494, accuracy: 1.000000
Step: 110, avg loss: 0.113214, loss: 0.043896, accuracy: 1.000000
Step: 120, avg loss: 0.103993, loss: 0.002555, accuracy: 1.000000
Step: 130, avg loss: 0.097093, loss: 0.014293, accuracy: 1.000000
Step: 140, avg loss: 0.091010, loss: 0.011936, accuracy: 1.000000
Step: 150, avg loss: 0.087906, loss: 0.044451, accuracy: 1.000000
Step: 160, avg loss: 0.084086, loss: 0.026787, accuracy: 1.000000
Step: 170, avg loss: 0.079649, loss: 0.008654, accuracy: 1.000000
Step: 180, avg loss: 0.115348, loss: 0.722234, accuracy: 0.900000
Step: 190, avg loss: 0.111556, loss: 0.043295, accuracy: 1.000000
Step: 200, avg loss: 0.106628, loss: 0.012985, accuracy: 1.000000
Step: 210, avg loss: 0.102311, loss: 0.015987, accuracy: 1.000000
Step: 220, avg loss: 0.098824, loss: 0.025597, accuracy: 1.000000
Step: 230, avg loss: 0.094808, loss: 0.006442, accuracy: 1.000000
Step: 240, avg loss: 0.092506, loss: 0.039575, accuracy: 1.000000
Step: 250, avg loss: 0.090498, loss: 0.042308, accuracy: 1.000000
Step: 260, avg loss: 0.088021, loss: 0.026095, accuracy: 1.000000
Step: 270, avg loss: 0.086198, loss: 0.038796, accuracy: 1.000000
Step: 280, avg loss: 0.083351, loss: 0.006468, accuracy: 1.000000
Step: 290, avg loss: 0.082314, loss: 0.053285, accuracy: 1.000000
Step: 300, avg loss: 0.080455, loss: 0.026535, accuracy: 1.000000
Step: 310, avg loss: 0.079053, loss: 0.037012, accuracy: 1.000000
Step: 320, avg loss: 0.077318, loss: 0.023521, accuracy: 1.000000
Step: 330, avg loss: 0.076662, loss: 0.055667, accuracy: 1.000000
Step: 340, avg loss: 0.075995, loss: 0.054007, accuracy: 1.000000
Step: 350, avg loss: 0.074644, loss: 0.028699, accuracy: 1.000000
Step: 360, avg loss: 0.073711, loss: 0.041064, accuracy: 1.000000
Step: 370, avg loss: 0.073794, loss: 0.076774, accuracy: 1.000000
Step: 380, avg loss: 0.095086, loss: 0.882868, accuracy: 0.900000
Step: 390, avg loss: 0.093526, loss: 0.034253, accuracy: 1.000000
Step: 400, avg loss: 0.092316, loss: 0.045145, accuracy: 1.000000
Step: 410, avg loss: 0.091858, loss: 0.073518, accuracy: 1.000000
Step: 420, avg loss: 0.089970, loss: 0.012587, accuracy: 1.000000
Step: 430, avg loss: 0.088814, loss: 0.040256, accuracy: 1.000000
Step: 440, avg loss: 0.088078, loss: 0.056418, accuracy: 1.000000
Step: 450, avg loss: 0.086779, loss: 0.029642, accuracy: 1.000000
Step: 460, avg loss: 0.086043, loss: 0.052888, accuracy: 1.000000
Step: 470, avg loss: 0.098461, loss: 0.669698, accuracy: 0.900000
Step: 480, avg loss: 0.106081, loss: 0.464214, accuracy: 0.900000
Step: 490, avg loss: 0.112111, loss: 0.401575, accuracy: 0.900000
Step: 500, avg loss: 0.111510, loss: 0.082065, accuracy: 1.000000
Step: 510, avg loss: 0.109815, loss: 0.025077, accuracy: 1.000000
Step: 520, avg loss: 0.108722, loss: 0.052944, accuracy: 1.000000
Step: 530, avg loss: 0.107825, loss: 0.061209, accuracy: 1.000000
Step: 540, avg loss: 0.106178, loss: 0.018872, accuracy: 1.000000
Step: 550, avg loss: 0.104655, loss: 0.022437, accuracy: 1.000000
Step: 560, avg loss: 0.103151, loss: 0.020431, accuracy: 1.000000
Step: 570, avg loss: 0.101952, loss: 0.034803, accuracy: 1.000000
Step: 580, avg loss: 0.100818, loss: 0.036165, accuracy: 1.000000
Step: 590, avg loss: 0.099953, loss: 0.049793, accuracy: 1.000000
Step: 600, avg loss: 0.099043, loss: 0.045325, accuracy: 1.000000
Step: 610, avg loss: 0.097826, loss: 0.024828, accuracy: 1.000000
Step: 620, avg loss: 0.096746, loss: 0.030855, accuracy: 1.000000
Step: 630, avg loss: 0.095421, loss: 0.013275, accuracy: 1.000000
Step: 640, avg loss: 0.094490, loss: 0.035808, accuracy: 1.000000
Step: 650, avg loss: 0.093217, loss: 0.011794, accuracy: 1.000000
Step: 660, avg loss: 0.092179, loss: 0.024708, accuracy: 1.000000
Step: 670, avg loss: 0.101651, loss: 0.726764, accuracy: 0.900000
Step: 680, avg loss: 0.100855, loss: 0.047575, accuracy: 1.000000
Step: 690, avg loss: 0.099784, loss: 0.026911, accuracy: 1.000000
Step: 700, avg loss: 0.098486, loss: 0.008961, accuracy: 1.000000
Step: 710, avg loss: 0.097286, loss: 0.013236, accuracy: 1.000000
Step: 720, avg loss: 0.096152, loss: 0.015652, accuracy: 1.000000
Step: 730, avg loss: 0.095033, loss: 0.014449, accuracy: 1.000000
Step: 740, avg loss: 0.094419, loss: 0.049594, accuracy: 1.000000
Step: 750, avg loss: 0.093382, loss: 0.016684, accuracy: 1.000000
Step: 760, avg loss: 0.092367, loss: 0.016201, accuracy: 1.000000
Step: 770, avg loss: 0.091332, loss: 0.012727, accuracy: 1.000000
Step: 780, avg loss: 0.090646, loss: 0.037817, accuracy: 1.000000
Step: 790, avg loss: 0.089647, loss: 0.011674, accuracy: 1.000000
Step: 800, avg loss: 0.088549, loss: 0.001816, accuracy: 1.000000
Step: 810, avg loss: 0.087763, loss: 0.024902, accuracy: 1.000000
Step: 820, avg loss: 0.087584, loss: 0.073099, accuracy: 1.000000
Step: 830, avg loss: 0.086953, loss: 0.035184, accuracy: 1.000000
Step: 840, avg loss: 0.086268, loss: 0.029395, accuracy: 1.000000
Step: 850, avg loss: 0.088028, loss: 0.235870, accuracy: 0.900000
Step: 860, avg loss: 0.087345, loss: 0.029360, accuracy: 1.000000
Step: 870, avg loss: 0.086356, loss: 0.001255, accuracy: 1.000000
Step: 880, avg loss: 0.085625, loss: 0.022039, accuracy: 1.000000
Step: 890, avg loss: 0.084778, loss: 0.010262, accuracy: 1.000000
Step: 900, avg loss: 0.083998, loss: 0.014549, accuracy: 1.000000
Step: 910, avg loss: 0.091913, loss: 0.804246, accuracy: 0.900000
Step: 920, avg loss: 0.091217, loss: 0.027951, accuracy: 1.000000
Step: 930, avg loss: 0.090292, loss: 0.005129, accuracy: 1.000000
Step: 940, avg loss: 0.089968, loss: 0.059899, accuracy: 1.000000
Step: 950, avg loss: 0.089419, loss: 0.037744, accuracy: 1.000000
Step: 960, avg loss: 0.088721, loss: 0.022452, accuracy: 1.000000
Step: 970, avg loss: 0.088098, loss: 0.028284, accuracy: 1.000000
Step: 980, avg loss: 0.087603, loss: 0.039564, accuracy: 1.000000
Step: 990, avg loss: 0.086745, loss: 0.002717, accuracy: 1.000000
Step: 1000, avg loss: 0.086010, loss: 0.013167, accuracy: 1.000000
Step: 1010, avg loss: 0.085426, loss: 0.027016, accuracy: 1.000000
Step: 1020, avg loss: 0.084615, loss: 0.002723, accuracy: 1.000000
Step: 1030, avg loss: 0.083901, loss: 0.011117, accuracy: 1.000000
Step: 1040, avg loss: 0.083123, loss: 0.002947, accuracy: 1.000000
Step: 1050, avg loss: 0.082545, loss: 0.022441, accuracy: 1.000000
Step: 1060, avg loss: 0.082026, loss: 0.027533, accuracy: 1.000000
Step: 1070, avg loss: 0.081374, loss: 0.012295, accuracy: 1.000000
Step: 1080, avg loss: 0.081337, loss: 0.077390, accuracy: 1.000000
Step: 1090, avg loss: 0.080804, loss: 0.023192, accuracy: 1.000000
Step: 1100, avg loss: 0.080104, loss: 0.003776, accuracy: 1.000000
Step: 1110, avg loss: 0.079389, loss: 0.000819, accuracy: 1.000000
Step: 1120, avg loss: 0.078826, loss: 0.016343, accuracy: 1.000000
Step: 1130, avg loss: 0.078221, loss: 0.010387, accuracy: 1.000000
Step: 1140, avg loss: 0.077786, loss: 0.028616, accuracy: 1.000000
Step: 1150, avg loss: 0.077499, loss: 0.044777, accuracy: 1.000000
Step: 1160, avg loss: 0.077468, loss: 0.073998, accuracy: 1.000000
Step: 1170, avg loss: 0.077132, loss: 0.038166, accuracy: 1.000000
Step: 1180, avg loss: 0.076840, loss: 0.042567, accuracy: 1.000000
Step: 1190, avg loss: 0.076755, loss: 0.066835, accuracy: 1.000000
Step: 1200, avg loss: 0.076495, loss: 0.045459, accuracy: 1.000000
Step: 1210, avg loss: 0.076577, loss: 0.086402, accuracy: 1.000000
Step: 1220, avg loss: 0.076101, loss: 0.018532, accuracy: 1.000000
Step: 1230, avg loss: 0.075579, loss: 0.011957, accuracy: 1.000000
Step: 1240, avg loss: 0.075295, loss: 0.040303, accuracy: 1.000000
Step: 1250, avg loss: 0.074717, loss: 0.003068, accuracy: 1.000000
Step: 1260, avg loss: 0.074326, loss: 0.025467, accuracy: 1.000000
Epoch 33 finished in loss: 0.074212 and accuracy: 0.992868
Step: 10, avg loss: 0.050353, loss: 0.050353, accuracy: 1.000000
Step: 20, avg loss: 0.037859, loss: 0.025365, accuracy: 1.000000
Step: 30, avg loss: 0.036455, loss: 0.033647, accuracy: 1.000000
Step: 40, avg loss: 0.030450, loss: 0.012434, accuracy: 1.000000
Step: 50, avg loss: 0.027006, loss: 0.013233, accuracy: 1.000000
Step: 60, avg loss: 0.026589, loss: 0.024503, accuracy: 1.000000
Step: 70, avg loss: 0.023087, loss: 0.002074, accuracy: 1.000000
Step: 80, avg loss: 0.023458, loss: 0.026051, accuracy: 1.000000
Step: 90, avg loss: 0.144487, loss: 1.112719, accuracy: 0.900000
Step: 100, avg loss: 0.131446, loss: 0.014076, accuracy: 1.000000
Step: 110, avg loss: 0.123305, loss: 0.041900, accuracy: 1.000000
Step: 120, avg loss: 0.113251, loss: 0.002651, accuracy: 1.000000
Step: 130, avg loss: 0.105535, loss: 0.012944, accuracy: 1.000000
Step: 140, avg loss: 0.098824, loss: 0.011587, accuracy: 1.000000
Step: 150, avg loss: 0.095057, loss: 0.042323, accuracy: 1.000000
Step: 160, avg loss: 0.090840, loss: 0.027584, accuracy: 1.000000
Step: 170, avg loss: 0.085708, loss: 0.003587, accuracy: 1.000000
Step: 180, avg loss: 0.122040, loss: 0.739684, accuracy: 0.900000
Step: 190, avg loss: 0.117891, loss: 0.043205, accuracy: 1.000000
Step: 200, avg loss: 0.115927, loss: 0.078622, accuracy: 1.000000
Step: 210, avg loss: 0.111581, loss: 0.024651, accuracy: 1.000000
Step: 220, avg loss: 0.110145, loss: 0.079992, accuracy: 1.000000
Step: 230, avg loss: 0.105680, loss: 0.007465, accuracy: 1.000000
Step: 240, avg loss: 0.112543, loss: 0.270376, accuracy: 0.900000
Step: 250, avg loss: 0.109808, loss: 0.044177, accuracy: 1.000000
Step: 260, avg loss: 0.106561, loss: 0.025380, accuracy: 1.000000
Step: 270, avg loss: 0.104242, loss: 0.043959, accuracy: 1.000000
Step: 280, avg loss: 0.100857, loss: 0.009448, accuracy: 1.000000
Step: 290, avg loss: 0.099322, loss: 0.056339, accuracy: 1.000000
Step: 300, avg loss: 0.096958, loss: 0.028418, accuracy: 1.000000
Step: 310, avg loss: 0.095146, loss: 0.040776, accuracy: 1.000000
Step: 320, avg loss: 0.092994, loss: 0.026273, accuracy: 1.000000
Step: 330, avg loss: 0.091871, loss: 0.055957, accuracy: 1.000000
Step: 340, avg loss: 0.090672, loss: 0.051083, accuracy: 1.000000
Step: 350, avg loss: 0.089299, loss: 0.042632, accuracy: 1.000000
Step: 360, avg loss: 0.087648, loss: 0.029847, accuracy: 1.000000
Step: 370, avg loss: 0.087226, loss: 0.072052, accuracy: 1.000000
Step: 380, avg loss: 0.105880, loss: 0.796060, accuracy: 0.900000
Step: 390, avg loss: 0.103976, loss: 0.031619, accuracy: 1.000000
Step: 400, avg loss: 0.102454, loss: 0.043116, accuracy: 1.000000
Step: 410, avg loss: 0.101815, loss: 0.076237, accuracy: 1.000000
Step: 420, avg loss: 0.099683, loss: 0.012306, accuracy: 1.000000
Step: 430, avg loss: 0.098318, loss: 0.040965, accuracy: 1.000000
Step: 440, avg loss: 0.098183, loss: 0.092380, accuracy: 1.000000
Step: 450, avg loss: 0.096750, loss: 0.033682, accuracy: 1.000000
Step: 460, avg loss: 0.095903, loss: 0.057816, accuracy: 1.000000
Step: 470, avg loss: 0.107393, loss: 0.635918, accuracy: 0.900000
Step: 480, avg loss: 0.114645, loss: 0.455477, accuracy: 0.900000
Step: 490, avg loss: 0.120591, loss: 0.406018, accuracy: 0.900000
Step: 500, avg loss: 0.119880, loss: 0.085054, accuracy: 1.000000
Step: 510, avg loss: 0.117985, loss: 0.023199, accuracy: 1.000000
Step: 520, avg loss: 0.116657, loss: 0.048967, accuracy: 1.000000
Step: 530, avg loss: 0.115539, loss: 0.057364, accuracy: 1.000000
Step: 540, avg loss: 0.113757, loss: 0.019339, accuracy: 1.000000
Step: 550, avg loss: 0.112008, loss: 0.017550, accuracy: 1.000000
Step: 560, avg loss: 0.110323, loss: 0.017682, accuracy: 1.000000
Step: 570, avg loss: 0.108876, loss: 0.027822, accuracy: 1.000000
Step: 580, avg loss: 0.107615, loss: 0.035731, accuracy: 1.000000
Step: 590, avg loss: 0.106603, loss: 0.047924, accuracy: 1.000000
Step: 600, avg loss: 0.105560, loss: 0.044009, accuracy: 1.000000
Step: 610, avg loss: 0.104273, loss: 0.027048, accuracy: 1.000000
Step: 620, avg loss: 0.103035, loss: 0.027502, accuracy: 1.000000
Step: 630, avg loss: 0.101611, loss: 0.013360, accuracy: 1.000000
Step: 640, avg loss: 0.100597, loss: 0.036720, accuracy: 1.000000
Step: 650, avg loss: 0.099213, loss: 0.010604, accuracy: 1.000000
Step: 660, avg loss: 0.098111, loss: 0.026477, accuracy: 1.000000
Step: 670, avg loss: 0.107928, loss: 0.755889, accuracy: 0.900000
Step: 680, avg loss: 0.107159, loss: 0.055610, accuracy: 1.000000
Step: 690, avg loss: 0.106000, loss: 0.027220, accuracy: 1.000000
Step: 700, avg loss: 0.104567, loss: 0.005651, accuracy: 1.000000
Step: 710, avg loss: 0.103276, loss: 0.012951, accuracy: 1.000000
Step: 720, avg loss: 0.102140, loss: 0.021460, accuracy: 1.000000
Step: 730, avg loss: 0.100942, loss: 0.014700, accuracy: 1.000000
Step: 740, avg loss: 0.100278, loss: 0.051800, accuracy: 1.000000
Step: 750, avg loss: 0.099167, loss: 0.016943, accuracy: 1.000000
Step: 760, avg loss: 0.098061, loss: 0.015071, accuracy: 1.000000
Step: 770, avg loss: 0.096941, loss: 0.011886, accuracy: 1.000000
Step: 780, avg loss: 0.096147, loss: 0.034946, accuracy: 1.000000
Step: 790, avg loss: 0.095080, loss: 0.011864, accuracy: 1.000000
Step: 800, avg loss: 0.093912, loss: 0.001672, accuracy: 1.000000
Step: 810, avg loss: 0.093052, loss: 0.024243, accuracy: 1.000000
Step: 820, avg loss: 0.092184, loss: 0.021838, accuracy: 1.000000
Step: 830, avg loss: 0.091470, loss: 0.032950, accuracy: 1.000000
Step: 840, avg loss: 0.090675, loss: 0.024705, accuracy: 1.000000
Step: 850, avg loss: 0.089641, loss: 0.002807, accuracy: 1.000000
Step: 860, avg loss: 0.089025, loss: 0.036638, accuracy: 1.000000
Step: 870, avg loss: 0.088120, loss: 0.010276, accuracy: 1.000000
Step: 880, avg loss: 0.087354, loss: 0.020725, accuracy: 1.000000
Step: 890, avg loss: 0.086412, loss: 0.003480, accuracy: 1.000000
Step: 900, avg loss: 0.085667, loss: 0.019414, accuracy: 1.000000
Step: 910, avg loss: 0.094241, loss: 0.865887, accuracy: 0.900000
Step: 920, avg loss: 0.093520, loss: 0.027920, accuracy: 1.000000
Step: 930, avg loss: 0.092591, loss: 0.007078, accuracy: 1.000000
Step: 940, avg loss: 0.092301, loss: 0.065397, accuracy: 1.000000
Step: 950, avg loss: 0.091731, loss: 0.038123, accuracy: 1.000000
Step: 960, avg loss: 0.091020, loss: 0.023505, accuracy: 1.000000
Step: 970, avg loss: 0.090361, loss: 0.027092, accuracy: 1.000000
Step: 980, avg loss: 0.089763, loss: 0.031725, accuracy: 1.000000
Step: 990, avg loss: 0.088883, loss: 0.002595, accuracy: 1.000000
Step: 1000, avg loss: 0.088137, loss: 0.014302, accuracy: 1.000000
Step: 1010, avg loss: 0.087588, loss: 0.032735, accuracy: 1.000000
Step: 1020, avg loss: 0.086748, loss: 0.001856, accuracy: 1.000000
Step: 1030, avg loss: 0.086017, loss: 0.011437, accuracy: 1.000000
Step: 1040, avg loss: 0.085222, loss: 0.003426, accuracy: 1.000000
Step: 1050, avg loss: 0.084622, loss: 0.022154, accuracy: 1.000000
Step: 1060, avg loss: 0.084067, loss: 0.025792, accuracy: 1.000000
Step: 1070, avg loss: 0.086045, loss: 0.295777, accuracy: 0.900000
Step: 1080, avg loss: 0.085824, loss: 0.062143, accuracy: 1.000000
Step: 1090, avg loss: 0.085336, loss: 0.032680, accuracy: 1.000000
Step: 1100, avg loss: 0.084569, loss: 0.000944, accuracy: 1.000000
Step: 1110, avg loss: 0.083814, loss: 0.000754, accuracy: 1.000000
Step: 1120, avg loss: 0.083799, loss: 0.082172, accuracy: 1.000000
Step: 1130, avg loss: 0.083153, loss: 0.010734, accuracy: 1.000000
Step: 1140, avg loss: 0.082708, loss: 0.032470, accuracy: 1.000000
Step: 1150, avg loss: 0.082135, loss: 0.016750, accuracy: 1.000000
Step: 1160, avg loss: 0.082088, loss: 0.076673, accuracy: 1.000000
Step: 1170, avg loss: 0.081740, loss: 0.041434, accuracy: 1.000000
Step: 1180, avg loss: 0.081802, loss: 0.089035, accuracy: 1.000000
Step: 1190, avg loss: 0.082665, loss: 0.184447, accuracy: 0.900000
Step: 1200, avg loss: 0.082350, loss: 0.044922, accuracy: 1.000000
Step: 1210, avg loss: 0.082456, loss: 0.095187, accuracy: 1.000000
Step: 1220, avg loss: 0.081973, loss: 0.023549, accuracy: 1.000000
Step: 1230, avg loss: 0.081413, loss: 0.013027, accuracy: 1.000000
Step: 1240, avg loss: 0.081039, loss: 0.035010, accuracy: 1.000000
Step: 1250, avg loss: 0.080896, loss: 0.063167, accuracy: 1.000000
Step: 1260, avg loss: 0.080514, loss: 0.032832, accuracy: 1.000000
Epoch 34 finished in loss: 0.080394 and accuracy: 0.991284
Step: 10, avg loss: 0.044309, loss: 0.044309, accuracy: 1.000000
Step: 20, avg loss: 0.040946, loss: 0.037582, accuracy: 1.000000
Step: 30, avg loss: 0.038893, loss: 0.034787, accuracy: 1.000000
Step: 40, avg loss: 0.037762, loss: 0.034369, accuracy: 1.000000
Step: 50, avg loss: 0.034400, loss: 0.020952, accuracy: 1.000000
Step: 60, avg loss: 0.032852, loss: 0.025111, accuracy: 1.000000
Step: 70, avg loss: 0.028474, loss: 0.002210, accuracy: 1.000000
Step: 80, avg loss: 0.027351, loss: 0.019485, accuracy: 1.000000
Step: 90, avg loss: 0.119208, loss: 0.854072, accuracy: 0.900000
Step: 100, avg loss: 0.108630, loss: 0.013423, accuracy: 1.000000
Step: 110, avg loss: 0.102849, loss: 0.045039, accuracy: 1.000000
Step: 120, avg loss: 0.094479, loss: 0.002413, accuracy: 1.000000
Step: 130, avg loss: 0.088260, loss: 0.013624, accuracy: 1.000000
Step: 140, avg loss: 0.082892, loss: 0.013119, accuracy: 1.000000
Step: 150, avg loss: 0.080172, loss: 0.042085, accuracy: 1.000000
Step: 160, avg loss: 0.076853, loss: 0.027074, accuracy: 1.000000
Step: 170, avg loss: 0.072409, loss: 0.001295, accuracy: 1.000000
Step: 180, avg loss: 0.107172, loss: 0.698146, accuracy: 0.900000
Step: 190, avg loss: 0.105994, loss: 0.084785, accuracy: 1.000000
Step: 200, avg loss: 0.101700, loss: 0.020130, accuracy: 1.000000
Step: 210, avg loss: 0.097577, loss: 0.015116, accuracy: 1.000000
Step: 220, avg loss: 0.094435, loss: 0.028440, accuracy: 1.000000
Step: 230, avg loss: 0.090499, loss: 0.003907, accuracy: 1.000000
Step: 240, avg loss: 0.088040, loss: 0.031494, accuracy: 1.000000
Step: 250, avg loss: 0.085920, loss: 0.035035, accuracy: 1.000000
Step: 260, avg loss: 0.083576, loss: 0.024966, accuracy: 1.000000
Step: 270, avg loss: 0.082084, loss: 0.043294, accuracy: 1.000000
Step: 280, avg loss: 0.079238, loss: 0.002404, accuracy: 1.000000
Step: 290, avg loss: 0.078343, loss: 0.053284, accuracy: 1.000000
Step: 300, avg loss: 0.076670, loss: 0.028150, accuracy: 1.000000
Step: 310, avg loss: 0.075447, loss: 0.038765, accuracy: 1.000000
Step: 320, avg loss: 0.073841, loss: 0.024033, accuracy: 1.000000
Step: 330, avg loss: 0.073258, loss: 0.054608, accuracy: 1.000000
Step: 340, avg loss: 0.072730, loss: 0.055312, accuracy: 1.000000
Step: 350, avg loss: 0.071604, loss: 0.033333, accuracy: 1.000000
Step: 360, avg loss: 0.070594, loss: 0.035236, accuracy: 1.000000
Step: 370, avg loss: 0.070718, loss: 0.075191, accuracy: 1.000000
Step: 380, avg loss: 0.090825, loss: 0.834785, accuracy: 0.900000
Step: 390, avg loss: 0.089423, loss: 0.036117, accuracy: 1.000000
Step: 400, avg loss: 0.088265, loss: 0.043136, accuracy: 1.000000
Step: 410, avg loss: 0.087894, loss: 0.073021, accuracy: 1.000000
Step: 420, avg loss: 0.086103, loss: 0.012701, accuracy: 1.000000
Step: 430, avg loss: 0.085304, loss: 0.051752, accuracy: 1.000000
Step: 440, avg loss: 0.084687, loss: 0.058137, accuracy: 1.000000
Step: 450, avg loss: 0.083482, loss: 0.030479, accuracy: 1.000000
Step: 460, avg loss: 0.082944, loss: 0.058703, accuracy: 1.000000
Step: 470, avg loss: 0.094581, loss: 0.629923, accuracy: 0.900000
Step: 480, avg loss: 0.101728, loss: 0.437594, accuracy: 0.900000
Step: 490, avg loss: 0.107890, loss: 0.403683, accuracy: 0.900000
Step: 500, avg loss: 0.107561, loss: 0.091419, accuracy: 1.000000
Step: 510, avg loss: 0.105928, loss: 0.024281, accuracy: 1.000000
Step: 520, avg loss: 0.104875, loss: 0.051186, accuracy: 1.000000
Step: 530, avg loss: 0.103972, loss: 0.057003, accuracy: 1.000000
Step: 540, avg loss: 0.102391, loss: 0.018624, accuracy: 1.000000
Step: 550, avg loss: 0.100822, loss: 0.016071, accuracy: 1.000000
Step: 560, avg loss: 0.099325, loss: 0.017010, accuracy: 1.000000
Step: 570, avg loss: 0.098049, loss: 0.026591, accuracy: 1.000000
Step: 580, avg loss: 0.096950, loss: 0.034330, accuracy: 1.000000
Step: 590, avg loss: 0.096113, loss: 0.047556, accuracy: 1.000000
Step: 600, avg loss: 0.095170, loss: 0.039549, accuracy: 1.000000
Step: 610, avg loss: 0.094039, loss: 0.026131, accuracy: 1.000000
Step: 620, avg loss: 0.092949, loss: 0.026489, accuracy: 1.000000
Step: 630, avg loss: 0.091668, loss: 0.012265, accuracy: 1.000000
Step: 640, avg loss: 0.090787, loss: 0.035261, accuracy: 1.000000
Step: 650, avg loss: 0.089557, loss: 0.010814, accuracy: 1.000000
Step: 660, avg loss: 0.088555, loss: 0.023421, accuracy: 1.000000
Step: 670, avg loss: 0.098106, loss: 0.728519, accuracy: 0.900000
Step: 680, avg loss: 0.097250, loss: 0.039842, accuracy: 1.000000
Step: 690, avg loss: 0.096221, loss: 0.026283, accuracy: 1.000000
Step: 700, avg loss: 0.094913, loss: 0.004693, accuracy: 1.000000
Step: 710, avg loss: 0.093779, loss: 0.014398, accuracy: 1.000000
Step: 720, avg loss: 0.092769, loss: 0.021010, accuracy: 1.000000
Step: 730, avg loss: 0.091707, loss: 0.015257, accuracy: 1.000000
Step: 740, avg loss: 0.091136, loss: 0.049479, accuracy: 1.000000
Step: 750, avg loss: 0.090586, loss: 0.049890, accuracy: 1.000000
Step: 760, avg loss: 0.089799, loss: 0.030729, accuracy: 1.000000
Step: 770, avg loss: 0.088796, loss: 0.012585, accuracy: 1.000000
Step: 780, avg loss: 0.088204, loss: 0.042639, accuracy: 1.000000
Step: 790, avg loss: 0.087240, loss: 0.011997, accuracy: 1.000000
Step: 800, avg loss: 0.086171, loss: 0.001789, accuracy: 1.000000
Step: 810, avg loss: 0.085414, loss: 0.024840, accuracy: 1.000000
Step: 820, avg loss: 0.084660, loss: 0.023549, accuracy: 1.000000
Step: 830, avg loss: 0.084045, loss: 0.033620, accuracy: 1.000000
Step: 840, avg loss: 0.083300, loss: 0.021509, accuracy: 1.000000
Step: 850, avg loss: 0.082329, loss: 0.000743, accuracy: 1.000000
Step: 860, avg loss: 0.081785, loss: 0.035538, accuracy: 1.000000
Step: 870, avg loss: 0.080956, loss: 0.009636, accuracy: 1.000000
Step: 880, avg loss: 0.080278, loss: 0.021338, accuracy: 1.000000
Step: 890, avg loss: 0.079484, loss: 0.009549, accuracy: 1.000000
Step: 900, avg loss: 0.078984, loss: 0.034563, accuracy: 1.000000
Step: 910, avg loss: 0.087588, loss: 0.861860, accuracy: 0.900000
Step: 920, avg loss: 0.086942, loss: 0.028167, accuracy: 1.000000
Step: 930, avg loss: 0.086054, loss: 0.004367, accuracy: 1.000000
Step: 940, avg loss: 0.085812, loss: 0.063358, accuracy: 1.000000
Step: 950, avg loss: 0.085399, loss: 0.046590, accuracy: 1.000000
Step: 960, avg loss: 0.084736, loss: 0.021722, accuracy: 1.000000
Step: 970, avg loss: 0.084158, loss: 0.028645, accuracy: 1.000000
Step: 980, avg loss: 0.083557, loss: 0.025230, accuracy: 1.000000
Step: 990, avg loss: 0.082765, loss: 0.005213, accuracy: 1.000000
Step: 1000, avg loss: 0.082063, loss: 0.012510, accuracy: 1.000000
Step: 1010, avg loss: 0.081561, loss: 0.031364, accuracy: 1.000000
Step: 1020, avg loss: 0.080782, loss: 0.002154, accuracy: 1.000000
Step: 1030, avg loss: 0.080119, loss: 0.012489, accuracy: 1.000000
Step: 1040, avg loss: 0.079379, loss: 0.003098, accuracy: 1.000000
Step: 1050, avg loss: 0.078745, loss: 0.012820, accuracy: 1.000000
Step: 1060, avg loss: 0.078236, loss: 0.024787, accuracy: 1.000000
Step: 1070, avg loss: 0.077621, loss: 0.012518, accuracy: 1.000000
Step: 1080, avg loss: 0.077439, loss: 0.057864, accuracy: 1.000000
Step: 1090, avg loss: 0.076962, loss: 0.025547, accuracy: 1.000000
Step: 1100, avg loss: 0.076309, loss: 0.005043, accuracy: 1.000000
Step: 1110, avg loss: 0.075628, loss: 0.000705, accuracy: 1.000000
Step: 1120, avg loss: 0.075068, loss: 0.013013, accuracy: 1.000000
Step: 1130, avg loss: 0.074495, loss: 0.010244, accuracy: 1.000000
Step: 1140, avg loss: 0.074119, loss: 0.031704, accuracy: 1.000000
Step: 1150, avg loss: 0.073650, loss: 0.020182, accuracy: 1.000000
Step: 1160, avg loss: 0.073635, loss: 0.071805, accuracy: 1.000000
Step: 1170, avg loss: 0.073343, loss: 0.039539, accuracy: 1.000000
Step: 1180, avg loss: 0.073018, loss: 0.034980, accuracy: 1.000000
Step: 1190, avg loss: 0.072896, loss: 0.058545, accuracy: 1.000000
Step: 1200, avg loss: 0.072690, loss: 0.048122, accuracy: 1.000000
Step: 1210, avg loss: 0.072792, loss: 0.085048, accuracy: 1.000000
Step: 1220, avg loss: 0.072413, loss: 0.026542, accuracy: 1.000000
Step: 1230, avg loss: 0.071931, loss: 0.013149, accuracy: 1.000000
Step: 1240, avg loss: 0.071633, loss: 0.034927, accuracy: 1.000000
Step: 1250, avg loss: 0.071085, loss: 0.003161, accuracy: 1.000000
Step: 1260, avg loss: 0.070737, loss: 0.027284, accuracy: 1.000000
Epoch 35 finished in loss: 0.070628 and accuracy: 0.993661
Step: 10, avg loss: 0.273232, loss: 0.273232, accuracy: 0.900000
Step: 20, avg loss: 0.148195, loss: 0.023159, accuracy: 1.000000
Step: 30, avg loss: 0.111392, loss: 0.037786, accuracy: 1.000000
Step: 40, avg loss: 0.089146, loss: 0.022406, accuracy: 1.000000
Step: 50, avg loss: 0.073759, loss: 0.012214, accuracy: 1.000000
Step: 60, avg loss: 0.065576, loss: 0.024661, accuracy: 1.000000
Step: 70, avg loss: 0.056405, loss: 0.001376, accuracy: 1.000000
Step: 80, avg loss: 0.051732, loss: 0.019022, accuracy: 1.000000
Step: 90, avg loss: 0.160869, loss: 1.033964, accuracy: 0.900000
Step: 100, avg loss: 0.146173, loss: 0.013905, accuracy: 1.000000
Step: 110, avg loss: 0.136356, loss: 0.038185, accuracy: 1.000000
Step: 120, avg loss: 0.125270, loss: 0.003332, accuracy: 1.000000
Step: 130, avg loss: 0.116656, loss: 0.013280, accuracy: 1.000000
Step: 140, avg loss: 0.109098, loss: 0.010850, accuracy: 1.000000
Step: 150, avg loss: 0.104518, loss: 0.040401, accuracy: 1.000000
Step: 160, avg loss: 0.099934, loss: 0.031167, accuracy: 1.000000
Step: 170, avg loss: 0.094127, loss: 0.001214, accuracy: 1.000000
Step: 180, avg loss: 0.134269, loss: 0.816690, accuracy: 0.900000
Step: 190, avg loss: 0.129495, loss: 0.043568, accuracy: 1.000000
Step: 200, avg loss: 0.123907, loss: 0.017731, accuracy: 1.000000
Step: 210, avg loss: 0.118600, loss: 0.012459, accuracy: 1.000000
Step: 220, avg loss: 0.114313, loss: 0.024285, accuracy: 1.000000
Step: 230, avg loss: 0.109488, loss: 0.003341, accuracy: 1.000000
Step: 240, avg loss: 0.106402, loss: 0.035425, accuracy: 1.000000
Step: 250, avg loss: 0.103155, loss: 0.025225, accuracy: 1.000000
Step: 260, avg loss: 0.100808, loss: 0.042133, accuracy: 1.000000
Step: 270, avg loss: 0.098567, loss: 0.040287, accuracy: 1.000000
Step: 280, avg loss: 0.095118, loss: 0.002008, accuracy: 1.000000
Step: 290, avg loss: 0.093666, loss: 0.053003, accuracy: 1.000000
Step: 300, avg loss: 0.091415, loss: 0.026142, accuracy: 1.000000
Step: 310, avg loss: 0.089621, loss: 0.035805, accuracy: 1.000000
Step: 320, avg loss: 0.087536, loss: 0.022887, accuracy: 1.000000
Step: 330, avg loss: 0.086443, loss: 0.051474, accuracy: 1.000000
Step: 340, avg loss: 0.085363, loss: 0.049716, accuracy: 1.000000
Step: 350, avg loss: 0.084065, loss: 0.039926, accuracy: 1.000000
Step: 360, avg loss: 0.082655, loss: 0.033335, accuracy: 1.000000
Step: 370, avg loss: 0.082154, loss: 0.064091, accuracy: 1.000000
Step: 380, avg loss: 0.101041, loss: 0.799861, accuracy: 0.900000
Step: 390, avg loss: 0.099322, loss: 0.034006, accuracy: 1.000000
Step: 400, avg loss: 0.097734, loss: 0.035793, accuracy: 1.000000
Step: 410, avg loss: 0.097316, loss: 0.080599, accuracy: 1.000000
Step: 420, avg loss: 0.095323, loss: 0.013626, accuracy: 1.000000
Step: 430, avg loss: 0.093994, loss: 0.038185, accuracy: 1.000000
Step: 440, avg loss: 0.097445, loss: 0.245802, accuracy: 0.900000
Step: 450, avg loss: 0.095967, loss: 0.030974, accuracy: 1.000000
Step: 460, avg loss: 0.095147, loss: 0.058220, accuracy: 1.000000
Step: 470, avg loss: 0.106352, loss: 0.621774, accuracy: 0.900000
Step: 480, avg loss: 0.113599, loss: 0.454203, accuracy: 0.900000
Step: 490, avg loss: 0.119680, loss: 0.411604, accuracy: 0.900000
Step: 500, avg loss: 0.119173, loss: 0.094318, accuracy: 1.000000
Step: 510, avg loss: 0.117718, loss: 0.044955, accuracy: 1.000000
Step: 520, avg loss: 0.116400, loss: 0.049184, accuracy: 1.000000
Step: 530, avg loss: 0.115211, loss: 0.053378, accuracy: 1.000000
Step: 540, avg loss: 0.113484, loss: 0.021977, accuracy: 1.000000
Step: 550, avg loss: 0.111733, loss: 0.017163, accuracy: 1.000000
Step: 560, avg loss: 0.109983, loss: 0.013740, accuracy: 1.000000
Step: 570, avg loss: 0.108545, loss: 0.028041, accuracy: 1.000000
Step: 580, avg loss: 0.107258, loss: 0.033874, accuracy: 1.000000
Step: 590, avg loss: 0.106225, loss: 0.046329, accuracy: 1.000000
Step: 600, avg loss: 0.105106, loss: 0.039058, accuracy: 1.000000
Step: 610, avg loss: 0.103807, loss: 0.025881, accuracy: 1.000000
Step: 620, avg loss: 0.102565, loss: 0.026815, accuracy: 1.000000
Step: 630, avg loss: 0.101147, loss: 0.013226, accuracy: 1.000000
Step: 640, avg loss: 0.100116, loss: 0.035166, accuracy: 1.000000
Step: 650, avg loss: 0.098753, loss: 0.011479, accuracy: 1.000000
Step: 660, avg loss: 0.097728, loss: 0.031140, accuracy: 1.000000
Step: 670, avg loss: 0.106900, loss: 0.712253, accuracy: 0.900000
Step: 680, avg loss: 0.105979, loss: 0.044251, accuracy: 1.000000
Step: 690, avg loss: 0.104856, loss: 0.028536, accuracy: 1.000000
Step: 700, avg loss: 0.103474, loss: 0.008050, accuracy: 1.000000
Step: 710, avg loss: 0.102205, loss: 0.013433, accuracy: 1.000000
Step: 720, avg loss: 0.100992, loss: 0.014830, accuracy: 1.000000
Step: 730, avg loss: 0.099820, loss: 0.015471, accuracy: 1.000000
Step: 740, avg loss: 0.099095, loss: 0.046116, accuracy: 1.000000
Step: 750, avg loss: 0.097957, loss: 0.013769, accuracy: 1.000000
Step: 760, avg loss: 0.096836, loss: 0.012778, accuracy: 1.000000
Step: 770, avg loss: 0.095738, loss: 0.012279, accuracy: 1.000000
Step: 780, avg loss: 0.095115, loss: 0.047176, accuracy: 1.000000
Step: 790, avg loss: 0.094066, loss: 0.012198, accuracy: 1.000000
Step: 800, avg loss: 0.092913, loss: 0.001821, accuracy: 1.000000
Step: 810, avg loss: 0.092052, loss: 0.023159, accuracy: 1.000000
Step: 820, avg loss: 0.091179, loss: 0.020515, accuracy: 1.000000
Step: 830, avg loss: 0.090501, loss: 0.034855, accuracy: 1.000000
Step: 840, avg loss: 0.089706, loss: 0.023776, accuracy: 1.000000
Step: 850, avg loss: 0.088865, loss: 0.018165, accuracy: 1.000000
Step: 860, avg loss: 0.088261, loss: 0.036956, accuracy: 1.000000
Step: 870, avg loss: 0.087556, loss: 0.026919, accuracy: 1.000000
Step: 880, avg loss: 0.086812, loss: 0.022072, accuracy: 1.000000
Step: 890, avg loss: 0.085867, loss: 0.002760, accuracy: 1.000000
Step: 900, avg loss: 0.085048, loss: 0.012137, accuracy: 1.000000
Step: 910, avg loss: 0.092780, loss: 0.788684, accuracy: 0.900000
Step: 920, avg loss: 0.092106, loss: 0.030744, accuracy: 1.000000
Step: 930, avg loss: 0.091168, loss: 0.004858, accuracy: 1.000000
Step: 940, avg loss: 0.090870, loss: 0.063189, accuracy: 1.000000
Step: 950, avg loss: 0.090222, loss: 0.029329, accuracy: 1.000000
Step: 960, avg loss: 0.089517, loss: 0.022501, accuracy: 1.000000
Step: 970, avg loss: 0.088881, loss: 0.027869, accuracy: 1.000000
Step: 980, avg loss: 0.088317, loss: 0.033577, accuracy: 1.000000
Step: 990, avg loss: 0.087450, loss: 0.002421, accuracy: 1.000000
Step: 1000, avg loss: 0.086702, loss: 0.012694, accuracy: 1.000000
Step: 1010, avg loss: 0.086149, loss: 0.030867, accuracy: 1.000000
Step: 1020, avg loss: 0.085332, loss: 0.002817, accuracy: 1.000000
Step: 1030, avg loss: 0.084697, loss: 0.019863, accuracy: 1.000000
Step: 1040, avg loss: 0.083923, loss: 0.004296, accuracy: 1.000000
Step: 1050, avg loss: 0.083331, loss: 0.021669, accuracy: 1.000000
Step: 1060, avg loss: 0.082768, loss: 0.023682, accuracy: 1.000000
Step: 1070, avg loss: 0.082092, loss: 0.010445, accuracy: 1.000000
Step: 1080, avg loss: 0.081966, loss: 0.068525, accuracy: 1.000000
Step: 1090, avg loss: 0.081405, loss: 0.020806, accuracy: 1.000000
Step: 1100, avg loss: 0.080688, loss: 0.002546, accuracy: 1.000000
Step: 1110, avg loss: 0.079970, loss: 0.000936, accuracy: 1.000000
Step: 1120, avg loss: 0.079370, loss: 0.012838, accuracy: 1.000000
Step: 1130, avg loss: 0.078757, loss: 0.010105, accuracy: 1.000000
Step: 1140, avg loss: 0.078408, loss: 0.038936, accuracy: 1.000000
Step: 1150, avg loss: 0.077899, loss: 0.019832, accuracy: 1.000000
Step: 1160, avg loss: 0.077851, loss: 0.072323, accuracy: 1.000000
Step: 1170, avg loss: 0.077529, loss: 0.040204, accuracy: 1.000000
Step: 1180, avg loss: 0.077137, loss: 0.031248, accuracy: 1.000000
Step: 1190, avg loss: 0.077010, loss: 0.062068, accuracy: 1.000000
Step: 1200, avg loss: 0.076712, loss: 0.041275, accuracy: 1.000000
Step: 1210, avg loss: 0.076695, loss: 0.074594, accuracy: 1.000000
Step: 1220, avg loss: 0.076282, loss: 0.026376, accuracy: 1.000000
Step: 1230, avg loss: 0.075763, loss: 0.012344, accuracy: 1.000000
Step: 1240, avg loss: 0.075446, loss: 0.036482, accuracy: 1.000000
Step: 1250, avg loss: 0.074856, loss: 0.001777, accuracy: 1.000000
Step: 1260, avg loss: 0.074554, loss: 0.036734, accuracy: 1.000000
Epoch 36 finished in loss: 0.074441 and accuracy: 0.992076
Step: 10, avg loss: 0.045050, loss: 0.045050, accuracy: 1.000000
Step: 20, avg loss: 0.081905, loss: 0.118759, accuracy: 0.900000
Step: 30, avg loss: 0.065736, loss: 0.033399, accuracy: 1.000000
Step: 40, avg loss: 0.055937, loss: 0.026537, accuracy: 1.000000
Step: 50, avg loss: 0.047363, loss: 0.013068, accuracy: 1.000000
Step: 60, avg loss: 0.043411, loss: 0.023653, accuracy: 1.000000
Step: 70, avg loss: 0.037435, loss: 0.001577, accuracy: 1.000000
Step: 80, avg loss: 0.035208, loss: 0.019617, accuracy: 1.000000
Step: 90, avg loss: 0.146246, loss: 1.034552, accuracy: 0.900000
Step: 100, avg loss: 0.133079, loss: 0.014577, accuracy: 1.000000
Step: 110, avg loss: 0.124812, loss: 0.042140, accuracy: 1.000000
Step: 120, avg loss: 0.114687, loss: 0.003319, accuracy: 1.000000
Step: 130, avg loss: 0.106895, loss: 0.013381, accuracy: 1.000000
Step: 140, avg loss: 0.100126, loss: 0.012135, accuracy: 1.000000
Step: 150, avg loss: 0.096322, loss: 0.043071, accuracy: 1.000000
Step: 160, avg loss: 0.092277, loss: 0.031602, accuracy: 1.000000
Step: 170, avg loss: 0.087149, loss: 0.005100, accuracy: 1.000000
Step: 180, avg loss: 0.127226, loss: 0.808532, accuracy: 0.900000
Step: 190, avg loss: 0.122781, loss: 0.042768, accuracy: 1.000000
Step: 200, avg loss: 0.117591, loss: 0.018982, accuracy: 1.000000
Step: 210, avg loss: 0.112596, loss: 0.012693, accuracy: 1.000000
Step: 220, avg loss: 0.108530, loss: 0.023139, accuracy: 1.000000
Step: 230, avg loss: 0.104764, loss: 0.021932, accuracy: 1.000000
Step: 240, avg loss: 0.101376, loss: 0.023452, accuracy: 1.000000
Step: 250, avg loss: 0.098520, loss: 0.029975, accuracy: 1.000000
Step: 260, avg loss: 0.095573, loss: 0.021881, accuracy: 1.000000
Step: 270, avg loss: 0.093504, loss: 0.039719, accuracy: 1.000000
Step: 280, avg loss: 0.090242, loss: 0.002169, accuracy: 1.000000
Step: 290, avg loss: 0.089007, loss: 0.054426, accuracy: 1.000000
Step: 300, avg loss: 0.086850, loss: 0.024301, accuracy: 1.000000
Step: 310, avg loss: 0.085072, loss: 0.031713, accuracy: 1.000000
Step: 320, avg loss: 0.082966, loss: 0.017693, accuracy: 1.000000
Step: 330, avg loss: 0.082112, loss: 0.054769, accuracy: 1.000000
Step: 340, avg loss: 0.081215, loss: 0.051616, accuracy: 1.000000
Step: 350, avg loss: 0.079762, loss: 0.030375, accuracy: 1.000000
Step: 360, avg loss: 0.078585, loss: 0.037398, accuracy: 1.000000
Step: 370, avg loss: 0.078572, loss: 0.078107, accuracy: 1.000000
Step: 380, avg loss: 0.100425, loss: 0.908955, accuracy: 0.900000
Step: 390, avg loss: 0.098813, loss: 0.037566, accuracy: 1.000000
Step: 400, avg loss: 0.097333, loss: 0.039605, accuracy: 1.000000
Step: 410, avg loss: 0.096641, loss: 0.068978, accuracy: 1.000000
Step: 420, avg loss: 0.094642, loss: 0.012677, accuracy: 1.000000
Step: 430, avg loss: 0.093358, loss: 0.039453, accuracy: 1.000000
Step: 440, avg loss: 0.092576, loss: 0.058939, accuracy: 1.000000
Step: 450, avg loss: 0.091226, loss: 0.031798, accuracy: 1.000000
Step: 460, avg loss: 0.090487, loss: 0.057247, accuracy: 1.000000
Step: 470, avg loss: 0.102410, loss: 0.650882, accuracy: 0.900000
Step: 480, avg loss: 0.109747, loss: 0.454565, accuracy: 0.900000
Step: 490, avg loss: 0.115421, loss: 0.387791, accuracy: 0.900000
Step: 500, avg loss: 0.114912, loss: 0.089943, accuracy: 1.000000
Step: 510, avg loss: 0.113035, loss: 0.019198, accuracy: 1.000000
Step: 520, avg loss: 0.111858, loss: 0.051848, accuracy: 1.000000
Step: 530, avg loss: 0.110891, loss: 0.060624, accuracy: 1.000000
Step: 540, avg loss: 0.109192, loss: 0.019132, accuracy: 1.000000
Step: 550, avg loss: 0.107500, loss: 0.016114, accuracy: 1.000000
Step: 560, avg loss: 0.105917, loss: 0.018882, accuracy: 1.000000
Step: 570, avg loss: 0.104525, loss: 0.026578, accuracy: 1.000000
Step: 580, avg loss: 0.103286, loss: 0.032646, accuracy: 1.000000
Step: 590, avg loss: 0.102303, loss: 0.045254, accuracy: 1.000000
Step: 600, avg loss: 0.101245, loss: 0.038855, accuracy: 1.000000
Step: 610, avg loss: 0.100016, loss: 0.026241, accuracy: 1.000000
Step: 620, avg loss: 0.098778, loss: 0.023271, accuracy: 1.000000
Step: 630, avg loss: 0.097406, loss: 0.012336, accuracy: 1.000000
Step: 640, avg loss: 0.096462, loss: 0.037008, accuracy: 1.000000
Step: 650, avg loss: 0.095148, loss: 0.011068, accuracy: 1.000000
Step: 660, avg loss: 0.094074, loss: 0.024247, accuracy: 1.000000
Step: 670, avg loss: 0.103417, loss: 0.720037, accuracy: 0.900000
Step: 680, avg loss: 0.102602, loss: 0.047988, accuracy: 1.000000
Step: 690, avg loss: 0.101527, loss: 0.028448, accuracy: 1.000000
Step: 700, avg loss: 0.100166, loss: 0.006258, accuracy: 1.000000
Step: 710, avg loss: 0.098947, loss: 0.013635, accuracy: 1.000000
Step: 720, avg loss: 0.097762, loss: 0.013648, accuracy: 1.000000
Step: 730, avg loss: 0.096634, loss: 0.015391, accuracy: 1.000000
Step: 740, avg loss: 0.096054, loss: 0.053738, accuracy: 1.000000
Step: 750, avg loss: 0.094998, loss: 0.016828, accuracy: 1.000000
Step: 760, avg loss: 0.093931, loss: 0.013909, accuracy: 1.000000
Step: 770, avg loss: 0.092822, loss: 0.008554, accuracy: 1.000000
Step: 780, avg loss: 0.092217, loss: 0.045611, accuracy: 1.000000
Step: 790, avg loss: 0.091204, loss: 0.012211, accuracy: 1.000000
Step: 800, avg loss: 0.090080, loss: 0.001251, accuracy: 1.000000
Step: 810, avg loss: 0.089261, loss: 0.023731, accuracy: 1.000000
Step: 820, avg loss: 0.088432, loss: 0.021324, accuracy: 1.000000
Step: 830, avg loss: 0.088006, loss: 0.053092, accuracy: 1.000000
Step: 840, avg loss: 0.087249, loss: 0.024350, accuracy: 1.000000
Step: 850, avg loss: 0.086246, loss: 0.001992, accuracy: 1.000000
Step: 860, avg loss: 0.085655, loss: 0.035475, accuracy: 1.000000
Step: 870, avg loss: 0.084778, loss: 0.009375, accuracy: 1.000000
Step: 880, avg loss: 0.084055, loss: 0.021153, accuracy: 1.000000
Step: 890, avg loss: 0.083226, loss: 0.010268, accuracy: 1.000000
Step: 900, avg loss: 0.082438, loss: 0.012284, accuracy: 1.000000
Step: 910, avg loss: 0.090559, loss: 0.821444, accuracy: 0.900000
Step: 920, avg loss: 0.089852, loss: 0.025462, accuracy: 1.000000
Step: 930, avg loss: 0.088934, loss: 0.004551, accuracy: 1.000000
Step: 940, avg loss: 0.088671, loss: 0.064156, accuracy: 1.000000
Step: 950, avg loss: 0.088025, loss: 0.027345, accuracy: 1.000000
Step: 960, avg loss: 0.087343, loss: 0.022570, accuracy: 1.000000
Step: 970, avg loss: 0.086716, loss: 0.026462, accuracy: 1.000000
Step: 980, avg loss: 0.086105, loss: 0.026864, accuracy: 1.000000
Step: 990, avg loss: 0.085258, loss: 0.002245, accuracy: 1.000000
Step: 1000, avg loss: 0.084533, loss: 0.012799, accuracy: 1.000000
Step: 1010, avg loss: 0.083993, loss: 0.029967, accuracy: 1.000000
Step: 1020, avg loss: 0.083188, loss: 0.001900, accuracy: 1.000000
Step: 1030, avg loss: 0.082487, loss: 0.010976, accuracy: 1.000000
Step: 1040, avg loss: 0.081722, loss: 0.002929, accuracy: 1.000000
Step: 1050, avg loss: 0.081061, loss: 0.012294, accuracy: 1.000000
Step: 1060, avg loss: 0.080530, loss: 0.024831, accuracy: 1.000000
Step: 1070, avg loss: 0.079872, loss: 0.010093, accuracy: 1.000000
Step: 1080, avg loss: 0.079692, loss: 0.060461, accuracy: 1.000000
Step: 1090, avg loss: 0.079234, loss: 0.029771, accuracy: 1.000000
Step: 1100, avg loss: 0.078541, loss: 0.002917, accuracy: 1.000000
Step: 1110, avg loss: 0.077839, loss: 0.000640, accuracy: 1.000000
Step: 1120, avg loss: 0.077252, loss: 0.012126, accuracy: 1.000000
Step: 1130, avg loss: 0.076692, loss: 0.013943, accuracy: 1.000000
Step: 1140, avg loss: 0.076224, loss: 0.023320, accuracy: 1.000000
Step: 1150, avg loss: 0.075695, loss: 0.015434, accuracy: 1.000000
Step: 1160, avg loss: 0.075677, loss: 0.073545, accuracy: 1.000000
Step: 1170, avg loss: 0.075371, loss: 0.039936, accuracy: 1.000000
Step: 1180, avg loss: 0.074934, loss: 0.023800, accuracy: 1.000000
Step: 1190, avg loss: 0.074804, loss: 0.059434, accuracy: 1.000000
Step: 1200, avg loss: 0.075065, loss: 0.106181, accuracy: 1.000000
Step: 1210, avg loss: 0.075123, loss: 0.082071, accuracy: 1.000000
Step: 1220, avg loss: 0.074699, loss: 0.023397, accuracy: 1.000000
Step: 1230, avg loss: 0.074193, loss: 0.012388, accuracy: 1.000000
Step: 1240, avg loss: 0.073865, loss: 0.033611, accuracy: 1.000000
Step: 1250, avg loss: 0.073301, loss: 0.003296, accuracy: 1.000000
Step: 1260, avg loss: 0.072923, loss: 0.025664, accuracy: 1.000000
Epoch 37 finished in loss: 0.072809 and accuracy: 0.992868
Step: 10, avg loss: 0.042680, loss: 0.042680, accuracy: 1.000000
Step: 20, avg loss: 0.035250, loss: 0.027819, accuracy: 1.000000
Step: 30, avg loss: 0.034915, loss: 0.034246, accuracy: 1.000000
Step: 40, avg loss: 0.031361, loss: 0.020701, accuracy: 1.000000
Step: 50, avg loss: 0.027601, loss: 0.012558, accuracy: 1.000000
Step: 60, avg loss: 0.026960, loss: 0.023758, accuracy: 1.000000
Step: 70, avg loss: 0.023258, loss: 0.001046, accuracy: 1.000000
Step: 80, avg loss: 0.022872, loss: 0.020169, accuracy: 1.000000
Step: 90, avg loss: 0.129762, loss: 0.984885, accuracy: 0.900000
Step: 100, avg loss: 0.118124, loss: 0.013380, accuracy: 1.000000
Step: 110, avg loss: 0.111371, loss: 0.043835, accuracy: 1.000000
Step: 120, avg loss: 0.102340, loss: 0.003003, accuracy: 1.000000
Step: 130, avg loss: 0.095453, loss: 0.012813, accuracy: 1.000000
Step: 140, avg loss: 0.089430, loss: 0.011134, accuracy: 1.000000
Step: 150, avg loss: 0.086082, loss: 0.039209, accuracy: 1.000000
Step: 160, avg loss: 0.082605, loss: 0.030442, accuracy: 1.000000
Step: 170, avg loss: 0.077838, loss: 0.001568, accuracy: 1.000000
Step: 180, avg loss: 0.115107, loss: 0.748688, accuracy: 0.900000
Step: 190, avg loss: 0.111564, loss: 0.047793, accuracy: 1.000000
Step: 200, avg loss: 0.106898, loss: 0.018238, accuracy: 1.000000
Step: 210, avg loss: 0.102940, loss: 0.023771, accuracy: 1.000000
Step: 220, avg loss: 0.099391, loss: 0.024869, accuracy: 1.000000
Step: 230, avg loss: 0.095257, loss: 0.004297, accuracy: 1.000000
Step: 240, avg loss: 0.092541, loss: 0.030080, accuracy: 1.000000
Step: 250, avg loss: 0.089963, loss: 0.028098, accuracy: 1.000000
Step: 260, avg loss: 0.087427, loss: 0.024027, accuracy: 1.000000
Step: 270, avg loss: 0.085583, loss: 0.037648, accuracy: 1.000000
Step: 280, avg loss: 0.082629, loss: 0.002856, accuracy: 1.000000
Step: 290, avg loss: 0.081651, loss: 0.054273, accuracy: 1.000000
Step: 300, avg loss: 0.079705, loss: 0.023263, accuracy: 1.000000
Step: 310, avg loss: 0.078402, loss: 0.039300, accuracy: 1.000000
Step: 320, avg loss: 0.076663, loss: 0.022755, accuracy: 1.000000
Step: 330, avg loss: 0.075978, loss: 0.054087, accuracy: 1.000000
Step: 340, avg loss: 0.075190, loss: 0.049177, accuracy: 1.000000
Step: 350, avg loss: 0.073975, loss: 0.032671, accuracy: 1.000000
Step: 360, avg loss: 0.072856, loss: 0.033690, accuracy: 1.000000
Step: 370, avg loss: 0.072466, loss: 0.058425, accuracy: 1.000000
Step: 380, avg loss: 0.092982, loss: 0.852070, accuracy: 0.900000
Step: 390, avg loss: 0.091447, loss: 0.033110, accuracy: 1.000000
Step: 400, avg loss: 0.090056, loss: 0.035827, accuracy: 1.000000
Step: 410, avg loss: 0.089486, loss: 0.066669, accuracy: 1.000000
Step: 420, avg loss: 0.087632, loss: 0.011615, accuracy: 1.000000
Step: 430, avg loss: 0.086461, loss: 0.037287, accuracy: 1.000000
Step: 440, avg loss: 0.085841, loss: 0.059160, accuracy: 1.000000
Step: 450, avg loss: 0.084585, loss: 0.029332, accuracy: 1.000000
Step: 460, avg loss: 0.083997, loss: 0.057544, accuracy: 1.000000
Step: 470, avg loss: 0.095979, loss: 0.647156, accuracy: 0.900000
Step: 480, avg loss: 0.103536, loss: 0.458684, accuracy: 0.900000
Step: 490, avg loss: 0.109391, loss: 0.390473, accuracy: 0.900000
Step: 500, avg loss: 0.109075, loss: 0.093591, accuracy: 1.000000
Step: 510, avg loss: 0.107298, loss: 0.018432, accuracy: 1.000000
Step: 520, avg loss: 0.106188, loss: 0.049588, accuracy: 1.000000
Step: 530, avg loss: 0.105133, loss: 0.050249, accuracy: 1.000000
Step: 540, avg loss: 0.103577, loss: 0.021136, accuracy: 1.000000
Step: 550, avg loss: 0.101979, loss: 0.015643, accuracy: 1.000000
Step: 560, avg loss: 0.100435, loss: 0.015558, accuracy: 1.000000
Step: 570, avg loss: 0.099154, loss: 0.027428, accuracy: 1.000000
Step: 580, avg loss: 0.098025, loss: 0.033653, accuracy: 1.000000
Step: 590, avg loss: 0.097208, loss: 0.049789, accuracy: 1.000000
Step: 600, avg loss: 0.096231, loss: 0.038615, accuracy: 1.000000
Step: 610, avg loss: 0.095099, loss: 0.027161, accuracy: 1.000000
Step: 620, avg loss: 0.093965, loss: 0.024815, accuracy: 1.000000
Step: 630, avg loss: 0.092680, loss: 0.012973, accuracy: 1.000000
Step: 640, avg loss: 0.091859, loss: 0.040164, accuracy: 1.000000
Step: 650, avg loss: 0.090620, loss: 0.011327, accuracy: 1.000000
Step: 660, avg loss: 0.089589, loss: 0.022552, accuracy: 1.000000
Step: 670, avg loss: 0.099198, loss: 0.733430, accuracy: 0.900000
Step: 680, avg loss: 0.098571, loss: 0.056543, accuracy: 1.000000
Step: 690, avg loss: 0.097530, loss: 0.026719, accuracy: 1.000000
Step: 700, avg loss: 0.096231, loss: 0.006638, accuracy: 1.000000
Step: 710, avg loss: 0.094990, loss: 0.008130, accuracy: 1.000000
Step: 720, avg loss: 0.093843, loss: 0.012408, accuracy: 1.000000
Step: 730, avg loss: 0.092769, loss: 0.015429, accuracy: 1.000000
Step: 740, avg loss: 0.092168, loss: 0.048311, accuracy: 1.000000
Step: 750, avg loss: 0.091120, loss: 0.013560, accuracy: 1.000000
Step: 760, avg loss: 0.090088, loss: 0.012697, accuracy: 1.000000
Step: 770, avg loss: 0.089088, loss: 0.013074, accuracy: 1.000000
Step: 780, avg loss: 0.088355, loss: 0.031906, accuracy: 1.000000
Step: 790, avg loss: 0.087394, loss: 0.012430, accuracy: 1.000000
Step: 800, avg loss: 0.086315, loss: 0.001070, accuracy: 1.000000
Step: 810, avg loss: 0.085544, loss: 0.023827, accuracy: 1.000000
Step: 820, avg loss: 0.084749, loss: 0.020413, accuracy: 1.000000
Step: 830, avg loss: 0.084096, loss: 0.030550, accuracy: 1.000000
Step: 840, avg loss: 0.083356, loss: 0.021902, accuracy: 1.000000
Step: 850, avg loss: 0.082390, loss: 0.001272, accuracy: 1.000000
Step: 860, avg loss: 0.081827, loss: 0.033930, accuracy: 1.000000
Step: 870, avg loss: 0.080896, loss: 0.000889, accuracy: 1.000000
Step: 880, avg loss: 0.080200, loss: 0.019587, accuracy: 1.000000
Step: 890, avg loss: 0.079320, loss: 0.001943, accuracy: 1.000000
Step: 900, avg loss: 0.078652, loss: 0.019201, accuracy: 1.000000
Step: 910, avg loss: 0.087922, loss: 0.922233, accuracy: 0.900000
Step: 920, avg loss: 0.087263, loss: 0.027277, accuracy: 1.000000
Step: 930, avg loss: 0.086358, loss: 0.003085, accuracy: 1.000000
Step: 940, avg loss: 0.086120, loss: 0.063976, accuracy: 1.000000
Step: 950, avg loss: 0.085497, loss: 0.026897, accuracy: 1.000000
Step: 960, avg loss: 0.084783, loss: 0.017005, accuracy: 1.000000
Step: 970, avg loss: 0.084172, loss: 0.025489, accuracy: 1.000000
Step: 980, avg loss: 0.083586, loss: 0.026788, accuracy: 1.000000
Step: 990, avg loss: 0.082769, loss: 0.002643, accuracy: 1.000000
Step: 1000, avg loss: 0.082061, loss: 0.011964, accuracy: 1.000000
Step: 1010, avg loss: 0.081539, loss: 0.029390, accuracy: 1.000000
Step: 1020, avg loss: 0.080754, loss: 0.001458, accuracy: 1.000000
Step: 1030, avg loss: 0.080080, loss: 0.011315, accuracy: 1.000000
Step: 1040, avg loss: 0.079334, loss: 0.002531, accuracy: 1.000000
Step: 1050, avg loss: 0.078789, loss: 0.022114, accuracy: 1.000000
Step: 1060, avg loss: 0.078267, loss: 0.023419, accuracy: 1.000000
Step: 1070, avg loss: 0.077698, loss: 0.017439, accuracy: 1.000000
Step: 1080, avg loss: 0.077481, loss: 0.054208, accuracy: 1.000000
Step: 1090, avg loss: 0.076955, loss: 0.020150, accuracy: 1.000000
Step: 1100, avg loss: 0.076276, loss: 0.002247, accuracy: 1.000000
Step: 1110, avg loss: 0.075595, loss: 0.000719, accuracy: 1.000000
Step: 1120, avg loss: 0.075035, loss: 0.012857, accuracy: 1.000000
Step: 1130, avg loss: 0.074462, loss: 0.010332, accuracy: 1.000000
Step: 1140, avg loss: 0.074252, loss: 0.050437, accuracy: 1.000000
Step: 1150, avg loss: 0.074224, loss: 0.071084, accuracy: 1.000000
Step: 1160, avg loss: 0.074187, loss: 0.069946, accuracy: 1.000000
Step: 1170, avg loss: 0.073883, loss: 0.038635, accuracy: 1.000000
Step: 1180, avg loss: 0.073607, loss: 0.041274, accuracy: 1.000000
Step: 1190, avg loss: 0.073494, loss: 0.060106, accuracy: 1.000000
Step: 1200, avg loss: 0.073259, loss: 0.045355, accuracy: 1.000000
Step: 1210, avg loss: 0.073319, loss: 0.080538, accuracy: 1.000000
Step: 1220, avg loss: 0.072910, loss: 0.023394, accuracy: 1.000000
Step: 1230, avg loss: 0.072416, loss: 0.012103, accuracy: 1.000000
Step: 1240, avg loss: 0.072107, loss: 0.034206, accuracy: 1.000000
Step: 1250, avg loss: 0.071561, loss: 0.003852, accuracy: 1.000000
Step: 1260, avg loss: 0.071206, loss: 0.026807, accuracy: 1.000000
Epoch 38 finished in loss: 0.071096 and accuracy: 0.993661
Step: 10, avg loss: 0.048095, loss: 0.048095, accuracy: 1.000000
Step: 20, avg loss: 0.037280, loss: 0.026465, accuracy: 1.000000
Step: 30, avg loss: 0.034874, loss: 0.030063, accuracy: 1.000000
Step: 40, avg loss: 0.039185, loss: 0.052116, accuracy: 1.000000
Step: 50, avg loss: 0.033846, loss: 0.012490, accuracy: 1.000000
Step: 60, avg loss: 0.032269, loss: 0.024389, accuracy: 1.000000
Step: 70, avg loss: 0.027884, loss: 0.001571, accuracy: 1.000000
Step: 80, avg loss: 0.026147, loss: 0.013985, accuracy: 1.000000
Step: 90, avg loss: 0.137470, loss: 1.028056, accuracy: 0.900000
Step: 100, avg loss: 0.124909, loss: 0.011864, accuracy: 1.000000
Step: 110, avg loss: 0.117361, loss: 0.041884, accuracy: 1.000000
Step: 120, avg loss: 0.108031, loss: 0.005394, accuracy: 1.000000
Step: 130, avg loss: 0.100668, loss: 0.012318, accuracy: 1.000000
Step: 140, avg loss: 0.094252, loss: 0.010834, accuracy: 1.000000
Step: 150, avg loss: 0.090393, loss: 0.036380, accuracy: 1.000000
Step: 160, avg loss: 0.086654, loss: 0.030557, accuracy: 1.000000
Step: 170, avg loss: 0.081593, loss: 0.000616, accuracy: 1.000000
Step: 180, avg loss: 0.120914, loss: 0.789384, accuracy: 0.900000
Step: 190, avg loss: 0.116754, loss: 0.041865, accuracy: 1.000000
Step: 200, avg loss: 0.111822, loss: 0.018118, accuracy: 1.000000
Step: 210, avg loss: 0.107070, loss: 0.012037, accuracy: 1.000000
Step: 220, avg loss: 0.103352, loss: 0.025259, accuracy: 1.000000
Step: 230, avg loss: 0.099058, loss: 0.004588, accuracy: 1.000000
Step: 240, avg loss: 0.096255, loss: 0.031786, accuracy: 1.000000
Step: 250, avg loss: 0.093437, loss: 0.025825, accuracy: 1.000000
Step: 260, avg loss: 0.090799, loss: 0.024828, accuracy: 1.000000
Step: 270, avg loss: 0.090129, loss: 0.072718, accuracy: 1.000000
Step: 280, avg loss: 0.086984, loss: 0.002061, accuracy: 1.000000
Step: 290, avg loss: 0.085866, loss: 0.054574, accuracy: 1.000000
Step: 300, avg loss: 0.083737, loss: 0.022001, accuracy: 1.000000
Step: 310, avg loss: 0.082202, loss: 0.036159, accuracy: 1.000000
Step: 320, avg loss: 0.080365, loss: 0.023406, accuracy: 1.000000
Step: 330, avg loss: 0.079540, loss: 0.053151, accuracy: 1.000000
Step: 340, avg loss: 0.078604, loss: 0.047704, accuracy: 1.000000
Step: 350, avg loss: 0.077474, loss: 0.039070, accuracy: 1.000000
Step: 360, avg loss: 0.076249, loss: 0.033363, accuracy: 1.000000
Step: 370, avg loss: 0.077200, loss: 0.111429, accuracy: 1.000000
Step: 380, avg loss: 0.097958, loss: 0.866005, accuracy: 0.900000
Step: 390, avg loss: 0.096301, loss: 0.033348, accuracy: 1.000000
Step: 400, avg loss: 0.094842, loss: 0.037919, accuracy: 1.000000
Step: 410, avg loss: 0.094130, loss: 0.065647, accuracy: 1.000000
Step: 420, avg loss: 0.092175, loss: 0.012024, accuracy: 1.000000
Step: 430, avg loss: 0.090863, loss: 0.035777, accuracy: 1.000000
Step: 440, avg loss: 0.090074, loss: 0.056140, accuracy: 1.000000
Step: 450, avg loss: 0.088727, loss: 0.029439, accuracy: 1.000000
Step: 460, avg loss: 0.088061, loss: 0.058116, accuracy: 1.000000
Step: 470, avg loss: 0.100552, loss: 0.675108, accuracy: 0.900000
Step: 480, avg loss: 0.108443, loss: 0.479363, accuracy: 0.900000
Step: 490, avg loss: 0.114522, loss: 0.406301, accuracy: 0.900000
Step: 500, avg loss: 0.113887, loss: 0.082748, accuracy: 1.000000
Step: 510, avg loss: 0.112086, loss: 0.022039, accuracy: 1.000000
Step: 520, avg loss: 0.110918, loss: 0.051358, accuracy: 1.000000
Step: 530, avg loss: 0.109733, loss: 0.048118, accuracy: 1.000000
Step: 540, avg loss: 0.108072, loss: 0.020015, accuracy: 1.000000
Step: 550, avg loss: 0.106409, loss: 0.016622, accuracy: 1.000000
Step: 560, avg loss: 0.105013, loss: 0.028228, accuracy: 1.000000
Step: 570, avg loss: 0.103639, loss: 0.026700, accuracy: 1.000000
Step: 580, avg loss: 0.102432, loss: 0.033671, accuracy: 1.000000
Step: 590, avg loss: 0.101472, loss: 0.045784, accuracy: 1.000000
Step: 600, avg loss: 0.100388, loss: 0.036400, accuracy: 1.000000
Step: 610, avg loss: 0.099148, loss: 0.024732, accuracy: 1.000000
Step: 620, avg loss: 0.097974, loss: 0.026410, accuracy: 1.000000
Step: 630, avg loss: 0.096622, loss: 0.012750, accuracy: 1.000000
Step: 640, avg loss: 0.101470, loss: 0.406905, accuracy: 0.900000
Step: 650, avg loss: 0.100083, loss: 0.011322, accuracy: 1.000000
Step: 660, avg loss: 0.098918, loss: 0.023177, accuracy: 1.000000
Step: 670, avg loss: 0.107189, loss: 0.653076, accuracy: 0.900000
Step: 680, avg loss: 0.106262, loss: 0.044163, accuracy: 1.000000
Step: 690, avg loss: 0.105119, loss: 0.027388, accuracy: 1.000000
Step: 700, avg loss: 0.103716, loss: 0.006902, accuracy: 1.000000
Step: 710, avg loss: 0.102452, loss: 0.014022, accuracy: 1.000000
Step: 720, avg loss: 0.101231, loss: 0.014528, accuracy: 1.000000
Step: 730, avg loss: 0.100067, loss: 0.016251, accuracy: 1.000000
Step: 740, avg loss: 0.099343, loss: 0.046502, accuracy: 1.000000
Step: 750, avg loss: 0.098134, loss: 0.008624, accuracy: 1.000000
Step: 760, avg loss: 0.096987, loss: 0.010990, accuracy: 1.000000
Step: 770, avg loss: 0.095892, loss: 0.012640, accuracy: 1.000000
Step: 780, avg loss: 0.095127, loss: 0.036224, accuracy: 1.000000
Step: 790, avg loss: 0.094078, loss: 0.012281, accuracy: 1.000000
Step: 800, avg loss: 0.092917, loss: 0.001229, accuracy: 1.000000
Step: 810, avg loss: 0.092053, loss: 0.022926, accuracy: 1.000000
Step: 820, avg loss: 0.091200, loss: 0.022058, accuracy: 1.000000
Step: 830, avg loss: 0.090492, loss: 0.032427, accuracy: 1.000000
Step: 840, avg loss: 0.089679, loss: 0.022218, accuracy: 1.000000
Step: 850, avg loss: 0.088639, loss: 0.001275, accuracy: 1.000000
Step: 860, avg loss: 0.087979, loss: 0.031935, accuracy: 1.000000
Step: 870, avg loss: 0.086977, loss: 0.000818, accuracy: 1.000000
Step: 880, avg loss: 0.086224, loss: 0.020654, accuracy: 1.000000
Step: 890, avg loss: 0.085301, loss: 0.004113, accuracy: 1.000000
Step: 900, avg loss: 0.084927, loss: 0.051639, accuracy: 1.000000
Step: 910, avg loss: 0.094202, loss: 0.928932, accuracy: 0.900000
Step: 920, avg loss: 0.093451, loss: 0.025127, accuracy: 1.000000
Step: 930, avg loss: 0.092496, loss: 0.004633, accuracy: 1.000000
Step: 940, avg loss: 0.092990, loss: 0.138881, accuracy: 0.900000
Step: 950, avg loss: 0.092308, loss: 0.028264, accuracy: 1.000000
Step: 960, avg loss: 0.091567, loss: 0.021179, accuracy: 1.000000
Step: 970, avg loss: 0.090877, loss: 0.024638, accuracy: 1.000000
Step: 980, avg loss: 0.090277, loss: 0.032062, accuracy: 1.000000
Step: 990, avg loss: 0.089377, loss: 0.001171, accuracy: 1.000000
Step: 1000, avg loss: 0.088598, loss: 0.011451, accuracy: 1.000000
Step: 1010, avg loss: 0.088009, loss: 0.029170, accuracy: 1.000000
Step: 1020, avg loss: 0.087162, loss: 0.001526, accuracy: 1.000000
Step: 1030, avg loss: 0.086485, loss: 0.017489, accuracy: 1.000000
Step: 1040, avg loss: 0.085682, loss: 0.002926, accuracy: 1.000000
Step: 1050, avg loss: 0.084999, loss: 0.014024, accuracy: 1.000000
Step: 1060, avg loss: 0.084405, loss: 0.021957, accuracy: 1.000000
Step: 1070, avg loss: 0.083712, loss: 0.010275, accuracy: 1.000000
Step: 1080, avg loss: 0.083465, loss: 0.057017, accuracy: 1.000000
Step: 1090, avg loss: 0.082894, loss: 0.021232, accuracy: 1.000000
Step: 1100, avg loss: 0.082151, loss: 0.001169, accuracy: 1.000000
Step: 1110, avg loss: 0.081416, loss: 0.000659, accuracy: 1.000000
Step: 1120, avg loss: 0.080803, loss: 0.012727, accuracy: 1.000000
Step: 1130, avg loss: 0.080177, loss: 0.010085, accuracy: 1.000000
Step: 1140, avg loss: 0.079780, loss: 0.034888, accuracy: 1.000000
Step: 1150, avg loss: 0.079918, loss: 0.095682, accuracy: 0.900000
Step: 1160, avg loss: 0.079918, loss: 0.079848, accuracy: 1.000000
Step: 1170, avg loss: 0.079574, loss: 0.039696, accuracy: 1.000000
Step: 1180, avg loss: 0.079203, loss: 0.035785, accuracy: 1.000000
Step: 1190, avg loss: 0.079052, loss: 0.061260, accuracy: 1.000000
Step: 1200, avg loss: 0.078776, loss: 0.045919, accuracy: 1.000000
Step: 1210, avg loss: 0.078803, loss: 0.082032, accuracy: 1.000000
Step: 1220, avg loss: 0.078354, loss: 0.024009, accuracy: 1.000000
Step: 1230, avg loss: 0.078127, loss: 0.050433, accuracy: 1.000000
Step: 1240, avg loss: 0.077760, loss: 0.032655, accuracy: 1.000000
Step: 1250, avg loss: 0.077162, loss: 0.002974, accuracy: 1.000000
Step: 1260, avg loss: 0.076762, loss: 0.026730, accuracy: 1.000000
Epoch 39 finished in loss: 0.076644 and accuracy: 0.991284
Step: 10, avg loss: 0.044437, loss: 0.044437, accuracy: 1.000000
Step: 20, avg loss: 0.034880, loss: 0.025322, accuracy: 1.000000
Step: 30, avg loss: 0.032090, loss: 0.026510, accuracy: 1.000000
Step: 40, avg loss: 0.028833, loss: 0.019063, accuracy: 1.000000
Step: 50, avg loss: 0.025449, loss: 0.011910, accuracy: 1.000000
Step: 60, avg loss: 0.025160, loss: 0.023717, accuracy: 1.000000
Step: 70, avg loss: 0.021723, loss: 0.001099, accuracy: 1.000000
Step: 80, avg loss: 0.021347, loss: 0.018719, accuracy: 1.000000
--------------------->Epoch: 40, batch: 82
batch_labels:  [[1]]
loss:  9.33574 9.33574 -0.0 [[ 1.  1.  1.  1.  1.]]
accuracy:  0.0
case_pred:  [[  8.82148743e-05]]
case_pred_each:  [[  1.76362482e-05   1.76362482e-05   1.76362482e-05   1.76362482e-05
    1.76362482e-05]]
miss mask:  [[ 1.  1.  1.  1.  1.]]
batch_isnode shape:  (1, 5)
batch_is_nod:  [[ 0.  0.  0.  0.  0.]]
batch_file_names:  11fe5426ef497bc490b9f1465f1fb25e
Step: 90, avg loss: 0.124478, loss: 0.949522, accuracy: 0.900000
Step: 100, avg loss: 0.113277, loss: 0.012473, accuracy: 1.000000
Step: 110, avg loss: 0.107093, loss: 0.045251, accuracy: 1.000000
Step: 120, avg loss: 0.098404, loss: 0.002830, accuracy: 1.000000
Step: 130, avg loss: 0.091918, loss: 0.014075, accuracy: 1.000000
Step: 140, avg loss: 0.086249, loss: 0.012561, accuracy: 1.000000
Step: 150, avg loss: 0.082766, loss: 0.033995, accuracy: 1.000000
Step: 160, avg loss: 0.079495, loss: 0.030428, accuracy: 1.000000
Step: 170, avg loss: 0.074874, loss: 0.000953, accuracy: 1.000000
--------------------->Epoch: 40, batch: 176
batch_labels:  [[1]]
loss:  7.3202 7.3202 -0.0 [[ 1.  1.  1.  1.  1.]]
accuracy:  0.0
case_pred:  [[ 0.00066203]]
case_pred_each:  [[ 0.00013241  0.00013241  0.00013241  0.00013241  0.00013241]]
miss mask:  [[ 1.  1.  1.  1.  1.]]
batch_isnode shape:  (1, 5)
batch_is_nod:  [[ 0.  0.  0.  0.  0.]]
batch_file_names:  263a1c3bfa43556623e75ed901e3fd8f
Step: 180, avg loss: 0.111483, loss: 0.733833, accuracy: 0.900000
Step: 190, avg loss: 0.108414, loss: 0.053169, accuracy: 1.000000
Step: 200, avg loss: 0.103689, loss: 0.013905, accuracy: 1.000000
Step: 210, avg loss: 0.099367, loss: 0.012928, accuracy: 1.000000
Step: 220, avg loss: 0.095916, loss: 0.023459, accuracy: 1.000000
Step: 230, avg loss: 0.091902, loss: 0.003598, accuracy: 1.000000
Step: 240, avg loss: 0.089017, loss: 0.022661, accuracy: 1.000000
Step: 250, avg loss: 0.086462, loss: 0.025124, accuracy: 1.000000
Step: 260, avg loss: 0.084041, loss: 0.023529, accuracy: 1.000000
Step: 270, avg loss: 0.082545, loss: 0.043638, accuracy: 1.000000
Step: 280, avg loss: 0.079684, loss: 0.002450, accuracy: 1.000000
Step: 290, avg loss: 0.078763, loss: 0.052963, accuracy: 1.000000
Step: 300, avg loss: 0.076900, loss: 0.022869, accuracy: 1.000000
Step: 310, avg loss: 0.075530, loss: 0.034428, accuracy: 1.000000
Step: 320, avg loss: 0.073858, loss: 0.022036, accuracy: 1.000000
Step: 330, avg loss: 0.073248, loss: 0.053723, accuracy: 1.000000
Step: 340, avg loss: 0.072465, loss: 0.046620, accuracy: 1.000000
Step: 350, avg loss: 0.071298, loss: 0.031643, accuracy: 1.000000
Step: 360, avg loss: 0.070219, loss: 0.032429, accuracy: 1.000000
Step: 370, avg loss: 0.069901, loss: 0.058455, accuracy: 1.000000
--------------------->Epoch: 40, batch: 372
batch_labels:  [[1]]
loss:  8.52481 8.52481 -0.0 [[ 1.  1.  1.  1.  1.]]
accuracy:  0.0
case_pred:  [[ 0.00019848]]
case_pred_each:  [[  3.96806099e-05   3.96806099e-05   3.96806099e-05   3.96806099e-05
    3.96806099e-05]]
miss mask:  [[ 1.  1.  1.  1.  1.]]
batch_isnode shape:  (1, 5)
batch_is_nod:  [[ 0.  0.  0.  0.  0.]]
batch_file_names:  4cc8af2efef2f41bf70684be25276ce5
Step: 380, avg loss: 0.091092, loss: 0.875170, accuracy: 0.900000
Step: 390, avg loss: 0.089616, loss: 0.033536, accuracy: 1.000000
Step: 400, avg loss: 0.088396, loss: 0.040791, accuracy: 1.000000
Step: 410, avg loss: 0.087914, loss: 0.068656, accuracy: 1.000000
Step: 420, avg loss: 0.086089, loss: 0.011253, accuracy: 1.000000
Step: 430, avg loss: 0.084931, loss: 0.036317, accuracy: 1.000000
Step: 440, avg loss: 0.084334, loss: 0.058626, accuracy: 1.000000
Step: 450, avg loss: 0.083161, loss: 0.031571, accuracy: 1.000000
Step: 460, avg loss: 0.082626, loss: 0.058537, accuracy: 1.000000
--------------------->Epoch: 40, batch: 463
batch_labels:  [[1]]
loss:  6.36394 6.36394 -0.0 [[ 1.  1.  1.  1.  1.]]
accuracy:  0.0
case_pred:  [[ 0.00172257]]
case_pred_each:  [[ 0.00034474  0.00034474  0.00034474  0.00034474  0.00034474]]
miss mask:  [[ 1.  1.  1.  1.  1.]]
batch_isnode shape:  (1, 5)
batch_is_nod:  [[ 0.  0.  0.  0.  0.]]
batch_file_names:  608202eb3c368512e55e9e339a203790
Step: 470, avg loss: 0.094942, loss: 0.661474, accuracy: 0.900000
--------------------->Epoch: 40, batch: 476
batch_labels:  [[1]]
loss:  4.3591 4.3591 -0.0 [[ 1.  1.  1.  1.  1.]]
accuracy:  0.0
case_pred:  [[ 0.01278985]]
case_pred_each:  [[ 0.00257116  0.00257116  0.00257116  0.00257116  0.00257116]]
miss mask:  [[ 1.  1.  1.  1.  1.]]
batch_isnode shape:  (1, 5)
batch_is_nod:  [[ 0.  0.  0.  0.  0.]]
batch_file_names:  63b5be42543c98ac5392f1bfbda085bf
Step: 480, avg loss: 0.102651, loss: 0.465003, accuracy: 0.900000
--------------------->Epoch: 40, batch: 481
batch_labels:  [[1]]
loss:  2.88566 2.88566 -0.0 [[ 1.  1.  1.  1.  1.]]
accuracy:  0.0
case_pred:  [[ 0.05581796]]
case_pred_each:  [[  1.54743520e-05   1.42526748e-02   1.42526748e-02   1.42526748e-02
    1.42526748e-02]]
miss mask:  [[ 1.  1.  1.  1.  1.]]
batch_isnode shape:  (1, 5)
batch_is_nod:  [[ 0.  0.  0.  0.  0.]]
batch_file_names:  64a5a866461a3b6006efb0075e04dffe
Step: 490, avg loss: 0.108875, loss: 0.407624, accuracy: 0.900000
Step: 500, avg loss: 0.108408, loss: 0.085497, accuracy: 1.000000
Step: 510, avg loss: 0.106688, loss: 0.020706, accuracy: 1.000000
Step: 520, avg loss: 0.105605, loss: 0.050361, accuracy: 1.000000
Step: 530, avg loss: 0.104582, loss: 0.051409, accuracy: 1.000000
Step: 540, avg loss: 0.102988, loss: 0.018488, accuracy: 1.000000
Step: 550, avg loss: 0.101394, loss: 0.015348, accuracy: 1.000000
Step: 560, avg loss: 0.101503, loss: 0.107460, accuracy: 0.900000
Step: 570, avg loss: 0.100219, loss: 0.028309, accuracy: 1.000000
Step: 580, avg loss: 0.099074, loss: 0.033800, accuracy: 1.000000
Step: 590, avg loss: 0.098055, loss: 0.038954, accuracy: 1.000000
Step: 600, avg loss: 0.097109, loss: 0.041321, accuracy: 1.000000
Step: 610, avg loss: 0.095952, loss: 0.026519, accuracy: 1.000000
Step: 620, avg loss: 0.094804, loss: 0.024765, accuracy: 1.000000
Step: 630, avg loss: 0.093506, loss: 0.013053, accuracy: 1.000000
Step: 640, avg loss: 0.092591, loss: 0.034961, accuracy: 1.000000
Step: 650, avg loss: 0.091338, loss: 0.011132, accuracy: 1.000000
Step: 660, avg loss: 0.090321, loss: 0.024216, accuracy: 1.000000
--------------------->Epoch: 40, batch: 665
batch_labels:  [[1]]
loss:  6.95531 6.95531 -0.0 [[ 1.  1.  1.  1.  1.]]
accuracy:  0.0
case_pred:  [[ 0.00095356]]
case_pred_each:  [[ 0.00019079  0.00019079  0.00019079  0.00019079  0.00019079]]
miss mask:  [[ 1.  1.  1.  1.  1.]]
batch_isnode shape:  (1, 5)
batch_is_nod:  [[ 0.  0.  0.  0.  0.]]
batch_file_names:  882107a204c302e27628f85522baea49
Step: 670, avg loss: 0.099482, loss: 0.704107, accuracy: 0.900000
Step: 680, avg loss: 0.098785, loss: 0.052105, accuracy: 1.000000
Step: 690, avg loss: 0.097736, loss: 0.026409, accuracy: 1.000000
Step: 700, avg loss: 0.096431, loss: 0.006388, accuracy: 1.000000
Step: 710, avg loss: 0.095262, loss: 0.013412, accuracy: 1.000000
Step: 720, avg loss: 0.094235, loss: 0.021294, accuracy: 1.000000
Step: 730, avg loss: 0.093160, loss: 0.015790, accuracy: 1.000000
Step: 740, avg loss: 0.092907, loss: 0.074456, accuracy: 1.000000
Step: 750, avg loss: 0.091838, loss: 0.012698, accuracy: 1.000000
Step: 760, avg loss: 0.090806, loss: 0.013396, accuracy: 1.000000
Step: 770, avg loss: 0.089788, loss: 0.012423, accuracy: 1.000000
Step: 780, avg loss: 0.089040, loss: 0.031458, accuracy: 1.000000
Step: 790, avg loss: 0.088064, loss: 0.011923, accuracy: 1.000000
Step: 800, avg loss: 0.086980, loss: 0.001382, accuracy: 1.000000
Step: 810, avg loss: 0.086188, loss: 0.022813, accuracy: 1.000000
Step: 820, avg loss: 0.085398, loss: 0.021373, accuracy: 1.000000
Step: 830, avg loss: 0.084744, loss: 0.031157, accuracy: 1.000000
Step: 840, avg loss: 0.083987, loss: 0.021166, accuracy: 1.000000
Step: 850, avg loss: 0.083019, loss: 0.001661, accuracy: 1.000000
Step: 860, avg loss: 0.082412, loss: 0.030840, accuracy: 1.000000
Step: 870, avg loss: 0.081567, loss: 0.008877, accuracy: 1.000000
Step: 880, avg loss: 0.080873, loss: 0.020484, accuracy: 1.000000
Step: 890, avg loss: 0.079988, loss: 0.002174, accuracy: 1.000000
Step: 900, avg loss: 0.079266, loss: 0.014941, accuracy: 1.000000
Step: 910, avg loss: 0.088737, loss: 0.941162, accuracy: 0.900000
--------------------->Epoch: 40, batch: 910
batch_labels:  [[1]]
loss:  9.00023 9.00023 -0.0 [[ 1.  1.  1.  1.  1.]]
accuracy:  0.0
case_pred:  [[ 0.00012338]]
case_pred_each:  [[  2.46719828e-05   2.46719828e-05   2.46719828e-05   2.46719828e-05
    2.46719828e-05]]
miss mask:  [[ 1.  1.  1.  1.  1.]]
batch_isnode shape:  (1, 5)
batch_is_nod:  [[ 0.  0.  0.  0.  0.]]
batch_file_names:  bb4b43d0dc4d9d2b61150df6556f6490
Step: 920, avg loss: 0.088057, loss: 0.026172, accuracy: 1.000000
Step: 930, avg loss: 0.087152, loss: 0.003884, accuracy: 1.000000
Step: 940, avg loss: 0.086922, loss: 0.065541, accuracy: 1.000000
Step: 950, avg loss: 0.086417, loss: 0.038905, accuracy: 1.000000
Step: 960, avg loss: 0.085773, loss: 0.024670, accuracy: 1.000000
Step: 970, avg loss: 0.085132, loss: 0.023579, accuracy: 1.000000
Step: 980, avg loss: 0.084602, loss: 0.033171, accuracy: 1.000000
Step: 990, avg loss: 0.083779, loss: 0.003168, accuracy: 1.000000
Step: 1000, avg loss: 0.083061, loss: 0.011963, accuracy: 1.000000
Step: 1010, avg loss: 0.082510, loss: 0.027397, accuracy: 1.000000
Step: 1020, avg loss: 0.081719, loss: 0.001787, accuracy: 1.000000
Step: 1030, avg loss: 0.081121, loss: 0.020198, accuracy: 1.000000
Step: 1040, avg loss: 0.080394, loss: 0.005512, accuracy: 1.000000
Step: 1050, avg loss: 0.080070, loss: 0.046323, accuracy: 1.000000
Step: 1060, avg loss: 0.079533, loss: 0.023184, accuracy: 1.000000
Step: 1070, avg loss: 0.078886, loss: 0.010260, accuracy: 1.000000
Step: 1080, avg loss: 0.078691, loss: 0.057826, accuracy: 1.000000
Step: 1090, avg loss: 0.078196, loss: 0.024719, accuracy: 1.000000
Step: 1100, avg loss: 0.077509, loss: 0.002643, accuracy: 1.000000
Step: 1110, avg loss: 0.076816, loss: 0.000582, accuracy: 1.000000
Step: 1120, avg loss: 0.076241, loss: 0.012393, accuracy: 1.000000
Step: 1130, avg loss: 0.075664, loss: 0.011077, accuracy: 1.000000
Step: 1140, avg loss: 0.075243, loss: 0.027679, accuracy: 1.000000
Step: 1150, avg loss: 0.074712, loss: 0.014158, accuracy: 1.000000
Step: 1160, avg loss: 0.074743, loss: 0.078291, accuracy: 1.000000
Step: 1170, avg loss: 0.074449, loss: 0.040350, accuracy: 1.000000
Step: 1180, avg loss: 0.073987, loss: 0.019988, accuracy: 1.000000
Step: 1190, avg loss: 0.073859, loss: 0.058681, accuracy: 1.000000
Step: 1200, avg loss: 0.073583, loss: 0.040839, accuracy: 1.000000
Step: 1210, avg loss: 0.073689, loss: 0.086301, accuracy: 1.000000
Step: 1220, avg loss: 0.073287, loss: 0.024745, accuracy: 1.000000
Step: 1230, avg loss: 0.072798, loss: 0.013102, accuracy: 1.000000
Step: 1240, avg loss: 0.072483, loss: 0.033791, accuracy: 1.000000
Step: 1250, avg loss: 0.071927, loss: 0.002959, accuracy: 1.000000
Step: 1260, avg loss: 0.071572, loss: 0.027153, accuracy: 1.000000
Epoch 40 finished in loss: 0.071460 and accuracy: 0.992868
--->Val epoch: 1, batch: 1
batch_labels:  [[1]]
loss:  3.55451 3.55451
accuracy:  0.0
batch_is_nod:  [[ 0.  0.  0.  0.  0.]]
batch_file_names:  f1a64fda219db48bcfb8ad3823ef9fc1
--->Val epoch: 1, batch: 2
batch_labels:  [[0]]
loss:  9.14668 9.14668
accuracy:  0.0
batch_is_nod:  [[ 0.  0.  0.  0.  0.]]
batch_file_names:  edbf53a8478049de1494b213fdf942e6
--->Val epoch: 1, batch: 4
batch_labels:  [[1]]
loss:  1.4151 1.4151
accuracy:  0.0
batch_is_nod:  [[ 1.  0.  0.  0.  0.]]
batch_file_names:  48e592418247393234dd658f9112c543
--->Val epoch: 1, batch: 6
batch_labels:  [[1]]
loss:  9.80574 9.80574
accuracy:  0.0
batch_is_nod:  [[ 0.  0.  0.  0.  0.]]
batch_file_names:  d032116d73789ff9c805f493357b4037
Val step: 10, avg loss: 2.419355, loss: 2.419355, accuracy: 0.600000
--->Val epoch: 1, batch: 11
batch_labels:  [[0]]
loss:  8.81952 8.81952
accuracy:  0.0
batch_is_nod:  [[ 0.  0.  0.  0.  0.]]
batch_file_names:  3dfe8e80106f4136d2933ff72a16035c
--->Val epoch: 1, batch: 12
batch_labels:  [[1]]
loss:  9.11396 8.92443
accuracy:  0.0
batch_is_nod:  [[ 1.  0.  0.  0.  0.]]
batch_file_names:  f5717f7cbc08d8bd942cd4c1128e3339
--->Val epoch: 1, batch: 13
batch_labels:  [[1]]
loss:  6.00813 6.00813
accuracy:  0.0
batch_is_nod:  [[ 0.  0.  0.  0.  0.]]
batch_file_names:  a2558184e0f4a68e9fb13579d20cb244
--->Val epoch: 1, batch: 17
batch_labels:  [[1]]
loss:  5.16082 5.05495
accuracy:  0.0
batch_is_nod:  [[ 1.  0.  0.  0.  0.]]
batch_file_names:  4d7df08f074b221eec6311c2617a5ba8
Val step: 20, avg loss: 2.671723, loss: 2.924090, accuracy: 0.600000
--->Val epoch: 1, batch: 21
batch_labels:  [[0]]
loss:  9.59325 9.59325
accuracy:  0.0
batch_is_nod:  [[ 1.  0.  0.  0.  0.]]
batch_file_names:  ef6a37afe024d33b4b1bb2fdee054a59
--->Val epoch: 1, batch: 24
batch_labels:  [[0]]
loss:  1.15528 1.15528
accuracy:  0.0
batch_is_nod:  [[ 0.  0.  0.  0.  0.]]
batch_file_names:  89f003dbfbdbd18a5cdeb9b128cb075b
--->Val epoch: 1, batch: 28
batch_labels:  [[0]]
loss:  11.5116 11.5116
accuracy:  0.0
batch_is_nod:  [[ 0.  0.  0.  0.  0.]]
batch_file_names:  f0f72264cd822301852578cc71288d3c
Val step: 30, avg loss: 2.523440, loss: 2.226874, accuracy: 0.700000
--->Val epoch: 1, batch: 31
batch_labels:  [[0]]
loss:  2.56163 2.56163
accuracy:  0.0
batch_is_nod:  [[ 0.  0.  0.  0.  0.]]
batch_file_names:  0d19f1c627df49eb223771c28548350e
--->Val epoch: 1, batch: 36
batch_labels:  [[1]]
loss:  1.81088 1.68781
accuracy:  0.0
batch_is_nod:  [[ 1.  0.  0.  0.  0.]]
batch_file_names:  f725f46908f16062fd12c141eb47c6a7
Val step: 40, avg loss: 2.008395, loss: 0.463260, accuracy: 0.800000
Val step: 50, avg loss: 1.606810, loss: 0.000471, accuracy: 1.000000
--->Val epoch: 1, batch: 56
batch_labels:  [[0]]
loss:  11.6232 11.5116
accuracy:  0.0
batch_is_nod:  [[ 1.  0.  0.  0.  0.]]
batch_file_names:  2885e3af725bc58dc1522d4bfb24bb2b
--->Val epoch: 1, batch: 57
batch_labels:  [[0]]
loss:  11.5116 11.5116
accuracy:  0.0
batch_is_nod:  [[ 0.  0.  0.  0.  0.]]
batch_file_names:  49a29b3f5bee32b350bedc4cfbad8e9c
Val step: 60, avg loss: 1.727552, loss: 2.331259, accuracy: 0.800000
--->Val epoch: 1, batch: 61
batch_labels:  [[0]]
loss:  7.31571 7.31571
accuracy:  0.0
batch_is_nod:  [[ 0.  0.  0.  0.  0.]]
batch_file_names:  e42065c1145ccf734312cb9edbe5234b
--->Val epoch: 1, batch: 64
batch_labels:  [[1]]
loss:  4.55794 4.55794
accuracy:  0.0
batch_is_nod:  [[ 0.  0.  0.  0.  0.]]
batch_file_names:  c67de8fbbe1e58b464334f93a1dd0447
Val step: 70, avg loss: 1.652061, loss: 1.199116, accuracy: 0.800000
--->Val epoch: 1, batch: 71
batch_labels:  [[1]]
loss:  4.62587 4.53111
accuracy:  0.0
batch_is_nod:  [[ 1.  0.  0.  0.  0.]]
batch_file_names:  028996723faa7840bb57f57e28275e4c
--->Val epoch: 1, batch: 75
batch_labels:  [[0]]
loss:  2.81245 2.81245
accuracy:  0.0
batch_is_nod:  [[ 0.  0.  0.  0.  0.]]
batch_file_names:  6faabf4152bf0ebfd91f686bc37a1f16
--->Val epoch: 1, batch: 77
batch_labels:  [[0]]
loss:  11.5116 11.5116
accuracy:  0.0
batch_is_nod:  [[ 1.  1.  0.  0.  0.]]
batch_file_names:  f8ecf6be8ae631c6dd694c9638a02b45
--->Val epoch: 1, batch: 79
batch_labels:  [[1]]
loss:  5.92933 5.92933
accuracy:  0.0
batch_is_nod:  [[ 0.  0.  0.  0.  0.]]
batch_file_names:  817a99e1a60bcf4e37c904d73845ca50
Val step: 80, avg loss: 1.756700, loss: 2.489173, accuracy: 0.600000
--->Val epoch: 1, batch: 82
batch_labels:  [[0]]
loss:  1.48109 1.48109
accuracy:  0.0
batch_is_nod:  [[ 1.  0.  0.  0.  0.]]
batch_file_names:  4fcf8b00ea7a99162dc70aba253ba669
--->Val epoch: 1, batch: 84
batch_labels:  [[1]]
loss:  4.93837 4.93837
accuracy:  0.0
batch_is_nod:  [[ 0.  0.  0.  0.  0.]]
batch_file_names:  9b7524785a9bf40f0651deeb3b05b75f
--->Val epoch: 1, batch: 88
batch_labels:  [[1]]
loss:  1.09044 1.09044
accuracy:  0.0
batch_is_nod:  [[ 0.  0.  0.  0.  0.]]
batch_file_names:  026470d51482c93efc18b9803159c960
--->Val epoch: 1, batch: 89
batch_labels:  [[1]]
loss:  5.38547 5.38547
accuracy:  0.0
batch_is_nod:  [[ 0.  0.  0.  0.  0.]]
batch_file_names:  6541df84fd779ba6513a530c128f4e9b
--->Val epoch: 1, batch: 90
batch_labels:  [[0]]
loss:  10.6771 10.3933
accuracy:  0.0
batch_is_nod:  [[ 1.  1.  1.  1.  0.]]
batch_file_names:  bcc701884a32d8883b73b5844241a354
Val step: 90, avg loss: 1.825420, loss: 2.375182, accuracy: 0.500000
--->Val epoch: 1, batch: 91
batch_labels:  [[0]]
loss:  11.5116 11.5116
accuracy:  0.0
batch_is_nod:  [[ 1.  0.  0.  0.  0.]]
batch_file_names:  483b89a4ffbbd85acc8b9af5a541dd4d
--->Val epoch: 1, batch: 99
batch_labels:  [[1]]
loss:  8.46611 8.29723
accuracy:  0.0
batch_is_nod:  [[ 1.  0.  0.  0.  0.]]
batch_file_names:  ebd601d40a18634b100c92e7db39f585
--->Val epoch: 1, batch: 100
batch_labels:  [[1]]
loss:  3.65357 3.58191
accuracy:  0.0
batch_is_nod:  [[ 1.  0.  0.  0.  0.]]
batch_file_names:  1f49f0c1d7feedcae9024d251797407c
Val step: 100, avg loss: 1.880063, loss: 2.371848, accuracy: 0.700000
Val step: 110, avg loss: 1.710923, loss: 0.019530, accuracy: 1.000000
--->Val epoch: 1, batch: 113
batch_labels:  [[1]]
loss:  8.05162 8.05162
accuracy:  0.0
batch_is_nod:  [[ 0.  0.  0.  0.  0.]]
batch_file_names:  ea01deecde93cd9503a049d71d46e6d5
--->Val epoch: 1, batch: 120
batch_labels:  [[1]]
loss:  4.09014 4.00538
accuracy:  0.0
batch_is_nod:  [[ 0.  1.  0.  0.  0.]]
batch_file_names:  93a6f37a72f60498986374f57bfc30c4
Val step: 120, avg loss: 1.669734, loss: 1.216647, accuracy: 0.800000
--->Val epoch: 1, batch: 126
batch_labels:  [[1]]
loss:  9.80574 9.80574
accuracy:  0.0
batch_is_nod:  [[ 0.  0.  0.  0.  0.]]
batch_file_names:  3252220375d82c3720d36d757bb17345
Val step: 130, avg loss: 1.622175, loss: 1.051472, accuracy: 0.900000
Val step: 140, avg loss: 1.507575, loss: 0.017777, accuracy: 1.000000
--->Val epoch: 1, batch: 141
batch_labels:  [[0]]
loss:  11.5116 11.5116
accuracy:  0.0
batch_is_nod:  [[ 1.  0.  0.  0.  0.]]
batch_file_names:  0334c8242ce7ee1a6c1263096e4cc535
--->Val epoch: 1, batch: 149
batch_labels:  [[1]]
loss:  2.60854 2.60854
accuracy:  0.0
batch_is_nod:  [[ 1.  0.  0.  0.  0.]]
batch_file_names:  15aa585fb2d3018b295df8619f2d1cf7
Val step: 150, avg loss: 1.502121, loss: 1.425768, accuracy: 0.800000
--->Val epoch: 1, batch: 152
batch_labels:  [[0]]
loss:  8.40017 8.40017
accuracy:  0.0
batch_is_nod:  [[ 0.  0.  0.  0.  0.]]
batch_file_names:  fcfab3eddbdf0421c39f71d651cc5c56
--->Val epoch: 1, batch: 157
batch_labels:  [[1]]
loss:  5.07359 4.94875
accuracy:  0.0
batch_is_nod:  [[ 1.  0.  0.  0.  0.]]
batch_file_names:  e38789c5eabb3005bfb82a5298055ba0
Val step: 160, avg loss: 1.493045, loss: 1.356898, accuracy: 0.800000
--->Val epoch: 1, batch: 161
batch_labels:  [[0]]
loss:  11.5116 11.5116
accuracy:  0.0
batch_is_nod:  [[ 1.  1.  0.  0.  0.]]
batch_file_names:  5f383eb9c3d8ea72ddec7e2e874d577d
--->Val epoch: 1, batch: 162
batch_labels:  [[0]]
loss:  5.87756 5.75718
accuracy:  0.0
batch_is_nod:  [[ 1.  0.  0.  0.  0.]]
batch_file_names:  fac65dbf7b6972049cfd37b5b122ec0b
--->Val epoch: 1, batch: 164
batch_labels:  [[1]]
loss:  5.02243 5.02243
accuracy:  0.0
batch_is_nod:  [[ 0.  0.  0.  0.  0.]]
batch_file_names:  761aeadb65fb84c8d04978a75b2f684c
--->Val epoch: 1, batch: 165
batch_labels:  [[1]]
loss:  5.5596 5.45015
accuracy:  0.0
batch_is_nod:  [[ 0.  1.  0.  0.  0.]]
batch_file_names:  54056288ab97cebc4b0ea33c23f47ff6
--->Val epoch: 1, batch: 166
batch_labels:  [[1]]
loss:  1.7214 1.6271
accuracy:  0.0
batch_is_nod:  [[ 1.  0.  0.  0.  0.]]
batch_file_names:  80600d4a5fee7424d689ba7d0906d50f
--->Val epoch: 1, batch: 170
batch_labels:  [[0]]
loss:  6.92206 6.92206
accuracy:  0.0
batch_is_nod:  [[ 1.  0.  0.  0.  0.]]
batch_file_names:  4d86e1657d46b9ee44c2c434fad231ce
Val step: 170, avg loss: 1.620651, loss: 3.662348, accuracy: 0.400000
--->Val epoch: 1, batch: 171
batch_labels:  [[1]]
loss:  3.25419 3.25419
accuracy:  0.0
batch_is_nod:  [[ 0.  0.  0.  0.  0.]]
batch_file_names:  2a2300103f80aadbfac57516d9a95365
--->Val epoch: 1, batch: 172
batch_labels:  [[1]]
loss:  4.55757 4.46803
accuracy:  0.0
batch_is_nod:  [[ 1.  0.  0.  0.  0.]]
batch_file_names:  f2ca85bb9ae82a3d79b9f321f727ac19
Val step: 180, avg loss: 1.576766, loss: 0.830711, accuracy: 0.800000
--->Val epoch: 1, batch: 181
batch_labels:  [[0]]
loss:  11.5857 11.5116
accuracy:  0.0
batch_is_nod:  [[ 1.  0.  0.  0.  0.]]
batch_file_names:  933cc0dec1c737d9654820453ce64284
Val step: 190, avg loss: 1.560408, loss: 1.265980, accuracy: 0.900000
--->Val epoch: 1, batch: 197
batch_labels:  [[0]]
loss:  11.5116 11.5116
accuracy:  0.0
batch_is_nod:  [[ 0.  0.  0.  0.  0.]]
batch_file_names:  337e7a428e7342d1e7f53a04247f7ad8
--->Val epoch: 1, batch: 199
batch_labels:  [[0]]
loss:  9.58454 9.42841
accuracy:  0.0
batch_is_nod:  [[ 1.  0.  0.  0.  0.]]
batch_file_names:  c004a9415539a0bc98c42c1a444cedb8
--->Val epoch: 1, batch: 200
batch_labels:  [[0]]
loss:  11.5116 11.5116
accuracy:  0.0
batch_is_nod:  [[ 1.  0.  0.  0.  0.]]
batch_file_names:  8c5288b86ffcd597f10d639e9948411d
Val step: 200, avg loss: 1.647068, loss: 3.293599, accuracy: 0.700000
--->Val epoch: 1, batch: 202
batch_labels:  [[1]]
loss:  5.01851 5.01851
accuracy:  0.0
batch_is_nod:  [[ 0.  0.  0.  0.  0.]]
batch_file_names:  1fdbc07019192de4a114e090389c8330
--->Val epoch: 1, batch: 204
batch_labels:  [[0]]
loss:  11.5116 11.5116
accuracy:  0.0
batch_is_nod:  [[ 0.  0.  0.  0.  0.]]
batch_file_names:  1a41350d4bbd74b7e0e28239cefa84c2
--->Val epoch: 1, batch: 205
batch_labels:  [[1]]
loss:  4.14793 4.14793
accuracy:  0.0
batch_is_nod:  [[ 0.  0.  0.  0.  0.]]
batch_file_names:  4a782bbc2608288a3ed05e511af6f8bb
--->Val epoch: 1, batch: 206
batch_labels:  [[0]]
loss:  4.15342 4.15342
accuracy:  0.0
batch_is_nod:  [[ 0.  0.  0.  0.  0.]]
batch_file_names:  f7cdd95c94818875ece1175561025038
--->Val epoch: 1, batch: 209
batch_labels:  [[1]]
loss:  4.65766 4.65766
accuracy:  0.0
batch_is_nod:  [[ 0.  0.  0.  0.  0.]]
batch_file_names:  3f6431400c2a07a46386dba3929da45d
--->Val epoch: 1, batch: 210
batch_labels:  [[1]]
loss:  6.60078 6.47091
accuracy:  0.0
batch_is_nod:  [[ 1.  0.  0.  0.  0.]]
batch_file_names:  31136e50b7205e9184227f94cdea0090
Val step: 210, avg loss: 1.741009, loss: 3.619828, accuracy: 0.400000
--->Val epoch: 1, batch: 213
batch_labels:  [[1]]
loss:  9.94469 9.94469
accuracy:  0.0
batch_is_nod:  [[ 0.  0.  0.  0.  0.]]
batch_file_names:  f467795ce3b50a771085d79ae8d29ecc
--->Val epoch: 1, batch: 215
batch_labels:  [[1]]
loss:  5.77725 5.77725
accuracy:  0.0
batch_is_nod:  [[ 0.  0.  0.  0.  0.]]
batch_file_names:  2f77fd993fbd858dec3c085b9ff1a3a2
--->Val epoch: 1, batch: 216
batch_labels:  [[1]]
loss:  9.80574 9.80574
accuracy:  0.0
batch_is_nod:  [[ 0.  0.  0.  0.  0.]]
batch_file_names:  fe45462987bacc32dbc7126119999392
--->Val epoch: 1, batch: 217
batch_labels:  [[1]]
loss:  3.9845 3.9845
accuracy:  0.0
batch_is_nod:  [[ 0.  0.  0.  0.  0.]]
batch_file_names:  fb99a80cbb2f441bb90135bab5b029fe
Val step: 220, avg loss: 1.798935, loss: 3.015394, accuracy: 0.600000
--->Val epoch: 1, batch: 224
batch_labels:  [[1]]
loss:  1.50431 1.50431
accuracy:  0.0
batch_is_nod:  [[ 0.  1.  0.  0.  0.]]
batch_file_names:  90409f7fcfec3581033559f8340e48a9
--->Val epoch: 1, batch: 226
batch_labels:  [[1]]
loss:  5.08635 5.08635
accuracy:  0.0
batch_is_nod:  [[ 0.  0.  0.  0.  0.]]
batch_file_names:  b17c07114dcf49ce71c8da4b43cf1192
Val step: 230, avg loss: 1.750538, loss: 0.685785, accuracy: 0.800000
--->Val epoch: 1, batch: 233
batch_labels:  [[1]]
loss:  7.65876 7.65876
accuracy:  0.0
batch_is_nod:  [[ 0.  0.  0.  0.  0.]]
batch_file_names:  04a8c47583142181728056310759dea1
--->Val epoch: 1, batch: 236
batch_labels:  [[1]]
loss:  5.50836 5.50836
accuracy:  0.0
batch_is_nod:  [[ 0.  0.  0.  0.  0.]]
batch_file_names:  88acee40bb9d8cb06898d1c5de01d3c8
--->Val epoch: 1, batch: 240
batch_labels:  [[1]]
loss:  4.87266 4.77638
accuracy:  0.0
batch_is_nod:  [[ 1.  0.  0.  0.  0.]]
batch_file_names:  cd10ceca9862ba0cc2ffd0ed8c9b055c
Val step: 240, avg loss: 1.754885, loss: 1.854871, accuracy: 0.700000
--->Val epoch: 1, batch: 243
batch_labels:  [[0]]
loss:  7.55428 7.55428
accuracy:  0.0
batch_is_nod:  [[ 0.  0.  0.  0.  0.]]
batch_file_names:  a53a4a019a24541c277e0a84301d8ec5
--->Val epoch: 1, batch: 245
batch_labels:  [[0]]
loss:  11.5116 11.5116
accuracy:  0.0
batch_is_nod:  [[ 1.  0.  0.  0.  0.]]
batch_file_names:  dcde02d4757bb845376fa6dbb0351df6
--->Val epoch: 1, batch: 248
batch_labels:  [[0]]
loss:  2.6291 2.6291
accuracy:  0.0
batch_is_nod:  [[ 0.  0.  0.  0.  0.]]
batch_file_names:  f73624b8b22774acf9a3e2c748131eac
Val step: 250, avg loss: 1.772021, loss: 2.183280, accuracy: 0.700000
--->Val epoch: 1, batch: 255
batch_labels:  [[1]]
loss:  5.7088 5.59668
accuracy:  0.0
batch_is_nod:  [[ 1.  0.  0.  0.  0.]]
batch_file_names:  a162d204827e4e89a2e5ba81cc53247a
Val step: 260, avg loss: 1.729942, loss: 0.677965, accuracy: 0.900000
Val step: 270, avg loss: 1.668712, loss: 0.076736, accuracy: 0.900000
--->Val epoch: 1, batch: 277
batch_labels:  [[1]]
loss:  4.00279 3.80786
accuracy:  0.0
batch_is_nod:  [[ 1.  1.  0.  0.  0.]]
batch_file_names:  0acbebb8d463b4b9ca88cf38431aac69
Val step: 280, avg loss: 1.624439, loss: 0.429088, accuracy: 0.900000
--->Val epoch: 1, batch: 284
batch_labels:  [[1]]
loss:  9.49746 9.49746
accuracy:  0.0
batch_is_nod:  [[ 0.  0.  0.  0.  0.]]
batch_file_names:  6171d57221e26d1f15d3c71fe966ab18
--->Val epoch: 1, batch: 285
batch_labels:  [[1]]
loss:  1.89603 1.89603
accuracy:  0.0
batch_is_nod:  [[ 1.  0.  0.  0.  0.]]
batch_file_names:  77033e4c1591403d1b1255607a20a983
Val step: 290, avg loss: 1.613003, loss: 1.292792, accuracy: 0.700000
--->Val epoch: 1, batch: 296
batch_labels:  [[0]]
loss:  3.5165 3.5165
accuracy:  0.0
batch_is_nod:  [[ 0.  0.  0.  0.  0.]]
batch_file_names:  88be713eb83cec7d31c4553ca05b2019
Val step: 300, avg loss: 1.571919, loss: 0.380486, accuracy: 0.900000
Val step: 310, avg loss: 1.522595, loss: 0.042865, accuracy: 1.000000
--->Val epoch: 1, batch: 315
batch_labels:  [[1]]
loss:  2.99378 2.99378
accuracy:  0.0
batch_is_nod:  [[ 0.  0.  0.  0.  0.]]
batch_file_names:  a2a4bc7708f6831470d757cd6f32bffe
--->Val epoch: 1, batch: 316
batch_labels:  [[0]]
loss:  8.236 8.236
accuracy:  0.0
batch_is_nod:  [[ 1.  0.  0.  0.  0.]]
batch_file_names:  fd7c0fb3c0e764357aa58e5f047be614
Validation epoch 1 finished in loss: 1.515604, loss2: 1.496082 and accuracy: 0.764890
Validation stat, total: 319, low accuracy: 75, 0.8 above: 244, 0.9 above: 244, 0.95 above: 244
Step: 10, avg loss: 0.189908, loss: 0.189908, accuracy: 0.900000
Step: 20, avg loss: 0.106950, loss: 0.023992, accuracy: 1.000000
Step: 30, avg loss: 0.080236, loss: 0.026808, accuracy: 1.000000
Step: 40, avg loss: 0.064891, loss: 0.018855, accuracy: 1.000000
Step: 50, avg loss: 0.054616, loss: 0.013518, accuracy: 1.000000
Step: 60, avg loss: 0.048946, loss: 0.020595, accuracy: 1.000000
Step: 70, avg loss: 0.042282, loss: 0.002296, accuracy: 1.000000
Step: 80, avg loss: 0.038797, loss: 0.014405, accuracy: 1.000000
Step: 90, avg loss: 0.157175, loss: 1.104202, accuracy: 0.900000
Step: 100, avg loss: 0.142829, loss: 0.013710, accuracy: 1.000000
Step: 110, avg loss: 0.133833, loss: 0.043873, accuracy: 1.000000
Step: 120, avg loss: 0.122817, loss: 0.001636, accuracy: 1.000000
Step: 130, avg loss: 0.114284, loss: 0.011893, accuracy: 1.000000
Step: 140, avg loss: 0.106925, loss: 0.011253, accuracy: 1.000000
Step: 150, avg loss: 0.102538, loss: 0.041132, accuracy: 1.000000
Step: 160, avg loss: 0.097781, loss: 0.026418, accuracy: 1.000000
Step: 170, avg loss: 0.092093, loss: 0.001089, accuracy: 1.000000
Step: 180, avg loss: 0.135387, loss: 0.871383, accuracy: 0.900000
Step: 190, avg loss: 0.130500, loss: 0.042539, accuracy: 1.000000
Step: 200, avg loss: 0.124868, loss: 0.017849, accuracy: 1.000000
Step: 210, avg loss: 0.119446, loss: 0.011006, accuracy: 1.000000
Step: 220, avg loss: 0.115073, loss: 0.023239, accuracy: 1.000000
Step: 230, avg loss: 0.110198, loss: 0.002956, accuracy: 1.000000
Step: 240, avg loss: 0.106516, loss: 0.021832, accuracy: 1.000000
Step: 250, avg loss: 0.104771, loss: 0.062891, accuracy: 1.000000
Step: 260, avg loss: 0.101349, loss: 0.015802, accuracy: 1.000000
Step: 270, avg loss: 0.098980, loss: 0.037370, accuracy: 1.000000
Step: 280, avg loss: 0.095561, loss: 0.003255, accuracy: 1.000000
Step: 290, avg loss: 0.094094, loss: 0.053019, accuracy: 1.000000
Step: 300, avg loss: 0.091740, loss: 0.023474, accuracy: 1.000000
Step: 310, avg loss: 0.089864, loss: 0.033586, accuracy: 1.000000
Step: 320, avg loss: 0.087761, loss: 0.022577, accuracy: 1.000000
Step: 330, avg loss: 0.086824, loss: 0.056842, accuracy: 1.000000
Step: 340, avg loss: 0.085650, loss: 0.046909, accuracy: 1.000000
Step: 350, avg loss: 0.084139, loss: 0.032766, accuracy: 1.000000
Step: 360, avg loss: 0.082746, loss: 0.033972, accuracy: 1.000000
Step: 370, avg loss: 0.082226, loss: 0.063508, accuracy: 1.000000
Step: 380, avg loss: 0.101626, loss: 0.819412, accuracy: 0.900000
Step: 390, avg loss: 0.099834, loss: 0.031750, accuracy: 1.000000
Step: 400, avg loss: 0.098237, loss: 0.035967, accuracy: 1.000000
Step: 410, avg loss: 0.097587, loss: 0.071562, accuracy: 1.000000
Step: 420, avg loss: 0.095587, loss: 0.013596, accuracy: 1.000000
Step: 430, avg loss: 0.094244, loss: 0.037842, accuracy: 1.000000
Step: 440, avg loss: 0.093414, loss: 0.057716, accuracy: 1.000000
Step: 450, avg loss: 0.091982, loss: 0.029002, accuracy: 1.000000
Step: 460, avg loss: 0.091228, loss: 0.057266, accuracy: 1.000000
Step: 470, avg loss: 0.103347, loss: 0.660822, accuracy: 0.900000
Step: 480, avg loss: 0.110987, loss: 0.470093, accuracy: 0.900000
Step: 490, avg loss: 0.116831, loss: 0.397327, accuracy: 0.900000
Step: 500, avg loss: 0.116044, loss: 0.077502, accuracy: 1.000000
Step: 510, avg loss: 0.114146, loss: 0.019255, accuracy: 1.000000
Step: 520, avg loss: 0.112943, loss: 0.051562, accuracy: 1.000000
Step: 530, avg loss: 0.111851, loss: 0.055089, accuracy: 1.000000
Step: 540, avg loss: 0.110109, loss: 0.017765, accuracy: 1.000000
Step: 550, avg loss: 0.108385, loss: 0.015271, accuracy: 1.000000
Step: 560, avg loss: 0.106724, loss: 0.015390, accuracy: 1.000000
Step: 570, avg loss: 0.105328, loss: 0.027159, accuracy: 1.000000
Step: 580, avg loss: 0.104095, loss: 0.033831, accuracy: 1.000000
Step: 590, avg loss: 0.103106, loss: 0.045700, accuracy: 1.000000
Step: 600, avg loss: 0.101984, loss: 0.035825, accuracy: 1.000000
Step: 610, avg loss: 0.100720, loss: 0.024850, accuracy: 1.000000
Step: 620, avg loss: 0.099490, loss: 0.024492, accuracy: 1.000000
Step: 630, avg loss: 0.098105, loss: 0.012207, accuracy: 1.000000
Step: 640, avg loss: 0.097136, loss: 0.036116, accuracy: 1.000000
Step: 650, avg loss: 0.095804, loss: 0.010551, accuracy: 1.000000
Step: 660, avg loss: 0.094701, loss: 0.022988, accuracy: 1.000000
Step: 670, avg loss: 0.104429, loss: 0.746487, accuracy: 0.900000
Step: 680, avg loss: 0.103527, loss: 0.043092, accuracy: 1.000000
Step: 690, avg loss: 0.102391, loss: 0.025145, accuracy: 1.000000
Step: 700, avg loss: 0.101007, loss: 0.005475, accuracy: 1.000000
Step: 710, avg loss: 0.099760, loss: 0.012519, accuracy: 1.000000
Step: 720, avg loss: 0.098607, loss: 0.016726, accuracy: 1.000000
Step: 730, avg loss: 0.097472, loss: 0.015746, accuracy: 1.000000
Step: 740, avg loss: 0.096716, loss: 0.041541, accuracy: 1.000000
Step: 750, avg loss: 0.095603, loss: 0.013259, accuracy: 1.000000
Step: 760, avg loss: 0.094863, loss: 0.039299, accuracy: 1.000000
Step: 770, avg loss: 0.093789, loss: 0.012188, accuracy: 1.000000
Step: 780, avg loss: 0.093010, loss: 0.033032, accuracy: 1.000000
Step: 790, avg loss: 0.091991, loss: 0.012532, accuracy: 1.000000
Step: 800, avg loss: 0.090862, loss: 0.001632, accuracy: 1.000000
Step: 810, avg loss: 0.090026, loss: 0.023158, accuracy: 1.000000
Step: 820, avg loss: 0.089178, loss: 0.020497, accuracy: 1.000000
Step: 830, avg loss: 0.090222, loss: 0.175829, accuracy: 0.900000
Step: 840, avg loss: 0.089420, loss: 0.022864, accuracy: 1.000000
Step: 850, avg loss: 0.088464, loss: 0.008148, accuracy: 1.000000
Step: 860, avg loss: 0.087821, loss: 0.033210, accuracy: 1.000000
Step: 870, avg loss: 0.086820, loss: 0.000683, accuracy: 1.000000
Step: 880, avg loss: 0.086073, loss: 0.021052, accuracy: 1.000000
Step: 890, avg loss: 0.085129, loss: 0.002089, accuracy: 1.000000
Step: 900, avg loss: 0.084336, loss: 0.013726, accuracy: 1.000000
Step: 910, avg loss: 0.092155, loss: 0.795902, accuracy: 0.900000
Step: 920, avg loss: 0.091464, loss: 0.028572, accuracy: 1.000000
Step: 930, avg loss: 0.090527, loss: 0.004304, accuracy: 1.000000
Step: 940, avg loss: 0.090262, loss: 0.065671, accuracy: 1.000000
Step: 950, avg loss: 0.089590, loss: 0.026404, accuracy: 1.000000
Step: 960, avg loss: 0.088885, loss: 0.021905, accuracy: 1.000000
Step: 970, avg loss: 0.088225, loss: 0.024895, accuracy: 1.000000
Step: 980, avg loss: 0.087582, loss: 0.025220, accuracy: 1.000000
Step: 990, avg loss: 0.086729, loss: 0.003138, accuracy: 1.000000
Step: 1000, avg loss: 0.085987, loss: 0.012459, accuracy: 1.000000
Step: 1010, avg loss: 0.085437, loss: 0.030434, accuracy: 1.000000
Step: 1020, avg loss: 0.084620, loss: 0.002117, accuracy: 1.000000
Step: 1030, avg loss: 0.083994, loss: 0.020169, accuracy: 1.000000
Step: 1040, avg loss: 0.083225, loss: 0.004000, accuracy: 1.000000
Step: 1050, avg loss: 0.082577, loss: 0.015207, accuracy: 1.000000
Step: 1060, avg loss: 0.082008, loss: 0.022263, accuracy: 1.000000
Step: 1070, avg loss: 0.081347, loss: 0.011315, accuracy: 1.000000
Step: 1080, avg loss: 0.081387, loss: 0.085647, accuracy: 1.000000
Step: 1090, avg loss: 0.080882, loss: 0.026269, accuracy: 1.000000
Step: 1100, avg loss: 0.080157, loss: 0.001177, accuracy: 1.000000
Step: 1110, avg loss: 0.079441, loss: 0.000737, accuracy: 1.000000
Step: 1120, avg loss: 0.078847, loss: 0.012873, accuracy: 1.000000
Step: 1130, avg loss: 0.078247, loss: 0.011018, accuracy: 1.000000
Step: 1140, avg loss: 0.077808, loss: 0.028202, accuracy: 1.000000
Step: 1150, avg loss: 0.077392, loss: 0.029949, accuracy: 1.000000
Step: 1160, avg loss: 0.077351, loss: 0.072645, accuracy: 1.000000
Step: 1170, avg loss: 0.077020, loss: 0.038675, accuracy: 1.000000
Step: 1180, avg loss: 0.076616, loss: 0.029377, accuracy: 1.000000
Step: 1190, avg loss: 0.076452, loss: 0.057104, accuracy: 1.000000
Step: 1200, avg loss: 0.076175, loss: 0.043111, accuracy: 1.000000
Step: 1210, avg loss: 0.076227, loss: 0.082546, accuracy: 1.000000
Step: 1220, avg loss: 0.075783, loss: 0.022054, accuracy: 1.000000
Step: 1230, avg loss: 0.075274, loss: 0.013203, accuracy: 1.000000
Step: 1240, avg loss: 0.074975, loss: 0.038081, accuracy: 1.000000
Step: 1250, avg loss: 0.074400, loss: 0.003204, accuracy: 1.000000
Step: 1260, avg loss: 0.074018, loss: 0.026274, accuracy: 1.000000
Epoch 41 finished in loss: 0.073904 and accuracy: 0.992076
Step: 10, avg loss: 0.045485, loss: 0.045485, accuracy: 1.000000
Step: 20, avg loss: 0.036407, loss: 0.027328, accuracy: 1.000000
Step: 30, avg loss: 0.034698, loss: 0.031281, accuracy: 1.000000
Step: 40, avg loss: 0.030751, loss: 0.018909, accuracy: 1.000000
Step: 50, avg loss: 0.027171, loss: 0.012851, accuracy: 1.000000
Step: 60, avg loss: 0.026445, loss: 0.022814, accuracy: 1.000000
Step: 70, avg loss: 0.022912, loss: 0.001716, accuracy: 1.000000
Step: 80, avg loss: 0.022325, loss: 0.018220, accuracy: 1.000000
Step: 90, avg loss: 0.137802, loss: 1.061614, accuracy: 0.900000
Step: 100, avg loss: 0.125350, loss: 0.013284, accuracy: 1.000000
Step: 110, avg loss: 0.117900, loss: 0.043397, accuracy: 1.000000
Step: 120, avg loss: 0.108459, loss: 0.004610, accuracy: 1.000000
Step: 130, avg loss: 0.101112, loss: 0.012952, accuracy: 1.000000
Step: 140, avg loss: 0.094771, loss: 0.012328, accuracy: 1.000000
Step: 150, avg loss: 0.090654, loss: 0.033023, accuracy: 1.000000
Step: 160, avg loss: 0.086918, loss: 0.030882, accuracy: 1.000000
Step: 170, avg loss: 0.081880, loss: 0.001275, accuracy: 1.000000
Step: 180, avg loss: 0.120331, loss: 0.773992, accuracy: 0.900000
Step: 190, avg loss: 0.116611, loss: 0.049659, accuracy: 1.000000
Step: 200, avg loss: 0.111415, loss: 0.012692, accuracy: 1.000000
Step: 210, avg loss: 0.106687, loss: 0.012111, accuracy: 1.000000
Step: 220, avg loss: 0.102834, loss: 0.021924, accuracy: 1.000000
Step: 230, avg loss: 0.098508, loss: 0.003349, accuracy: 1.000000
Step: 240, avg loss: 0.095468, loss: 0.025533, accuracy: 1.000000
Step: 250, avg loss: 0.092662, loss: 0.025327, accuracy: 1.000000
Step: 260, avg loss: 0.089998, loss: 0.023387, accuracy: 1.000000
Step: 270, avg loss: 0.087977, loss: 0.035449, accuracy: 1.000000
Step: 280, avg loss: 0.085197, loss: 0.010139, accuracy: 1.000000
Step: 290, avg loss: 0.084017, loss: 0.050967, accuracy: 1.000000
Step: 300, avg loss: 0.081976, loss: 0.022788, accuracy: 1.000000
Step: 310, avg loss: 0.080827, loss: 0.046350, accuracy: 1.000000
Step: 320, avg loss: 0.078983, loss: 0.021819, accuracy: 1.000000
Step: 330, avg loss: 0.078266, loss: 0.055314, accuracy: 1.000000
Step: 340, avg loss: 0.077266, loss: 0.044271, accuracy: 1.000000
Step: 350, avg loss: 0.075972, loss: 0.031967, accuracy: 1.000000
Step: 360, avg loss: 0.074734, loss: 0.031435, accuracy: 1.000000
Step: 370, avg loss: 0.074219, loss: 0.055652, accuracy: 1.000000
Step: 380, avg loss: 0.094515, loss: 0.845461, accuracy: 0.900000
Step: 390, avg loss: 0.092933, loss: 0.032832, accuracy: 1.000000
Step: 400, avg loss: 0.091499, loss: 0.035571, accuracy: 1.000000
Step: 410, avg loss: 0.090857, loss: 0.065166, accuracy: 1.000000
Step: 420, avg loss: 0.089003, loss: 0.012986, accuracy: 1.000000
Step: 430, avg loss: 0.087860, loss: 0.039875, accuracy: 1.000000
Step: 440, avg loss: 0.087136, loss: 0.056007, accuracy: 1.000000
Step: 450, avg loss: 0.085745, loss: 0.024538, accuracy: 1.000000
Step: 460, avg loss: 0.085074, loss: 0.054863, accuracy: 1.000000
Step: 470, avg loss: 0.097112, loss: 0.650894, accuracy: 0.900000
Step: 480, avg loss: 0.104811, loss: 0.466623, accuracy: 0.900000
Step: 490, avg loss: 0.111024, loss: 0.409271, accuracy: 0.900000
Step: 500, avg loss: 0.110251, loss: 0.072390, accuracy: 1.000000
Step: 510, avg loss: 0.108517, loss: 0.021780, accuracy: 1.000000
Step: 520, avg loss: 0.107400, loss: 0.050434, accuracy: 1.000000
Step: 530, avg loss: 0.106203, loss: 0.043950, accuracy: 1.000000
Step: 540, avg loss: 0.104575, loss: 0.018327, accuracy: 1.000000
Step: 550, avg loss: 0.102925, loss: 0.013806, accuracy: 1.000000
Step: 560, avg loss: 0.101290, loss: 0.011356, accuracy: 1.000000
Step: 570, avg loss: 0.099981, loss: 0.026676, accuracy: 1.000000
Step: 580, avg loss: 0.098834, loss: 0.033466, accuracy: 1.000000
Step: 590, avg loss: 0.097913, loss: 0.044509, accuracy: 1.000000
Step: 600, avg loss: 0.096853, loss: 0.034282, accuracy: 1.000000
Step: 610, avg loss: 0.095638, loss: 0.022774, accuracy: 1.000000
Step: 620, avg loss: 0.094484, loss: 0.024094, accuracy: 1.000000
Step: 630, avg loss: 0.093194, loss: 0.013224, accuracy: 1.000000
Step: 640, avg loss: 0.092301, loss: 0.036040, accuracy: 1.000000
Step: 650, avg loss: 0.091051, loss: 0.011059, accuracy: 1.000000
Step: 660, avg loss: 0.090013, loss: 0.022523, accuracy: 1.000000
Step: 670, avg loss: 0.099672, loss: 0.737157, accuracy: 0.900000
Step: 680, avg loss: 0.098875, loss: 0.045480, accuracy: 1.000000
Step: 690, avg loss: 0.097812, loss: 0.025510, accuracy: 1.000000
Step: 700, avg loss: 0.096493, loss: 0.005508, accuracy: 1.000000
Step: 710, avg loss: 0.095313, loss: 0.012668, accuracy: 1.000000
Step: 720, avg loss: 0.094152, loss: 0.011730, accuracy: 1.000000
Step: 730, avg loss: 0.093063, loss: 0.014680, accuracy: 1.000000
Step: 740, avg loss: 0.092457, loss: 0.048194, accuracy: 1.000000
Step: 750, avg loss: 0.091401, loss: 0.013313, accuracy: 1.000000
Step: 760, avg loss: 0.090412, loss: 0.016209, accuracy: 1.000000
Step: 770, avg loss: 0.089336, loss: 0.007556, accuracy: 1.000000
Step: 780, avg loss: 0.088654, loss: 0.036101, accuracy: 1.000000
Step: 790, avg loss: 0.087688, loss: 0.012357, accuracy: 1.000000
Step: 800, avg loss: 0.086610, loss: 0.001472, accuracy: 1.000000
Step: 810, avg loss: 0.085823, loss: 0.022891, accuracy: 1.000000
Step: 820, avg loss: 0.085030, loss: 0.020749, accuracy: 1.000000
Step: 830, avg loss: 0.084404, loss: 0.033070, accuracy: 1.000000
Step: 840, avg loss: 0.083703, loss: 0.025515, accuracy: 1.000000
Step: 850, avg loss: 0.082745, loss: 0.002336, accuracy: 1.000000
Step: 860, avg loss: 0.082156, loss: 0.032033, accuracy: 1.000000
Step: 870, avg loss: 0.081217, loss: 0.000512, accuracy: 1.000000
Step: 880, avg loss: 0.080525, loss: 0.020318, accuracy: 1.000000
Step: 890, avg loss: 0.079648, loss: 0.002442, accuracy: 1.000000
Step: 900, avg loss: 0.078929, loss: 0.014946, accuracy: 1.000000
Step: 910, avg loss: 0.088083, loss: 0.911967, accuracy: 0.900000
Step: 920, avg loss: 0.087401, loss: 0.025334, accuracy: 1.000000
Step: 930, avg loss: 0.086496, loss: 0.003204, accuracy: 1.000000
Step: 940, avg loss: 0.086206, loss: 0.059202, accuracy: 1.000000
Step: 950, avg loss: 0.085622, loss: 0.030774, accuracy: 1.000000
Step: 960, avg loss: 0.084920, loss: 0.018204, accuracy: 1.000000
Step: 970, avg loss: 0.084295, loss: 0.024307, accuracy: 1.000000
Step: 980, avg loss: 0.083684, loss: 0.024413, accuracy: 1.000000
Step: 990, avg loss: 0.082854, loss: 0.001517, accuracy: 1.000000
Step: 1000, avg loss: 0.082142, loss: 0.011635, accuracy: 1.000000
Step: 1010, avg loss: 0.081587, loss: 0.026140, accuracy: 1.000000
Step: 1020, avg loss: 0.080812, loss: 0.002553, accuracy: 1.000000
Step: 1030, avg loss: 0.080136, loss: 0.011187, accuracy: 1.000000
Step: 1040, avg loss: 0.079386, loss: 0.002133, accuracy: 1.000000
Step: 1050, avg loss: 0.078758, loss: 0.013442, accuracy: 1.000000
Step: 1060, avg loss: 0.078225, loss: 0.022276, accuracy: 1.000000
Step: 1070, avg loss: 0.077592, loss: 0.010423, accuracy: 1.000000
Step: 1080, avg loss: 0.077422, loss: 0.059207, accuracy: 1.000000
Step: 1090, avg loss: 0.076889, loss: 0.019358, accuracy: 1.000000
Step: 1100, avg loss: 0.076464, loss: 0.030140, accuracy: 1.000000
Step: 1110, avg loss: 0.075784, loss: 0.001002, accuracy: 1.000000
Step: 1120, avg loss: 0.075296, loss: 0.021150, accuracy: 1.000000
Step: 1130, avg loss: 0.074687, loss: 0.006504, accuracy: 1.000000
Step: 1140, avg loss: 0.074184, loss: 0.017328, accuracy: 1.000000
Step: 1150, avg loss: 0.073651, loss: 0.012900, accuracy: 1.000000
Step: 1160, avg loss: 0.073695, loss: 0.078742, accuracy: 1.000000
Step: 1170, avg loss: 0.073434, loss: 0.043140, accuracy: 1.000000
Step: 1180, avg loss: 0.073084, loss: 0.032171, accuracy: 1.000000
Step: 1190, avg loss: 0.072958, loss: 0.057999, accuracy: 1.000000
Step: 1200, avg loss: 0.072703, loss: 0.042355, accuracy: 1.000000
Step: 1210, avg loss: 0.072794, loss: 0.083775, accuracy: 1.000000
Step: 1220, avg loss: 0.072397, loss: 0.024305, accuracy: 1.000000
Step: 1230, avg loss: 0.071908, loss: 0.012226, accuracy: 1.000000
Step: 1240, avg loss: 0.071587, loss: 0.032216, accuracy: 1.000000
Step: 1250, avg loss: 0.071037, loss: 0.002755, accuracy: 1.000000
Step: 1260, avg loss: 0.070676, loss: 0.025624, accuracy: 1.000000
Epoch 42 finished in loss: 0.070566 and accuracy: 0.993661
Step: 10, avg loss: 0.041478, loss: 0.041478, accuracy: 1.000000
Step: 20, avg loss: 0.033265, loss: 0.025052, accuracy: 1.000000
Step: 30, avg loss: 0.031791, loss: 0.028843, accuracy: 1.000000
Step: 40, avg loss: 0.028840, loss: 0.019988, accuracy: 1.000000
Step: 50, avg loss: 0.026942, loss: 0.019347, accuracy: 1.000000
Step: 60, avg loss: 0.026305, loss: 0.023124, accuracy: 1.000000
Step: 70, avg loss: 0.022684, loss: 0.000958, accuracy: 1.000000
Step: 80, avg loss: 0.022250, loss: 0.019207, accuracy: 1.000000
Step: 90, avg loss: 0.136481, loss: 1.050330, accuracy: 0.900000
Step: 100, avg loss: 0.138068, loss: 0.152348, accuracy: 0.900000
Step: 110, avg loss: 0.129515, loss: 0.043994, accuracy: 1.000000
Step: 120, avg loss: 0.118915, loss: 0.002308, accuracy: 1.000000
Step: 130, avg loss: 0.111120, loss: 0.017587, accuracy: 1.000000
Step: 140, avg loss: 0.103947, loss: 0.010699, accuracy: 1.000000
Step: 150, avg loss: 0.099223, loss: 0.033080, accuracy: 1.000000
Step: 160, avg loss: 0.094805, loss: 0.028542, accuracy: 1.000000
Step: 170, avg loss: 0.089296, loss: 0.001143, accuracy: 1.000000
Step: 180, avg loss: 0.127043, loss: 0.768751, accuracy: 0.900000
Step: 190, avg loss: 0.122501, loss: 0.040749, accuracy: 1.000000
Step: 200, avg loss: 0.116988, loss: 0.012236, accuracy: 1.000000
Step: 210, avg loss: 0.111995, loss: 0.012127, accuracy: 1.000000
Step: 220, avg loss: 0.107913, loss: 0.022186, accuracy: 1.000000
Step: 230, avg loss: 0.103367, loss: 0.003373, accuracy: 1.000000
Step: 240, avg loss: 0.100005, loss: 0.022665, accuracy: 1.000000
Step: 250, avg loss: 0.097013, loss: 0.025210, accuracy: 1.000000
Step: 260, avg loss: 0.095595, loss: 0.060144, accuracy: 1.000000
Step: 270, avg loss: 0.093390, loss: 0.036064, accuracy: 1.000000
Step: 280, avg loss: 0.090187, loss: 0.003705, accuracy: 1.000000
Step: 290, avg loss: 0.088848, loss: 0.051366, accuracy: 1.000000
Step: 300, avg loss: 0.086691, loss: 0.024118, accuracy: 1.000000
Step: 310, avg loss: 0.085045, loss: 0.035668, accuracy: 1.000000
Step: 320, avg loss: 0.083075, loss: 0.022022, accuracy: 1.000000
Step: 330, avg loss: 0.082285, loss: 0.057006, accuracy: 1.000000
Step: 340, avg loss: 0.081253, loss: 0.047177, accuracy: 1.000000
Step: 350, avg loss: 0.079815, loss: 0.030940, accuracy: 1.000000
Step: 360, avg loss: 0.078475, loss: 0.031555, accuracy: 1.000000
Step: 370, avg loss: 0.077839, loss: 0.054970, accuracy: 1.000000
Step: 380, avg loss: 0.105401, loss: 1.125172, accuracy: 0.800000
Step: 390, avg loss: 0.103532, loss: 0.032504, accuracy: 1.000000
Step: 400, avg loss: 0.101758, loss: 0.032592, accuracy: 1.000000
Step: 410, avg loss: 0.100974, loss: 0.069614, accuracy: 1.000000
Step: 420, avg loss: 0.098847, loss: 0.011647, accuracy: 1.000000
Step: 430, avg loss: 0.097453, loss: 0.038875, accuracy: 1.000000
Step: 440, avg loss: 0.096535, loss: 0.057090, accuracy: 1.000000
Step: 450, avg loss: 0.094904, loss: 0.023108, accuracy: 1.000000
Step: 460, avg loss: 0.094032, loss: 0.054828, accuracy: 1.000000
Step: 470, avg loss: 0.105834, loss: 0.648704, accuracy: 0.900000
Step: 480, avg loss: 0.113706, loss: 0.483680, accuracy: 0.900000
Step: 490, avg loss: 0.120072, loss: 0.425635, accuracy: 0.900000
Step: 500, avg loss: 0.119120, loss: 0.072478, accuracy: 1.000000
Step: 510, avg loss: 0.117858, loss: 0.054789, accuracy: 1.000000
Step: 520, avg loss: 0.116584, loss: 0.051614, accuracy: 1.000000
Step: 530, avg loss: 0.115346, loss: 0.050976, accuracy: 1.000000
Step: 540, avg loss: 0.113543, loss: 0.017950, accuracy: 1.000000
Step: 550, avg loss: 0.111718, loss: 0.013193, accuracy: 1.000000
Step: 560, avg loss: 0.110113, loss: 0.021800, accuracy: 1.000000
Step: 570, avg loss: 0.108663, loss: 0.027466, accuracy: 1.000000
Step: 580, avg loss: 0.107291, loss: 0.029136, accuracy: 1.000000
Step: 590, avg loss: 0.106893, loss: 0.083784, accuracy: 1.000000
Step: 600, avg loss: 0.105674, loss: 0.033744, accuracy: 1.000000
Step: 610, avg loss: 0.104317, loss: 0.022891, accuracy: 1.000000
Step: 620, avg loss: 0.103002, loss: 0.022824, accuracy: 1.000000
Step: 630, avg loss: 0.101576, loss: 0.013113, accuracy: 1.000000
Step: 640, avg loss: 0.100549, loss: 0.035888, accuracy: 1.000000
Step: 650, avg loss: 0.099172, loss: 0.011046, accuracy: 1.000000
Step: 660, avg loss: 0.098025, loss: 0.023427, accuracy: 1.000000
Step: 670, avg loss: 0.106900, loss: 0.692666, accuracy: 0.900000
Step: 680, avg loss: 0.105874, loss: 0.037126, accuracy: 1.000000
Step: 690, avg loss: 0.104723, loss: 0.026490, accuracy: 1.000000
Step: 700, avg loss: 0.103296, loss: 0.004844, accuracy: 1.000000
Step: 710, avg loss: 0.102025, loss: 0.013012, accuracy: 1.000000
Step: 720, avg loss: 0.100822, loss: 0.015430, accuracy: 1.000000
Step: 730, avg loss: 0.099641, loss: 0.014585, accuracy: 1.000000
Step: 740, avg loss: 0.099000, loss: 0.052212, accuracy: 1.000000
Step: 750, avg loss: 0.097824, loss: 0.010780, accuracy: 1.000000
Step: 760, avg loss: 0.096956, loss: 0.031852, accuracy: 1.000000
Step: 770, avg loss: 0.095852, loss: 0.011988, accuracy: 1.000000
Step: 780, avg loss: 0.095721, loss: 0.085630, accuracy: 1.000000
Step: 790, avg loss: 0.094668, loss: 0.012504, accuracy: 1.000000
Step: 800, avg loss: 0.093494, loss: 0.000791, accuracy: 1.000000
Step: 810, avg loss: 0.092607, loss: 0.021630, accuracy: 1.000000
Step: 820, avg loss: 0.091733, loss: 0.020912, accuracy: 1.000000
Step: 830, avg loss: 0.091013, loss: 0.032030, accuracy: 1.000000
Step: 840, avg loss: 0.090208, loss: 0.023385, accuracy: 1.000000
Step: 850, avg loss: 0.089155, loss: 0.000674, accuracy: 1.000000
Step: 860, avg loss: 0.088497, loss: 0.032604, accuracy: 1.000000
Step: 870, avg loss: 0.087560, loss: 0.006920, accuracy: 1.000000
Step: 880, avg loss: 0.086810, loss: 0.021572, accuracy: 1.000000
Step: 890, avg loss: 0.085860, loss: 0.002242, accuracy: 1.000000
Step: 900, avg loss: 0.085084, loss: 0.016055, accuracy: 1.000000
Step: 910, avg loss: 0.093049, loss: 0.809885, accuracy: 0.900000
Step: 920, avg loss: 0.092320, loss: 0.025958, accuracy: 1.000000
Step: 930, avg loss: 0.091380, loss: 0.004970, accuracy: 1.000000
Step: 940, avg loss: 0.091075, loss: 0.062639, accuracy: 1.000000
Step: 950, avg loss: 0.090398, loss: 0.026770, accuracy: 1.000000
Step: 960, avg loss: 0.089696, loss: 0.023009, accuracy: 1.000000
Step: 970, avg loss: 0.089028, loss: 0.024908, accuracy: 1.000000
Step: 980, avg loss: 0.088369, loss: 0.024499, accuracy: 1.000000
Step: 990, avg loss: 0.087504, loss: 0.002690, accuracy: 1.000000
Step: 1000, avg loss: 0.086759, loss: 0.013008, accuracy: 1.000000
Step: 1010, avg loss: 0.086169, loss: 0.027168, accuracy: 1.000000
Step: 1020, avg loss: 0.085345, loss: 0.002122, accuracy: 1.000000
Step: 1030, avg loss: 0.084625, loss: 0.011219, accuracy: 1.000000
Step: 1040, avg loss: 0.083836, loss: 0.002582, accuracy: 1.000000
Step: 1050, avg loss: 0.083153, loss: 0.012044, accuracy: 1.000000
Step: 1060, avg loss: 0.082578, loss: 0.022285, accuracy: 1.000000
Step: 1070, avg loss: 0.081918, loss: 0.011939, accuracy: 1.000000
Step: 1080, avg loss: 0.081697, loss: 0.058067, accuracy: 1.000000
Step: 1090, avg loss: 0.081124, loss: 0.019213, accuracy: 1.000000
Step: 1100, avg loss: 0.080398, loss: 0.001199, accuracy: 1.000000
Step: 1110, avg loss: 0.079678, loss: 0.000562, accuracy: 1.000000
Step: 1120, avg loss: 0.079078, loss: 0.012444, accuracy: 1.000000
Step: 1130, avg loss: 0.078471, loss: 0.010527, accuracy: 1.000000
Step: 1140, avg loss: 0.078086, loss: 0.034538, accuracy: 1.000000
Step: 1150, avg loss: 0.077530, loss: 0.014132, accuracy: 1.000000
Step: 1160, avg loss: 0.077510, loss: 0.075173, accuracy: 1.000000
Step: 1170, avg loss: 0.077175, loss: 0.038336, accuracy: 1.000000
Step: 1180, avg loss: 0.076719, loss: 0.023361, accuracy: 1.000000
Step: 1190, avg loss: 0.076562, loss: 0.058074, accuracy: 1.000000
Step: 1200, avg loss: 0.076290, loss: 0.043926, accuracy: 1.000000
Step: 1210, avg loss: 0.076315, loss: 0.079302, accuracy: 1.000000
Step: 1220, avg loss: 0.075874, loss: 0.022534, accuracy: 1.000000
Step: 1230, avg loss: 0.075365, loss: 0.013193, accuracy: 1.000000
Step: 1240, avg loss: 0.075018, loss: 0.032361, accuracy: 1.000000
Step: 1250, avg loss: 0.074489, loss: 0.008959, accuracy: 1.000000
Step: 1260, avg loss: 0.074116, loss: 0.027426, accuracy: 1.000000
Epoch 43 finished in loss: 0.074000 and accuracy: 0.992076
Step: 10, avg loss: 0.045999, loss: 0.045999, accuracy: 1.000000
Step: 20, avg loss: 0.036037, loss: 0.026076, accuracy: 1.000000
Step: 30, avg loss: 0.032315, loss: 0.024871, accuracy: 1.000000
Step: 40, avg loss: 0.028697, loss: 0.017843, accuracy: 1.000000
Step: 50, avg loss: 0.025497, loss: 0.012699, accuracy: 1.000000
Step: 60, avg loss: 0.024941, loss: 0.022158, accuracy: 1.000000
Step: 70, avg loss: 0.021561, loss: 0.001279, accuracy: 1.000000
Step: 80, avg loss: 0.021016, loss: 0.017204, accuracy: 1.000000
Step: 90, avg loss: 0.139123, loss: 1.083981, accuracy: 0.900000
Step: 100, avg loss: 0.126521, loss: 0.013106, accuracy: 1.000000
Step: 110, avg loss: 0.118632, loss: 0.039738, accuracy: 1.000000
Step: 120, avg loss: 0.108919, loss: 0.002070, accuracy: 1.000000
Step: 130, avg loss: 0.101502, loss: 0.012503, accuracy: 1.000000
Step: 140, avg loss: 0.094722, loss: 0.006584, accuracy: 1.000000
Step: 150, avg loss: 0.091056, loss: 0.039726, accuracy: 1.000000
Step: 160, avg loss: 0.087264, loss: 0.030396, accuracy: 1.000000
Step: 170, avg loss: 0.082163, loss: 0.000541, accuracy: 1.000000
Step: 180, avg loss: 0.123805, loss: 0.831722, accuracy: 0.900000
Step: 190, avg loss: 0.119680, loss: 0.045431, accuracy: 1.000000
Step: 200, avg loss: 0.114267, loss: 0.011413, accuracy: 1.000000
Step: 210, avg loss: 0.109348, loss: 0.010978, accuracy: 1.000000
Step: 220, avg loss: 0.105357, loss: 0.021542, accuracy: 1.000000
Step: 230, avg loss: 0.100866, loss: 0.002071, accuracy: 1.000000
Step: 240, avg loss: 0.097807, loss: 0.027447, accuracy: 1.000000
Step: 250, avg loss: 0.094784, loss: 0.022229, accuracy: 1.000000
Step: 260, avg loss: 0.091837, loss: 0.018161, accuracy: 1.000000
Step: 270, avg loss: 0.089790, loss: 0.036564, accuracy: 1.000000
Step: 280, avg loss: 0.086656, loss: 0.002031, accuracy: 1.000000
Step: 290, avg loss: 0.085419, loss: 0.050797, accuracy: 1.000000
Step: 300, avg loss: 0.083303, loss: 0.021940, accuracy: 1.000000
Step: 310, avg loss: 0.081571, loss: 0.029607, accuracy: 1.000000
Step: 320, avg loss: 0.079698, loss: 0.021638, accuracy: 1.000000
Step: 330, avg loss: 0.078808, loss: 0.050316, accuracy: 1.000000
Step: 340, avg loss: 0.077934, loss: 0.049101, accuracy: 1.000000
Step: 350, avg loss: 0.076621, loss: 0.031972, accuracy: 1.000000
Step: 360, avg loss: 0.075378, loss: 0.031868, accuracy: 1.000000
Step: 370, avg loss: 0.074745, loss: 0.051965, accuracy: 1.000000
Step: 380, avg loss: 0.095556, loss: 0.865575, accuracy: 0.900000
Step: 390, avg loss: 0.093905, loss: 0.031176, accuracy: 1.000000
Step: 400, avg loss: 0.092433, loss: 0.035018, accuracy: 1.000000
Step: 410, avg loss: 0.091858, loss: 0.068858, accuracy: 1.000000
Step: 420, avg loss: 0.089936, loss: 0.011139, accuracy: 1.000000
Step: 430, avg loss: 0.088712, loss: 0.037288, accuracy: 1.000000
Step: 440, avg loss: 0.087927, loss: 0.054154, accuracy: 1.000000
Step: 450, avg loss: 0.086637, loss: 0.029900, accuracy: 1.000000
Step: 460, avg loss: 0.085914, loss: 0.053373, accuracy: 1.000000
Step: 470, avg loss: 0.098115, loss: 0.659377, accuracy: 0.900000
Step: 480, avg loss: 0.106169, loss: 0.484680, accuracy: 0.900000
Step: 490, avg loss: 0.112691, loss: 0.425779, accuracy: 0.900000
Step: 500, avg loss: 0.112109, loss: 0.083551, accuracy: 1.000000
Step: 510, avg loss: 0.110315, loss: 0.020636, accuracy: 1.000000
Step: 520, avg loss: 0.109140, loss: 0.049237, accuracy: 1.000000
Step: 530, avg loss: 0.107837, loss: 0.040039, accuracy: 1.000000
Step: 540, avg loss: 0.106176, loss: 0.018148, accuracy: 1.000000
Step: 550, avg loss: 0.104496, loss: 0.013789, accuracy: 1.000000
Step: 560, avg loss: 0.102928, loss: 0.016664, accuracy: 1.000000
Step: 570, avg loss: 0.101588, loss: 0.026586, accuracy: 1.000000
Step: 580, avg loss: 0.100392, loss: 0.032224, accuracy: 1.000000
Step: 590, avg loss: 0.099485, loss: 0.046886, accuracy: 1.000000
Step: 600, avg loss: 0.098380, loss: 0.033173, accuracy: 1.000000
Step: 610, avg loss: 0.097136, loss: 0.022479, accuracy: 1.000000
Step: 620, avg loss: 0.095947, loss: 0.023416, accuracy: 1.000000
Step: 630, avg loss: 0.094628, loss: 0.012874, accuracy: 1.000000
Step: 640, avg loss: 0.093709, loss: 0.035806, accuracy: 1.000000
Step: 650, avg loss: 0.092452, loss: 0.011988, accuracy: 1.000000
Step: 660, avg loss: 0.091390, loss: 0.022365, accuracy: 1.000000
Step: 670, avg loss: 0.100882, loss: 0.727360, accuracy: 0.900000
Step: 680, avg loss: 0.099977, loss: 0.039365, accuracy: 1.000000
Step: 690, avg loss: 0.098892, loss: 0.025067, accuracy: 1.000000
Step: 700, avg loss: 0.097568, loss: 0.006234, accuracy: 1.000000
Step: 710, avg loss: 0.098187, loss: 0.141507, accuracy: 0.900000
Step: 720, avg loss: 0.096966, loss: 0.010246, accuracy: 1.000000
Step: 730, avg loss: 0.095850, loss: 0.015526, accuracy: 1.000000
Step: 740, avg loss: 0.095171, loss: 0.045601, accuracy: 1.000000
Step: 750, avg loss: 0.094074, loss: 0.012936, accuracy: 1.000000
Step: 760, avg loss: 0.093015, loss: 0.013534, accuracy: 1.000000
Step: 770, avg loss: 0.091925, loss: 0.009084, accuracy: 1.000000
Step: 780, avg loss: 0.090997, loss: 0.019560, accuracy: 1.000000
Step: 790, avg loss: 0.090041, loss: 0.015461, accuracy: 1.000000
Step: 800, avg loss: 0.088935, loss: 0.001572, accuracy: 1.000000
Step: 810, avg loss: 0.088115, loss: 0.022529, accuracy: 1.000000
Step: 820, avg loss: 0.087289, loss: 0.020405, accuracy: 1.000000
Step: 830, avg loss: 0.086624, loss: 0.032045, accuracy: 1.000000
Step: 840, avg loss: 0.085842, loss: 0.020949, accuracy: 1.000000
Step: 850, avg loss: 0.084838, loss: 0.000510, accuracy: 1.000000
Step: 860, avg loss: 0.084242, loss: 0.033576, accuracy: 1.000000
Step: 870, avg loss: 0.083281, loss: 0.000644, accuracy: 1.000000
Step: 880, avg loss: 0.082572, loss: 0.020893, accuracy: 1.000000
Step: 890, avg loss: 0.081666, loss: 0.001900, accuracy: 1.000000
Step: 900, avg loss: 0.080932, loss: 0.015623, accuracy: 1.000000
Step: 910, avg loss: 0.089420, loss: 0.853383, accuracy: 0.900000
Step: 920, avg loss: 0.088722, loss: 0.025211, accuracy: 1.000000
Step: 930, avg loss: 0.087808, loss: 0.003711, accuracy: 1.000000
Step: 940, avg loss: 0.087506, loss: 0.059364, accuracy: 1.000000
Step: 950, avg loss: 0.086909, loss: 0.030832, accuracy: 1.000000
Step: 960, avg loss: 0.086243, loss: 0.022969, accuracy: 1.000000
Step: 970, avg loss: 0.085585, loss: 0.022382, accuracy: 1.000000
Step: 980, avg loss: 0.085022, loss: 0.030447, accuracy: 1.000000
Step: 990, avg loss: 0.084193, loss: 0.002937, accuracy: 1.000000
Step: 1000, avg loss: 0.083475, loss: 0.012403, accuracy: 1.000000
Step: 1010, avg loss: 0.082903, loss: 0.025739, accuracy: 1.000000
Step: 1020, avg loss: 0.082109, loss: 0.001870, accuracy: 1.000000
Step: 1030, avg loss: 0.081427, loss: 0.011860, accuracy: 1.000000
Step: 1040, avg loss: 0.080715, loss: 0.007358, accuracy: 1.000000
Step: 1050, avg loss: 0.080074, loss: 0.013452, accuracy: 1.000000
Step: 1060, avg loss: 0.079531, loss: 0.022549, accuracy: 1.000000
Step: 1070, avg loss: 0.078885, loss: 0.010313, accuracy: 1.000000
Step: 1080, avg loss: 0.078750, loss: 0.064303, accuracy: 1.000000
Step: 1090, avg loss: 0.078195, loss: 0.018323, accuracy: 1.000000
Step: 1100, avg loss: 0.077494, loss: 0.001062, accuracy: 1.000000
Step: 1110, avg loss: 0.076802, loss: 0.000723, accuracy: 1.000000
Step: 1120, avg loss: 0.076234, loss: 0.013132, accuracy: 1.000000
Step: 1130, avg loss: 0.075654, loss: 0.010751, accuracy: 1.000000
Step: 1140, avg loss: 0.075250, loss: 0.029572, accuracy: 1.000000
Step: 1150, avg loss: 0.075493, loss: 0.103146, accuracy: 0.900000
Step: 1160, avg loss: 0.075524, loss: 0.079106, accuracy: 1.000000
Step: 1170, avg loss: 0.075213, loss: 0.039131, accuracy: 1.000000
Step: 1180, avg loss: 0.074710, loss: 0.015921, accuracy: 1.000000
Step: 1190, avg loss: 0.074600, loss: 0.061639, accuracy: 1.000000
Step: 1200, avg loss: 0.074363, loss: 0.046149, accuracy: 1.000000
Step: 1210, avg loss: 0.074432, loss: 0.082641, accuracy: 1.000000
Step: 1220, avg loss: 0.074023, loss: 0.024505, accuracy: 1.000000
Step: 1230, avg loss: 0.073516, loss: 0.011673, accuracy: 1.000000
Step: 1240, avg loss: 0.073163, loss: 0.029729, accuracy: 1.000000
Step: 1250, avg loss: 0.072602, loss: 0.003048, accuracy: 1.000000
Step: 1260, avg loss: 0.072339, loss: 0.039451, accuracy: 1.000000
Epoch 44 finished in loss: 0.072225 and accuracy: 0.992076
Step: 10, avg loss: 0.041970, loss: 0.041970, accuracy: 1.000000
Step: 20, avg loss: 0.201192, loss: 0.360415, accuracy: 0.900000
Step: 30, avg loss: 0.143166, loss: 0.027113, accuracy: 1.000000
Step: 40, avg loss: 0.109952, loss: 0.010311, accuracy: 1.000000
Step: 50, avg loss: 0.091820, loss: 0.019293, accuracy: 1.000000
Step: 60, avg loss: 0.080394, loss: 0.023260, accuracy: 1.000000
Step: 70, avg loss: 0.069033, loss: 0.000869, accuracy: 1.000000
Step: 80, avg loss: 0.062663, loss: 0.018072, accuracy: 1.000000
Step: 90, avg loss: 0.160214, loss: 0.940626, accuracy: 0.900000
Step: 100, avg loss: 0.145260, loss: 0.010671, accuracy: 1.000000
Step: 110, avg loss: 0.135655, loss: 0.039610, accuracy: 1.000000
Step: 120, avg loss: 0.125501, loss: 0.013796, accuracy: 1.000000
Step: 130, avg loss: 0.116835, loss: 0.012845, accuracy: 1.000000
Step: 140, avg loss: 0.109343, loss: 0.011955, accuracy: 1.000000
Step: 150, avg loss: 0.104150, loss: 0.031445, accuracy: 1.000000
Step: 160, avg loss: 0.099568, loss: 0.030835, accuracy: 1.000000
Step: 170, avg loss: 0.093791, loss: 0.001356, accuracy: 1.000000
Step: 180, avg loss: 0.131709, loss: 0.776316, accuracy: 0.900000
Step: 190, avg loss: 0.127499, loss: 0.051717, accuracy: 1.000000
Step: 200, avg loss: 0.121725, loss: 0.012024, accuracy: 1.000000
Step: 210, avg loss: 0.116495, loss: 0.011902, accuracy: 1.000000
Step: 220, avg loss: 0.112203, loss: 0.022058, accuracy: 1.000000
Step: 230, avg loss: 0.107465, loss: 0.003247, accuracy: 1.000000
Step: 240, avg loss: 0.103975, loss: 0.023701, accuracy: 1.000000
Step: 250, avg loss: 0.100955, loss: 0.028480, accuracy: 1.000000
Step: 260, avg loss: 0.097352, loss: 0.007259, accuracy: 1.000000
Step: 270, avg loss: 0.095147, loss: 0.037831, accuracy: 1.000000
Step: 280, avg loss: 0.091868, loss: 0.003340, accuracy: 1.000000
Step: 290, avg loss: 0.090479, loss: 0.051567, accuracy: 1.000000
Step: 300, avg loss: 0.088217, loss: 0.022616, accuracy: 1.000000
Step: 310, avg loss: 0.086535, loss: 0.036072, accuracy: 1.000000
Step: 320, avg loss: 0.084518, loss: 0.021994, accuracy: 1.000000
Step: 330, avg loss: 0.083585, loss: 0.053739, accuracy: 1.000000
Step: 340, avg loss: 0.082447, loss: 0.044905, accuracy: 1.000000
Step: 350, avg loss: 0.081003, loss: 0.031885, accuracy: 1.000000
Step: 360, avg loss: 0.079654, loss: 0.032462, accuracy: 1.000000
Step: 370, avg loss: 0.078989, loss: 0.055027, accuracy: 1.000000
Step: 380, avg loss: 0.100897, loss: 0.911512, accuracy: 0.900000
Step: 390, avg loss: 0.099149, loss: 0.032718, accuracy: 1.000000
Step: 400, avg loss: 0.097504, loss: 0.033354, accuracy: 1.000000
Step: 410, avg loss: 0.096855, loss: 0.070875, accuracy: 1.000000
Step: 420, avg loss: 0.094817, loss: 0.011290, accuracy: 1.000000
Step: 430, avg loss: 0.093492, loss: 0.037834, accuracy: 1.000000
Step: 440, avg loss: 0.092444, loss: 0.047355, accuracy: 1.000000
Step: 450, avg loss: 0.090960, loss: 0.025680, accuracy: 1.000000
Step: 460, avg loss: 0.090109, loss: 0.051817, accuracy: 1.000000
Step: 470, avg loss: 0.102870, loss: 0.689892, accuracy: 0.900000
Step: 480, avg loss: 0.111075, loss: 0.496680, accuracy: 0.900000
Step: 490, avg loss: 0.117358, loss: 0.418960, accuracy: 0.900000
Step: 500, avg loss: 0.116531, loss: 0.075997, accuracy: 1.000000
Step: 510, avg loss: 0.115805, loss: 0.079498, accuracy: 1.000000
Step: 520, avg loss: 0.114506, loss: 0.048249, accuracy: 1.000000
Step: 530, avg loss: 0.113126, loss: 0.041389, accuracy: 1.000000
Step: 540, avg loss: 0.111396, loss: 0.019706, accuracy: 1.000000
Step: 550, avg loss: 0.109624, loss: 0.013917, accuracy: 1.000000
Step: 560, avg loss: 0.107951, loss: 0.015966, accuracy: 1.000000
Step: 570, avg loss: 0.106529, loss: 0.026863, accuracy: 1.000000
Step: 580, avg loss: 0.105211, loss: 0.030126, accuracy: 1.000000
Step: 590, avg loss: 0.104169, loss: 0.043693, accuracy: 1.000000
Step: 600, avg loss: 0.103066, loss: 0.038002, accuracy: 1.000000
Step: 610, avg loss: 0.101753, loss: 0.022964, accuracy: 1.000000
Step: 620, avg loss: 0.100460, loss: 0.021604, accuracy: 1.000000
Step: 630, avg loss: 0.099058, loss: 0.012110, accuracy: 1.000000
Step: 640, avg loss: 0.098051, loss: 0.034625, accuracy: 1.000000
Step: 650, avg loss: 0.096705, loss: 0.010581, accuracy: 1.000000
Step: 660, avg loss: 0.095581, loss: 0.022528, accuracy: 1.000000
Step: 670, avg loss: 0.104883, loss: 0.718759, accuracy: 0.900000
Step: 680, avg loss: 0.103898, loss: 0.037941, accuracy: 1.000000
Step: 690, avg loss: 0.102737, loss: 0.023784, accuracy: 1.000000
Step: 700, avg loss: 0.101326, loss: 0.003983, accuracy: 1.000000
Step: 710, avg loss: 0.100080, loss: 0.012848, accuracy: 1.000000
Step: 720, avg loss: 0.098875, loss: 0.013295, accuracy: 1.000000
Step: 730, avg loss: 0.097721, loss: 0.014621, accuracy: 1.000000
Step: 740, avg loss: 0.096987, loss: 0.043455, accuracy: 1.000000
Step: 750, avg loss: 0.095803, loss: 0.008174, accuracy: 1.000000
Step: 760, avg loss: 0.094709, loss: 0.012623, accuracy: 1.000000
Step: 770, avg loss: 0.093644, loss: 0.012724, accuracy: 1.000000
Step: 780, avg loss: 0.092789, loss: 0.026955, accuracy: 1.000000
Step: 790, avg loss: 0.091772, loss: 0.012424, accuracy: 1.000000
Step: 800, avg loss: 0.090637, loss: 0.000998, accuracy: 1.000000
Step: 810, avg loss: 0.089793, loss: 0.022295, accuracy: 1.000000
Step: 820, avg loss: 0.089656, loss: 0.078522, accuracy: 1.000000
Step: 830, avg loss: 0.088956, loss: 0.031548, accuracy: 1.000000
Step: 840, avg loss: 0.088165, loss: 0.022578, accuracy: 1.000000
Step: 850, avg loss: 0.087139, loss: 0.000954, accuracy: 1.000000
Step: 860, avg loss: 0.086519, loss: 0.033756, accuracy: 1.000000
Step: 870, avg loss: 0.085531, loss: 0.000582, accuracy: 1.000000
Step: 880, avg loss: 0.084808, loss: 0.021932, accuracy: 1.000000
Step: 890, avg loss: 0.083946, loss: 0.008099, accuracy: 1.000000
Step: 900, avg loss: 0.083137, loss: 0.011083, accuracy: 1.000000
Step: 910, avg loss: 0.091306, loss: 0.826545, accuracy: 0.900000
Step: 920, avg loss: 0.090613, loss: 0.027572, accuracy: 1.000000
Step: 930, avg loss: 0.089672, loss: 0.003115, accuracy: 1.000000
Step: 940, avg loss: 0.089420, loss: 0.065965, accuracy: 1.000000
Step: 950, avg loss: 0.088838, loss: 0.034068, accuracy: 1.000000
Step: 960, avg loss: 0.088145, loss: 0.022309, accuracy: 1.000000
Step: 970, avg loss: 0.087475, loss: 0.023150, accuracy: 1.000000
Step: 980, avg loss: 0.087009, loss: 0.041872, accuracy: 1.000000
Step: 990, avg loss: 0.086156, loss: 0.002503, accuracy: 1.000000
Step: 1000, avg loss: 0.085414, loss: 0.011968, accuracy: 1.000000
Step: 1010, avg loss: 0.084833, loss: 0.026741, accuracy: 1.000000
Step: 1020, avg loss: 0.084023, loss: 0.002236, accuracy: 1.000000
Step: 1030, avg loss: 0.083318, loss: 0.011436, accuracy: 1.000000
Step: 1040, avg loss: 0.082558, loss: 0.004224, accuracy: 1.000000
Step: 1050, avg loss: 0.081889, loss: 0.012377, accuracy: 1.000000
Step: 1060, avg loss: 0.081320, loss: 0.021514, accuracy: 1.000000
Step: 1070, avg loss: 0.080662, loss: 0.010975, accuracy: 1.000000
Step: 1080, avg loss: 0.080442, loss: 0.056825, accuracy: 1.000000
Step: 1090, avg loss: 0.079807, loss: 0.011240, accuracy: 1.000000
Step: 1100, avg loss: 0.079092, loss: 0.001136, accuracy: 1.000000
Step: 1110, avg loss: 0.078385, loss: 0.000663, accuracy: 1.000000
Step: 1120, avg loss: 0.077794, loss: 0.012149, accuracy: 1.000000
Step: 1130, avg loss: 0.077195, loss: 0.010138, accuracy: 1.000000
Step: 1140, avg loss: 0.076764, loss: 0.028109, accuracy: 1.000000
Step: 1150, avg loss: 0.076216, loss: 0.013682, accuracy: 1.000000
Step: 1160, avg loss: 0.076177, loss: 0.071745, accuracy: 1.000000
Step: 1170, avg loss: 0.075846, loss: 0.037365, accuracy: 1.000000
Step: 1180, avg loss: 0.075321, loss: 0.013904, accuracy: 1.000000
Step: 1190, avg loss: 0.075146, loss: 0.054486, accuracy: 1.000000
Step: 1200, avg loss: 0.074915, loss: 0.047541, accuracy: 1.000000
Step: 1210, avg loss: 0.074966, loss: 0.081045, accuracy: 1.000000
Step: 1220, avg loss: 0.074553, loss: 0.024620, accuracy: 1.000000
Step: 1230, avg loss: 0.074002, loss: 0.006755, accuracy: 1.000000
Step: 1240, avg loss: 0.073665, loss: 0.032187, accuracy: 1.000000
Step: 1250, avg loss: 0.073096, loss: 0.002597, accuracy: 1.000000
Step: 1260, avg loss: 0.072679, loss: 0.020453, accuracy: 1.000000
Epoch 45 finished in loss: 0.072565 and accuracy: 0.992868
Step: 10, avg loss: 0.194153, loss: 0.194153, accuracy: 0.900000
Step: 20, avg loss: 0.109330, loss: 0.024507, accuracy: 1.000000
Step: 30, avg loss: 0.081501, loss: 0.025844, accuracy: 1.000000
Step: 40, avg loss: 0.063794, loss: 0.010671, accuracy: 1.000000
Step: 50, avg loss: 0.053380, loss: 0.011727, accuracy: 1.000000
Step: 60, avg loss: 0.048681, loss: 0.025183, accuracy: 1.000000
Step: 70, avg loss: 0.041983, loss: 0.001796, accuracy: 1.000000
Step: 80, avg loss: 0.059055, loss: 0.178556, accuracy: 0.900000
Step: 90, avg loss: 0.170893, loss: 1.065598, accuracy: 0.900000
Step: 100, avg loss: 0.155232, loss: 0.014281, accuracy: 1.000000
Step: 110, avg loss: 0.144537, loss: 0.037594, accuracy: 1.000000
Step: 120, avg loss: 0.132724, loss: 0.002783, accuracy: 1.000000
Step: 130, avg loss: 0.123627, loss: 0.014457, accuracy: 1.000000
Step: 140, avg loss: 0.115563, loss: 0.010731, accuracy: 1.000000
Step: 150, avg loss: 0.109941, loss: 0.031233, accuracy: 1.000000
Step: 160, avg loss: 0.105006, loss: 0.030979, accuracy: 1.000000
Step: 170, avg loss: 0.098866, loss: 0.000627, accuracy: 1.000000
Step: 180, avg loss: 0.141212, loss: 0.861101, accuracy: 0.900000
Step: 190, avg loss: 0.135900, loss: 0.040288, accuracy: 1.000000
Step: 200, avg loss: 0.129645, loss: 0.010797, accuracy: 1.000000
Step: 210, avg loss: 0.123990, loss: 0.010891, accuracy: 1.000000
Step: 220, avg loss: 0.119328, loss: 0.021419, accuracy: 1.000000
Step: 230, avg loss: 0.114309, loss: 0.003880, accuracy: 1.000000
Step: 240, avg loss: 0.110451, loss: 0.021739, accuracy: 1.000000
Step: 250, avg loss: 0.106970, loss: 0.023405, accuracy: 1.000000
Step: 260, avg loss: 0.103358, loss: 0.013061, accuracy: 1.000000
Step: 270, avg loss: 0.100873, loss: 0.036281, accuracy: 1.000000
Step: 280, avg loss: 0.097345, loss: 0.002081, accuracy: 1.000000
Step: 290, avg loss: 0.095845, loss: 0.053840, accuracy: 1.000000
Step: 300, avg loss: 0.093364, loss: 0.021406, accuracy: 1.000000
Step: 310, avg loss: 0.091583, loss: 0.038163, accuracy: 1.000000
Step: 320, avg loss: 0.089394, loss: 0.021532, accuracy: 1.000000
Step: 330, avg loss: 0.088265, loss: 0.052144, accuracy: 1.000000
Step: 340, avg loss: 0.086960, loss: 0.043883, accuracy: 1.000000
Step: 350, avg loss: 0.085419, loss: 0.033035, accuracy: 1.000000
Step: 360, avg loss: 0.083919, loss: 0.031419, accuracy: 1.000000
Step: 370, avg loss: 0.083244, loss: 0.058958, accuracy: 1.000000
Step: 380, avg loss: 0.104920, loss: 0.906927, accuracy: 0.900000
Step: 390, avg loss: 0.103001, loss: 0.030056, accuracy: 1.000000
Step: 400, avg loss: 0.101255, loss: 0.033171, accuracy: 1.000000
Step: 410, avg loss: 0.100173, loss: 0.056890, accuracy: 1.000000
Step: 420, avg loss: 0.098067, loss: 0.011710, accuracy: 1.000000
Step: 430, avg loss: 0.096669, loss: 0.037975, accuracy: 1.000000
Step: 440, avg loss: 0.095809, loss: 0.058835, accuracy: 1.000000
Step: 450, avg loss: 0.094251, loss: 0.025707, accuracy: 1.000000
Step: 460, avg loss: 0.093341, loss: 0.052388, accuracy: 1.000000
Step: 470, avg loss: 0.105683, loss: 0.673420, accuracy: 0.900000
Step: 480, avg loss: 0.113878, loss: 0.499004, accuracy: 0.900000
Step: 490, avg loss: 0.120072, loss: 0.417417, accuracy: 0.900000
Step: 500, avg loss: 0.119092, loss: 0.071078, accuracy: 1.000000
Step: 510, avg loss: 0.117137, loss: 0.019379, accuracy: 1.000000
Step: 520, avg loss: 0.115854, loss: 0.050403, accuracy: 1.000000
Step: 530, avg loss: 0.114708, loss: 0.055098, accuracy: 1.000000
Step: 540, avg loss: 0.112953, loss: 0.019935, accuracy: 1.000000
Step: 550, avg loss: 0.111224, loss: 0.017907, accuracy: 1.000000
Step: 560, avg loss: 0.109516, loss: 0.015530, accuracy: 1.000000
Step: 570, avg loss: 0.108058, loss: 0.026429, accuracy: 1.000000
Step: 580, avg loss: 0.106769, loss: 0.033275, accuracy: 1.000000
Step: 590, avg loss: 0.105719, loss: 0.044816, accuracy: 1.000000
Step: 600, avg loss: 0.104557, loss: 0.036009, accuracy: 1.000000
Step: 610, avg loss: 0.103226, loss: 0.023369, accuracy: 1.000000
Step: 620, avg loss: 0.101925, loss: 0.022603, accuracy: 1.000000
Step: 630, avg loss: 0.100502, loss: 0.012269, accuracy: 1.000000
Step: 640, avg loss: 0.099471, loss: 0.034523, accuracy: 1.000000
Step: 650, avg loss: 0.098102, loss: 0.010465, accuracy: 1.000000
Step: 660, avg loss: 0.096960, loss: 0.022709, accuracy: 1.000000
Step: 670, avg loss: 0.106262, loss: 0.720244, accuracy: 0.900000
Step: 680, avg loss: 0.105285, loss: 0.039786, accuracy: 1.000000
Step: 690, avg loss: 0.104111, loss: 0.024263, accuracy: 1.000000
Step: 700, avg loss: 0.102709, loss: 0.005965, accuracy: 1.000000
Step: 710, avg loss: 0.101435, loss: 0.012310, accuracy: 1.000000
Step: 720, avg loss: 0.100190, loss: 0.011761, accuracy: 1.000000
Step: 730, avg loss: 0.099026, loss: 0.015250, accuracy: 1.000000
Step: 740, avg loss: 0.098293, loss: 0.044724, accuracy: 1.000000
Step: 750, avg loss: 0.097160, loss: 0.013390, accuracy: 1.000000
Step: 760, avg loss: 0.096048, loss: 0.012643, accuracy: 1.000000
Step: 770, avg loss: 0.094890, loss: 0.006857, accuracy: 1.000000
Step: 780, avg loss: 0.093977, loss: 0.023669, accuracy: 1.000000
Step: 790, avg loss: 0.092944, loss: 0.012338, accuracy: 1.000000
Step: 800, avg loss: 0.091795, loss: 0.001074, accuracy: 1.000000
Step: 810, avg loss: 0.090937, loss: 0.022274, accuracy: 1.000000
Step: 820, avg loss: 0.090117, loss: 0.023721, accuracy: 1.000000
Step: 830, avg loss: 0.090025, loss: 0.082448, accuracy: 1.000000
Step: 840, avg loss: 0.089235, loss: 0.023713, accuracy: 1.000000
Step: 850, avg loss: 0.088194, loss: 0.000717, accuracy: 1.000000
Step: 860, avg loss: 0.087626, loss: 0.039312, accuracy: 1.000000
Step: 870, avg loss: 0.086623, loss: 0.000412, accuracy: 1.000000
Step: 880, avg loss: 0.085880, loss: 0.021246, accuracy: 1.000000
Step: 890, avg loss: 0.084993, loss: 0.006950, accuracy: 1.000000
Step: 900, avg loss: 0.084222, loss: 0.015532, accuracy: 1.000000
Step: 910, avg loss: 0.092137, loss: 0.804488, accuracy: 0.900000
Step: 920, avg loss: 0.091389, loss: 0.023348, accuracy: 1.000000
Step: 930, avg loss: 0.090450, loss: 0.004100, accuracy: 1.000000
Step: 940, avg loss: 0.090178, loss: 0.064838, accuracy: 1.000000
Step: 950, avg loss: 0.089479, loss: 0.023836, accuracy: 1.000000
Step: 960, avg loss: 0.088771, loss: 0.021440, accuracy: 1.000000
Step: 970, avg loss: 0.088115, loss: 0.025132, accuracy: 1.000000
Step: 980, avg loss: 0.087542, loss: 0.032034, accuracy: 1.000000
Step: 990, avg loss: 0.086688, loss: 0.002905, accuracy: 1.000000
Step: 1000, avg loss: 0.085939, loss: 0.011882, accuracy: 1.000000
Step: 1010, avg loss: 0.085342, loss: 0.025634, accuracy: 1.000000
Step: 1020, avg loss: 0.084525, loss: 0.001953, accuracy: 1.000000
Step: 1030, avg loss: 0.083811, loss: 0.011023, accuracy: 1.000000
Step: 1040, avg loss: 0.083031, loss: 0.002657, accuracy: 1.000000
Step: 1050, avg loss: 0.082368, loss: 0.013471, accuracy: 1.000000
Step: 1060, avg loss: 0.081793, loss: 0.021383, accuracy: 1.000000
Step: 1070, avg loss: 0.081126, loss: 0.010454, accuracy: 1.000000
Step: 1080, avg loss: 0.080870, loss: 0.053426, accuracy: 1.000000
Step: 1090, avg loss: 0.080302, loss: 0.019004, accuracy: 1.000000
Step: 1100, avg loss: 0.079589, loss: 0.001816, accuracy: 1.000000
Step: 1110, avg loss: 0.078878, loss: 0.000720, accuracy: 1.000000
Step: 1120, avg loss: 0.078292, loss: 0.013205, accuracy: 1.000000
Step: 1130, avg loss: 0.077689, loss: 0.010166, accuracy: 1.000000
Step: 1140, avg loss: 0.077279, loss: 0.030971, accuracy: 1.000000
Step: 1150, avg loss: 0.076715, loss: 0.012440, accuracy: 1.000000
Step: 1160, avg loss: 0.076699, loss: 0.074853, accuracy: 1.000000
Step: 1170, avg loss: 0.076354, loss: 0.036348, accuracy: 1.000000
Step: 1180, avg loss: 0.075958, loss: 0.029535, accuracy: 1.000000
Step: 1190, avg loss: 0.075832, loss: 0.061001, accuracy: 1.000000
Step: 1200, avg loss: 0.075561, loss: 0.043309, accuracy: 1.000000
Step: 1210, avg loss: 0.075583, loss: 0.078214, accuracy: 1.000000
Step: 1220, avg loss: 0.075138, loss: 0.021345, accuracy: 1.000000
Step: 1230, avg loss: 0.074624, loss: 0.011913, accuracy: 1.000000
Step: 1240, avg loss: 0.074286, loss: 0.032658, accuracy: 1.000000
Step: 1250, avg loss: 0.073717, loss: 0.003206, accuracy: 1.000000
Step: 1260, avg loss: 0.073398, loss: 0.033559, accuracy: 1.000000
Epoch 46 finished in loss: 0.073284 and accuracy: 0.992076
Step: 10, avg loss: 0.112989, loss: 0.112989, accuracy: 1.000000
Step: 20, avg loss: 0.070322, loss: 0.027655, accuracy: 1.000000
Step: 30, avg loss: 0.055025, loss: 0.024430, accuracy: 1.000000
Step: 40, avg loss: 0.043803, loss: 0.010139, accuracy: 1.000000
Step: 50, avg loss: 0.037297, loss: 0.011273, accuracy: 1.000000
Step: 60, avg loss: 0.035102, loss: 0.024126, accuracy: 1.000000
Step: 70, avg loss: 0.030270, loss: 0.001281, accuracy: 1.000000
Step: 80, avg loss: 0.028611, loss: 0.016994, accuracy: 1.000000
Step: 90, avg loss: 0.138173, loss: 1.014667, accuracy: 0.900000
Step: 100, avg loss: 0.125447, loss: 0.010911, accuracy: 1.000000
Step: 110, avg loss: 0.119089, loss: 0.055511, accuracy: 1.000000
Step: 120, avg loss: 0.109446, loss: 0.003371, accuracy: 1.000000
Step: 130, avg loss: 0.101991, loss: 0.012541, accuracy: 1.000000
Step: 140, avg loss: 0.095210, loss: 0.007047, accuracy: 1.000000
Step: 150, avg loss: 0.091015, loss: 0.032288, accuracy: 1.000000
Step: 160, avg loss: 0.087212, loss: 0.030163, accuracy: 1.000000
Step: 170, avg loss: 0.082118, loss: 0.000618, accuracy: 1.000000
Step: 180, avg loss: 0.123116, loss: 0.820091, accuracy: 0.900000
Step: 190, avg loss: 0.119016, loss: 0.045217, accuracy: 1.000000
Step: 200, avg loss: 0.113642, loss: 0.011529, accuracy: 1.000000
Step: 210, avg loss: 0.108754, loss: 0.011002, accuracy: 1.000000
Step: 220, avg loss: 0.104843, loss: 0.022699, accuracy: 1.000000
Step: 230, avg loss: 0.100380, loss: 0.002193, accuracy: 1.000000
Step: 240, avg loss: 0.097084, loss: 0.021290, accuracy: 1.000000
Step: 250, avg loss: 0.094199, loss: 0.024940, accuracy: 1.000000
Step: 260, avg loss: 0.091291, loss: 0.018596, accuracy: 1.000000
Step: 270, avg loss: 0.089310, loss: 0.037797, accuracy: 1.000000
Step: 280, avg loss: 0.086240, loss: 0.003351, accuracy: 1.000000
Step: 290, avg loss: 0.085076, loss: 0.052494, accuracy: 1.000000
Step: 300, avg loss: 0.082944, loss: 0.021117, accuracy: 1.000000
Step: 310, avg loss: 0.081402, loss: 0.035133, accuracy: 1.000000
Step: 320, avg loss: 0.079527, loss: 0.021405, accuracy: 1.000000
Step: 330, avg loss: 0.078710, loss: 0.052558, accuracy: 1.000000
Step: 340, avg loss: 0.077719, loss: 0.045030, accuracy: 1.000000
Step: 350, avg loss: 0.076278, loss: 0.027293, accuracy: 1.000000
Step: 360, avg loss: 0.075233, loss: 0.038639, accuracy: 1.000000
Step: 370, avg loss: 0.074673, loss: 0.054507, accuracy: 1.000000
Step: 380, avg loss: 0.094697, loss: 0.835599, accuracy: 0.900000
Step: 390, avg loss: 0.092982, loss: 0.027822, accuracy: 1.000000
Step: 400, avg loss: 0.091508, loss: 0.034026, accuracy: 1.000000
Step: 410, avg loss: 0.090850, loss: 0.064521, accuracy: 1.000000
Step: 420, avg loss: 0.088954, loss: 0.011209, accuracy: 1.000000
Step: 430, avg loss: 0.087692, loss: 0.034699, accuracy: 1.000000
Step: 440, avg loss: 0.086944, loss: 0.054777, accuracy: 1.000000
Step: 450, avg loss: 0.085812, loss: 0.035994, accuracy: 1.000000
Step: 460, avg loss: 0.085115, loss: 0.053759, accuracy: 1.000000
Step: 470, avg loss: 0.097805, loss: 0.681526, accuracy: 0.900000
Step: 480, avg loss: 0.106347, loss: 0.507857, accuracy: 0.900000
Step: 490, avg loss: 0.112872, loss: 0.426060, accuracy: 0.900000
Step: 500, avg loss: 0.112070, loss: 0.072759, accuracy: 1.000000
Step: 510, avg loss: 0.110258, loss: 0.019684, accuracy: 1.000000
Step: 520, avg loss: 0.109086, loss: 0.049303, accuracy: 1.000000
Step: 530, avg loss: 0.108049, loss: 0.054108, accuracy: 1.000000
Step: 540, avg loss: 0.106399, loss: 0.018946, accuracy: 1.000000
Step: 550, avg loss: 0.104751, loss: 0.015786, accuracy: 1.000000
Step: 560, avg loss: 0.103073, loss: 0.010771, accuracy: 1.000000
Step: 570, avg loss: 0.101727, loss: 0.026374, accuracy: 1.000000
Step: 580, avg loss: 0.100481, loss: 0.029405, accuracy: 1.000000
Step: 590, avg loss: 0.099513, loss: 0.043373, accuracy: 1.000000
Step: 600, avg loss: 0.098435, loss: 0.034847, accuracy: 1.000000
Step: 610, avg loss: 0.097200, loss: 0.023082, accuracy: 1.000000
Step: 620, avg loss: 0.095990, loss: 0.022211, accuracy: 1.000000
Step: 630, avg loss: 0.094659, loss: 0.012126, accuracy: 1.000000
Step: 640, avg loss: 0.093725, loss: 0.034878, accuracy: 1.000000
Step: 650, avg loss: 0.092465, loss: 0.011813, accuracy: 1.000000
Step: 660, avg loss: 0.091412, loss: 0.022992, accuracy: 1.000000
Step: 670, avg loss: 0.100708, loss: 0.714231, accuracy: 0.900000
Step: 680, avg loss: 0.099827, loss: 0.040780, accuracy: 1.000000
Step: 690, avg loss: 0.098723, loss: 0.023678, accuracy: 1.000000
Step: 700, avg loss: 0.097386, loss: 0.005103, accuracy: 1.000000
Step: 710, avg loss: 0.096194, loss: 0.012790, accuracy: 1.000000
Step: 720, avg loss: 0.095026, loss: 0.012078, accuracy: 1.000000
Step: 730, avg loss: 0.093938, loss: 0.015646, accuracy: 1.000000
Step: 740, avg loss: 0.093342, loss: 0.049813, accuracy: 1.000000
Step: 750, avg loss: 0.092205, loss: 0.008075, accuracy: 1.000000
Step: 760, avg loss: 0.091156, loss: 0.012432, accuracy: 1.000000
Step: 770, avg loss: 0.090155, loss: 0.014142, accuracy: 1.000000
Step: 780, avg loss: 0.089239, loss: 0.018715, accuracy: 1.000000
Step: 790, avg loss: 0.088260, loss: 0.011892, accuracy: 1.000000
Step: 800, avg loss: 0.087171, loss: 0.001131, accuracy: 1.000000
Step: 810, avg loss: 0.086378, loss: 0.022905, accuracy: 1.000000
Step: 820, avg loss: 0.085574, loss: 0.020469, accuracy: 1.000000
Step: 830, avg loss: 0.084939, loss: 0.032895, accuracy: 1.000000
Step: 840, avg loss: 0.084222, loss: 0.024714, accuracy: 1.000000
Step: 850, avg loss: 0.083241, loss: 0.000776, accuracy: 1.000000
Step: 860, avg loss: 0.082634, loss: 0.031051, accuracy: 1.000000
Step: 870, avg loss: 0.081691, loss: 0.000591, accuracy: 1.000000
Step: 880, avg loss: 0.081001, loss: 0.020957, accuracy: 1.000000
Step: 890, avg loss: 0.080117, loss: 0.002398, accuracy: 1.000000
Step: 900, avg loss: 0.079385, loss: 0.014159, accuracy: 1.000000
Step: 910, avg loss: 0.088102, loss: 0.872711, accuracy: 0.900000
Step: 920, avg loss: 0.087406, loss: 0.024044, accuracy: 1.000000
Step: 930, avg loss: 0.086519, loss: 0.004945, accuracy: 1.000000
Step: 940, avg loss: 0.086290, loss: 0.064951, accuracy: 1.000000
Step: 950, avg loss: 0.085618, loss: 0.022437, accuracy: 1.000000
Step: 960, avg loss: 0.084945, loss: 0.021024, accuracy: 1.000000
Step: 970, avg loss: 0.084304, loss: 0.022770, accuracy: 1.000000
Step: 980, avg loss: 0.083700, loss: 0.025069, accuracy: 1.000000
Step: 990, avg loss: 0.082872, loss: 0.001776, accuracy: 1.000000
Step: 1000, avg loss: 0.082160, loss: 0.011623, accuracy: 1.000000
Step: 1010, avg loss: 0.081584, loss: 0.024048, accuracy: 1.000000
Step: 1020, avg loss: 0.080812, loss: 0.002805, accuracy: 1.000000
Step: 1030, avg loss: 0.080142, loss: 0.011764, accuracy: 1.000000
Step: 1040, avg loss: 0.079397, loss: 0.002683, accuracy: 1.000000
Step: 1050, avg loss: 0.078839, loss: 0.020830, accuracy: 1.000000
Step: 1060, avg loss: 0.078291, loss: 0.020717, accuracy: 1.000000
Step: 1070, avg loss: 0.077657, loss: 0.010461, accuracy: 1.000000
Step: 1080, avg loss: 0.077469, loss: 0.057372, accuracy: 1.000000
Step: 1090, avg loss: 0.076917, loss: 0.017341, accuracy: 1.000000
Step: 1100, avg loss: 0.076229, loss: 0.001187, accuracy: 1.000000
Step: 1110, avg loss: 0.075547, loss: 0.000504, accuracy: 1.000000
Step: 1120, avg loss: 0.074995, loss: 0.013821, accuracy: 1.000000
Step: 1130, avg loss: 0.074421, loss: 0.010075, accuracy: 1.000000
Step: 1140, avg loss: 0.074022, loss: 0.028981, accuracy: 1.000000
Step: 1150, avg loss: 0.073483, loss: 0.011949, accuracy: 1.000000
Step: 1160, avg loss: 0.073414, loss: 0.065485, accuracy: 1.000000
Step: 1170, avg loss: 0.073102, loss: 0.036959, accuracy: 1.000000
Step: 1180, avg loss: 0.072594, loss: 0.013157, accuracy: 1.000000
Step: 1190, avg loss: 0.072483, loss: 0.059338, accuracy: 1.000000
Step: 1200, avg loss: 0.072233, loss: 0.042471, accuracy: 1.000000
Step: 1210, avg loss: 0.072280, loss: 0.077947, accuracy: 1.000000
Step: 1220, avg loss: 0.071872, loss: 0.022495, accuracy: 1.000000
Step: 1230, avg loss: 0.071385, loss: 0.011996, accuracy: 1.000000
Step: 1240, avg loss: 0.070981, loss: 0.021333, accuracy: 1.000000
Step: 1250, avg loss: 0.070445, loss: 0.003882, accuracy: 1.000000
Step: 1260, avg loss: 0.070087, loss: 0.025369, accuracy: 1.000000
Epoch 47 finished in loss: 0.069978 and accuracy: 0.993661
Step: 10, avg loss: 0.043542, loss: 0.043542, accuracy: 1.000000
Step: 20, avg loss: 0.039088, loss: 0.034635, accuracy: 1.000000
Step: 30, avg loss: 0.035377, loss: 0.027955, accuracy: 1.000000
Step: 40, avg loss: 0.029238, loss: 0.010821, accuracy: 1.000000
Step: 50, avg loss: 0.025760, loss: 0.011848, accuracy: 1.000000
Step: 60, avg loss: 0.025284, loss: 0.022904, accuracy: 1.000000
Step: 70, avg loss: 0.021907, loss: 0.001643, accuracy: 1.000000
Step: 80, avg loss: 0.021377, loss: 0.017672, accuracy: 1.000000
Step: 90, avg loss: 0.142139, loss: 1.108228, accuracy: 0.900000
Step: 100, avg loss: 0.129076, loss: 0.011517, accuracy: 1.000000
Step: 110, avg loss: 0.120854, loss: 0.038628, accuracy: 1.000000
Step: 120, avg loss: 0.110912, loss: 0.001555, accuracy: 1.000000
Step: 130, avg loss: 0.103384, loss: 0.013040, accuracy: 1.000000
Step: 140, avg loss: 0.096786, loss: 0.011023, accuracy: 1.000000
Step: 150, avg loss: 0.092421, loss: 0.031307, accuracy: 1.000000
Step: 160, avg loss: 0.088580, loss: 0.030957, accuracy: 1.000000
Step: 170, avg loss: 0.083433, loss: 0.001089, accuracy: 1.000000
Step: 180, avg loss: 0.125410, loss: 0.839012, accuracy: 0.900000
Step: 190, avg loss: 0.121126, loss: 0.044022, accuracy: 1.000000
Step: 200, avg loss: 0.115943, loss: 0.017458, accuracy: 1.000000
Step: 210, avg loss: 0.111053, loss: 0.013258, accuracy: 1.000000
Step: 220, avg loss: 0.107295, loss: 0.028378, accuracy: 1.000000
Step: 230, avg loss: 0.102751, loss: 0.002783, accuracy: 1.000000
Step: 240, avg loss: 0.099200, loss: 0.017539, accuracy: 1.000000
Step: 250, avg loss: 0.096160, loss: 0.023177, accuracy: 1.000000
Step: 260, avg loss: 0.092879, loss: 0.010872, accuracy: 1.000000
Step: 270, avg loss: 0.090856, loss: 0.038247, accuracy: 1.000000
Step: 280, avg loss: 0.087676, loss: 0.001807, accuracy: 1.000000
Step: 290, avg loss: 0.086373, loss: 0.049907, accuracy: 1.000000
Step: 300, avg loss: 0.084214, loss: 0.021585, accuracy: 1.000000
Step: 310, avg loss: 0.082605, loss: 0.034334, accuracy: 1.000000
Step: 320, avg loss: 0.080711, loss: 0.022027, accuracy: 1.000000
Step: 330, avg loss: 0.079913, loss: 0.054366, accuracy: 1.000000
Step: 340, avg loss: 0.078899, loss: 0.045447, accuracy: 1.000000
Step: 350, avg loss: 0.077473, loss: 0.028989, accuracy: 1.000000
Step: 360, avg loss: 0.076310, loss: 0.035599, accuracy: 1.000000
Step: 370, avg loss: 0.075666, loss: 0.052458, accuracy: 1.000000
Step: 380, avg loss: 0.095906, loss: 0.844794, accuracy: 0.900000
Step: 390, avg loss: 0.094263, loss: 0.031847, accuracy: 1.000000
Step: 400, avg loss: 0.092646, loss: 0.029585, accuracy: 1.000000
Step: 410, avg loss: 0.092030, loss: 0.067362, accuracy: 1.000000
Step: 420, avg loss: 0.090140, loss: 0.012674, accuracy: 1.000000
Step: 430, avg loss: 0.088863, loss: 0.035215, accuracy: 1.000000
Step: 440, avg loss: 0.088084, loss: 0.054614, accuracy: 1.000000
Step: 450, avg loss: 0.086748, loss: 0.027947, accuracy: 1.000000
Step: 460, avg loss: 0.086029, loss: 0.053667, accuracy: 1.000000
Step: 470, avg loss: 0.098089, loss: 0.652832, accuracy: 0.900000
Step: 480, avg loss: 0.105913, loss: 0.473642, accuracy: 0.900000
Step: 490, avg loss: 0.112221, loss: 0.415030, accuracy: 0.900000
Step: 500, avg loss: 0.111398, loss: 0.071045, accuracy: 1.000000
Step: 510, avg loss: 0.109611, loss: 0.020306, accuracy: 1.000000
Step: 520, avg loss: 0.108474, loss: 0.050487, accuracy: 1.000000
Step: 530, avg loss: 0.107409, loss: 0.052029, accuracy: 1.000000
Step: 540, avg loss: 0.105778, loss: 0.019314, accuracy: 1.000000
Step: 550, avg loss: 0.104142, loss: 0.015768, accuracy: 1.000000
Step: 560, avg loss: 0.102602, loss: 0.017947, accuracy: 1.000000
Step: 570, avg loss: 0.101272, loss: 0.026797, accuracy: 1.000000
Step: 580, avg loss: 0.100111, loss: 0.033883, accuracy: 1.000000
Step: 590, avg loss: 0.099117, loss: 0.041519, accuracy: 1.000000
Step: 600, avg loss: 0.099017, loss: 0.093096, accuracy: 1.000000
Step: 610, avg loss: 0.097759, loss: 0.022258, accuracy: 1.000000
Step: 620, avg loss: 0.096568, loss: 0.023907, accuracy: 1.000000
Step: 630, avg loss: 0.095234, loss: 0.012550, accuracy: 1.000000
Step: 640, avg loss: 0.094279, loss: 0.034103, accuracy: 1.000000
Step: 650, avg loss: 0.092996, loss: 0.010896, accuracy: 1.000000
Step: 660, avg loss: 0.091927, loss: 0.022428, accuracy: 1.000000
Step: 670, avg loss: 0.100452, loss: 0.663085, accuracy: 0.900000
Step: 680, avg loss: 0.099671, loss: 0.047369, accuracy: 1.000000
Step: 690, avg loss: 0.098618, loss: 0.027010, accuracy: 1.000000
Step: 700, avg loss: 0.097277, loss: 0.004779, accuracy: 1.000000
Step: 710, avg loss: 0.096093, loss: 0.013169, accuracy: 1.000000
Step: 720, avg loss: 0.094951, loss: 0.013897, accuracy: 1.000000
Step: 730, avg loss: 0.093851, loss: 0.014638, accuracy: 1.000000
Step: 740, avg loss: 0.093247, loss: 0.049158, accuracy: 1.000000
Step: 750, avg loss: 0.092181, loss: 0.013302, accuracy: 1.000000
Step: 760, avg loss: 0.091145, loss: 0.013420, accuracy: 1.000000
Step: 770, avg loss: 0.090120, loss: 0.012238, accuracy: 1.000000
Step: 780, avg loss: 0.089219, loss: 0.019879, accuracy: 1.000000
Step: 790, avg loss: 0.088251, loss: 0.012753, accuracy: 1.000000
Step: 800, avg loss: 0.087161, loss: 0.001008, accuracy: 1.000000
Step: 810, avg loss: 0.086360, loss: 0.022308, accuracy: 1.000000
Step: 820, avg loss: 0.085563, loss: 0.020981, accuracy: 1.000000
Step: 830, avg loss: 0.084910, loss: 0.031339, accuracy: 1.000000
Step: 840, avg loss: 0.084153, loss: 0.021340, accuracy: 1.000000
Step: 850, avg loss: 0.083251, loss: 0.007468, accuracy: 1.000000
Step: 860, avg loss: 0.082665, loss: 0.032847, accuracy: 1.000000
Step: 870, avg loss: 0.081722, loss: 0.000682, accuracy: 1.000000
Step: 880, avg loss: 0.081033, loss: 0.021051, accuracy: 1.000000
Step: 890, avg loss: 0.080139, loss: 0.001456, accuracy: 1.000000
Step: 900, avg loss: 0.079401, loss: 0.013713, accuracy: 1.000000
Step: 910, avg loss: 0.088109, loss: 0.871902, accuracy: 0.900000
Step: 920, avg loss: 0.087434, loss: 0.025981, accuracy: 1.000000
Step: 930, avg loss: 0.086518, loss: 0.002268, accuracy: 1.000000
Step: 940, avg loss: 0.086274, loss: 0.063564, accuracy: 1.000000
Step: 950, avg loss: 0.085594, loss: 0.021612, accuracy: 1.000000
Step: 960, avg loss: 0.084924, loss: 0.021302, accuracy: 1.000000
Step: 970, avg loss: 0.084277, loss: 0.022145, accuracy: 1.000000
Step: 980, avg loss: 0.083669, loss: 0.024707, accuracy: 1.000000
Step: 990, avg loss: 0.082842, loss: 0.001859, accuracy: 1.000000
Step: 1000, avg loss: 0.082137, loss: 0.012307, accuracy: 1.000000
Step: 1010, avg loss: 0.081567, loss: 0.024598, accuracy: 1.000000
Step: 1020, avg loss: 0.080785, loss: 0.001721, accuracy: 1.000000
Step: 1030, avg loss: 0.080118, loss: 0.012121, accuracy: 1.000000
Step: 1040, avg loss: 0.079373, loss: 0.002661, accuracy: 1.000000
Step: 1050, avg loss: 0.078738, loss: 0.012724, accuracy: 1.000000
Step: 1060, avg loss: 0.078195, loss: 0.021150, accuracy: 1.000000
Step: 1070, avg loss: 0.077560, loss: 0.010212, accuracy: 1.000000
Step: 1080, avg loss: 0.077324, loss: 0.052142, accuracy: 1.000000
Step: 1090, avg loss: 0.076780, loss: 0.017936, accuracy: 1.000000
Step: 1100, avg loss: 0.076096, loss: 0.001588, accuracy: 1.000000
Step: 1110, avg loss: 0.075417, loss: 0.000750, accuracy: 1.000000
Step: 1120, avg loss: 0.074858, loss: 0.012775, accuracy: 1.000000
Step: 1130, avg loss: 0.074248, loss: 0.005946, accuracy: 1.000000
Step: 1140, avg loss: 0.073786, loss: 0.021540, accuracy: 1.000000
Step: 1150, avg loss: 0.073276, loss: 0.015228, accuracy: 1.000000
Step: 1160, avg loss: 0.073254, loss: 0.070644, accuracy: 1.000000
Step: 1170, avg loss: 0.072957, loss: 0.038578, accuracy: 1.000000
Step: 1180, avg loss: 0.072789, loss: 0.053128, accuracy: 1.000000
Step: 1190, avg loss: 0.072666, loss: 0.058136, accuracy: 1.000000
Step: 1200, avg loss: 0.072541, loss: 0.057593, accuracy: 1.000000
Step: 1210, avg loss: 0.072602, loss: 0.079977, accuracy: 1.000000
Step: 1220, avg loss: 0.072204, loss: 0.023988, accuracy: 1.000000
Step: 1230, avg loss: 0.071709, loss: 0.011384, accuracy: 1.000000
Step: 1240, avg loss: 0.071370, loss: 0.029599, accuracy: 1.000000
Step: 1250, avg loss: 0.070818, loss: 0.002374, accuracy: 1.000000
Step: 1260, avg loss: 0.070471, loss: 0.027200, accuracy: 1.000000
Epoch 48 finished in loss: 0.070361 and accuracy: 0.993661
Step: 10, avg loss: 0.055520, loss: 0.055520, accuracy: 1.000000
Step: 20, avg loss: 0.039855, loss: 0.024190, accuracy: 1.000000
Step: 30, avg loss: 0.039146, loss: 0.037727, accuracy: 1.000000
Step: 40, avg loss: 0.032157, loss: 0.011193, accuracy: 1.000000
Step: 50, avg loss: 0.028099, loss: 0.011864, accuracy: 1.000000
Step: 60, avg loss: 0.027282, loss: 0.023197, accuracy: 1.000000
Step: 70, avg loss: 0.023605, loss: 0.001547, accuracy: 1.000000
Step: 80, avg loss: 0.022722, loss: 0.016542, accuracy: 1.000000
Step: 90, avg loss: 0.130769, loss: 0.995139, accuracy: 0.900000
Step: 100, avg loss: 0.118715, loss: 0.010236, accuracy: 1.000000
Step: 110, avg loss: 0.112184, loss: 0.046872, accuracy: 1.000000
Step: 120, avg loss: 0.102997, loss: 0.001936, accuracy: 1.000000
Step: 130, avg loss: 0.096099, loss: 0.013328, accuracy: 1.000000
Step: 140, avg loss: 0.090459, loss: 0.017135, accuracy: 1.000000
Step: 150, avg loss: 0.087018, loss: 0.038845, accuracy: 1.000000
Step: 160, avg loss: 0.083481, loss: 0.030424, accuracy: 1.000000
Step: 170, avg loss: 0.078617, loss: 0.000794, accuracy: 1.000000
Step: 180, avg loss: 0.119833, loss: 0.820507, accuracy: 0.900000
Step: 190, avg loss: 0.115616, loss: 0.039715, accuracy: 1.000000
Step: 200, avg loss: 0.110715, loss: 0.017583, accuracy: 1.000000
Step: 210, avg loss: 0.105961, loss: 0.010890, accuracy: 1.000000
Step: 220, avg loss: 0.102110, loss: 0.021234, accuracy: 1.000000
Step: 230, avg loss: 0.097764, loss: 0.002156, accuracy: 1.000000
Step: 240, avg loss: 0.094562, loss: 0.020908, accuracy: 1.000000
Step: 250, avg loss: 0.091741, loss: 0.024034, accuracy: 1.000000
Step: 260, avg loss: 0.088656, loss: 0.011535, accuracy: 1.000000
Step: 270, avg loss: 0.086732, loss: 0.036710, accuracy: 1.000000
Step: 280, avg loss: 0.083698, loss: 0.001799, accuracy: 1.000000
Step: 290, avg loss: 0.082613, loss: 0.052231, accuracy: 1.000000
Step: 300, avg loss: 0.080551, loss: 0.020727, accuracy: 1.000000
Step: 310, avg loss: 0.079055, loss: 0.034201, accuracy: 1.000000
Step: 320, avg loss: 0.077255, loss: 0.021433, accuracy: 1.000000
Step: 330, avg loss: 0.076527, loss: 0.053234, accuracy: 1.000000
Step: 340, avg loss: 0.075524, loss: 0.042442, accuracy: 1.000000
Step: 350, avg loss: 0.074545, loss: 0.041238, accuracy: 1.000000
Step: 360, avg loss: 0.073376, loss: 0.032487, accuracy: 1.000000
Step: 370, avg loss: 0.072926, loss: 0.056718, accuracy: 1.000000
Step: 380, avg loss: 0.094435, loss: 0.890274, accuracy: 0.900000
Step: 390, avg loss: 0.092814, loss: 0.031205, accuracy: 1.000000
Step: 400, avg loss: 0.091303, loss: 0.032380, accuracy: 1.000000
Step: 410, avg loss: 0.090678, loss: 0.065651, accuracy: 1.000000
Step: 420, avg loss: 0.088780, loss: 0.010991, accuracy: 1.000000
Step: 430, avg loss: 0.087509, loss: 0.034096, accuracy: 1.000000
Step: 440, avg loss: 0.086764, loss: 0.054757, accuracy: 1.000000
Step: 450, avg loss: 0.085469, loss: 0.028467, accuracy: 1.000000
Step: 460, avg loss: 0.084740, loss: 0.051967, accuracy: 1.000000
Step: 470, avg loss: 0.097551, loss: 0.686860, accuracy: 0.900000
Step: 480, avg loss: 0.106377, loss: 0.521175, accuracy: 0.900000
Step: 490, avg loss: 0.113189, loss: 0.440150, accuracy: 0.900000
Step: 500, avg loss: 0.112395, loss: 0.073511, accuracy: 1.000000
Step: 510, avg loss: 0.110561, loss: 0.018881, accuracy: 1.000000
Step: 520, avg loss: 0.109411, loss: 0.050717, accuracy: 1.000000
Step: 530, avg loss: 0.108396, loss: 0.055663, accuracy: 1.000000
Step: 540, avg loss: 0.106729, loss: 0.018371, accuracy: 1.000000
Step: 550, avg loss: 0.105063, loss: 0.015097, accuracy: 1.000000
Step: 560, avg loss: 0.103507, loss: 0.017905, accuracy: 1.000000
Step: 570, avg loss: 0.102146, loss: 0.025943, accuracy: 1.000000
Step: 580, avg loss: 0.100966, loss: 0.033718, accuracy: 1.000000
Step: 590, avg loss: 0.100026, loss: 0.045477, accuracy: 1.000000
Step: 600, avg loss: 0.098936, loss: 0.034629, accuracy: 1.000000
Step: 610, avg loss: 0.097699, loss: 0.023485, accuracy: 1.000000
Step: 620, avg loss: 0.096468, loss: 0.021406, accuracy: 1.000000
Step: 630, avg loss: 0.095127, loss: 0.011968, accuracy: 1.000000
Step: 640, avg loss: 0.094177, loss: 0.034340, accuracy: 1.000000
Step: 650, avg loss: 0.092893, loss: 0.010721, accuracy: 1.000000
Step: 660, avg loss: 0.091815, loss: 0.021728, accuracy: 1.000000
Step: 670, avg loss: 0.101305, loss: 0.727659, accuracy: 0.900000
Step: 680, avg loss: 0.100416, loss: 0.040820, accuracy: 1.000000
Step: 690, avg loss: 0.099297, loss: 0.023198, accuracy: 1.000000
Step: 700, avg loss: 0.097943, loss: 0.004499, accuracy: 1.000000
Step: 710, avg loss: 0.098720, loss: 0.153171, accuracy: 0.900000
Step: 720, avg loss: 0.097572, loss: 0.016005, accuracy: 1.000000
Step: 730, avg loss: 0.096428, loss: 0.014062, accuracy: 1.000000
Step: 740, avg loss: 0.095745, loss: 0.045895, accuracy: 1.000000
Step: 750, avg loss: 0.094635, loss: 0.012488, accuracy: 1.000000
Step: 760, avg loss: 0.093513, loss: 0.009426, accuracy: 1.000000
Step: 770, avg loss: 0.092484, loss: 0.014232, accuracy: 1.000000
Step: 780, avg loss: 0.091459, loss: 0.012566, accuracy: 1.000000
Step: 790, avg loss: 0.090449, loss: 0.011654, accuracy: 1.000000
Step: 800, avg loss: 0.089336, loss: 0.001385, accuracy: 1.000000
Step: 810, avg loss: 0.088515, loss: 0.022858, accuracy: 1.000000
Step: 820, avg loss: 0.087702, loss: 0.021842, accuracy: 1.000000
Step: 830, avg loss: 0.087022, loss: 0.031279, accuracy: 1.000000
Step: 840, avg loss: 0.086246, loss: 0.021840, accuracy: 1.000000
Step: 850, avg loss: 0.085316, loss: 0.007188, accuracy: 1.000000
Step: 860, avg loss: 0.084678, loss: 0.030459, accuracy: 1.000000
Step: 870, avg loss: 0.083791, loss: 0.007516, accuracy: 1.000000
Step: 880, avg loss: 0.083074, loss: 0.020692, accuracy: 1.000000
Step: 890, avg loss: 0.082166, loss: 0.002220, accuracy: 1.000000
Step: 900, avg loss: 0.081360, loss: 0.009646, accuracy: 1.000000
Step: 910, avg loss: 0.090138, loss: 0.880194, accuracy: 0.900000
Step: 920, avg loss: 0.089440, loss: 0.025907, accuracy: 1.000000
Step: 930, avg loss: 0.088507, loss: 0.002606, accuracy: 1.000000
Step: 940, avg loss: 0.088250, loss: 0.064397, accuracy: 1.000000
Step: 950, avg loss: 0.087622, loss: 0.028547, accuracy: 1.000000
Step: 960, avg loss: 0.087342, loss: 0.060757, accuracy: 1.000000
Step: 970, avg loss: 0.086664, loss: 0.021587, accuracy: 1.000000
Step: 980, avg loss: 0.086024, loss: 0.023926, accuracy: 1.000000
Step: 990, avg loss: 0.085167, loss: 0.001230, accuracy: 1.000000
Step: 1000, avg loss: 0.084428, loss: 0.011201, accuracy: 1.000000
Step: 1010, avg loss: 0.083834, loss: 0.024490, accuracy: 1.000000
Step: 1020, avg loss: 0.083029, loss: 0.001752, accuracy: 1.000000
Step: 1030, avg loss: 0.082332, loss: 0.011163, accuracy: 1.000000
Step: 1040, avg loss: 0.081582, loss: 0.004400, accuracy: 1.000000
Step: 1050, avg loss: 0.080928, loss: 0.012887, accuracy: 1.000000
Step: 1060, avg loss: 0.080363, loss: 0.020991, accuracy: 1.000000
Step: 1070, avg loss: 0.079707, loss: 0.010181, accuracy: 1.000000
Step: 1080, avg loss: 0.079622, loss: 0.070584, accuracy: 1.000000
Step: 1090, avg loss: 0.079049, loss: 0.017191, accuracy: 1.000000
Step: 1100, avg loss: 0.078337, loss: 0.000699, accuracy: 1.000000
Step: 1110, avg loss: 0.077636, loss: 0.000506, accuracy: 1.000000
Step: 1120, avg loss: 0.077049, loss: 0.011840, accuracy: 1.000000
Step: 1130, avg loss: 0.076460, loss: 0.010592, accuracy: 1.000000
Step: 1140, avg loss: 0.075980, loss: 0.021661, accuracy: 1.000000
Step: 1150, avg loss: 0.075421, loss: 0.011699, accuracy: 1.000000
Step: 1160, avg loss: 0.075447, loss: 0.078424, accuracy: 1.000000
Step: 1170, avg loss: 0.075131, loss: 0.038531, accuracy: 1.000000
Step: 1180, avg loss: 0.074722, loss: 0.026814, accuracy: 1.000000
Step: 1190, avg loss: 0.074576, loss: 0.057443, accuracy: 1.000000
Step: 1200, avg loss: 0.074317, loss: 0.043453, accuracy: 1.000000
Step: 1210, avg loss: 0.074337, loss: 0.076746, accuracy: 1.000000
Step: 1220, avg loss: 0.073908, loss: 0.021940, accuracy: 1.000000
Step: 1230, avg loss: 0.073408, loss: 0.012467, accuracy: 1.000000
Step: 1240, avg loss: 0.073056, loss: 0.029762, accuracy: 1.000000
Step: 1250, avg loss: 0.072487, loss: 0.001959, accuracy: 1.000000
Step: 1260, avg loss: 0.072117, loss: 0.025771, accuracy: 1.000000
Epoch 49 finished in loss: 0.072004 and accuracy: 0.992868
Step: 10, avg loss: 0.114065, loss: 0.114065, accuracy: 0.900000
Step: 20, avg loss: 0.070323, loss: 0.026581, accuracy: 1.000000
Step: 30, avg loss: 0.055010, loss: 0.024385, accuracy: 1.000000
Step: 40, avg loss: 0.043976, loss: 0.010874, accuracy: 1.000000
Step: 50, avg loss: 0.037504, loss: 0.011614, accuracy: 1.000000
Step: 60, avg loss: 0.035287, loss: 0.024202, accuracy: 1.000000
Step: 70, avg loss: 0.030443, loss: 0.001382, accuracy: 1.000000
Step: 80, avg loss: 0.028825, loss: 0.017501, accuracy: 1.000000
--------------------->Epoch: 50, batch: 82
batch_labels:  [[1]]
loss:  9.99566 9.99566 -0.0 [[ 1.  1.  1.  1.  1.]]
accuracy:  0.0
case_pred:  [[  4.55975533e-05]]
case_pred_each:  [[  9.11450115e-06   9.11450115e-06   9.11450115e-06   9.11450115e-06
    9.11450115e-06]]
miss mask:  [[ 1.  1.  1.  1.  1.]]
batch_isnode shape:  (1, 5)
batch_is_nod:  [[ 0.  0.  0.  0.  0.]]
batch_file_names:  11fe5426ef497bc490b9f1465f1fb25e
Step: 90, avg loss: 0.138154, loss: 1.012784, accuracy: 0.900000
Step: 100, avg loss: 0.125301, loss: 0.009620, accuracy: 1.000000
Step: 110, avg loss: 0.118033, loss: 0.045351, accuracy: 1.000000
Step: 120, avg loss: 0.108377, loss: 0.002170, accuracy: 1.000000
Step: 130, avg loss: 0.100956, loss: 0.011894, accuracy: 1.000000
Step: 140, avg loss: 0.094750, loss: 0.014074, accuracy: 1.000000
Step: 150, avg loss: 0.090707, loss: 0.034111, accuracy: 1.000000
Step: 160, avg loss: 0.086952, loss: 0.030624, accuracy: 1.000000
Step: 170, avg loss: 0.081914, loss: 0.001298, accuracy: 1.000000
--------------------->Epoch: 50, batch: 176
batch_labels:  [[1]]
loss:  8.25875 8.25875 -0.0 [[ 1.  1.  1.  1.  1.]]
accuracy:  0.0
case_pred:  [[ 0.00025898]]
case_pred_each:  [[  5.17787084e-05   5.17787084e-05   5.17787084e-05   5.17787084e-05
    5.17787084e-05]]
miss mask:  [[ 1.  1.  1.  1.  1.]]
batch_isnode shape:  (1, 5)
batch_is_nod:  [[ 0.  0.  0.  0.  0.]]
batch_file_names:  263a1c3bfa43556623e75ed901e3fd8f
Step: 180, avg loss: 0.123296, loss: 0.826798, accuracy: 0.900000
Step: 190, avg loss: 0.119234, loss: 0.046110, accuracy: 1.000000
Step: 200, avg loss: 0.113849, loss: 0.011553, accuracy: 1.000000
Step: 210, avg loss: 0.108948, loss: 0.010917, accuracy: 1.000000
Step: 220, avg loss: 0.104947, loss: 0.020929, accuracy: 1.000000
Step: 230, avg loss: 0.100506, loss: 0.002813, accuracy: 1.000000
Step: 240, avg loss: 0.097210, loss: 0.021380, accuracy: 1.000000
Step: 250, avg loss: 0.094197, loss: 0.021900, accuracy: 1.000000
Step: 260, avg loss: 0.091342, loss: 0.019964, accuracy: 1.000000
Step: 270, avg loss: 0.089308, loss: 0.036433, accuracy: 1.000000
Step: 280, avg loss: 0.086166, loss: 0.001326, accuracy: 1.000000
Step: 290, avg loss: 0.084979, loss: 0.051741, accuracy: 1.000000
Step: 300, avg loss: 0.082865, loss: 0.021555, accuracy: 1.000000
Step: 310, avg loss: 0.081141, loss: 0.029431, accuracy: 1.000000
Step: 320, avg loss: 0.079294, loss: 0.022029, accuracy: 1.000000
Step: 330, avg loss: 0.078316, loss: 0.047024, accuracy: 1.000000
Step: 340, avg loss: 0.077440, loss: 0.048519, accuracy: 1.000000
Step: 350, avg loss: 0.076129, loss: 0.031582, accuracy: 1.000000
Step: 360, avg loss: 0.074896, loss: 0.031741, accuracy: 1.000000
Step: 370, avg loss: 0.074290, loss: 0.052470, accuracy: 1.000000
--------------------->Epoch: 50, batch: 372
batch_labels:  [[1]]
loss:  8.17174 8.17174 -0.0 [[ 1.  1.  1.  1.  1.]]
accuracy:  0.0
case_pred:  [[ 0.00028253]]
case_pred_each:  [[  5.64940528e-05   5.64940528e-05   5.64940528e-05   5.64940528e-05
    5.64940528e-05]]
miss mask:  [[ 1.  1.  1.  1.  1.]]
batch_isnode shape:  (1, 5)
batch_is_nod:  [[ 0.  0.  0.  0.  0.]]
batch_file_names:  4cc8af2efef2f41bf70684be25276ce5
Step: 380, avg loss: 0.094425, loss: 0.839408, accuracy: 0.900000
Step: 390, avg loss: 0.092738, loss: 0.028618, accuracy: 1.000000
Step: 400, avg loss: 0.091277, loss: 0.034317, accuracy: 1.000000
Step: 410, avg loss: 0.090608, loss: 0.063858, accuracy: 1.000000
Step: 420, avg loss: 0.088748, loss: 0.012477, accuracy: 1.000000
Step: 430, avg loss: 0.087482, loss: 0.034315, accuracy: 1.000000
Step: 440, avg loss: 0.086737, loss: 0.054671, accuracy: 1.000000
Step: 450, avg loss: 0.085424, loss: 0.027650, accuracy: 1.000000
Step: 460, avg loss: 0.084605, loss: 0.047763, accuracy: 1.000000
--------------------->Epoch: 50, batch: 463
batch_labels:  [[1]]
loss:  6.61386 6.61386 -0.0 [[ 1.  1.  1.  1.  1.]]
accuracy:  0.0
case_pred:  [[ 0.00134164]]
case_pred_each:  [[ 0.00026843  0.00026843  0.00026843  0.00026843  0.00026843]]
miss mask:  [[ 1.  1.  1.  1.  1.]]
batch_isnode shape:  (1, 5)
batch_is_nod:  [[ 0.  0.  0.  0.  0.]]
batch_file_names:  608202eb3c368512e55e9e339a203790
Step: 470, avg loss: 0.097169, loss: 0.675139, accuracy: 0.900000
--------------------->Epoch: 50, batch: 476
batch_labels:  [[1]]
loss:  5.07135 5.07135 -0.0 [[ 1.  1.  1.  1.  1.]]
accuracy:  0.0
case_pred:  [[ 0.00627393]]
case_pred_each:  [[ 0.00125797  0.00125797  0.00125797  0.00125797  0.00125797]]
miss mask:  [[ 1.  1.  1.  1.  1.]]
batch_isnode shape:  (1, 5)
batch_is_nod:  [[ 0.  0.  0.  0.  0.]]
batch_file_names:  63b5be42543c98ac5392f1bfbda085bf
Step: 480, avg loss: 0.106013, loss: 0.521678, accuracy: 0.900000
--------------------->Epoch: 50, batch: 481
batch_labels:  [[1]]
loss:  3.89561 3.89561 -0.0 [[ 1.  1.  1.  1.  1.]]
accuracy:  0.0
case_pred:  [[ 0.02033103]]
case_pred_each:  [[  3.24312668e-06   5.12117008e-03   5.12117008e-03   5.12117008e-03
    5.12117008e-03]]
miss mask:  [[ 1.  1.  1.  1.  1.]]
batch_isnode shape:  (1, 5)
batch_is_nod:  [[ 0.  0.  0.  0.  0.]]
batch_file_names:  64a5a866461a3b6006efb0075e04dffe
Step: 490, avg loss: 0.112998, loss: 0.448289, accuracy: 0.900000
Step: 500, avg loss: 0.112064, loss: 0.066267, accuracy: 1.000000
Step: 510, avg loss: 0.110226, loss: 0.018313, accuracy: 1.000000
Step: 520, avg loss: 0.109029, loss: 0.047981, accuracy: 1.000000
Step: 530, avg loss: 0.107729, loss: 0.040124, accuracy: 1.000000
Step: 540, avg loss: 0.106063, loss: 0.017809, accuracy: 1.000000
Step: 550, avg loss: 0.104380, loss: 0.013470, accuracy: 1.000000
Step: 560, avg loss: 0.102868, loss: 0.019718, accuracy: 1.000000
Step: 570, avg loss: 0.101530, loss: 0.026597, accuracy: 1.000000
Step: 580, avg loss: 0.100382, loss: 0.034925, accuracy: 1.000000
Step: 590, avg loss: 0.099454, loss: 0.045636, accuracy: 1.000000
Step: 600, avg loss: 0.098395, loss: 0.035952, accuracy: 1.000000
Step: 610, avg loss: 0.097150, loss: 0.022442, accuracy: 1.000000
Step: 620, avg loss: 0.095975, loss: 0.024275, accuracy: 1.000000
Step: 630, avg loss: 0.094647, loss: 0.012331, accuracy: 1.000000
Step: 640, avg loss: 0.093717, loss: 0.035149, accuracy: 1.000000
Step: 650, avg loss: 0.092439, loss: 0.010602, accuracy: 1.000000
Step: 660, avg loss: 0.091369, loss: 0.021824, accuracy: 1.000000
--------------------->Epoch: 50, batch: 665
batch_labels:  [[1]]
loss:  6.87892 6.87892 -0.0 [[ 1.  1.  1.  1.  1.]]
accuracy:  0.0
case_pred:  [[ 0.00102925]]
case_pred_each:  [[ 0.00020596  0.00020596  0.00020596  0.00020596  0.00020596]]
miss mask:  [[ 1.  1.  1.  1.  1.]]
batch_isnode shape:  (1, 5)
batch_is_nod:  [[ 0.  0.  0.  0.  0.]]
batch_file_names:  882107a204c302e27628f85522baea49
Step: 670, avg loss: 0.100375, loss: 0.694773, accuracy: 0.900000
Step: 680, avg loss: 0.099609, loss: 0.048330, accuracy: 1.000000
Step: 690, avg loss: 0.098516, loss: 0.024139, accuracy: 1.000000
Step: 700, avg loss: 0.097175, loss: 0.004690, accuracy: 1.000000
Step: 710, avg loss: 0.096020, loss: 0.015171, accuracy: 1.000000
Step: 720, avg loss: 0.094871, loss: 0.013277, accuracy: 1.000000
Step: 730, avg loss: 0.093768, loss: 0.014362, accuracy: 1.000000
Step: 740, avg loss: 0.093078, loss: 0.042720, accuracy: 1.000000
Step: 750, avg loss: 0.092015, loss: 0.013315, accuracy: 1.000000
Step: 760, avg loss: 0.091107, loss: 0.022984, accuracy: 1.000000
Step: 770, avg loss: 0.090083, loss: 0.012266, accuracy: 1.000000
Step: 780, avg loss: 0.089275, loss: 0.027098, accuracy: 1.000000
Step: 790, avg loss: 0.088303, loss: 0.012476, accuracy: 1.000000
Step: 800, avg loss: 0.087222, loss: 0.001814, accuracy: 1.000000
Step: 810, avg loss: 0.086421, loss: 0.022358, accuracy: 1.000000
Step: 820, avg loss: 0.085615, loss: 0.020289, accuracy: 1.000000
Step: 830, avg loss: 0.084957, loss: 0.030995, accuracy: 1.000000
Step: 840, avg loss: 0.084195, loss: 0.020954, accuracy: 1.000000
Step: 850, avg loss: 0.083212, loss: 0.000699, accuracy: 1.000000
Step: 860, avg loss: 0.082658, loss: 0.035534, accuracy: 1.000000
Step: 870, avg loss: 0.081814, loss: 0.009201, accuracy: 1.000000
Step: 880, avg loss: 0.081116, loss: 0.020419, accuracy: 1.000000
Step: 890, avg loss: 0.080221, loss: 0.001490, accuracy: 1.000000
Step: 900, avg loss: 0.079447, loss: 0.010496, accuracy: 1.000000
Step: 910, avg loss: 0.087903, loss: 0.849020, accuracy: 0.900000
--------------------->Epoch: 50, batch: 910
batch_labels:  [[1]]
loss:  8.43031 8.43031 -0.0 [[ 1.  1.  1.  1.  1.]]
accuracy:  0.0
case_pred:  [[ 0.00021815]]
case_pred_each:  [[  4.36027767e-05   4.36027767e-05   4.36027767e-05   4.36027767e-05
    4.36027767e-05]]
miss mask:  [[ 1.  1.  1.  1.  1.]]
batch_isnode shape:  (1, 5)
batch_is_nod:  [[ 0.  0.  0.  0.  0.]]
batch_file_names:  bb4b43d0dc4d9d2b61150df6556f6490
Step: 920, avg loss: 0.087233, loss: 0.026259, accuracy: 1.000000
Step: 930, avg loss: 0.086319, loss: 0.002201, accuracy: 1.000000
Step: 940, avg loss: 0.086099, loss: 0.065590, accuracy: 1.000000
Step: 950, avg loss: 0.085371, loss: 0.016962, accuracy: 1.000000
Step: 960, avg loss: 0.084703, loss: 0.021240, accuracy: 1.000000
Step: 970, avg loss: 0.084056, loss: 0.021998, accuracy: 1.000000
Step: 980, avg loss: 0.083442, loss: 0.023904, accuracy: 1.000000
Step: 990, avg loss: 0.082626, loss: 0.002608, accuracy: 1.000000
Step: 1000, avg loss: 0.081922, loss: 0.012194, accuracy: 1.000000
Step: 1010, avg loss: 0.081353, loss: 0.024447, accuracy: 1.000000
Step: 1020, avg loss: 0.081226, loss: 0.068489, accuracy: 1.000000
Step: 1030, avg loss: 0.080558, loss: 0.012373, accuracy: 1.000000
Step: 1040, avg loss: 0.079826, loss: 0.004472, accuracy: 1.000000
Step: 1050, avg loss: 0.079207, loss: 0.014754, accuracy: 1.000000
Step: 1060, avg loss: 0.078669, loss: 0.022203, accuracy: 1.000000
Step: 1070, avg loss: 0.078003, loss: 0.007457, accuracy: 1.000000
Step: 1080, avg loss: 0.077800, loss: 0.055994, accuracy: 1.000000
Step: 1090, avg loss: 0.077185, loss: 0.010793, accuracy: 1.000000
Step: 1100, avg loss: 0.076489, loss: 0.000619, accuracy: 1.000000
Step: 1110, avg loss: 0.075805, loss: 0.000631, accuracy: 1.000000
Step: 1120, avg loss: 0.075239, loss: 0.012355, accuracy: 1.000000
Step: 1130, avg loss: 0.074663, loss: 0.010136, accuracy: 1.000000
Step: 1140, avg loss: 0.074202, loss: 0.022090, accuracy: 1.000000
Step: 1150, avg loss: 0.073663, loss: 0.012313, accuracy: 1.000000
Step: 1160, avg loss: 0.073658, loss: 0.073079, accuracy: 1.000000
Step: 1170, avg loss: 0.073341, loss: 0.036501, accuracy: 1.000000
Step: 1180, avg loss: 0.072884, loss: 0.019497, accuracy: 1.000000
Step: 1190, avg loss: 0.072762, loss: 0.058330, accuracy: 1.000000
Step: 1200, avg loss: 0.072497, loss: 0.040921, accuracy: 1.000000
Step: 1210, avg loss: 0.072543, loss: 0.078140, accuracy: 1.000000
Step: 1220, avg loss: 0.072124, loss: 0.021353, accuracy: 1.000000
Step: 1230, avg loss: 0.071630, loss: 0.011346, accuracy: 1.000000
Step: 1240, avg loss: 0.071301, loss: 0.030843, accuracy: 1.000000
Step: 1250, avg loss: 0.070751, loss: 0.002543, accuracy: 1.000000
Step: 1260, avg loss: 0.070371, loss: 0.022840, accuracy: 1.000000
Epoch 50 finished in loss: 0.070261 and accuracy: 0.992868
--->Val epoch: 2, batch: 1
batch_labels:  [[1]]
loss:  3.30268 3.30268
accuracy:  0.0
batch_is_nod:  [[ 0.  0.  0.  0.  0.]]
batch_file_names:  f1a64fda219db48bcfb8ad3823ef9fc1
--->Val epoch: 2, batch: 2
batch_labels:  [[0]]
loss:  11.3991 11.3991
accuracy:  0.0
batch_is_nod:  [[ 0.  0.  0.  0.  0.]]
batch_file_names:  edbf53a8478049de1494b213fdf942e6
--->Val epoch: 2, batch: 4
batch_labels:  [[1]]
loss:  1.12791 1.12791
accuracy:  0.0
batch_is_nod:  [[ 1.  0.  0.  0.  0.]]
batch_file_names:  48e592418247393234dd658f9112c543
--->Val epoch: 2, batch: 6
batch_labels:  [[1]]
loss:  9.49667 9.49667
accuracy:  0.0
batch_is_nod:  [[ 0.  0.  0.  0.  0.]]
batch_file_names:  d032116d73789ff9c805f493357b4037
Val step: 10, avg loss: 2.558600, loss: 2.558600, accuracy: 0.600000
--->Val epoch: 2, batch: 11
batch_labels:  [[0]]
loss:  11.5116 11.5116
accuracy:  0.0
batch_is_nod:  [[ 0.  0.  0.  0.  0.]]
batch_file_names:  3dfe8e80106f4136d2933ff72a16035c
--->Val epoch: 2, batch: 12
batch_labels:  [[1]]
loss:  8.25444 8.08859
accuracy:  0.0
batch_is_nod:  [[ 1.  0.  0.  0.  0.]]
batch_file_names:  f5717f7cbc08d8bd942cd4c1128e3339
--->Val epoch: 2, batch: 13
batch_labels:  [[1]]
loss:  6.54631 6.54631
accuracy:  0.0
batch_is_nod:  [[ 0.  0.  0.  0.  0.]]
batch_file_names:  a2558184e0f4a68e9fb13579d20cb244
--->Val epoch: 2, batch: 17
batch_labels:  [[1]]
loss:  5.19231 5.08742
accuracy:  0.0
batch_is_nod:  [[ 1.  0.  0.  0.  0.]]
batch_file_names:  4d7df08f074b221eec6311c2617a5ba8
Val step: 20, avg loss: 2.862657, loss: 3.166714, accuracy: 0.600000
--->Val epoch: 2, batch: 21
batch_labels:  [[0]]
loss:  4.24018 4.24018
accuracy:  0.0
batch_is_nod:  [[ 1.  0.  0.  0.  0.]]
batch_file_names:  ef6a37afe024d33b4b1bb2fdee054a59
--->Val epoch: 2, batch: 24
batch_labels:  [[0]]
loss:  1.0002 1.0002
accuracy:  0.0
batch_is_nod:  [[ 0.  0.  0.  0.  0.]]
batch_file_names:  89f003dbfbdbd18a5cdeb9b128cb075b
--->Val epoch: 2, batch: 28
batch_labels:  [[0]]
loss:  11.5116 11.5116
accuracy:  0.0
batch_is_nod:  [[ 0.  0.  0.  0.  0.]]
batch_file_names:  f0f72264cd822301852578cc71288d3c
Val step: 30, avg loss: 2.467184, loss: 1.676239, accuracy: 0.700000
--->Val epoch: 2, batch: 36
batch_labels:  [[1]]
loss:  1.05522 0.920935
accuracy:  0.0
batch_is_nod:  [[ 1.  0.  0.  0.  0.]]
batch_file_names:  f725f46908f16062fd12c141eb47c6a7
Val step: 40, avg loss: 1.885192, loss: 0.139214, accuracy: 0.900000
Val step: 50, avg loss: 1.508191, loss: 0.000190, accuracy: 1.000000
--->Val epoch: 2, batch: 56
batch_labels:  [[0]]
loss:  11.5116 11.5116
accuracy:  0.0
batch_is_nod:  [[ 1.  0.  0.  0.  0.]]
batch_file_names:  2885e3af725bc58dc1522d4bfb24bb2b
--->Val epoch: 2, batch: 57
batch_labels:  [[0]]
loss:  11.5116 11.5116
accuracy:  0.0
batch_is_nod:  [[ 0.  0.  0.  0.  0.]]
batch_file_names:  49a29b3f5bee32b350bedc4cfbad8e9c
Val step: 60, avg loss: 1.645659, loss: 2.332994, accuracy: 0.800000
--->Val epoch: 2, batch: 61
batch_labels:  [[0]]
loss:  11.5116 11.5116
accuracy:  0.0
batch_is_nod:  [[ 0.  0.  0.  0.  0.]]
batch_file_names:  e42065c1145ccf734312cb9edbe5234b
--->Val epoch: 2, batch: 64
batch_labels:  [[1]]
loss:  4.34365 4.34365
accuracy:  0.0
batch_is_nod:  [[ 0.  0.  0.  0.  0.]]
batch_file_names:  c67de8fbbe1e58b464334f93a1dd0447
Val step: 70, avg loss: 1.639334, loss: 1.601387, accuracy: 0.800000
--->Val epoch: 2, batch: 71
batch_labels:  [[1]]
loss:  4.61301 4.52126
accuracy:  0.0
batch_is_nod:  [[ 1.  0.  0.  0.  0.]]
batch_file_names:  028996723faa7840bb57f57e28275e4c
--->Val epoch: 2, batch: 75
batch_labels:  [[0]]
loss:  5.30895 5.30895
accuracy:  0.0
batch_is_nod:  [[ 0.  0.  0.  0.  0.]]
batch_file_names:  6faabf4152bf0ebfd91f686bc37a1f16
--->Val epoch: 2, batch: 77
batch_labels:  [[0]]
loss:  11.5116 11.5116
accuracy:  0.0
batch_is_nod:  [[ 1.  1.  0.  0.  0.]]
batch_file_names:  f8ecf6be8ae631c6dd694c9638a02b45
--->Val epoch: 2, batch: 79
batch_labels:  [[1]]
loss:  4.93189 4.93189
accuracy:  0.0
batch_is_nod:  [[ 0.  0.  0.  0.  0.]]
batch_file_names:  817a99e1a60bcf4e37c904d73845ca50
Val step: 80, avg loss: 1.764690, loss: 2.642184, accuracy: 0.600000
--->Val epoch: 2, batch: 84
batch_labels:  [[1]]
loss:  4.78138 4.78138
accuracy:  0.0
batch_is_nod:  [[ 0.  0.  0.  0.  0.]]
batch_file_names:  9b7524785a9bf40f0651deeb3b05b75f
--->Val epoch: 2, batch: 88
batch_labels:  [[1]]
loss:  3.53048 3.53048
accuracy:  0.0
batch_is_nod:  [[ 0.  0.  0.  0.  0.]]
batch_file_names:  026470d51482c93efc18b9803159c960
--->Val epoch: 2, batch: 89
batch_labels:  [[1]]
loss:  5.51494 5.51494
accuracy:  0.0
batch_is_nod:  [[ 0.  0.  0.  0.  0.]]
batch_file_names:  6541df84fd779ba6513a530c128f4e9b
--->Val epoch: 2, batch: 90
batch_labels:  [[0]]
loss:  3.11953 2.86439
accuracy:  0.0
batch_is_nod:  [[ 1.  1.  1.  1.  0.]]
batch_file_names:  bcc701884a32d8883b73b5844241a354
Val step: 90, avg loss: 1.763054, loss: 1.749963, accuracy: 0.600000
--->Val epoch: 2, batch: 91
batch_labels:  [[0]]
loss:  11.5116 11.5116
accuracy:  0.0
batch_is_nod:  [[ 1.  0.  0.  0.  0.]]
batch_file_names:  483b89a4ffbbd85acc8b9af5a541dd4d
--->Val epoch: 2, batch: 99
batch_labels:  [[1]]
loss:  8.43319 8.2636
accuracy:  0.0
batch_is_nod:  [[ 1.  0.  0.  0.  0.]]
batch_file_names:  ebd601d40a18634b100c92e7db39f585
--->Val epoch: 2, batch: 100
batch_labels:  [[1]]
loss:  2.54601 2.54601
accuracy:  0.0
batch_is_nod:  [[ 1.  0.  0.  0.  0.]]
batch_file_names:  1f49f0c1d7feedcae9024d251797407c
Val step: 100, avg loss: 1.817357, loss: 2.306082, accuracy: 0.700000
Val step: 110, avg loss: 1.653770, loss: 0.017904, accuracy: 1.000000
--->Val epoch: 2, batch: 113
batch_labels:  [[1]]
loss:  8.70713 8.70713
accuracy:  0.0
batch_is_nod:  [[ 0.  0.  0.  0.  0.]]
batch_file_names:  ea01deecde93cd9503a049d71d46e6d5
--->Val epoch: 2, batch: 120
batch_labels:  [[1]]
loss:  4.08801 3.99869
accuracy:  0.0
batch_is_nod:  [[ 0.  1.  0.  0.  0.]]
batch_file_names:  93a6f37a72f60498986374f57bfc30c4
Val step: 120, avg loss: 1.622826, loss: 1.282445, accuracy: 0.800000
--->Val epoch: 2, batch: 126
batch_labels:  [[1]]
loss:  9.49667 9.49667
accuracy:  0.0
batch_is_nod:  [[ 0.  0.  0.  0.  0.]]
batch_file_names:  3252220375d82c3720d36d757bb17345
Val step: 130, avg loss: 1.573344, loss: 0.979561, accuracy: 0.900000
--->Val epoch: 2, batch: 138
batch_labels:  [[1]]
loss:  1.09376 1.09376
accuracy:  0.0
batch_is_nod:  [[ 0.  0.  0.  0.  0.]]
batch_file_names:  b82efe72526c59a96257208d95e54baf
Val step: 140, avg loss: 1.468890, loss: 0.110978, accuracy: 0.900000
--->Val epoch: 2, batch: 141
batch_labels:  [[0]]
loss:  11.5116 11.5116
accuracy:  0.0
batch_is_nod:  [[ 1.  0.  0.  0.  0.]]
batch_file_names:  0334c8242ce7ee1a6c1263096e4cc535
--->Val epoch: 2, batch: 149
batch_labels:  [[1]]
loss:  3.02168 2.96148
accuracy:  0.0
batch_is_nod:  [[ 1.  0.  0.  0.  0.]]
batch_file_names:  15aa585fb2d3018b295df8619f2d1cf7
Val step: 150, avg loss: 1.468838, loss: 1.468117, accuracy: 0.800000
--->Val epoch: 2, batch: 152
batch_labels:  [[0]]
loss:  6.48409 6.48409
accuracy:  0.0
batch_is_nod:  [[ 0.  0.  0.  0.  0.]]
batch_file_names:  fcfab3eddbdf0421c39f71d651cc5c56
--->Val epoch: 2, batch: 157
batch_labels:  [[1]]
loss:  4.65948 4.52641
accuracy:  0.0
batch_is_nod:  [[ 1.  0.  0.  0.  0.]]
batch_file_names:  e38789c5eabb3005bfb82a5298055ba0
Val step: 160, avg loss: 1.447410, loss: 1.125986, accuracy: 0.800000
--->Val epoch: 2, batch: 161
batch_labels:  [[0]]
loss:  11.5116 11.5116
accuracy:  0.0
batch_is_nod:  [[ 1.  1.  0.  0.  0.]]
batch_file_names:  5f383eb9c3d8ea72ddec7e2e874d577d
--->Val epoch: 2, batch: 162
batch_labels:  [[0]]
loss:  4.09909 3.98315
accuracy:  0.0
batch_is_nod:  [[ 1.  0.  0.  0.  0.]]
batch_file_names:  fac65dbf7b6972049cfd37b5b122ec0b
--->Val epoch: 2, batch: 164
batch_labels:  [[1]]
loss:  3.2165 3.2165
accuracy:  0.0
batch_is_nod:  [[ 0.  0.  0.  0.  0.]]
batch_file_names:  761aeadb65fb84c8d04978a75b2f684c
--->Val epoch: 2, batch: 165
batch_labels:  [[1]]
loss:  4.9336 4.83659
accuracy:  0.0
batch_is_nod:  [[ 0.  1.  0.  0.  0.]]
batch_file_names:  54056288ab97cebc4b0ea33c23f47ff6
--->Val epoch: 2, batch: 166
batch_labels:  [[1]]
loss:  2.7726 2.69924
accuracy:  0.0
batch_is_nod:  [[ 1.  0.  0.  0.  0.]]
batch_file_names:  80600d4a5fee7424d689ba7d0906d50f
--->Val epoch: 2, batch: 170
batch_labels:  [[0]]
loss:  2.89879 2.89879
accuracy:  0.0
batch_is_nod:  [[ 1.  0.  0.  0.  0.]]
batch_file_names:  4d86e1657d46b9ee44c2c434fad231ce
Val step: 170, avg loss: 1.535454, loss: 2.944162, accuracy: 0.400000
--->Val epoch: 2, batch: 171
batch_labels:  [[1]]
loss:  2.98276 2.98276
accuracy:  0.0
batch_is_nod:  [[ 0.  0.  0.  0.  0.]]
batch_file_names:  2a2300103f80aadbfac57516d9a95365
--->Val epoch: 2, batch: 172
batch_labels:  [[1]]
loss:  4.98993 4.89197
accuracy:  0.0
batch_is_nod:  [[ 1.  0.  0.  0.  0.]]
batch_file_names:  f2ca85bb9ae82a3d79b9f321f727ac19
Val step: 180, avg loss: 1.496758, loss: 0.838921, accuracy: 0.800000
--->Val epoch: 2, batch: 181
batch_labels:  [[0]]
loss:  9.4396 9.4396
accuracy:  0.0
batch_is_nod:  [[ 1.  0.  0.  0.  0.]]
batch_file_names:  933cc0dec1c737d9654820453ce64284
--->Val epoch: 2, batch: 184
batch_labels:  [[1]]
loss:  1.30327 1.23145
accuracy:  0.0
batch_is_nod:  [[ 0.  1.  1.  0.  0.]]
batch_file_names:  d09e4124b97b22ef45692b62b4ca7f03
--->Val epoch: 2, batch: 189
batch_labels:  [[1]]
loss:  4.39914 4.31281
accuracy:  0.0
batch_is_nod:  [[ 1.  0.  0.  0.  0.]]
batch_file_names:  85d59b470b927e825937ea3483571c6d
Val step: 190, avg loss: 1.498195, loss: 1.524054, accuracy: 0.700000
--->Val epoch: 2, batch: 197
batch_labels:  [[0]]
loss:  11.5116 11.5116
accuracy:  0.0
batch_is_nod:  [[ 0.  0.  0.  0.  0.]]
batch_file_names:  337e7a428e7342d1e7f53a04247f7ad8
--->Val epoch: 2, batch: 199
batch_labels:  [[0]]
loss:  6.4053 6.22423
accuracy:  0.0
batch_is_nod:  [[ 1.  0.  0.  0.  0.]]
batch_file_names:  c004a9415539a0bc98c42c1a444cedb8
--->Val epoch: 2, batch: 200
batch_labels:  [[0]]
loss:  11.5116 11.5116
accuracy:  0.0
batch_is_nod:  [[ 1.  0.  0.  0.  0.]]
batch_file_names:  8c5288b86ffcd597f10d639e9948411d
Val step: 200, avg loss: 1.571515, loss: 2.964596, accuracy: 0.700000
--->Val epoch: 2, batch: 202
batch_labels:  [[1]]
loss:  4.97126 4.97126
accuracy:  0.0
batch_is_nod:  [[ 0.  0.  0.  0.  0.]]
batch_file_names:  1fdbc07019192de4a114e090389c8330
--->Val epoch: 2, batch: 204
batch_labels:  [[0]]
loss:  4.91036 4.91036
accuracy:  0.0
batch_is_nod:  [[ 0.  0.  0.  0.  0.]]
batch_file_names:  1a41350d4bbd74b7e0e28239cefa84c2
--->Val epoch: 2, batch: 205
batch_labels:  [[1]]
loss:  4.58629 4.58629
accuracy:  0.0
batch_is_nod:  [[ 0.  0.  0.  0.  0.]]
batch_file_names:  4a782bbc2608288a3ed05e511af6f8bb
--->Val epoch: 2, batch: 206
batch_labels:  [[0]]
loss:  9.73783 9.73783
accuracy:  0.0
batch_is_nod:  [[ 0.  0.  0.  0.  0.]]
batch_file_names:  f7cdd95c94818875ece1175561025038
--->Val epoch: 2, batch: 209
batch_labels:  [[1]]
loss:  4.12762 4.12762
accuracy:  0.0
batch_is_nod:  [[ 0.  0.  0.  0.  0.]]
batch_file_names:  3f6431400c2a07a46386dba3929da45d
--->Val epoch: 2, batch: 210
batch_labels:  [[1]]
loss:  6.10614 5.98602
accuracy:  0.0
batch_is_nod:  [[ 1.  0.  0.  0.  0.]]
batch_file_names:  31136e50b7205e9184227f94cdea0090
Val step: 210, avg loss: 1.661182, loss: 3.454530, accuracy: 0.400000
--->Val epoch: 2, batch: 213
batch_labels:  [[1]]
loss:  9.71289 9.71289
accuracy:  0.0
batch_is_nod:  [[ 0.  0.  0.  0.  0.]]
batch_file_names:  f467795ce3b50a771085d79ae8d29ecc
--->Val epoch: 2, batch: 215
batch_labels:  [[1]]
loss:  6.04976 6.04976
accuracy:  0.0
batch_is_nod:  [[ 0.  0.  0.  0.  0.]]
batch_file_names:  2f77fd993fbd858dec3c085b9ff1a3a2
--->Val epoch: 2, batch: 216
batch_labels:  [[1]]
loss:  9.49667 9.49667
accuracy:  0.0
batch_is_nod:  [[ 0.  0.  0.  0.  0.]]
batch_file_names:  fe45462987bacc32dbc7126119999392
--->Val epoch: 2, batch: 217
batch_labels:  [[1]]
loss:  2.91781 2.91781
accuracy:  0.0
batch_is_nod:  [[ 0.  0.  0.  0.  0.]]
batch_file_names:  fb99a80cbb2f441bb90135bab5b029fe
Val step: 220, avg loss: 1.717079, loss: 2.890914, accuracy: 0.600000
--->Val epoch: 2, batch: 224
batch_labels:  [[1]]
loss:  2.06873 2.06873
accuracy:  0.0
batch_is_nod:  [[ 0.  1.  0.  0.  0.]]
batch_file_names:  90409f7fcfec3581033559f8340e48a9
--->Val epoch: 2, batch: 226
batch_labels:  [[1]]
loss:  4.88004 4.88004
accuracy:  0.0
batch_is_nod:  [[ 0.  0.  0.  0.  0.]]
batch_file_names:  b17c07114dcf49ce71c8da4b43cf1192
Val step: 230, avg loss: 1.673438, loss: 0.713339, accuracy: 0.800000
--->Val epoch: 2, batch: 233
batch_labels:  [[1]]
loss:  8.54513 8.54513
accuracy:  0.0
batch_is_nod:  [[ 0.  0.  0.  0.  0.]]
batch_file_names:  04a8c47583142181728056310759dea1
--->Val epoch: 2, batch: 236
batch_labels:  [[1]]
loss:  5.29075 5.29075
accuracy:  0.0
batch_is_nod:  [[ 0.  0.  0.  0.  0.]]
batch_file_names:  88acee40bb9d8cb06898d1c5de01d3c8
--->Val epoch: 2, batch: 240
batch_labels:  [[1]]
loss:  4.41235 4.32556
accuracy:  0.0
batch_is_nod:  [[ 1.  0.  0.  0.  0.]]
batch_file_names:  cd10ceca9862ba0cc2ffd0ed8c9b055c
Val step: 240, avg loss: 1.681867, loss: 1.875721, accuracy: 0.700000
--->Val epoch: 2, batch: 243
batch_labels:  [[0]]
loss:  10.7113 10.7113
accuracy:  0.0
batch_is_nod:  [[ 0.  0.  0.  0.  0.]]
batch_file_names:  a53a4a019a24541c277e0a84301d8ec5
--->Val epoch: 2, batch: 245
batch_labels:  [[0]]
loss:  11.5116 11.5116
accuracy:  0.0
batch_is_nod:  [[ 1.  0.  0.  0.  0.]]
batch_file_names:  dcde02d4757bb845376fa6dbb0351df6
--->Val epoch: 2, batch: 248
batch_labels:  [[0]]
loss:  10.2899 10.2899
accuracy:  0.0
batch_is_nod:  [[ 0.  0.  0.  0.  0.]]
batch_file_names:  f73624b8b22774acf9a3e2c748131eac
Val step: 250, avg loss: 1.745115, loss: 3.263080, accuracy: 0.700000
--->Val epoch: 2, batch: 255
batch_labels:  [[1]]
loss:  4.70684 4.61445
accuracy:  0.0
batch_is_nod:  [[ 1.  0.  0.  0.  0.]]
batch_file_names:  a162d204827e4e89a2e5ba81cc53247a
--->Val epoch: 2, batch: 257
batch_labels:  [[0]]
loss:  3.97776 3.97776
accuracy:  0.0
batch_is_nod:  [[ 0.  0.  0.  0.  0.]]
batch_file_names:  46199ffd681fd429aca3823c76f1034d
Val step: 260, avg loss: 1.715778, loss: 0.982363, accuracy: 0.800000
Val step: 270, avg loss: 1.654262, loss: 0.054840, accuracy: 1.000000
--->Val epoch: 2, batch: 277
batch_labels:  [[1]]
loss:  4.03385 3.83446
accuracy:  0.0
batch_is_nod:  [[ 1.  1.  0.  0.  0.]]
batch_file_names:  0acbebb8d463b4b9ca88cf38431aac69
--->Val epoch: 2, batch: 278
batch_labels:  [[0]]
loss:  1.90041 1.90041
accuracy:  0.0
batch_is_nod:  [[ 1.  0.  0.  0.  0.]]
batch_file_names:  aadd54d387e9be8fab53507c4cedf338
Val step: 280, avg loss: 1.616380, loss: 0.593548, accuracy: 0.800000
--->Val epoch: 2, batch: 281
batch_labels:  [[1]]
loss:  1.22334 0.925512
accuracy:  0.0
batch_is_nod:  [[ 1.  0.  1.  0.  0.]]
batch_file_names:  ea7373271a2441b5864df2053c0f5c3e
--->Val epoch: 2, batch: 284
batch_labels:  [[1]]
loss:  9.39059 9.39059
accuracy:  0.0
batch_is_nod:  [[ 0.  0.  0.  0.  0.]]
batch_file_names:  6171d57221e26d1f15d3c71fe966ab18
--->Val epoch: 2, batch: 285
batch_labels:  [[1]]
loss:  2.4612 2.4612
accuracy:  0.0
batch_is_nod:  [[ 1.  0.  0.  0.  0.]]
batch_file_names:  77033e4c1591403d1b1255607a20a983
--->Val epoch: 2, batch: 290
batch_labels:  [[1]]
loss:  3.21133 3.14834
accuracy:  0.0
batch_is_nod:  [[ 1.  0.  0.  0.  0.]]
batch_file_names:  9e98136d07b953c3362e0a132c8810b6
Val step: 290, avg loss: 1.617658, loss: 1.653450, accuracy: 0.600000
--->Val epoch: 2, batch: 296
batch_labels:  [[0]]
loss:  4.20926 4.20926
accuracy:  0.0
batch_is_nod:  [[ 0.  0.  0.  0.  0.]]
batch_file_names:  88be713eb83cec7d31c4553ca05b2019
Val step: 300, avg loss: 1.578536, loss: 0.444004, accuracy: 0.900000
Val step: 310, avg loss: 1.529639, loss: 0.062733, accuracy: 1.000000
--->Val epoch: 2, batch: 315
batch_labels:  [[1]]
loss:  2.73876 2.73876
accuracy:  0.0
batch_is_nod:  [[ 0.  0.  0.  0.  0.]]
batch_file_names:  a2a4bc7708f6831470d757cd6f32bffe
--->Val epoch: 2, batch: 316
batch_labels:  [[0]]
loss:  4.79007 4.79007
accuracy:  0.0
batch_is_nod:  [[ 1.  0.  0.  0.  0.]]
batch_file_names:  fd7c0fb3c0e764357aa58e5f047be614
Validation epoch 2 finished in loss: 1.510733, loss2: 1.491396 and accuracy: 0.755486
Validation stat, total: 319, low accuracy: 78, 0.8 above: 241, 0.9 above: 241, 0.95 above: 241
Step: 10, avg loss: 0.043351, loss: 0.043351, accuracy: 1.000000
Step: 20, avg loss: 0.039790, loss: 0.036229, accuracy: 1.000000
Step: 30, avg loss: 0.034960, loss: 0.025299, accuracy: 1.000000
Step: 40, avg loss: 0.029015, loss: 0.011181, accuracy: 1.000000
Step: 50, avg loss: 0.025472, loss: 0.011298, accuracy: 1.000000
Step: 60, avg loss: 0.024928, loss: 0.022208, accuracy: 1.000000
Step: 70, avg loss: 0.021460, loss: 0.000655, accuracy: 1.000000
Step: 80, avg loss: 0.021000, loss: 0.017780, accuracy: 1.000000
Step: 90, avg loss: 0.147649, loss: 1.160841, accuracy: 0.900000
Step: 100, avg loss: 0.133980, loss: 0.010962, accuracy: 1.000000
Step: 110, avg loss: 0.125603, loss: 0.041824, accuracy: 1.000000
Step: 120, avg loss: 0.115268, loss: 0.001589, accuracy: 1.000000
Step: 130, avg loss: 0.107414, loss: 0.013168, accuracy: 1.000000
Step: 140, avg loss: 0.100568, loss: 0.011562, accuracy: 1.000000
Step: 150, avg loss: 0.096386, loss: 0.037840, accuracy: 1.000000
Step: 160, avg loss: 0.092285, loss: 0.030779, accuracy: 1.000000
Step: 170, avg loss: 0.086878, loss: 0.000365, accuracy: 1.000000
Step: 180, avg loss: 0.131079, loss: 0.882487, accuracy: 0.900000
Step: 190, avg loss: 0.126461, loss: 0.043346, accuracy: 1.000000
Step: 200, avg loss: 0.120997, loss: 0.017182, accuracy: 1.000000
Step: 210, avg loss: 0.115737, loss: 0.010529, accuracy: 1.000000
Step: 220, avg loss: 0.111422, loss: 0.020802, accuracy: 1.000000
Step: 230, avg loss: 0.106660, loss: 0.001901, accuracy: 1.000000
Step: 240, avg loss: 0.102927, loss: 0.017066, accuracy: 1.000000
Step: 250, avg loss: 0.099654, loss: 0.021095, accuracy: 1.000000
Step: 260, avg loss: 0.096521, loss: 0.018218, accuracy: 1.000000
Step: 270, avg loss: 0.094369, loss: 0.038406, accuracy: 1.000000
Step: 280, avg loss: 0.091065, loss: 0.001847, accuracy: 1.000000
Step: 290, avg loss: 0.089690, loss: 0.051208, accuracy: 1.000000
Step: 300, avg loss: 0.087392, loss: 0.020730, accuracy: 1.000000
Step: 310, avg loss: 0.085770, loss: 0.037132, accuracy: 1.000000
Step: 320, avg loss: 0.083775, loss: 0.021931, accuracy: 1.000000
Step: 330, avg loss: 0.082846, loss: 0.053091, accuracy: 1.000000
Step: 340, avg loss: 0.081621, loss: 0.041227, accuracy: 1.000000
Step: 350, avg loss: 0.080226, loss: 0.032793, accuracy: 1.000000
Step: 360, avg loss: 0.078885, loss: 0.031933, accuracy: 1.000000
Step: 370, avg loss: 0.078231, loss: 0.054678, accuracy: 1.000000
Step: 380, avg loss: 0.098492, loss: 0.848165, accuracy: 0.900000
Step: 390, avg loss: 0.096727, loss: 0.029640, accuracy: 1.000000
Step: 400, avg loss: 0.095138, loss: 0.033177, accuracy: 1.000000
Step: 410, avg loss: 0.094420, loss: 0.065705, accuracy: 1.000000
Step: 420, avg loss: 0.092446, loss: 0.011528, accuracy: 1.000000
Step: 430, avg loss: 0.091137, loss: 0.036130, accuracy: 1.000000
Step: 440, avg loss: 0.090285, loss: 0.053680, accuracy: 1.000000
Step: 450, avg loss: 0.088802, loss: 0.023553, accuracy: 1.000000
Step: 460, avg loss: 0.088035, loss: 0.053486, accuracy: 1.000000
Step: 470, avg loss: 0.100505, loss: 0.674130, accuracy: 0.900000
Step: 480, avg loss: 0.108809, loss: 0.499086, accuracy: 0.900000
Step: 490, avg loss: 0.115477, loss: 0.435546, accuracy: 0.900000
Step: 500, avg loss: 0.114582, loss: 0.070722, accuracy: 1.000000
Step: 510, avg loss: 0.112731, loss: 0.020214, accuracy: 1.000000
Step: 520, avg loss: 0.111535, loss: 0.050541, accuracy: 1.000000
Step: 530, avg loss: 0.110369, loss: 0.049737, accuracy: 1.000000
Step: 540, avg loss: 0.108653, loss: 0.017717, accuracy: 1.000000
Step: 550, avg loss: 0.106906, loss: 0.012549, accuracy: 1.000000
Step: 560, avg loss: 0.105291, loss: 0.016466, accuracy: 1.000000
Step: 570, avg loss: 0.103902, loss: 0.026103, accuracy: 1.000000
Step: 580, avg loss: 0.102711, loss: 0.034833, accuracy: 1.000000
Step: 590, avg loss: 0.101695, loss: 0.042740, accuracy: 1.000000
Step: 600, avg loss: 0.100617, loss: 0.037020, accuracy: 1.000000
Step: 610, avg loss: 0.099339, loss: 0.022675, accuracy: 1.000000
Step: 620, avg loss: 0.098104, loss: 0.022754, accuracy: 1.000000
Step: 630, avg loss: 0.096743, loss: 0.012358, accuracy: 1.000000
Step: 640, avg loss: 0.095726, loss: 0.031653, accuracy: 1.000000
Step: 650, avg loss: 0.094418, loss: 0.010737, accuracy: 1.000000
Step: 660, avg loss: 0.093329, loss: 0.022513, accuracy: 1.000000
Step: 670, avg loss: 0.102758, loss: 0.725086, accuracy: 0.900000
Step: 680, avg loss: 0.101964, loss: 0.048798, accuracy: 1.000000
Step: 690, avg loss: 0.100819, loss: 0.022942, accuracy: 1.000000
Step: 700, avg loss: 0.099421, loss: 0.002983, accuracy: 1.000000
Step: 710, avg loss: 0.098128, loss: 0.007564, accuracy: 1.000000
Step: 720, avg loss: 0.096895, loss: 0.009399, accuracy: 1.000000
Step: 730, avg loss: 0.095775, loss: 0.015123, accuracy: 1.000000
Step: 740, avg loss: 0.095084, loss: 0.044668, accuracy: 1.000000
Step: 750, avg loss: 0.093980, loss: 0.012242, accuracy: 1.000000
Step: 760, avg loss: 0.092908, loss: 0.012476, accuracy: 1.000000
Step: 770, avg loss: 0.091884, loss: 0.014134, accuracy: 1.000000
Step: 780, avg loss: 0.091139, loss: 0.033750, accuracy: 1.000000
Step: 790, avg loss: 0.090158, loss: 0.013609, accuracy: 1.000000
Step: 800, avg loss: 0.089045, loss: 0.001142, accuracy: 1.000000
Step: 810, avg loss: 0.088218, loss: 0.022032, accuracy: 1.000000
Step: 820, avg loss: 0.087410, loss: 0.021968, accuracy: 1.000000
Step: 830, avg loss: 0.086747, loss: 0.032399, accuracy: 1.000000
Step: 840, avg loss: 0.085974, loss: 0.021837, accuracy: 1.000000
Step: 850, avg loss: 0.084967, loss: 0.000377, accuracy: 1.000000
Step: 860, avg loss: 0.084353, loss: 0.032145, accuracy: 1.000000
Step: 870, avg loss: 0.083567, loss: 0.015988, accuracy: 1.000000
Step: 880, avg loss: 0.082853, loss: 0.020754, accuracy: 1.000000
Step: 890, avg loss: 0.081946, loss: 0.002128, accuracy: 1.000000
Step: 900, avg loss: 0.081146, loss: 0.009926, accuracy: 1.000000
Step: 910, avg loss: 0.089227, loss: 0.816505, accuracy: 0.900000
Step: 920, avg loss: 0.088529, loss: 0.025006, accuracy: 1.000000
Step: 930, avg loss: 0.087603, loss: 0.002390, accuracy: 1.000000
Step: 940, avg loss: 0.087332, loss: 0.062140, accuracy: 1.000000
Step: 950, avg loss: 0.086579, loss: 0.015851, accuracy: 1.000000
Step: 960, avg loss: 0.085941, loss: 0.025271, accuracy: 1.000000
Step: 970, avg loss: 0.085283, loss: 0.022086, accuracy: 1.000000
Step: 980, avg loss: 0.084655, loss: 0.023791, accuracy: 1.000000
Step: 990, avg loss: 0.083823, loss: 0.002319, accuracy: 1.000000
Step: 1000, avg loss: 0.083105, loss: 0.011990, accuracy: 1.000000
Step: 1010, avg loss: 0.082505, loss: 0.022466, accuracy: 1.000000
Step: 1020, avg loss: 0.081713, loss: 0.001754, accuracy: 1.000000
Step: 1030, avg loss: 0.081124, loss: 0.021077, accuracy: 1.000000
Step: 1040, avg loss: 0.080375, loss: 0.003217, accuracy: 1.000000
Step: 1050, avg loss: 0.079734, loss: 0.013093, accuracy: 1.000000
Step: 1060, avg loss: 0.079195, loss: 0.022566, accuracy: 1.000000
Step: 1070, avg loss: 0.078557, loss: 0.010911, accuracy: 1.000000
Step: 1080, avg loss: 0.078372, loss: 0.058626, accuracy: 1.000000
Step: 1090, avg loss: 0.077756, loss: 0.011205, accuracy: 1.000000
Step: 1100, avg loss: 0.077065, loss: 0.001775, accuracy: 1.000000
Step: 1110, avg loss: 0.076376, loss: 0.000520, accuracy: 1.000000
Step: 1120, avg loss: 0.075809, loss: 0.012857, accuracy: 1.000000
Step: 1130, avg loss: 0.075233, loss: 0.010745, accuracy: 1.000000
Step: 1140, avg loss: 0.074872, loss: 0.034078, accuracy: 1.000000
Step: 1150, avg loss: 0.074329, loss: 0.012448, accuracy: 1.000000
Step: 1160, avg loss: 0.074333, loss: 0.074751, accuracy: 1.000000
Step: 1170, avg loss: 0.074026, loss: 0.038431, accuracy: 1.000000
Step: 1180, avg loss: 0.073600, loss: 0.023825, accuracy: 1.000000
Step: 1190, avg loss: 0.073459, loss: 0.056752, accuracy: 1.000000
Step: 1200, avg loss: 0.073186, loss: 0.040679, accuracy: 1.000000
Step: 1210, avg loss: 0.073239, loss: 0.079672, accuracy: 1.000000
Step: 1220, avg loss: 0.072809, loss: 0.020719, accuracy: 1.000000
Step: 1230, avg loss: 0.072306, loss: 0.011020, accuracy: 1.000000
Step: 1240, avg loss: 0.071967, loss: 0.030183, accuracy: 1.000000
Step: 1250, avg loss: 0.071406, loss: 0.001856, accuracy: 1.000000
Step: 1260, avg loss: 0.071023, loss: 0.023205, accuracy: 1.000000
Epoch 51 finished in loss: 0.070912 and accuracy: 0.993661
Step: 10, avg loss: 0.043776, loss: 0.043776, accuracy: 1.000000
Step: 20, avg loss: 0.032217, loss: 0.020658, accuracy: 1.000000
Step: 30, avg loss: 0.029649, loss: 0.024513, accuracy: 1.000000
Step: 40, avg loss: 0.024909, loss: 0.010690, accuracy: 1.000000
Step: 50, avg loss: 0.023812, loss: 0.019426, accuracy: 1.000000
Step: 60, avg loss: 0.023686, loss: 0.023053, accuracy: 1.000000
Step: 70, avg loss: 0.020624, loss: 0.002250, accuracy: 1.000000
Step: 80, avg loss: 0.019366, loss: 0.010565, accuracy: 1.000000
Step: 90, avg loss: 0.138789, loss: 1.094173, accuracy: 0.900000
Step: 100, avg loss: 0.125923, loss: 0.010123, accuracy: 1.000000
Step: 110, avg loss: 0.118116, loss: 0.040045, accuracy: 1.000000
Step: 120, avg loss: 0.108462, loss: 0.002269, accuracy: 1.000000
Step: 130, avg loss: 0.101037, loss: 0.011936, accuracy: 1.000000
Step: 140, avg loss: 0.094513, loss: 0.009702, accuracy: 1.000000
Step: 150, avg loss: 0.090245, loss: 0.030501, accuracy: 1.000000
Step: 160, avg loss: 0.086486, loss: 0.030090, accuracy: 1.000000
Step: 170, avg loss: 0.081496, loss: 0.001659, accuracy: 1.000000
Step: 180, avg loss: 0.125464, loss: 0.872928, accuracy: 0.900000
Step: 190, avg loss: 0.121123, loss: 0.042972, accuracy: 1.000000
Step: 200, avg loss: 0.115598, loss: 0.010628, accuracy: 1.000000
Step: 210, avg loss: 0.110616, loss: 0.010973, accuracy: 1.000000
Step: 220, avg loss: 0.106516, loss: 0.020426, accuracy: 1.000000
Step: 230, avg loss: 0.101944, loss: 0.001366, accuracy: 1.000000
Step: 240, avg loss: 0.098432, loss: 0.017651, accuracy: 1.000000
Step: 250, avg loss: 0.095337, loss: 0.021041, accuracy: 1.000000
Step: 260, avg loss: 0.092172, loss: 0.013054, accuracy: 1.000000
Step: 270, avg loss: 0.090224, loss: 0.039582, accuracy: 1.000000
Step: 280, avg loss: 0.087101, loss: 0.002790, accuracy: 1.000000
Step: 290, avg loss: 0.085884, loss: 0.051787, accuracy: 1.000000
Step: 300, avg loss: 0.083790, loss: 0.023069, accuracy: 1.000000
Step: 310, avg loss: 0.082161, loss: 0.033307, accuracy: 1.000000
Step: 320, avg loss: 0.080266, loss: 0.021502, accuracy: 1.000000
Step: 330, avg loss: 0.079370, loss: 0.050696, accuracy: 1.000000
Step: 340, avg loss: 0.078167, loss: 0.038492, accuracy: 1.000000
Step: 350, avg loss: 0.076766, loss: 0.029111, accuracy: 1.000000
Step: 360, avg loss: 0.075504, loss: 0.031353, accuracy: 1.000000
Step: 370, avg loss: 0.075015, loss: 0.057392, accuracy: 1.000000
Step: 380, avg loss: 0.095506, loss: 0.853676, accuracy: 0.900000
Step: 390, avg loss: 0.093829, loss: 0.030089, accuracy: 1.000000
Step: 400, avg loss: 0.092316, loss: 0.033338, accuracy: 1.000000
Step: 410, avg loss: 0.091573, loss: 0.061833, accuracy: 1.000000
Step: 420, avg loss: 0.089689, loss: 0.012435, accuracy: 1.000000
Step: 430, avg loss: 0.088381, loss: 0.033449, accuracy: 1.000000
Step: 440, avg loss: 0.087571, loss: 0.052767, accuracy: 1.000000
Step: 450, avg loss: 0.086266, loss: 0.028828, accuracy: 1.000000
Step: 460, avg loss: 0.085514, loss: 0.051700, accuracy: 1.000000
Step: 470, avg loss: 0.098769, loss: 0.708483, accuracy: 0.900000
Step: 480, avg loss: 0.108225, loss: 0.552661, accuracy: 0.900000
Step: 490, avg loss: 0.115540, loss: 0.466634, accuracy: 0.900000
Step: 500, avg loss: 0.114317, loss: 0.054407, accuracy: 1.000000
Step: 510, avg loss: 0.112402, loss: 0.016675, accuracy: 1.000000
Step: 520, avg loss: 0.111146, loss: 0.047045, accuracy: 1.000000
Step: 530, avg loss: 0.116331, loss: 0.385973, accuracy: 0.900000
Step: 540, avg loss: 0.114518, loss: 0.018442, accuracy: 1.000000
Step: 550, avg loss: 0.112688, loss: 0.013844, accuracy: 1.000000
Step: 560, avg loss: 0.110956, loss: 0.015689, accuracy: 1.000000
Step: 570, avg loss: 0.109465, loss: 0.025999, accuracy: 1.000000
Step: 580, avg loss: 0.108169, loss: 0.034268, accuracy: 1.000000
Step: 590, avg loss: 0.107077, loss: 0.043748, accuracy: 1.000000
Step: 600, avg loss: 0.105938, loss: 0.038773, accuracy: 1.000000
Step: 610, avg loss: 0.104595, loss: 0.023966, accuracy: 1.000000
Step: 620, avg loss: 0.103283, loss: 0.023280, accuracy: 1.000000
Step: 630, avg loss: 0.101835, loss: 0.012070, accuracy: 1.000000
Step: 640, avg loss: 0.100783, loss: 0.034509, accuracy: 1.000000
Step: 650, avg loss: 0.099501, loss: 0.017459, accuracy: 1.000000
Step: 660, avg loss: 0.098332, loss: 0.022321, accuracy: 1.000000
Step: 670, avg loss: 0.106807, loss: 0.666188, accuracy: 0.900000
Step: 680, avg loss: 0.105911, loss: 0.045873, accuracy: 1.000000
Step: 690, avg loss: 0.104723, loss: 0.023936, accuracy: 1.000000
Step: 700, avg loss: 0.103299, loss: 0.005046, accuracy: 1.000000
Step: 710, avg loss: 0.102025, loss: 0.012817, accuracy: 1.000000
Step: 720, avg loss: 0.100742, loss: 0.009638, accuracy: 1.000000
Step: 730, avg loss: 0.099564, loss: 0.014786, accuracy: 1.000000
Step: 740, avg loss: 0.098800, loss: 0.043032, accuracy: 1.000000
Step: 750, avg loss: 0.097653, loss: 0.012759, accuracy: 1.000000
Step: 760, avg loss: 0.096545, loss: 0.013443, accuracy: 1.000000
Step: 770, avg loss: 0.095453, loss: 0.012472, accuracy: 1.000000
Step: 780, avg loss: 0.094662, loss: 0.033731, accuracy: 1.000000
Step: 790, avg loss: 0.093623, loss: 0.012557, accuracy: 1.000000
Step: 800, avg loss: 0.092471, loss: 0.001462, accuracy: 1.000000
Step: 810, avg loss: 0.091604, loss: 0.022241, accuracy: 1.000000
Step: 820, avg loss: 0.090736, loss: 0.020495, accuracy: 1.000000
Step: 830, avg loss: 0.090039, loss: 0.032881, accuracy: 1.000000
Step: 840, avg loss: 0.089226, loss: 0.021703, accuracy: 1.000000
Step: 850, avg loss: 0.088185, loss: 0.000750, accuracy: 1.000000
Step: 860, avg loss: 0.087512, loss: 0.030302, accuracy: 1.000000
Step: 870, avg loss: 0.086513, loss: 0.000638, accuracy: 1.000000
Step: 880, avg loss: 0.085764, loss: 0.020568, accuracy: 1.000000
Step: 890, avg loss: 0.084815, loss: 0.001282, accuracy: 1.000000
Step: 900, avg loss: 0.084002, loss: 0.011662, accuracy: 1.000000
Step: 910, avg loss: 0.092795, loss: 0.884213, accuracy: 0.900000
Step: 920, avg loss: 0.092062, loss: 0.025316, accuracy: 1.000000
Step: 930, avg loss: 0.091102, loss: 0.002775, accuracy: 1.000000
Step: 940, avg loss: 0.090808, loss: 0.063511, accuracy: 1.000000
Step: 950, avg loss: 0.090095, loss: 0.023065, accuracy: 1.000000
Step: 960, avg loss: 0.089363, loss: 0.019824, accuracy: 1.000000
Step: 970, avg loss: 0.088671, loss: 0.022180, accuracy: 1.000000
Step: 980, avg loss: 0.088011, loss: 0.024038, accuracy: 1.000000
Step: 990, avg loss: 0.087134, loss: 0.001120, accuracy: 1.000000
Step: 1000, avg loss: 0.086382, loss: 0.011940, accuracy: 1.000000
Step: 1010, avg loss: 0.085731, loss: 0.020721, accuracy: 1.000000
Step: 1020, avg loss: 0.084903, loss: 0.001257, accuracy: 1.000000
Step: 1030, avg loss: 0.084194, loss: 0.011827, accuracy: 1.000000
Step: 1040, avg loss: 0.083404, loss: 0.002051, accuracy: 1.000000
Step: 1050, avg loss: 0.082739, loss: 0.013620, accuracy: 1.000000
Step: 1060, avg loss: 0.082154, loss: 0.020732, accuracy: 1.000000
Step: 1070, avg loss: 0.081482, loss: 0.010226, accuracy: 1.000000
Step: 1080, avg loss: 0.081199, loss: 0.050875, accuracy: 1.000000
Step: 1090, avg loss: 0.080689, loss: 0.025624, accuracy: 1.000000
Step: 1100, avg loss: 0.079961, loss: 0.000630, accuracy: 1.000000
Step: 1110, avg loss: 0.079246, loss: 0.000617, accuracy: 1.000000
Step: 1120, avg loss: 0.078658, loss: 0.013351, accuracy: 1.000000
Step: 1130, avg loss: 0.078052, loss: 0.010131, accuracy: 1.000000
Step: 1140, avg loss: 0.077515, loss: 0.016943, accuracy: 1.000000
Step: 1150, avg loss: 0.077065, loss: 0.025658, accuracy: 1.000000
Step: 1160, avg loss: 0.080718, loss: 0.500895, accuracy: 0.900000
Step: 1170, avg loss: 0.080403, loss: 0.043886, accuracy: 1.000000
Step: 1180, avg loss: 0.080026, loss: 0.035810, accuracy: 1.000000
Step: 1190, avg loss: 0.079884, loss: 0.063135, accuracy: 1.000000
Step: 1200, avg loss: 0.079620, loss: 0.048278, accuracy: 1.000000
Step: 1210, avg loss: 0.079793, loss: 0.100508, accuracy: 1.000000
Step: 1220, avg loss: 0.079374, loss: 0.028686, accuracy: 1.000000
Step: 1230, avg loss: 0.078816, loss: 0.010754, accuracy: 1.000000
Step: 1240, avg loss: 0.078459, loss: 0.034490, accuracy: 1.000000
Step: 1250, avg loss: 0.077837, loss: 0.000706, accuracy: 1.000000
Step: 1260, avg loss: 0.077410, loss: 0.024039, accuracy: 1.000000
Epoch 52 finished in loss: 0.077288 and accuracy: 0.992076
Step: 10, avg loss: 0.043906, loss: 0.043906, accuracy: 1.000000
Step: 20, avg loss: 0.031947, loss: 0.019987, accuracy: 1.000000
Step: 30, avg loss: 0.029748, loss: 0.025352, accuracy: 1.000000
Step: 40, avg loss: 0.025053, loss: 0.010966, accuracy: 1.000000
Step: 50, avg loss: 0.023927, loss: 0.019426, accuracy: 1.000000
Step: 60, avg loss: 0.023715, loss: 0.022655, accuracy: 1.000000
Step: 70, avg loss: 0.020566, loss: 0.001674, accuracy: 1.000000
Step: 80, avg loss: 0.020177, loss: 0.017450, accuracy: 1.000000
Step: 90, avg loss: 0.117958, loss: 0.900204, accuracy: 0.900000
Step: 100, avg loss: 0.107102, loss: 0.009399, accuracy: 1.000000
Step: 110, avg loss: 0.101497, loss: 0.045445, accuracy: 1.000000
Step: 120, avg loss: 0.093304, loss: 0.003184, accuracy: 1.000000
Step: 130, avg loss: 0.086988, loss: 0.011196, accuracy: 1.000000
Step: 140, avg loss: 0.081528, loss: 0.010546, accuracy: 1.000000
Step: 150, avg loss: 0.078238, loss: 0.032177, accuracy: 1.000000
Step: 160, avg loss: 0.075276, loss: 0.030844, accuracy: 1.000000
Step: 170, avg loss: 0.070893, loss: 0.000771, accuracy: 1.000000
Step: 180, avg loss: 0.107877, loss: 0.736597, accuracy: 0.900000
Step: 190, avg loss: 0.104647, loss: 0.046518, accuracy: 1.000000
Step: 200, avg loss: 0.100309, loss: 0.017884, accuracy: 1.000000
Step: 210, avg loss: 0.096082, loss: 0.011544, accuracy: 1.000000
Step: 220, avg loss: 0.092713, loss: 0.021955, accuracy: 1.000000
Step: 230, avg loss: 0.088778, loss: 0.002206, accuracy: 1.000000
Step: 240, avg loss: 0.085965, loss: 0.021268, accuracy: 1.000000
Step: 250, avg loss: 0.083406, loss: 0.021998, accuracy: 1.000000
Step: 260, avg loss: 0.080722, loss: 0.013623, accuracy: 1.000000
Step: 270, avg loss: 0.078995, loss: 0.034097, accuracy: 1.000000
Step: 280, avg loss: 0.076223, loss: 0.001375, accuracy: 1.000000
Step: 290, avg loss: 0.075416, loss: 0.052813, accuracy: 1.000000
Step: 300, avg loss: 0.073654, loss: 0.022552, accuracy: 1.000000
Step: 310, avg loss: 0.072336, loss: 0.032796, accuracy: 1.000000
Step: 320, avg loss: 0.070766, loss: 0.022100, accuracy: 1.000000
Step: 330, avg loss: 0.070276, loss: 0.054600, accuracy: 1.000000
Step: 340, avg loss: 0.069626, loss: 0.048194, accuracy: 1.000000
Step: 350, avg loss: 0.068927, loss: 0.045155, accuracy: 1.000000
Step: 360, avg loss: 0.067896, loss: 0.031813, accuracy: 1.000000
Step: 370, avg loss: 0.068439, loss: 0.087969, accuracy: 1.000000
Step: 380, avg loss: 0.089278, loss: 0.860309, accuracy: 0.900000
Step: 390, avg loss: 0.087728, loss: 0.028858, accuracy: 1.000000
Step: 400, avg loss: 0.086348, loss: 0.032523, accuracy: 1.000000
Step: 410, avg loss: 0.085949, loss: 0.069994, accuracy: 1.000000
Step: 420, avg loss: 0.084158, loss: 0.010727, accuracy: 1.000000
Step: 430, avg loss: 0.083001, loss: 0.034403, accuracy: 1.000000
Step: 440, avg loss: 0.082354, loss: 0.054518, accuracy: 1.000000
Step: 450, avg loss: 0.081041, loss: 0.023265, accuracy: 1.000000
Step: 460, avg loss: 0.080398, loss: 0.051476, accuracy: 1.000000
Step: 470, avg loss: 0.093050, loss: 0.675035, accuracy: 0.900000
Step: 480, avg loss: 0.102256, loss: 0.534924, accuracy: 0.900000
Step: 490, avg loss: 0.109815, loss: 0.472682, accuracy: 0.900000
Step: 500, avg loss: 0.108900, loss: 0.064066, accuracy: 1.000000
Step: 510, avg loss: 0.107074, loss: 0.015769, accuracy: 1.000000
Step: 520, avg loss: 0.105936, loss: 0.047874, accuracy: 1.000000
Step: 530, avg loss: 0.104861, loss: 0.048982, accuracy: 1.000000
Step: 540, avg loss: 0.103268, loss: 0.018829, accuracy: 1.000000
Step: 550, avg loss: 0.101650, loss: 0.014285, accuracy: 1.000000
Step: 560, avg loss: 0.100159, loss: 0.018147, accuracy: 1.000000
Step: 570, avg loss: 0.098876, loss: 0.027016, accuracy: 1.000000
Step: 580, avg loss: 0.097773, loss: 0.034895, accuracy: 1.000000
Step: 590, avg loss: 0.096861, loss: 0.043971, accuracy: 1.000000
Step: 600, avg loss: 0.095954, loss: 0.042444, accuracy: 1.000000
Step: 610, avg loss: 0.094777, loss: 0.024196, accuracy: 1.000000
Step: 620, avg loss: 0.093610, loss: 0.022365, accuracy: 1.000000
Step: 630, avg loss: 0.092310, loss: 0.011734, accuracy: 1.000000
Step: 640, avg loss: 0.091358, loss: 0.031384, accuracy: 1.000000
Step: 650, avg loss: 0.090126, loss: 0.011274, accuracy: 1.000000
Step: 660, avg loss: 0.089086, loss: 0.021476, accuracy: 1.000000
Step: 670, avg loss: 0.098381, loss: 0.711837, accuracy: 0.900000
Step: 680, avg loss: 0.097485, loss: 0.037455, accuracy: 1.000000
Step: 690, avg loss: 0.096451, loss: 0.026142, accuracy: 1.000000
Step: 700, avg loss: 0.095127, loss: 0.003811, accuracy: 1.000000
Step: 710, avg loss: 0.093964, loss: 0.012522, accuracy: 1.000000
Step: 720, avg loss: 0.092697, loss: 0.002764, accuracy: 1.000000
Step: 730, avg loss: 0.091628, loss: 0.014677, accuracy: 1.000000
Step: 740, avg loss: 0.090981, loss: 0.043704, accuracy: 1.000000
Step: 750, avg loss: 0.089948, loss: 0.013499, accuracy: 1.000000
Step: 760, avg loss: 0.088928, loss: 0.012424, accuracy: 1.000000
Step: 770, avg loss: 0.087872, loss: 0.007641, accuracy: 1.000000
Step: 780, avg loss: 0.087200, loss: 0.035488, accuracy: 1.000000
Step: 790, avg loss: 0.086256, loss: 0.012612, accuracy: 1.000000
Step: 800, avg loss: 0.085191, loss: 0.001034, accuracy: 1.000000
Step: 810, avg loss: 0.084422, loss: 0.022875, accuracy: 1.000000
Step: 820, avg loss: 0.083659, loss: 0.021893, accuracy: 1.000000
Step: 830, avg loss: 0.083023, loss: 0.030869, accuracy: 1.000000
Step: 840, avg loss: 0.082303, loss: 0.022564, accuracy: 1.000000
Step: 850, avg loss: 0.081344, loss: 0.000791, accuracy: 1.000000
Step: 860, avg loss: 0.080792, loss: 0.033820, accuracy: 1.000000
Step: 870, avg loss: 0.079869, loss: 0.000485, accuracy: 1.000000
Step: 880, avg loss: 0.079203, loss: 0.021291, accuracy: 1.000000
Step: 890, avg loss: 0.078331, loss: 0.001574, accuracy: 1.000000
Step: 900, avg loss: 0.077588, loss: 0.011516, accuracy: 1.000000
Step: 910, avg loss: 0.086227, loss: 0.863728, accuracy: 0.900000
Step: 920, avg loss: 0.085580, loss: 0.026686, accuracy: 1.000000
Step: 930, avg loss: 0.084705, loss: 0.004194, accuracy: 1.000000
Step: 940, avg loss: 0.084459, loss: 0.061628, accuracy: 1.000000
Step: 950, avg loss: 0.083801, loss: 0.021930, accuracy: 1.000000
Step: 960, avg loss: 0.083156, loss: 0.021830, accuracy: 1.000000
Step: 970, avg loss: 0.082526, loss: 0.022116, accuracy: 1.000000
Step: 980, avg loss: 0.081921, loss: 0.023216, accuracy: 1.000000
Step: 990, avg loss: 0.081119, loss: 0.002518, accuracy: 1.000000
Step: 1000, avg loss: 0.080419, loss: 0.011144, accuracy: 1.000000
Step: 1010, avg loss: 0.079873, loss: 0.025269, accuracy: 1.000000
Step: 1020, avg loss: 0.079105, loss: 0.001521, accuracy: 1.000000
Step: 1030, avg loss: 0.078445, loss: 0.011158, accuracy: 1.000000
Step: 1040, avg loss: 0.077718, loss: 0.002766, accuracy: 1.000000
Step: 1050, avg loss: 0.077091, loss: 0.011875, accuracy: 1.000000
Step: 1060, avg loss: 0.076564, loss: 0.021240, accuracy: 1.000000
Step: 1070, avg loss: 0.075908, loss: 0.006411, accuracy: 1.000000
Step: 1080, avg loss: 0.075693, loss: 0.052676, accuracy: 1.000000
Step: 1090, avg loss: 0.075154, loss: 0.016949, accuracy: 1.000000
Step: 1100, avg loss: 0.074480, loss: 0.000964, accuracy: 1.000000
Step: 1110, avg loss: 0.073813, loss: 0.000503, accuracy: 1.000000
Step: 1120, avg loss: 0.073260, loss: 0.011903, accuracy: 1.000000
Step: 1130, avg loss: 0.072703, loss: 0.010320, accuracy: 1.000000
Step: 1140, avg loss: 0.072309, loss: 0.027691, accuracy: 1.000000
Step: 1150, avg loss: 0.071779, loss: 0.011366, accuracy: 1.000000
Step: 1160, avg loss: 0.071848, loss: 0.079874, accuracy: 1.000000
Step: 1170, avg loss: 0.071530, loss: 0.034529, accuracy: 1.000000
Step: 1180, avg loss: 0.071034, loss: 0.013079, accuracy: 1.000000
Step: 1190, avg loss: 0.070918, loss: 0.057225, accuracy: 1.000000
Step: 1200, avg loss: 0.070614, loss: 0.034471, accuracy: 1.000000
Step: 1210, avg loss: 0.070708, loss: 0.081977, accuracy: 1.000000
Step: 1220, avg loss: 0.070328, loss: 0.024270, accuracy: 1.000000
Step: 1230, avg loss: 0.069844, loss: 0.010817, accuracy: 1.000000
Step: 1240, avg loss: 0.069460, loss: 0.022237, accuracy: 1.000000
Step: 1250, avg loss: 0.068916, loss: 0.001503, accuracy: 1.000000
Step: 1260, avg loss: 0.068556, loss: 0.023508, accuracy: 1.000000
Epoch 53 finished in loss: 0.068448 and accuracy: 0.993661
Step: 10, avg loss: 0.043904, loss: 0.043904, accuracy: 1.000000
Step: 20, avg loss: 0.033870, loss: 0.023836, accuracy: 1.000000
Step: 30, avg loss: 0.038158, loss: 0.046734, accuracy: 1.000000
Step: 40, avg loss: 0.038082, loss: 0.037856, accuracy: 1.000000
Step: 50, avg loss: 0.032845, loss: 0.011896, accuracy: 1.000000
Step: 60, avg loss: 0.031039, loss: 0.022006, accuracy: 1.000000
Step: 70, avg loss: 0.026743, loss: 0.000968, accuracy: 1.000000
Step: 80, avg loss: 0.024769, loss: 0.010951, accuracy: 1.000000
Step: 90, avg loss: 0.140554, loss: 1.066834, accuracy: 0.900000
Step: 100, avg loss: 0.127415, loss: 0.009168, accuracy: 1.000000
Step: 110, avg loss: 0.119851, loss: 0.044205, accuracy: 1.000000
Step: 120, avg loss: 0.110043, loss: 0.002161, accuracy: 1.000000
Step: 130, avg loss: 0.102479, loss: 0.011709, accuracy: 1.000000
Step: 140, avg loss: 0.096067, loss: 0.012712, accuracy: 1.000000
Step: 150, avg loss: 0.091698, loss: 0.030529, accuracy: 1.000000
Step: 160, avg loss: 0.087693, loss: 0.027612, accuracy: 1.000000
Step: 170, avg loss: 0.082572, loss: 0.000641, accuracy: 1.000000
Step: 180, avg loss: 0.127792, loss: 0.896536, accuracy: 0.900000
Step: 190, avg loss: 0.123289, loss: 0.042223, accuracy: 1.000000
Step: 200, avg loss: 0.119093, loss: 0.039378, accuracy: 1.000000
Step: 210, avg loss: 0.113924, loss: 0.010549, accuracy: 1.000000
Step: 220, avg loss: 0.109695, loss: 0.020886, accuracy: 1.000000
Step: 230, avg loss: 0.105001, loss: 0.001739, accuracy: 1.000000
Step: 240, avg loss: 0.101657, loss: 0.024729, accuracy: 1.000000
Step: 250, avg loss: 0.098483, loss: 0.022305, accuracy: 1.000000
Step: 260, avg loss: 0.095221, loss: 0.013665, accuracy: 1.000000
Step: 270, avg loss: 0.092981, loss: 0.034757, accuracy: 1.000000
Step: 280, avg loss: 0.089710, loss: 0.001401, accuracy: 1.000000
Step: 290, avg loss: 0.088376, loss: 0.051002, accuracy: 1.000000
Step: 300, avg loss: 0.086128, loss: 0.020952, accuracy: 1.000000
Step: 310, avg loss: 0.084415, loss: 0.033015, accuracy: 1.000000
Step: 320, avg loss: 0.082452, loss: 0.021592, accuracy: 1.000000
Step: 330, avg loss: 0.081551, loss: 0.052740, accuracy: 1.000000
Step: 340, avg loss: 0.080584, loss: 0.048657, accuracy: 1.000000
Step: 350, avg loss: 0.079187, loss: 0.031699, accuracy: 1.000000
Step: 360, avg loss: 0.077854, loss: 0.031184, accuracy: 1.000000
Step: 370, avg loss: 0.077120, loss: 0.050700, accuracy: 1.000000
Step: 380, avg loss: 0.097921, loss: 0.867581, accuracy: 0.900000
Step: 390, avg loss: 0.096152, loss: 0.028911, accuracy: 1.000000
Step: 400, avg loss: 0.094567, loss: 0.032743, accuracy: 1.000000
Step: 410, avg loss: 0.093781, loss: 0.062347, accuracy: 1.000000
Step: 420, avg loss: 0.091801, loss: 0.010646, accuracy: 1.000000
Step: 430, avg loss: 0.090454, loss: 0.033850, accuracy: 1.000000
Step: 440, avg loss: 0.089466, loss: 0.047006, accuracy: 1.000000
Step: 450, avg loss: 0.088122, loss: 0.028984, accuracy: 1.000000
Step: 460, avg loss: 0.087323, loss: 0.051355, accuracy: 1.000000
Step: 470, avg loss: 0.100348, loss: 0.699485, accuracy: 0.900000
Step: 480, avg loss: 0.109735, loss: 0.550949, accuracy: 0.900000
Step: 490, avg loss: 0.117321, loss: 0.481461, accuracy: 0.900000
Step: 500, avg loss: 0.116177, loss: 0.060076, accuracy: 1.000000
Step: 510, avg loss: 0.114192, loss: 0.014958, accuracy: 1.000000
Step: 520, avg loss: 0.112783, loss: 0.040949, accuracy: 1.000000
Step: 530, avg loss: 0.111412, loss: 0.040082, accuracy: 1.000000
Step: 540, avg loss: 0.109673, loss: 0.017513, accuracy: 1.000000
Step: 550, avg loss: 0.107956, loss: 0.015260, accuracy: 1.000000
Step: 560, avg loss: 0.106316, loss: 0.016093, accuracy: 1.000000
Step: 570, avg loss: 0.104919, loss: 0.026690, accuracy: 1.000000
Step: 580, avg loss: 0.103694, loss: 0.033877, accuracy: 1.000000
Step: 590, avg loss: 0.102691, loss: 0.044529, accuracy: 1.000000
Step: 600, avg loss: 0.101655, loss: 0.040511, accuracy: 1.000000
Step: 610, avg loss: 0.100368, loss: 0.023187, accuracy: 1.000000
Step: 620, avg loss: 0.099107, loss: 0.022152, accuracy: 1.000000
Step: 630, avg loss: 0.097718, loss: 0.011599, accuracy: 1.000000
Step: 640, avg loss: 0.096679, loss: 0.031247, accuracy: 1.000000
Step: 650, avg loss: 0.095358, loss: 0.010824, accuracy: 1.000000
Step: 660, avg loss: 0.094234, loss: 0.021122, accuracy: 1.000000
Step: 670, avg loss: 0.103282, loss: 0.700473, accuracy: 0.900000
Step: 680, avg loss: 0.102302, loss: 0.036667, accuracy: 1.000000
Step: 690, avg loss: 0.101212, loss: 0.027062, accuracy: 1.000000
Step: 700, avg loss: 0.099821, loss: 0.003836, accuracy: 1.000000
Step: 710, avg loss: 0.098597, loss: 0.012948, accuracy: 1.000000
Step: 720, avg loss: 0.097376, loss: 0.010640, accuracy: 1.000000
Step: 730, avg loss: 0.096243, loss: 0.014697, accuracy: 1.000000
Step: 740, avg loss: 0.095549, loss: 0.044858, accuracy: 1.000000
Step: 750, avg loss: 0.094434, loss: 0.011971, accuracy: 1.000000
Step: 760, avg loss: 0.094407, loss: 0.092351, accuracy: 0.900000
Step: 770, avg loss: 0.093347, loss: 0.012787, accuracy: 1.000000
Step: 780, avg loss: 0.092496, loss: 0.026969, accuracy: 1.000000
Step: 790, avg loss: 0.091483, loss: 0.012511, accuracy: 1.000000
Step: 800, avg loss: 0.090357, loss: 0.001345, accuracy: 1.000000
Step: 810, avg loss: 0.089517, loss: 0.022355, accuracy: 1.000000
Step: 820, avg loss: 0.088687, loss: 0.021408, accuracy: 1.000000
Step: 830, avg loss: 0.087999, loss: 0.031580, accuracy: 1.000000
Step: 840, avg loss: 0.087221, loss: 0.022686, accuracy: 1.000000
Step: 850, avg loss: 0.086200, loss: 0.000473, accuracy: 1.000000
Step: 860, avg loss: 0.085573, loss: 0.032263, accuracy: 1.000000
Step: 870, avg loss: 0.084595, loss: 0.000455, accuracy: 1.000000
Step: 880, avg loss: 0.083869, loss: 0.020724, accuracy: 1.000000
Step: 890, avg loss: 0.082943, loss: 0.001483, accuracy: 1.000000
Step: 900, avg loss: 0.082106, loss: 0.007591, accuracy: 1.000000
Step: 910, avg loss: 0.090337, loss: 0.831068, accuracy: 0.900000
Step: 920, avg loss: 0.089613, loss: 0.023798, accuracy: 1.000000
Step: 930, avg loss: 0.088669, loss: 0.001802, accuracy: 1.000000
Step: 940, avg loss: 0.088382, loss: 0.061658, accuracy: 1.000000
Step: 950, avg loss: 0.087591, loss: 0.013265, accuracy: 1.000000
Step: 960, avg loss: 0.086900, loss: 0.021300, accuracy: 1.000000
Step: 970, avg loss: 0.086234, loss: 0.022225, accuracy: 1.000000
Step: 980, avg loss: 0.085587, loss: 0.022874, accuracy: 1.000000
Step: 990, avg loss: 0.084758, loss: 0.003508, accuracy: 1.000000
Step: 1000, avg loss: 0.084025, loss: 0.011485, accuracy: 1.000000
Step: 1010, avg loss: 0.083441, loss: 0.025025, accuracy: 1.000000
Step: 1020, avg loss: 0.082642, loss: 0.001961, accuracy: 1.000000
Step: 1030, avg loss: 0.081948, loss: 0.011144, accuracy: 1.000000
Step: 1040, avg loss: 0.081182, loss: 0.002212, accuracy: 1.000000
Step: 1050, avg loss: 0.080524, loss: 0.012170, accuracy: 1.000000
Step: 1060, avg loss: 0.079976, loss: 0.022421, accuracy: 1.000000
Step: 1070, avg loss: 0.079325, loss: 0.010302, accuracy: 1.000000
Step: 1080, avg loss: 0.079069, loss: 0.051642, accuracy: 1.000000
Step: 1090, avg loss: 0.078439, loss: 0.010406, accuracy: 1.000000
Step: 1100, avg loss: 0.077732, loss: 0.000731, accuracy: 1.000000
Step: 1110, avg loss: 0.077037, loss: 0.000503, accuracy: 1.000000
Step: 1120, avg loss: 0.076464, loss: 0.012906, accuracy: 1.000000
Step: 1130, avg loss: 0.075876, loss: 0.010037, accuracy: 1.000000
Step: 1140, avg loss: 0.075423, loss: 0.024218, accuracy: 1.000000
Step: 1150, avg loss: 0.074865, loss: 0.011236, accuracy: 1.000000
Step: 1160, avg loss: 0.075837, loss: 0.187625, accuracy: 0.900000
Step: 1170, avg loss: 0.075558, loss: 0.043164, accuracy: 1.000000
Step: 1180, avg loss: 0.075130, loss: 0.025156, accuracy: 1.000000
Step: 1190, avg loss: 0.075027, loss: 0.062823, accuracy: 1.000000
Step: 1200, avg loss: 0.074788, loss: 0.046391, accuracy: 1.000000
Step: 1210, avg loss: 0.074875, loss: 0.085285, accuracy: 1.000000
Step: 1220, avg loss: 0.074467, loss: 0.025141, accuracy: 1.000000
Step: 1230, avg loss: 0.073950, loss: 0.010834, accuracy: 1.000000
Step: 1240, avg loss: 0.073538, loss: 0.022871, accuracy: 1.000000
Step: 1250, avg loss: 0.072956, loss: 0.000723, accuracy: 1.000000
Step: 1260, avg loss: 0.072572, loss: 0.024651, accuracy: 1.000000
Epoch 54 finished in loss: 0.072458 and accuracy: 0.992076
Step: 10, avg loss: 0.047998, loss: 0.047998, accuracy: 1.000000
Step: 20, avg loss: 0.035822, loss: 0.023645, accuracy: 1.000000
Step: 30, avg loss: 0.032551, loss: 0.026009, accuracy: 1.000000
Step: 40, avg loss: 0.027091, loss: 0.010711, accuracy: 1.000000
Step: 50, avg loss: 0.023999, loss: 0.011633, accuracy: 1.000000
Step: 60, avg loss: 0.023837, loss: 0.023023, accuracy: 1.000000
Step: 70, avg loss: 0.020753, loss: 0.002253, accuracy: 1.000000
Step: 80, avg loss: 0.020209, loss: 0.016396, accuracy: 1.000000
Step: 90, avg loss: 0.122383, loss: 0.939777, accuracy: 0.900000
Step: 100, avg loss: 0.111253, loss: 0.011088, accuracy: 1.000000
Step: 110, avg loss: 0.104826, loss: 0.040557, accuracy: 1.000000
Step: 120, avg loss: 0.096194, loss: 0.001233, accuracy: 1.000000
Step: 130, avg loss: 0.089716, loss: 0.011980, accuracy: 1.000000
Step: 140, avg loss: 0.084052, loss: 0.010424, accuracy: 1.000000
Step: 150, avg loss: 0.080521, loss: 0.031079, accuracy: 1.000000
Step: 160, avg loss: 0.077376, loss: 0.030204, accuracy: 1.000000
Step: 170, avg loss: 0.073037, loss: 0.003618, accuracy: 1.000000
Step: 180, avg loss: 0.112005, loss: 0.774453, accuracy: 0.900000
Step: 190, avg loss: 0.108328, loss: 0.042155, accuracy: 1.000000
Step: 200, avg loss: 0.103772, loss: 0.017197, accuracy: 1.000000
Step: 210, avg loss: 0.099350, loss: 0.010912, accuracy: 1.000000
Step: 220, avg loss: 0.095783, loss: 0.020887, accuracy: 1.000000
Step: 230, avg loss: 0.091708, loss: 0.002047, accuracy: 1.000000
Step: 240, avg loss: 0.088793, loss: 0.021742, accuracy: 1.000000
Step: 250, avg loss: 0.086129, loss: 0.022207, accuracy: 1.000000
Step: 260, avg loss: 0.083062, loss: 0.006374, accuracy: 1.000000
Step: 270, avg loss: 0.081286, loss: 0.035117, accuracy: 1.000000
Step: 280, avg loss: 0.078421, loss: 0.001080, accuracy: 1.000000
Step: 290, avg loss: 0.077508, loss: 0.051947, accuracy: 1.000000
Step: 300, avg loss: 0.075652, loss: 0.021828, accuracy: 1.000000
Step: 310, avg loss: 0.074294, loss: 0.033535, accuracy: 1.000000
Step: 320, avg loss: 0.072658, loss: 0.021958, accuracy: 1.000000
Step: 330, avg loss: 0.072033, loss: 0.052033, accuracy: 1.000000
Step: 340, avg loss: 0.071198, loss: 0.043643, accuracy: 1.000000
Step: 350, avg loss: 0.069994, loss: 0.029057, accuracy: 1.000000
Step: 360, avg loss: 0.068936, loss: 0.031906, accuracy: 1.000000
Step: 370, avg loss: 0.068531, loss: 0.053948, accuracy: 1.000000
Step: 380, avg loss: 0.088718, loss: 0.835612, accuracy: 0.900000
Step: 390, avg loss: 0.087203, loss: 0.029637, accuracy: 1.000000
Step: 400, avg loss: 0.085838, loss: 0.032610, accuracy: 1.000000
Step: 410, avg loss: 0.085360, loss: 0.066234, accuracy: 1.000000
Step: 420, avg loss: 0.083584, loss: 0.010771, accuracy: 1.000000
Step: 430, avg loss: 0.082423, loss: 0.033679, accuracy: 1.000000
Step: 440, avg loss: 0.081779, loss: 0.054083, accuracy: 1.000000
Step: 450, avg loss: 0.080467, loss: 0.022741, accuracy: 1.000000
Step: 460, avg loss: 0.079870, loss: 0.053018, accuracy: 1.000000
Step: 470, avg loss: 0.092856, loss: 0.690173, accuracy: 0.900000
Step: 480, avg loss: 0.102544, loss: 0.557893, accuracy: 0.900000
Step: 490, avg loss: 0.110511, loss: 0.492924, accuracy: 0.900000
Step: 500, avg loss: 0.109325, loss: 0.051229, accuracy: 1.000000
Step: 510, avg loss: 0.107432, loss: 0.012754, accuracy: 1.000000
Step: 520, avg loss: 0.106242, loss: 0.045597, accuracy: 1.000000
Step: 530, avg loss: 0.105004, loss: 0.040596, accuracy: 1.000000
Step: 540, avg loss: 0.103394, loss: 0.018078, accuracy: 1.000000
Step: 550, avg loss: 0.101792, loss: 0.015251, accuracy: 1.000000
Step: 560, avg loss: 0.100302, loss: 0.018405, accuracy: 1.000000
Step: 570, avg loss: 0.098995, loss: 0.025758, accuracy: 1.000000
Step: 580, avg loss: 0.097908, loss: 0.035946, accuracy: 1.000000
Step: 590, avg loss: 0.097001, loss: 0.044419, accuracy: 1.000000
Step: 600, avg loss: 0.096152, loss: 0.046028, accuracy: 1.000000
Step: 610, avg loss: 0.095266, loss: 0.042116, accuracy: 1.000000
Step: 620, avg loss: 0.094079, loss: 0.021666, accuracy: 1.000000
Step: 630, avg loss: 0.092779, loss: 0.012194, accuracy: 1.000000
Step: 640, avg loss: 0.091816, loss: 0.031179, accuracy: 1.000000
Step: 650, avg loss: 0.092886, loss: 0.161363, accuracy: 0.900000
Step: 660, avg loss: 0.091795, loss: 0.020888, accuracy: 1.000000
Step: 670, avg loss: 0.100443, loss: 0.671212, accuracy: 0.900000
Step: 680, avg loss: 0.099653, loss: 0.046679, accuracy: 1.000000
Step: 690, avg loss: 0.098537, loss: 0.022646, accuracy: 1.000000
Step: 700, avg loss: 0.097179, loss: 0.003467, accuracy: 1.000000
Step: 710, avg loss: 0.095988, loss: 0.012681, accuracy: 1.000000
Step: 720, avg loss: 0.094773, loss: 0.008478, accuracy: 1.000000
Step: 730, avg loss: 0.093673, loss: 0.014499, accuracy: 1.000000
Step: 740, avg loss: 0.092933, loss: 0.038863, accuracy: 1.000000
Step: 750, avg loss: 0.091881, loss: 0.014062, accuracy: 1.000000
Step: 760, avg loss: 0.090841, loss: 0.012851, accuracy: 1.000000
Step: 770, avg loss: 0.089789, loss: 0.009807, accuracy: 1.000000
Step: 780, avg loss: 0.088952, loss: 0.024478, accuracy: 1.000000
Step: 790, avg loss: 0.087987, loss: 0.012724, accuracy: 1.000000
Step: 800, avg loss: 0.086906, loss: 0.001546, accuracy: 1.000000
Step: 810, avg loss: 0.086110, loss: 0.022423, accuracy: 1.000000
Step: 820, avg loss: 0.085348, loss: 0.023644, accuracy: 1.000000
Step: 830, avg loss: 0.084731, loss: 0.034099, accuracy: 1.000000
Step: 840, avg loss: 0.083976, loss: 0.021332, accuracy: 1.000000
Step: 850, avg loss: 0.082994, loss: 0.000542, accuracy: 1.000000
Step: 860, avg loss: 0.082382, loss: 0.030301, accuracy: 1.000000
Step: 870, avg loss: 0.081440, loss: 0.000414, accuracy: 1.000000
Step: 880, avg loss: 0.080751, loss: 0.020802, accuracy: 1.000000
Step: 890, avg loss: 0.079858, loss: 0.001298, accuracy: 1.000000
Step: 900, avg loss: 0.079097, loss: 0.011361, accuracy: 1.000000
Step: 910, avg loss: 0.087405, loss: 0.835109, accuracy: 0.900000
Step: 920, avg loss: 0.086724, loss: 0.024785, accuracy: 1.000000
Step: 930, avg loss: 0.085812, loss: 0.001871, accuracy: 1.000000
Step: 940, avg loss: 0.085557, loss: 0.061901, accuracy: 1.000000
Step: 950, avg loss: 0.084826, loss: 0.016090, accuracy: 1.000000
Step: 960, avg loss: 0.084165, loss: 0.021408, accuracy: 1.000000
Step: 970, avg loss: 0.083514, loss: 0.020988, accuracy: 1.000000
Step: 980, avg loss: 0.082894, loss: 0.022726, accuracy: 1.000000
Step: 990, avg loss: 0.082069, loss: 0.001274, accuracy: 1.000000
Step: 1000, avg loss: 0.081364, loss: 0.011520, accuracy: 1.000000
Step: 1010, avg loss: 0.080775, loss: 0.021912, accuracy: 1.000000
Step: 1020, avg loss: 0.079997, loss: 0.001451, accuracy: 1.000000
Step: 1030, avg loss: 0.079333, loss: 0.011516, accuracy: 1.000000
Step: 1040, avg loss: 0.078589, loss: 0.001958, accuracy: 1.000000
Step: 1050, avg loss: 0.077966, loss: 0.013165, accuracy: 1.000000
Step: 1060, avg loss: 0.077428, loss: 0.020937, accuracy: 1.000000
Step: 1070, avg loss: 0.076799, loss: 0.010203, accuracy: 1.000000
Step: 1080, avg loss: 0.076552, loss: 0.050120, accuracy: 1.000000
Step: 1090, avg loss: 0.075954, loss: 0.011373, accuracy: 1.000000
Step: 1100, avg loss: 0.075268, loss: 0.000518, accuracy: 1.000000
Step: 1110, avg loss: 0.074593, loss: 0.000315, accuracy: 1.000000
Step: 1120, avg loss: 0.074042, loss: 0.012905, accuracy: 1.000000
Step: 1130, avg loss: 0.073478, loss: 0.010247, accuracy: 1.000000
Step: 1140, avg loss: 0.073084, loss: 0.028570, accuracy: 1.000000
Step: 1150, avg loss: 0.072557, loss: 0.012518, accuracy: 1.000000
Step: 1160, avg loss: 0.072603, loss: 0.077826, accuracy: 1.000000
Step: 1170, avg loss: 0.072294, loss: 0.036482, accuracy: 1.000000
Step: 1180, avg loss: 0.071954, loss: 0.032140, accuracy: 1.000000
Step: 1190, avg loss: 0.071837, loss: 0.058020, accuracy: 1.000000
Step: 1200, avg loss: 0.071583, loss: 0.041466, accuracy: 1.000000
Step: 1210, avg loss: 0.071634, loss: 0.077668, accuracy: 1.000000
Step: 1220, avg loss: 0.071221, loss: 0.021277, accuracy: 1.000000
Step: 1230, avg loss: 0.070729, loss: 0.010685, accuracy: 1.000000
Step: 1240, avg loss: 0.070336, loss: 0.021992, accuracy: 1.000000
Step: 1250, avg loss: 0.069785, loss: 0.001457, accuracy: 1.000000
Step: 1260, avg loss: 0.069407, loss: 0.022247, accuracy: 1.000000
Epoch 55 finished in loss: 0.069298 and accuracy: 0.992868
Step: 10, avg loss: 0.043296, loss: 0.043296, accuracy: 1.000000
Step: 20, avg loss: 0.034329, loss: 0.025362, accuracy: 1.000000
Step: 30, avg loss: 0.031057, loss: 0.024512, accuracy: 1.000000
Step: 40, avg loss: 0.028882, loss: 0.022358, accuracy: 1.000000
Step: 50, avg loss: 0.026857, loss: 0.018755, accuracy: 1.000000
Step: 60, avg loss: 0.025882, loss: 0.021009, accuracy: 1.000000
Step: 70, avg loss: 0.022373, loss: 0.001322, accuracy: 1.000000
Step: 80, avg loss: 0.020871, loss: 0.010354, accuracy: 1.000000
Step: 90, avg loss: 0.138531, loss: 1.079810, accuracy: 0.900000
Step: 100, avg loss: 0.125577, loss: 0.008991, accuracy: 1.000000
Step: 110, avg loss: 0.117839, loss: 0.040465, accuracy: 1.000000
Step: 120, avg loss: 0.108148, loss: 0.001540, accuracy: 1.000000
Step: 130, avg loss: 0.100715, loss: 0.011524, accuracy: 1.000000
Step: 140, avg loss: 0.094314, loss: 0.011101, accuracy: 1.000000
Step: 150, avg loss: 0.090163, loss: 0.032053, accuracy: 1.000000
Step: 160, avg loss: 0.086474, loss: 0.031137, accuracy: 1.000000
Step: 170, avg loss: 0.081409, loss: 0.000370, accuracy: 1.000000
Step: 180, avg loss: 0.125772, loss: 0.879931, accuracy: 0.900000
Step: 190, avg loss: 0.121253, loss: 0.039924, accuracy: 1.000000
Step: 200, avg loss: 0.116040, loss: 0.016988, accuracy: 1.000000
Step: 210, avg loss: 0.111020, loss: 0.010616, accuracy: 1.000000
Step: 220, avg loss: 0.106902, loss: 0.020416, accuracy: 1.000000
Step: 230, avg loss: 0.102338, loss: 0.001947, accuracy: 1.000000
Step: 240, avg loss: 0.098960, loss: 0.021261, accuracy: 1.000000
Step: 250, avg loss: 0.095874, loss: 0.021806, accuracy: 1.000000
Step: 260, avg loss: 0.092589, loss: 0.010455, accuracy: 1.000000
Step: 270, avg loss: 0.090616, loss: 0.039327, accuracy: 1.000000
Step: 280, avg loss: 0.087440, loss: 0.001680, accuracy: 1.000000
Step: 290, avg loss: 0.086181, loss: 0.050936, accuracy: 1.000000
Step: 300, avg loss: 0.083996, loss: 0.020626, accuracy: 1.000000
Step: 310, avg loss: 0.082363, loss: 0.033373, accuracy: 1.000000
Step: 320, avg loss: 0.080456, loss: 0.021345, accuracy: 1.000000
Step: 330, avg loss: 0.079569, loss: 0.051202, accuracy: 1.000000
Step: 340, avg loss: 0.081132, loss: 0.132685, accuracy: 0.900000
Step: 350, avg loss: 0.079725, loss: 0.031916, accuracy: 1.000000
Step: 360, avg loss: 0.078377, loss: 0.031180, accuracy: 1.000000
Step: 370, avg loss: 0.077745, loss: 0.054996, accuracy: 1.000000
Step: 380, avg loss: 0.098811, loss: 0.878248, accuracy: 0.900000
Step: 390, avg loss: 0.097005, loss: 0.028393, accuracy: 1.000000
Step: 400, avg loss: 0.095390, loss: 0.032379, accuracy: 1.000000
Step: 410, avg loss: 0.094543, loss: 0.060692, accuracy: 1.000000
Step: 420, avg loss: 0.092539, loss: 0.010340, accuracy: 1.000000
Step: 430, avg loss: 0.091171, loss: 0.033748, accuracy: 1.000000
Step: 440, avg loss: 0.090336, loss: 0.054416, accuracy: 1.000000
Step: 450, avg loss: 0.088863, loss: 0.024068, accuracy: 1.000000
Step: 460, avg loss: 0.088073, loss: 0.052502, accuracy: 1.000000
Step: 470, avg loss: 0.101416, loss: 0.715216, accuracy: 0.900000
Step: 480, avg loss: 0.111453, loss: 0.583171, accuracy: 0.900000
Step: 490, avg loss: 0.119728, loss: 0.516945, accuracy: 0.900000
Step: 500, avg loss: 0.118299, loss: 0.048257, accuracy: 1.000000
Step: 510, avg loss: 0.116225, loss: 0.012545, accuracy: 1.000000
Step: 520, avg loss: 0.114862, loss: 0.045356, accuracy: 1.000000
Step: 530, avg loss: 0.113498, loss: 0.042557, accuracy: 1.000000
Step: 540, avg loss: 0.111711, loss: 0.017018, accuracy: 1.000000
Step: 550, avg loss: 0.109940, loss: 0.014298, accuracy: 1.000000
Step: 560, avg loss: 0.108287, loss: 0.017336, accuracy: 1.000000
Step: 570, avg loss: 0.106847, loss: 0.026242, accuracy: 1.000000
Step: 580, avg loss: 0.105587, loss: 0.033727, accuracy: 1.000000
Step: 590, avg loss: 0.104710, loss: 0.053856, accuracy: 1.000000
Step: 600, avg loss: 0.103578, loss: 0.036829, accuracy: 1.000000
Step: 610, avg loss: 0.102287, loss: 0.024772, accuracy: 1.000000
Step: 620, avg loss: 0.101003, loss: 0.022716, accuracy: 1.000000
Step: 630, avg loss: 0.099597, loss: 0.012433, accuracy: 1.000000
Step: 640, avg loss: 0.098529, loss: 0.031211, accuracy: 1.000000
Step: 650, avg loss: 0.097176, loss: 0.010581, accuracy: 1.000000
Step: 660, avg loss: 0.096045, loss: 0.022538, accuracy: 1.000000
Step: 670, avg loss: 0.104725, loss: 0.677595, accuracy: 0.900000
Step: 680, avg loss: 0.103865, loss: 0.046284, accuracy: 1.000000
Step: 690, avg loss: 0.102687, loss: 0.022534, accuracy: 1.000000
Step: 700, avg loss: 0.101279, loss: 0.004189, accuracy: 1.000000
Step: 710, avg loss: 0.100030, loss: 0.012572, accuracy: 1.000000
Step: 720, avg loss: 0.099309, loss: 0.048078, accuracy: 1.000000
Step: 730, avg loss: 0.098145, loss: 0.014340, accuracy: 1.000000
Step: 740, avg loss: 0.097411, loss: 0.043869, accuracy: 1.000000
Step: 750, avg loss: 0.096393, loss: 0.021045, accuracy: 1.000000
Step: 760, avg loss: 0.095301, loss: 0.013420, accuracy: 1.000000
Step: 770, avg loss: 0.094233, loss: 0.013073, accuracy: 1.000000
Step: 780, avg loss: 0.093176, loss: 0.011729, accuracy: 1.000000
Step: 790, avg loss: 0.092153, loss: 0.012432, accuracy: 1.000000
Step: 800, avg loss: 0.091021, loss: 0.001560, accuracy: 1.000000
Step: 810, avg loss: 0.090180, loss: 0.022922, accuracy: 1.000000
Step: 820, avg loss: 0.089302, loss: 0.018169, accuracy: 1.000000
Step: 830, avg loss: 0.088602, loss: 0.031189, accuracy: 1.000000
Step: 840, avg loss: 0.087797, loss: 0.021007, accuracy: 1.000000
Step: 850, avg loss: 0.086772, loss: 0.000673, accuracy: 1.000000
Step: 860, avg loss: 0.086142, loss: 0.032607, accuracy: 1.000000
Step: 870, avg loss: 0.085158, loss: 0.000508, accuracy: 1.000000
Step: 880, avg loss: 0.084429, loss: 0.020958, accuracy: 1.000000
Step: 890, avg loss: 0.083495, loss: 0.001385, accuracy: 1.000000
Step: 900, avg loss: 0.082573, loss: 0.000442, accuracy: 1.000000
Step: 910, avg loss: 0.091182, loss: 0.865984, accuracy: 0.900000
Step: 920, avg loss: 0.090502, loss: 0.028701, accuracy: 1.000000
Step: 930, avg loss: 0.089548, loss: 0.001771, accuracy: 1.000000
Step: 940, avg loss: 0.089272, loss: 0.063551, accuracy: 1.000000
Step: 950, avg loss: 0.088506, loss: 0.016533, accuracy: 1.000000
Step: 960, avg loss: 0.087799, loss: 0.020594, accuracy: 1.000000
Step: 970, avg loss: 0.087114, loss: 0.021358, accuracy: 1.000000
Step: 980, avg loss: 0.086464, loss: 0.023462, accuracy: 1.000000
Step: 990, avg loss: 0.085598, loss: 0.000731, accuracy: 1.000000
Step: 1000, avg loss: 0.084854, loss: 0.011147, accuracy: 1.000000
Step: 1010, avg loss: 0.084241, loss: 0.022924, accuracy: 1.000000
Step: 1020, avg loss: 0.083429, loss: 0.001466, accuracy: 1.000000
Step: 1030, avg loss: 0.082730, loss: 0.011377, accuracy: 1.000000
Step: 1040, avg loss: 0.081973, loss: 0.004047, accuracy: 1.000000
Step: 1050, avg loss: 0.081303, loss: 0.011648, accuracy: 1.000000
Step: 1060, avg loss: 0.080733, loss: 0.020877, accuracy: 1.000000
Step: 1070, avg loss: 0.080073, loss: 0.010046, accuracy: 1.000000
Step: 1080, avg loss: 0.079815, loss: 0.052271, accuracy: 1.000000
Step: 1090, avg loss: 0.079245, loss: 0.017666, accuracy: 1.000000
Step: 1100, avg loss: 0.078530, loss: 0.000605, accuracy: 1.000000
Step: 1110, avg loss: 0.077828, loss: 0.000573, accuracy: 1.000000
Step: 1120, avg loss: 0.077238, loss: 0.011764, accuracy: 1.000000
Step: 1130, avg loss: 0.076643, loss: 0.010062, accuracy: 1.000000
Step: 1140, avg loss: 0.076208, loss: 0.027069, accuracy: 1.000000
Step: 1150, avg loss: 0.075655, loss: 0.012501, accuracy: 1.000000
Step: 1160, avg loss: 0.075629, loss: 0.072705, accuracy: 1.000000
Step: 1170, avg loss: 0.075303, loss: 0.037439, accuracy: 1.000000
Step: 1180, avg loss: 0.074770, loss: 0.012435, accuracy: 1.000000
Step: 1190, avg loss: 0.074673, loss: 0.063280, accuracy: 1.000000
Step: 1200, avg loss: 0.074407, loss: 0.042716, accuracy: 1.000000
Step: 1210, avg loss: 0.074424, loss: 0.076400, accuracy: 1.000000
Step: 1220, avg loss: 0.073979, loss: 0.020255, accuracy: 1.000000
Step: 1230, avg loss: 0.073464, loss: 0.010578, accuracy: 1.000000
Step: 1240, avg loss: 0.073050, loss: 0.022126, accuracy: 1.000000
Step: 1250, avg loss: 0.072476, loss: 0.001237, accuracy: 1.000000
Step: 1260, avg loss: 0.072085, loss: 0.023291, accuracy: 1.000000
Epoch 56 finished in loss: 0.071972 and accuracy: 0.992868
Step: 10, avg loss: 0.043829, loss: 0.043829, accuracy: 1.000000
Step: 20, avg loss: 0.033660, loss: 0.023491, accuracy: 1.000000
Step: 30, avg loss: 0.029786, loss: 0.022039, accuracy: 1.000000
Step: 40, avg loss: 0.026668, loss: 0.017314, accuracy: 1.000000
Step: 50, avg loss: 0.023538, loss: 0.011015, accuracy: 1.000000
Step: 60, avg loss: 0.023574, loss: 0.023757, accuracy: 1.000000
Step: 70, avg loss: 0.020363, loss: 0.001095, accuracy: 1.000000
Step: 80, avg loss: 0.019170, loss: 0.010818, accuracy: 1.000000
Step: 90, avg loss: 0.136647, loss: 1.076467, accuracy: 0.900000
Step: 100, avg loss: 0.123989, loss: 0.010063, accuracy: 1.000000
Step: 110, avg loss: 0.116702, loss: 0.043838, accuracy: 1.000000
Step: 120, avg loss: 0.107120, loss: 0.001712, accuracy: 1.000000
Step: 130, avg loss: 0.099948, loss: 0.013883, accuracy: 1.000000
Step: 140, avg loss: 0.093596, loss: 0.011024, accuracy: 1.000000
Step: 150, avg loss: 0.089417, loss: 0.030903, accuracy: 1.000000
Step: 160, avg loss: 0.085732, loss: 0.030469, accuracy: 1.000000
Step: 170, avg loss: 0.080849, loss: 0.002709, accuracy: 1.000000
Step: 180, avg loss: 0.126407, loss: 0.900895, accuracy: 0.900000
Step: 190, avg loss: 0.122181, loss: 0.046124, accuracy: 1.000000
Step: 200, avg loss: 0.116942, loss: 0.017384, accuracy: 1.000000
Step: 210, avg loss: 0.111865, loss: 0.010339, accuracy: 1.000000
Step: 220, avg loss: 0.107702, loss: 0.020267, accuracy: 1.000000
Step: 230, avg loss: 0.103058, loss: 0.000900, accuracy: 1.000000
Step: 240, avg loss: 0.099598, loss: 0.020012, accuracy: 1.000000
Step: 250, avg loss: 0.096314, loss: 0.017495, accuracy: 1.000000
Step: 260, avg loss: 0.093155, loss: 0.014189, accuracy: 1.000000
Step: 270, avg loss: 0.091073, loss: 0.036948, accuracy: 1.000000
Step: 280, avg loss: 0.087840, loss: 0.000534, accuracy: 1.000000
Step: 290, avg loss: 0.086572, loss: 0.051079, accuracy: 1.000000
Step: 300, avg loss: 0.084391, loss: 0.021150, accuracy: 1.000000
Step: 310, avg loss: 0.082693, loss: 0.031733, accuracy: 1.000000
Step: 320, avg loss: 0.080791, loss: 0.021842, accuracy: 1.000000
Step: 330, avg loss: 0.079929, loss: 0.052330, accuracy: 1.000000
Step: 340, avg loss: 0.078932, loss: 0.046049, accuracy: 1.000000
Step: 350, avg loss: 0.077593, loss: 0.032048, accuracy: 1.000000
Step: 360, avg loss: 0.076299, loss: 0.031037, accuracy: 1.000000
Step: 370, avg loss: 0.075589, loss: 0.050009, accuracy: 1.000000
Step: 380, avg loss: 0.097554, loss: 0.910246, accuracy: 0.900000
Step: 390, avg loss: 0.095806, loss: 0.029399, accuracy: 1.000000
Step: 400, avg loss: 0.094283, loss: 0.034907, accuracy: 1.000000
Step: 410, avg loss: 0.093496, loss: 0.061985, accuracy: 1.000000
Step: 420, avg loss: 0.091524, loss: 0.010697, accuracy: 1.000000
Step: 430, avg loss: 0.090206, loss: 0.034832, accuracy: 1.000000
Step: 440, avg loss: 0.089378, loss: 0.053762, accuracy: 1.000000
Step: 450, avg loss: 0.087944, loss: 0.024847, accuracy: 1.000000
Step: 460, avg loss: 0.087165, loss: 0.052112, accuracy: 1.000000
Step: 470, avg loss: 0.100910, loss: 0.733212, accuracy: 0.900000
Step: 480, avg loss: 0.111269, loss: 0.598114, accuracy: 0.900000
Step: 490, avg loss: 0.119780, loss: 0.528322, accuracy: 0.900000
Step: 500, avg loss: 0.118310, loss: 0.046276, accuracy: 1.000000
Step: 510, avg loss: 0.116198, loss: 0.010614, accuracy: 1.000000
Step: 520, avg loss: 0.114682, loss: 0.037354, accuracy: 1.000000
Step: 530, avg loss: 0.115867, loss: 0.177461, accuracy: 0.900000
Step: 540, avg loss: 0.114017, loss: 0.016009, accuracy: 1.000000
Step: 550, avg loss: 0.112201, loss: 0.014105, accuracy: 1.000000
Step: 560, avg loss: 0.110469, loss: 0.015243, accuracy: 1.000000
Step: 570, avg loss: 0.108979, loss: 0.025539, accuracy: 1.000000
Step: 580, avg loss: 0.107626, loss: 0.030505, accuracy: 1.000000
Step: 590, avg loss: 0.106546, loss: 0.043874, accuracy: 1.000000
Step: 600, avg loss: 0.105331, loss: 0.033657, accuracy: 1.000000
Step: 610, avg loss: 0.103983, loss: 0.023109, accuracy: 1.000000
Step: 620, avg loss: 0.102677, loss: 0.023012, accuracy: 1.000000
Step: 630, avg loss: 0.101240, loss: 0.012171, accuracy: 1.000000
Step: 640, avg loss: 0.100178, loss: 0.033259, accuracy: 1.000000
Step: 650, avg loss: 0.098803, loss: 0.010780, accuracy: 1.000000
Step: 660, avg loss: 0.097636, loss: 0.021777, accuracy: 1.000000
Step: 670, avg loss: 0.106049, loss: 0.661301, accuracy: 0.900000
Step: 680, avg loss: 0.105142, loss: 0.044365, accuracy: 1.000000
Step: 690, avg loss: 0.103964, loss: 0.023854, accuracy: 1.000000
Step: 700, avg loss: 0.102534, loss: 0.003900, accuracy: 1.000000
Step: 710, avg loss: 0.101272, loss: 0.012908, accuracy: 1.000000
Step: 720, avg loss: 0.099997, loss: 0.009462, accuracy: 1.000000
Step: 730, avg loss: 0.098821, loss: 0.014139, accuracy: 1.000000
Step: 740, avg loss: 0.098109, loss: 0.046194, accuracy: 1.000000
Step: 750, avg loss: 0.097168, loss: 0.027503, accuracy: 1.000000
Step: 760, avg loss: 0.096068, loss: 0.013606, accuracy: 1.000000
Step: 770, avg loss: 0.095017, loss: 0.015090, accuracy: 1.000000
Step: 780, avg loss: 0.094143, loss: 0.026881, accuracy: 1.000000
Step: 790, avg loss: 0.093154, loss: 0.016034, accuracy: 1.000000
Step: 800, avg loss: 0.092009, loss: 0.001527, accuracy: 1.000000
Step: 810, avg loss: 0.091162, loss: 0.023376, accuracy: 1.000000
Step: 820, avg loss: 0.090275, loss: 0.018418, accuracy: 1.000000
Step: 830, avg loss: 0.089571, loss: 0.031837, accuracy: 1.000000
Step: 840, avg loss: 0.088759, loss: 0.021400, accuracy: 1.000000
Step: 850, avg loss: 0.087805, loss: 0.007687, accuracy: 1.000000
Step: 860, avg loss: 0.087160, loss: 0.032314, accuracy: 1.000000
Step: 870, avg loss: 0.086163, loss: 0.000413, accuracy: 1.000000
Step: 880, avg loss: 0.085419, loss: 0.020717, accuracy: 1.000000
Step: 890, avg loss: 0.084470, loss: 0.000962, accuracy: 1.000000
Step: 900, avg loss: 0.083635, loss: 0.009250, accuracy: 1.000000
Step: 910, avg loss: 0.091792, loss: 0.825962, accuracy: 0.900000
Step: 920, avg loss: 0.091063, loss: 0.024771, accuracy: 1.000000
Step: 930, avg loss: 0.090103, loss: 0.001767, accuracy: 1.000000
Step: 940, avg loss: 0.089817, loss: 0.063166, accuracy: 1.000000
Step: 950, avg loss: 0.089083, loss: 0.020094, accuracy: 1.000000
Step: 960, avg loss: 0.088373, loss: 0.020909, accuracy: 1.000000
Step: 970, avg loss: 0.087683, loss: 0.021516, accuracy: 1.000000
Step: 980, avg loss: 0.087026, loss: 0.023211, accuracy: 1.000000
Step: 990, avg loss: 0.086221, loss: 0.007399, accuracy: 1.000000
Step: 1000, avg loss: 0.085477, loss: 0.011779, accuracy: 1.000000
Step: 1010, avg loss: 0.084862, loss: 0.023359, accuracy: 1.000000
Step: 1020, avg loss: 0.084042, loss: 0.001206, accuracy: 1.000000
Step: 1030, avg loss: 0.083429, loss: 0.020967, accuracy: 1.000000
Step: 1040, avg loss: 0.082652, loss: 0.002604, accuracy: 1.000000
Step: 1050, avg loss: 0.082015, loss: 0.015728, accuracy: 1.000000
Step: 1060, avg loss: 0.081451, loss: 0.022267, accuracy: 1.000000
Step: 1070, avg loss: 0.080779, loss: 0.009589, accuracy: 1.000000
Step: 1080, avg loss: 0.080601, loss: 0.061556, accuracy: 1.000000
Step: 1090, avg loss: 0.080015, loss: 0.016630, accuracy: 1.000000
Step: 1100, avg loss: 0.079296, loss: 0.000997, accuracy: 1.000000
Step: 1110, avg loss: 0.078586, loss: 0.000459, accuracy: 1.000000
Step: 1120, avg loss: 0.077986, loss: 0.011341, accuracy: 1.000000
Step: 1130, avg loss: 0.077385, loss: 0.010067, accuracy: 1.000000
Step: 1140, avg loss: 0.076889, loss: 0.020939, accuracy: 1.000000
Step: 1150, avg loss: 0.076320, loss: 0.011420, accuracy: 1.000000
Step: 1160, avg loss: 0.076310, loss: 0.075096, accuracy: 1.000000
Step: 1170, avg loss: 0.075964, loss: 0.035934, accuracy: 1.000000
Step: 1180, avg loss: 0.075505, loss: 0.021698, accuracy: 1.000000
Step: 1190, avg loss: 0.075351, loss: 0.057230, accuracy: 1.000000
Step: 1200, avg loss: 0.075064, loss: 0.040874, accuracy: 1.000000
Step: 1210, avg loss: 0.075114, loss: 0.081203, accuracy: 1.000000
Step: 1220, avg loss: 0.074673, loss: 0.021249, accuracy: 1.000000
Step: 1230, avg loss: 0.074158, loss: 0.011292, accuracy: 1.000000
Step: 1240, avg loss: 0.073732, loss: 0.021384, accuracy: 1.000000
Step: 1250, avg loss: 0.073158, loss: 0.001962, accuracy: 1.000000
Step: 1260, avg loss: 0.072783, loss: 0.025881, accuracy: 1.000000
Epoch 57 finished in loss: 0.072668 and accuracy: 0.992868
Step: 10, avg loss: 0.042709, loss: 0.042709, accuracy: 1.000000
Step: 20, avg loss: 0.031167, loss: 0.019624, accuracy: 1.000000
Step: 30, avg loss: 0.029132, loss: 0.025062, accuracy: 1.000000
Step: 40, avg loss: 0.024520, loss: 0.010684, accuracy: 1.000000
Step: 50, avg loss: 0.021813, loss: 0.010985, accuracy: 1.000000
Step: 60, avg loss: 0.022018, loss: 0.023043, accuracy: 1.000000
Step: 70, avg loss: 0.018986, loss: 0.000792, accuracy: 1.000000
Step: 80, avg loss: 0.017908, loss: 0.010367, accuracy: 1.000000
Step: 90, avg loss: 0.136567, loss: 1.085835, accuracy: 0.900000
Step: 100, avg loss: 0.123875, loss: 0.009644, accuracy: 1.000000
Step: 110, avg loss: 0.116584, loss: 0.043678, accuracy: 1.000000
Step: 120, avg loss: 0.107216, loss: 0.004172, accuracy: 1.000000
Step: 130, avg loss: 0.099812, loss: 0.010964, accuracy: 1.000000
Step: 140, avg loss: 0.093483, loss: 0.011195, accuracy: 1.000000
Step: 150, avg loss: 0.089298, loss: 0.030716, accuracy: 1.000000
Step: 160, avg loss: 0.085589, loss: 0.029946, accuracy: 1.000000
Step: 170, avg loss: 0.080649, loss: 0.001620, accuracy: 1.000000
Step: 180, avg loss: 0.126224, loss: 0.900986, accuracy: 0.900000
Step: 190, avg loss: 0.122241, loss: 0.050563, accuracy: 1.000000
Step: 200, avg loss: 0.117010, loss: 0.017617, accuracy: 1.000000
Step: 210, avg loss: 0.111930, loss: 0.010331, accuracy: 1.000000
Step: 220, avg loss: 0.107807, loss: 0.021216, accuracy: 1.000000
Step: 230, avg loss: 0.103177, loss: 0.001315, accuracy: 1.000000
Step: 240, avg loss: 0.099768, loss: 0.021365, accuracy: 1.000000
Step: 250, avg loss: 0.096659, loss: 0.022044, accuracy: 1.000000
Step: 260, avg loss: 0.093344, loss: 0.010471, accuracy: 1.000000
Step: 270, avg loss: 0.091220, loss: 0.036000, accuracy: 1.000000
Step: 280, avg loss: 0.087986, loss: 0.000650, accuracy: 1.000000
Step: 290, avg loss: 0.086705, loss: 0.050835, accuracy: 1.000000
Step: 300, avg loss: 0.084447, loss: 0.018982, accuracy: 1.000000
Step: 310, avg loss: 0.082733, loss: 0.031313, accuracy: 1.000000
Step: 320, avg loss: 0.080831, loss: 0.021852, accuracy: 1.000000
Step: 330, avg loss: 0.079980, loss: 0.052753, accuracy: 1.000000
Step: 340, avg loss: 0.078936, loss: 0.044486, accuracy: 1.000000
Step: 350, avg loss: 0.077608, loss: 0.032471, accuracy: 1.000000
Step: 360, avg loss: 0.076334, loss: 0.031726, accuracy: 1.000000
Step: 370, avg loss: 0.075735, loss: 0.054176, accuracy: 1.000000
Step: 380, avg loss: 0.096517, loss: 0.865444, accuracy: 0.900000
Step: 390, avg loss: 0.094738, loss: 0.027159, accuracy: 1.000000
Step: 400, avg loss: 0.093241, loss: 0.034850, accuracy: 1.000000
Step: 410, avg loss: 0.092368, loss: 0.057427, accuracy: 1.000000
Step: 420, avg loss: 0.090424, loss: 0.010725, accuracy: 1.000000
Step: 430, avg loss: 0.089096, loss: 0.033323, accuracy: 1.000000
Step: 440, avg loss: 0.088320, loss: 0.054974, accuracy: 1.000000
Step: 450, avg loss: 0.086801, loss: 0.019939, accuracy: 1.000000
Step: 460, avg loss: 0.086049, loss: 0.052223, accuracy: 1.000000
Step: 470, avg loss: 0.099586, loss: 0.722288, accuracy: 0.900000
Step: 480, avg loss: 0.110345, loss: 0.616016, accuracy: 0.900000
Step: 490, avg loss: 0.119496, loss: 0.558744, accuracy: 0.900000
Step: 500, avg loss: 0.118046, loss: 0.046998, accuracy: 1.000000
Step: 510, avg loss: 0.115897, loss: 0.008452, accuracy: 1.000000
Step: 520, avg loss: 0.114409, loss: 0.038501, accuracy: 1.000000
Step: 530, avg loss: 0.112980, loss: 0.038702, accuracy: 1.000000
Step: 540, avg loss: 0.111184, loss: 0.015968, accuracy: 1.000000
Step: 550, avg loss: 0.109417, loss: 0.013982, accuracy: 1.000000
Step: 560, avg loss: 0.107733, loss: 0.015138, accuracy: 1.000000
Step: 570, avg loss: 0.106289, loss: 0.025445, accuracy: 1.000000
Step: 580, avg loss: 0.105042, loss: 0.033949, accuracy: 1.000000
Step: 590, avg loss: 0.103912, loss: 0.038379, accuracy: 1.000000
Step: 600, avg loss: 0.102770, loss: 0.035395, accuracy: 1.000000
Step: 610, avg loss: 0.101449, loss: 0.022190, accuracy: 1.000000
Step: 620, avg loss: 0.100173, loss: 0.022346, accuracy: 1.000000
Step: 630, avg loss: 0.098766, loss: 0.011536, accuracy: 1.000000
Step: 640, avg loss: 0.097718, loss: 0.031666, accuracy: 1.000000
Step: 650, avg loss: 0.096409, loss: 0.012638, accuracy: 1.000000
Step: 660, avg loss: 0.095269, loss: 0.021191, accuracy: 1.000000
Step: 670, avg loss: 0.104290, loss: 0.699678, accuracy: 0.900000
Step: 680, avg loss: 0.103400, loss: 0.043748, accuracy: 1.000000
Step: 690, avg loss: 0.102230, loss: 0.022633, accuracy: 1.000000
Step: 700, avg loss: 0.100824, loss: 0.003840, accuracy: 1.000000
Step: 710, avg loss: 0.099578, loss: 0.012338, accuracy: 1.000000
Step: 720, avg loss: 0.098332, loss: 0.009890, accuracy: 1.000000
Step: 730, avg loss: 0.097177, loss: 0.013992, accuracy: 1.000000
Step: 740, avg loss: 0.096462, loss: 0.044265, accuracy: 1.000000
Step: 750, avg loss: 0.095312, loss: 0.010226, accuracy: 1.000000
Step: 760, avg loss: 0.094242, loss: 0.014033, accuracy: 1.000000
Step: 770, avg loss: 0.093197, loss: 0.013743, accuracy: 1.000000
Step: 780, avg loss: 0.092251, loss: 0.019376, accuracy: 1.000000
Step: 790, avg loss: 0.091245, loss: 0.012848, accuracy: 1.000000
Step: 800, avg loss: 0.090117, loss: 0.001000, accuracy: 1.000000
Step: 810, avg loss: 0.089280, loss: 0.022270, accuracy: 1.000000
Step: 820, avg loss: 0.088450, loss: 0.021265, accuracy: 1.000000
Step: 830, avg loss: 0.087762, loss: 0.031301, accuracy: 1.000000
Step: 840, avg loss: 0.086968, loss: 0.021073, accuracy: 1.000000
Step: 850, avg loss: 0.085955, loss: 0.000836, accuracy: 1.000000
Step: 860, avg loss: 0.085323, loss: 0.031678, accuracy: 1.000000
Step: 870, avg loss: 0.084346, loss: 0.000321, accuracy: 1.000000
Step: 880, avg loss: 0.083631, loss: 0.021364, accuracy: 1.000000
Step: 890, avg loss: 0.082703, loss: 0.001034, accuracy: 1.000000
Step: 900, avg loss: 0.081886, loss: 0.009224, accuracy: 1.000000
Step: 910, avg loss: 0.090182, loss: 0.836848, accuracy: 0.900000
Step: 920, avg loss: 0.089510, loss: 0.028332, accuracy: 1.000000
Step: 930, avg loss: 0.088565, loss: 0.001637, accuracy: 1.000000
Step: 940, avg loss: 0.088297, loss: 0.063339, accuracy: 1.000000
Step: 950, avg loss: 0.087607, loss: 0.022708, accuracy: 1.000000
Step: 960, avg loss: 0.086915, loss: 0.021178, accuracy: 1.000000
Step: 970, avg loss: 0.086234, loss: 0.020938, accuracy: 1.000000
Step: 980, avg loss: 0.085597, loss: 0.023772, accuracy: 1.000000
Step: 990, avg loss: 0.084742, loss: 0.000987, accuracy: 1.000000
Step: 1000, avg loss: 0.084016, loss: 0.012127, accuracy: 1.000000
Step: 1010, avg loss: 0.083430, loss: 0.024839, accuracy: 1.000000
Step: 1020, avg loss: 0.082631, loss: 0.001876, accuracy: 1.000000
Step: 1030, avg loss: 0.081937, loss: 0.011191, accuracy: 1.000000
Step: 1040, avg loss: 0.081172, loss: 0.002407, accuracy: 1.000000
Step: 1050, avg loss: 0.080512, loss: 0.011839, accuracy: 1.000000
Step: 1060, avg loss: 0.079949, loss: 0.020845, accuracy: 1.000000
Step: 1070, avg loss: 0.079299, loss: 0.010350, accuracy: 1.000000
Step: 1080, avg loss: 0.079049, loss: 0.052367, accuracy: 1.000000
Step: 1090, avg loss: 0.078422, loss: 0.010632, accuracy: 1.000000
Step: 1100, avg loss: 0.077722, loss: 0.001394, accuracy: 1.000000
Step: 1110, avg loss: 0.077025, loss: 0.000400, accuracy: 1.000000
Step: 1120, avg loss: 0.076441, loss: 0.011637, accuracy: 1.000000
Step: 1130, avg loss: 0.075854, loss: 0.010106, accuracy: 1.000000
Step: 1140, avg loss: 0.075386, loss: 0.022486, accuracy: 1.000000
Step: 1150, avg loss: 0.074830, loss: 0.011461, accuracy: 1.000000
Step: 1160, avg loss: 0.074756, loss: 0.066271, accuracy: 1.000000
Step: 1170, avg loss: 0.074417, loss: 0.035109, accuracy: 1.000000
Step: 1180, avg loss: 0.073942, loss: 0.018354, accuracy: 1.000000
Step: 1190, avg loss: 0.073793, loss: 0.056138, accuracy: 1.000000
Step: 1200, avg loss: 0.073525, loss: 0.041676, accuracy: 1.000000
Step: 1210, avg loss: 0.073525, loss: 0.073496, accuracy: 1.000000
Step: 1220, avg loss: 0.073106, loss: 0.022470, accuracy: 1.000000
Step: 1230, avg loss: 0.072572, loss: 0.007443, accuracy: 1.000000
Step: 1240, avg loss: 0.072166, loss: 0.022190, accuracy: 1.000000
Step: 1250, avg loss: 0.071600, loss: 0.001446, accuracy: 1.000000
Step: 1260, avg loss: 0.071224, loss: 0.024130, accuracy: 1.000000
Epoch 58 finished in loss: 0.071111 and accuracy: 0.993661
Step: 10, avg loss: 0.043061, loss: 0.043061, accuracy: 1.000000
Step: 20, avg loss: 0.033576, loss: 0.024091, accuracy: 1.000000
Step: 30, avg loss: 0.030572, loss: 0.024563, accuracy: 1.000000
Step: 40, avg loss: 0.025582, loss: 0.010611, accuracy: 1.000000
Step: 50, avg loss: 0.022619, loss: 0.010767, accuracy: 1.000000
Step: 60, avg loss: 0.022687, loss: 0.023028, accuracy: 1.000000
Step: 70, avg loss: 0.019700, loss: 0.001776, accuracy: 1.000000
Step: 80, avg loss: 0.019441, loss: 0.017627, accuracy: 1.000000
Step: 90, avg loss: 0.142832, loss: 1.129965, accuracy: 0.900000
Step: 100, avg loss: 0.129704, loss: 0.011553, accuracy: 1.000000
Step: 110, avg loss: 0.121855, loss: 0.043361, accuracy: 1.000000
Step: 120, avg loss: 0.111808, loss: 0.001291, accuracy: 1.000000
Step: 130, avg loss: 0.104174, loss: 0.012565, accuracy: 1.000000
Step: 140, avg loss: 0.097297, loss: 0.007894, accuracy: 1.000000
Step: 150, avg loss: 0.093018, loss: 0.033121, accuracy: 1.000000
Step: 160, avg loss: 0.089115, loss: 0.030573, accuracy: 1.000000
Step: 170, avg loss: 0.083891, loss: 0.000293, accuracy: 1.000000
Step: 180, avg loss: 0.129721, loss: 0.908830, accuracy: 0.900000
Step: 190, avg loss: 0.125077, loss: 0.041494, accuracy: 1.000000
Step: 200, avg loss: 0.119729, loss: 0.018106, accuracy: 1.000000
Step: 210, avg loss: 0.114553, loss: 0.011042, accuracy: 1.000000
Step: 220, avg loss: 0.110275, loss: 0.020445, accuracy: 1.000000
Step: 230, avg loss: 0.105521, loss: 0.000929, accuracy: 1.000000
Step: 240, avg loss: 0.101943, loss: 0.019654, accuracy: 1.000000
Step: 250, avg loss: 0.105413, loss: 0.188679, accuracy: 0.900000
Step: 260, avg loss: 0.101682, loss: 0.008410, accuracy: 1.000000
Step: 270, avg loss: 0.099253, loss: 0.036095, accuracy: 1.000000
Step: 280, avg loss: 0.095724, loss: 0.000438, accuracy: 1.000000
Step: 290, avg loss: 0.094183, loss: 0.051051, accuracy: 1.000000
Step: 300, avg loss: 0.091717, loss: 0.020190, accuracy: 1.000000
Step: 310, avg loss: 0.089804, loss: 0.032434, accuracy: 1.000000
Step: 320, avg loss: 0.087668, loss: 0.021425, accuracy: 1.000000
Step: 330, avg loss: 0.086595, loss: 0.052274, accuracy: 1.000000
Step: 340, avg loss: 0.085384, loss: 0.045428, accuracy: 1.000000
Step: 350, avg loss: 0.083882, loss: 0.032813, accuracy: 1.000000
Step: 360, avg loss: 0.082453, loss: 0.032414, accuracy: 1.000000
Step: 370, avg loss: 0.081763, loss: 0.056938, accuracy: 1.000000
Step: 380, avg loss: 0.102137, loss: 0.855961, accuracy: 0.900000
Step: 390, avg loss: 0.100265, loss: 0.029127, accuracy: 1.000000
Step: 400, avg loss: 0.098574, loss: 0.032640, accuracy: 1.000000
Step: 410, avg loss: 0.097498, loss: 0.054448, accuracy: 1.000000
Step: 420, avg loss: 0.095443, loss: 0.011215, accuracy: 1.000000
Step: 430, avg loss: 0.093987, loss: 0.032814, accuracy: 1.000000
Step: 440, avg loss: 0.093004, loss: 0.050747, accuracy: 1.000000
Step: 450, avg loss: 0.091510, loss: 0.025785, accuracy: 1.000000
Step: 460, avg loss: 0.090624, loss: 0.050718, accuracy: 1.000000
Step: 470, avg loss: 0.103906, loss: 0.714888, accuracy: 0.900000
Step: 480, avg loss: 0.114036, loss: 0.590137, accuracy: 0.900000
Step: 490, avg loss: 0.122754, loss: 0.541233, accuracy: 0.900000
Step: 500, avg loss: 0.121156, loss: 0.042856, accuracy: 1.000000
Step: 510, avg loss: 0.118967, loss: 0.009519, accuracy: 1.000000
Step: 520, avg loss: 0.117445, loss: 0.039836, accuracy: 1.000000
Step: 530, avg loss: 0.116097, loss: 0.045983, accuracy: 1.000000
Step: 540, avg loss: 0.114244, loss: 0.016062, accuracy: 1.000000
Step: 550, avg loss: 0.112405, loss: 0.013049, accuracy: 1.000000
Step: 560, avg loss: 0.110702, loss: 0.017057, accuracy: 1.000000
Step: 570, avg loss: 0.109208, loss: 0.025544, accuracy: 1.000000
Step: 580, avg loss: 0.108093, loss: 0.044557, accuracy: 1.000000
Step: 590, avg loss: 0.106979, loss: 0.042346, accuracy: 1.000000
Step: 600, avg loss: 0.105767, loss: 0.034261, accuracy: 1.000000
Step: 610, avg loss: 0.104405, loss: 0.022679, accuracy: 1.000000
Step: 620, avg loss: 0.103081, loss: 0.022313, accuracy: 1.000000
Step: 630, avg loss: 0.101642, loss: 0.012450, accuracy: 1.000000
Step: 640, avg loss: 0.102593, loss: 0.162477, accuracy: 0.900000
Step: 650, avg loss: 0.101186, loss: 0.011190, accuracy: 1.000000
Step: 660, avg loss: 0.099983, loss: 0.021788, accuracy: 1.000000
Step: 670, avg loss: 0.108201, loss: 0.650572, accuracy: 0.900000
Step: 680, avg loss: 0.107305, loss: 0.047269, accuracy: 1.000000
Step: 690, avg loss: 0.106105, loss: 0.024489, accuracy: 1.000000
Step: 700, avg loss: 0.104641, loss: 0.003619, accuracy: 1.000000
Step: 710, avg loss: 0.103345, loss: 0.012639, accuracy: 1.000000
Step: 720, avg loss: 0.102042, loss: 0.009549, accuracy: 1.000000
Step: 730, avg loss: 0.100838, loss: 0.014092, accuracy: 1.000000
Step: 740, avg loss: 0.100074, loss: 0.044307, accuracy: 1.000000
Step: 750, avg loss: 0.098908, loss: 0.012627, accuracy: 1.000000
Step: 760, avg loss: 0.097787, loss: 0.013736, accuracy: 1.000000
Step: 770, avg loss: 0.096697, loss: 0.013846, accuracy: 1.000000
Step: 780, avg loss: 0.095775, loss: 0.024814, accuracy: 1.000000
Step: 790, avg loss: 0.094733, loss: 0.013404, accuracy: 1.000000
Step: 800, avg loss: 0.093560, loss: 0.000958, accuracy: 1.000000
Step: 810, avg loss: 0.092692, loss: 0.023192, accuracy: 1.000000
Step: 820, avg loss: 0.091827, loss: 0.021760, accuracy: 1.000000
Step: 830, avg loss: 0.091092, loss: 0.030838, accuracy: 1.000000
Step: 840, avg loss: 0.090253, loss: 0.020618, accuracy: 1.000000
Step: 850, avg loss: 0.089199, loss: 0.000657, accuracy: 1.000000
Step: 860, avg loss: 0.088546, loss: 0.033021, accuracy: 1.000000
Step: 870, avg loss: 0.087617, loss: 0.007727, accuracy: 1.000000
Step: 880, avg loss: 0.086855, loss: 0.020627, accuracy: 1.000000
Step: 890, avg loss: 0.085898, loss: 0.001650, accuracy: 1.000000
Step: 900, avg loss: 0.085029, loss: 0.007731, accuracy: 1.000000
Step: 910, avg loss: 0.093213, loss: 0.829740, accuracy: 0.900000
Step: 920, avg loss: 0.092503, loss: 0.027867, accuracy: 1.000000
Step: 930, avg loss: 0.091527, loss: 0.001742, accuracy: 1.000000
Step: 940, avg loss: 0.091227, loss: 0.063292, accuracy: 1.000000
Step: 950, avg loss: 0.090385, loss: 0.011320, accuracy: 1.000000
Step: 960, avg loss: 0.089670, loss: 0.021743, accuracy: 1.000000
Step: 970, avg loss: 0.088967, loss: 0.021400, accuracy: 1.000000
Step: 980, avg loss: 0.088289, loss: 0.022540, accuracy: 1.000000
Step: 990, avg loss: 0.087407, loss: 0.000976, accuracy: 1.000000
Step: 1000, avg loss: 0.086646, loss: 0.011279, accuracy: 1.000000
Step: 1010, avg loss: 0.086012, loss: 0.022676, accuracy: 1.000000
Step: 1020, avg loss: 0.085181, loss: 0.001217, accuracy: 1.000000
Step: 1030, avg loss: 0.084474, loss: 0.012413, accuracy: 1.000000
Step: 1040, avg loss: 0.083689, loss: 0.002830, accuracy: 1.000000
Step: 1050, avg loss: 0.083080, loss: 0.019710, accuracy: 1.000000
Step: 1060, avg loss: 0.082498, loss: 0.021409, accuracy: 1.000000
Step: 1070, avg loss: 0.081822, loss: 0.010192, accuracy: 1.000000
Step: 1080, avg loss: 0.081545, loss: 0.051912, accuracy: 1.000000
Step: 1090, avg loss: 0.080899, loss: 0.011089, accuracy: 1.000000
Step: 1100, avg loss: 0.080174, loss: 0.001103, accuracy: 1.000000
Step: 1110, avg loss: 0.079456, loss: 0.000565, accuracy: 1.000000
Step: 1120, avg loss: 0.078854, loss: 0.012022, accuracy: 1.000000
Step: 1130, avg loss: 0.078247, loss: 0.010178, accuracy: 1.000000
Step: 1140, avg loss: 0.077767, loss: 0.023557, accuracy: 1.000000
Step: 1150, avg loss: 0.077210, loss: 0.013720, accuracy: 1.000000
Step: 1160, avg loss: 0.077199, loss: 0.075898, accuracy: 1.000000
Step: 1170, avg loss: 0.076870, loss: 0.038741, accuracy: 1.000000
Step: 1180, avg loss: 0.076414, loss: 0.023122, accuracy: 1.000000
Step: 1190, avg loss: 0.076259, loss: 0.057893, accuracy: 1.000000
Step: 1200, avg loss: 0.076006, loss: 0.045935, accuracy: 1.000000
Step: 1210, avg loss: 0.076028, loss: 0.078662, accuracy: 1.000000
Step: 1220, avg loss: 0.075588, loss: 0.022372, accuracy: 1.000000
Step: 1230, avg loss: 0.075067, loss: 0.011469, accuracy: 1.000000
Step: 1240, avg loss: 0.074689, loss: 0.028203, accuracy: 1.000000
Step: 1250, avg loss: 0.074105, loss: 0.001717, accuracy: 1.000000
Step: 1260, avg loss: 0.073701, loss: 0.023127, accuracy: 1.000000
Epoch 59 finished in loss: 0.073585 and accuracy: 0.992076
Step: 10, avg loss: 0.056960, loss: 0.056960, accuracy: 1.000000
Step: 20, avg loss: 0.040788, loss: 0.024617, accuracy: 1.000000
Step: 30, avg loss: 0.034935, loss: 0.023229, accuracy: 1.000000
Step: 40, avg loss: 0.028845, loss: 0.010576, accuracy: 1.000000
Step: 50, avg loss: 0.025271, loss: 0.010971, accuracy: 1.000000
Step: 60, avg loss: 0.024902, loss: 0.023058, accuracy: 1.000000
Step: 70, avg loss: 0.021603, loss: 0.001812, accuracy: 1.000000
Step: 80, avg loss: 0.019784, loss: 0.007053, accuracy: 1.000000
--------------------->Epoch: 60, batch: 82
batch_labels:  [[1]]
loss:  10.0845 10.0845 -0.0 [[ 1.  1.  1.  1.  1.]]
accuracy:  0.0
case_pred:  [[  4.17232513e-05]]
case_pred_each:  [[  8.36781237e-06   8.36781237e-06   8.36781237e-06   8.36781237e-06
    8.36781237e-06]]
miss mask:  [[ 1.  1.  1.  1.  1.]]
batch_isnode shape:  (1, 5)
batch_is_nod:  [[ 0.  0.  0.  0.  0.]]
batch_file_names:  11fe5426ef497bc490b9f1465f1fb25e
Step: 90, avg loss: 0.131201, loss: 1.022532, accuracy: 0.900000
Step: 100, avg loss: 0.119295, loss: 0.012139, accuracy: 1.000000
Step: 110, avg loss: 0.112369, loss: 0.043108, accuracy: 1.000000
Step: 120, avg loss: 0.103099, loss: 0.001139, accuracy: 1.000000
Step: 130, avg loss: 0.096142, loss: 0.012652, accuracy: 1.000000
Step: 140, avg loss: 0.089790, loss: 0.007217, accuracy: 1.000000
Step: 150, avg loss: 0.085909, loss: 0.031574, accuracy: 1.000000
Step: 160, avg loss: 0.082484, loss: 0.031098, accuracy: 1.000000
Step: 170, avg loss: 0.077672, loss: 0.000692, accuracy: 1.000000
--------------------->Epoch: 60, batch: 176
batch_labels:  [[1]]
loss:  8.62916 8.62916 -0.0 [[ 1.  1.  1.  1.  1.]]
accuracy:  0.0
case_pred:  [[ 0.00017881]]
case_pred_each:  [[  3.57485878e-05   3.57485878e-05   3.57485878e-05   3.57485878e-05
    3.57485878e-05]]
miss mask:  [[ 1.  1.  1.  1.  1.]]
batch_isnode shape:  (1, 5)
batch_is_nod:  [[ 0.  0.  0.  0.  0.]]
batch_file_names:  263a1c3bfa43556623e75ed901e3fd8f
Step: 180, avg loss: 0.121317, loss: 0.863281, accuracy: 0.900000
Step: 190, avg loss: 0.116888, loss: 0.037156, accuracy: 1.000000
Step: 200, avg loss: 0.111576, loss: 0.010658, accuracy: 1.000000
Step: 210, avg loss: 0.106770, loss: 0.010648, accuracy: 1.000000
Step: 220, avg loss: 0.102853, loss: 0.020592, accuracy: 1.000000
Step: 230, avg loss: 0.098421, loss: 0.000912, accuracy: 1.000000
Step: 240, avg loss: 0.095231, loss: 0.021860, accuracy: 1.000000
Step: 250, avg loss: 0.092274, loss: 0.021316, accuracy: 1.000000
Step: 260, avg loss: 0.089077, loss: 0.009141, accuracy: 1.000000
Step: 270, avg loss: 0.087142, loss: 0.036831, accuracy: 1.000000
Step: 280, avg loss: 0.084048, loss: 0.000533, accuracy: 1.000000
Step: 290, avg loss: 0.082885, loss: 0.050303, accuracy: 1.000000
Step: 300, avg loss: 0.080806, loss: 0.020523, accuracy: 1.000000
Step: 310, avg loss: 0.079208, loss: 0.031260, accuracy: 1.000000
Step: 320, avg loss: 0.077397, loss: 0.021256, accuracy: 1.000000
Step: 330, avg loss: 0.076594, loss: 0.050914, accuracy: 1.000000
Step: 340, avg loss: 0.075613, loss: 0.043224, accuracy: 1.000000
Step: 350, avg loss: 0.074373, loss: 0.032223, accuracy: 1.000000
Step: 360, avg loss: 0.073196, loss: 0.032006, accuracy: 1.000000
Step: 370, avg loss: 0.075919, loss: 0.173956, accuracy: 0.900000
--------------------->Epoch: 60, batch: 372
batch_labels:  [[1]]
loss:  8.18128 8.18128 -0.0 [[ 1.  1.  1.  1.  1.]]
accuracy:  0.0
case_pred:  [[ 0.00027984]]
case_pred_each:  [[  5.59397886e-05   5.59397886e-05   5.59397886e-05   5.59397886e-05
    5.59397886e-05]]
miss mask:  [[ 1.  1.  1.  1.  1.]]
batch_isnode shape:  (1, 5)
batch_is_nod:  [[ 0.  0.  0.  0.  0.]]
batch_file_names:  4cc8af2efef2f41bf70684be25276ce5
Step: 380, avg loss: 0.096046, loss: 0.840727, accuracy: 0.900000
Step: 390, avg loss: 0.094309, loss: 0.028317, accuracy: 1.000000
Step: 400, avg loss: 0.092842, loss: 0.035607, accuracy: 1.000000
Step: 410, avg loss: 0.092122, loss: 0.063350, accuracy: 1.000000
Step: 420, avg loss: 0.090210, loss: 0.011810, accuracy: 1.000000
Step: 430, avg loss: 0.088882, loss: 0.033073, accuracy: 1.000000
Step: 440, avg loss: 0.088110, loss: 0.054943, accuracy: 1.000000
Step: 450, avg loss: 0.086745, loss: 0.026687, accuracy: 1.000000
Step: 460, avg loss: 0.085974, loss: 0.051282, accuracy: 1.000000
--------------------->Epoch: 60, batch: 463
batch_labels:  [[1]]
loss:  6.88415 6.88415 -0.0 [[ 1.  1.  1.  1.  1.]]
accuracy:  0.0
case_pred:  [[ 0.00102389]]
case_pred_each:  [[ 0.00020485  0.00020485  0.00020485  0.00020485  0.00020485]]
miss mask:  [[ 1.  1.  1.  1.  1.]]
batch_isnode shape:  (1, 5)
batch_is_nod:  [[ 0.  0.  0.  0.  0.]]
batch_file_names:  608202eb3c368512e55e9e339a203790
Step: 470, avg loss: 0.099046, loss: 0.700353, accuracy: 0.900000
--------------------->Epoch: 60, batch: 476
batch_labels:  [[1]]
loss:  5.8339 5.8339 -0.0 [[ 1.  1.  1.  1.  1.]]
accuracy:  0.0
case_pred:  [[ 0.00292665]]
case_pred_each:  [[ 0.00058602  0.00058602  0.00058602  0.00058602  0.00058602]]
miss mask:  [[ 1.  1.  1.  1.  1.]]
batch_isnode shape:  (1, 5)
batch_is_nod:  [[ 0.  0.  0.  0.  0.]]
batch_file_names:  63b5be42543c98ac5392f1bfbda085bf
Step: 480, avg loss: 0.109208, loss: 0.586830, accuracy: 0.900000
--------------------->Epoch: 60, batch: 481
batch_labels:  [[1]]
loss:  5.08644 5.08644 -0.0 [[ 1.  1.  1.  1.  1.]]
accuracy:  0.0
case_pred:  [[ 0.00617999]]
case_pred_each:  [[  2.27516139e-07   1.54852064e-03   1.54852064e-03   1.54852064e-03
    1.54852064e-03]]
miss mask:  [[ 1.  1.  1.  1.  1.]]
batch_isnode shape:  (1, 5)
batch_is_nod:  [[ 0.  0.  0.  0.  0.]]
batch_file_names:  64a5a866461a3b6006efb0075e04dffe
Step: 490, avg loss: 0.118116, loss: 0.545678, accuracy: 0.900000
Step: 500, avg loss: 0.116742, loss: 0.049417, accuracy: 1.000000
Step: 510, avg loss: 0.114673, loss: 0.011215, accuracy: 1.000000
Step: 520, avg loss: 0.113217, loss: 0.038977, accuracy: 1.000000
Step: 530, avg loss: 0.112096, loss: 0.053818, accuracy: 1.000000
Step: 540, avg loss: 0.110316, loss: 0.015962, accuracy: 1.000000
Step: 550, avg loss: 0.108558, loss: 0.013633, accuracy: 1.000000
Step: 560, avg loss: 0.106911, loss: 0.016292, accuracy: 1.000000
Step: 570, avg loss: 0.105488, loss: 0.025847, accuracy: 1.000000
Step: 580, avg loss: 0.104184, loss: 0.029847, accuracy: 1.000000
Step: 590, avg loss: 0.103157, loss: 0.043577, accuracy: 1.000000
Step: 600, avg loss: 0.102036, loss: 0.035919, accuracy: 1.000000
Step: 610, avg loss: 0.100745, loss: 0.023254, accuracy: 1.000000
Step: 620, avg loss: 0.099471, loss: 0.021769, accuracy: 1.000000
Step: 630, avg loss: 0.098083, loss: 0.011996, accuracy: 1.000000
Step: 640, avg loss: 0.097081, loss: 0.033976, accuracy: 1.000000
Step: 650, avg loss: 0.095753, loss: 0.010781, accuracy: 1.000000
Step: 660, avg loss: 0.094615, loss: 0.020660, accuracy: 1.000000
--------------------->Epoch: 60, batch: 665
batch_labels:  [[1]]
loss:  6.80887 6.80887 -0.0 [[ 1.  1.  1.  1.  1.]]
accuracy:  0.0
case_pred:  [[ 0.00110394]]
case_pred_each:  [[ 0.00022089  0.00022089  0.00022089  0.00022089  0.00022089]]
miss mask:  [[ 1.  1.  1.  1.  1.]]
batch_isnode shape:  (1, 5)
batch_is_nod:  [[ 0.  0.  0.  0.  0.]]
batch_file_names:  882107a204c302e27628f85522baea49
Step: 670, avg loss: 0.103375, loss: 0.681497, accuracy: 0.900000
Step: 680, avg loss: 0.102530, loss: 0.045918, accuracy: 1.000000
Step: 690, avg loss: 0.101371, loss: 0.022578, accuracy: 1.000000
Step: 700, avg loss: 0.099970, loss: 0.003294, accuracy: 1.000000
Step: 710, avg loss: 0.098771, loss: 0.014820, accuracy: 1.000000
Step: 720, avg loss: 0.097601, loss: 0.014578, accuracy: 1.000000
Step: 730, avg loss: 0.096461, loss: 0.014321, accuracy: 1.000000
Step: 740, avg loss: 0.095754, loss: 0.044174, accuracy: 1.000000
Step: 750, avg loss: 0.094719, loss: 0.018144, accuracy: 1.000000
Step: 760, avg loss: 0.093646, loss: 0.013188, accuracy: 1.000000
Step: 770, avg loss: 0.092590, loss: 0.012299, accuracy: 1.000000
Step: 780, avg loss: 0.091631, loss: 0.017762, accuracy: 1.000000
Step: 790, avg loss: 0.090634, loss: 0.012889, accuracy: 1.000000
Step: 800, avg loss: 0.089519, loss: 0.001446, accuracy: 1.000000
Step: 810, avg loss: 0.088689, loss: 0.022275, accuracy: 1.000000
Step: 820, avg loss: 0.087870, loss: 0.021515, accuracy: 1.000000
Step: 830, avg loss: 0.087187, loss: 0.031197, accuracy: 1.000000
Step: 840, avg loss: 0.086428, loss: 0.023437, accuracy: 1.000000
Step: 850, avg loss: 0.085512, loss: 0.008570, accuracy: 1.000000
Step: 860, avg loss: 0.084882, loss: 0.031297, accuracy: 1.000000
Step: 870, avg loss: 0.083983, loss: 0.006717, accuracy: 1.000000
Step: 880, avg loss: 0.083262, loss: 0.020518, accuracy: 1.000000
Step: 890, avg loss: 0.082347, loss: 0.001836, accuracy: 1.000000
Step: 900, avg loss: 0.081528, loss: 0.008632, accuracy: 1.000000
Step: 910, avg loss: 0.089959, loss: 0.848770, accuracy: 0.900000
--------------------->Epoch: 60, batch: 910
batch_labels:  [[1]]
loss:  8.36296 8.36296 -0.0 [[ 1.  1.  1.  1.  1.]]
accuracy:  0.0
case_pred:  [[ 0.00023335]]
case_pred_each:  [[  4.66682141e-05   4.66682141e-05   4.66682141e-05   4.66682141e-05
    4.66682141e-05]]
miss mask:  [[ 1.  1.  1.  1.  1.]]
batch_isnode shape:  (1, 5)
batch_is_nod:  [[ 0.  0.  0.  0.  0.]]
batch_file_names:  bb4b43d0dc4d9d2b61150df6556f6490
Step: 920, avg loss: 0.089241, loss: 0.023844, accuracy: 1.000000
Step: 930, avg loss: 0.088300, loss: 0.001787, accuracy: 1.000000
Step: 940, avg loss: 0.088016, loss: 0.061563, accuracy: 1.000000
Step: 950, avg loss: 0.087223, loss: 0.012680, accuracy: 1.000000
Step: 960, avg loss: 0.086537, loss: 0.021395, accuracy: 1.000000
Step: 970, avg loss: 0.085868, loss: 0.021681, accuracy: 1.000000
Step: 980, avg loss: 0.085220, loss: 0.022281, accuracy: 1.000000
Step: 990, avg loss: 0.084368, loss: 0.000884, accuracy: 1.000000
Step: 1000, avg loss: 0.083634, loss: 0.010960, accuracy: 1.000000
Step: 1010, avg loss: 0.083024, loss: 0.022008, accuracy: 1.000000
Step: 1020, avg loss: 0.082224, loss: 0.001437, accuracy: 1.000000
Step: 1030, avg loss: 0.081535, loss: 0.011260, accuracy: 1.000000
Step: 1040, avg loss: 0.080778, loss: 0.002884, accuracy: 1.000000
Step: 1050, avg loss: 0.080156, loss: 0.015398, accuracy: 1.000000
Step: 1060, avg loss: 0.079597, loss: 0.020935, accuracy: 1.000000
Step: 1070, avg loss: 0.078948, loss: 0.010128, accuracy: 1.000000
Step: 1080, avg loss: 0.078806, loss: 0.063666, accuracy: 1.000000
Step: 1090, avg loss: 0.078184, loss: 0.011016, accuracy: 1.000000
Step: 1100, avg loss: 0.077480, loss: 0.000695, accuracy: 1.000000
Step: 1110, avg loss: 0.076785, loss: 0.000342, accuracy: 1.000000
Step: 1120, avg loss: 0.076213, loss: 0.012771, accuracy: 1.000000
Step: 1130, avg loss: 0.075632, loss: 0.010463, accuracy: 1.000000
Step: 1140, avg loss: 0.075209, loss: 0.027453, accuracy: 1.000000
Step: 1150, avg loss: 0.074651, loss: 0.011093, accuracy: 1.000000
Step: 1160, avg loss: 0.074632, loss: 0.072374, accuracy: 1.000000
Step: 1170, avg loss: 0.074283, loss: 0.033811, accuracy: 1.000000
Step: 1180, avg loss: 0.073804, loss: 0.017749, accuracy: 1.000000
Step: 1190, avg loss: 0.073638, loss: 0.054086, accuracy: 1.000000
Step: 1200, avg loss: 0.073511, loss: 0.058336, accuracy: 1.000000
Step: 1210, avg loss: 0.073715, loss: 0.098272, accuracy: 1.000000
Step: 1220, avg loss: 0.073316, loss: 0.024978, accuracy: 1.000000
Step: 1230, avg loss: 0.072805, loss: 0.010471, accuracy: 1.000000
Step: 1240, avg loss: 0.072464, loss: 0.030532, accuracy: 1.000000
Step: 1250, avg loss: 0.071893, loss: 0.001090, accuracy: 1.000000
Step: 1260, avg loss: 0.071510, loss: 0.023628, accuracy: 1.000000
Epoch 60 finished in loss: 0.071397 and accuracy: 0.992868
--->Val epoch: 3, batch: 2
batch_labels:  [[0]]
loss:  11.5116 11.5116
accuracy:  0.0
batch_is_nod:  [[ 0.  0.  0.  0.  0.]]
batch_file_names:  edbf53a8478049de1494b213fdf942e6
--->Val epoch: 3, batch: 4
batch_labels:  [[1]]
loss:  1.3278 1.3278
accuracy:  0.0
batch_is_nod:  [[ 1.  0.  0.  0.  0.]]
batch_file_names:  48e592418247393234dd658f9112c543
--->Val epoch: 3, batch: 6
batch_labels:  [[1]]
loss:  8.75889 8.75889
accuracy:  0.0
batch_is_nod:  [[ 0.  0.  0.  0.  0.]]
batch_file_names:  d032116d73789ff9c805f493357b4037
Val step: 10, avg loss: 2.252526, loss: 2.252526, accuracy: 0.700000
--->Val epoch: 3, batch: 11
batch_labels:  [[0]]
loss:  11.5116 11.5116
accuracy:  0.0
batch_is_nod:  [[ 0.  0.  0.  0.  0.]]
batch_file_names:  3dfe8e80106f4136d2933ff72a16035c
--->Val epoch: 3, batch: 12
batch_labels:  [[1]]
loss:  8.86158 8.67277
accuracy:  0.0
batch_is_nod:  [[ 1.  0.  0.  0.  0.]]
batch_file_names:  f5717f7cbc08d8bd942cd4c1128e3339
--->Val epoch: 3, batch: 13
batch_labels:  [[1]]
loss:  7.42339 7.42339
accuracy:  0.0
batch_is_nod:  [[ 0.  0.  0.  0.  0.]]
batch_file_names:  a2558184e0f4a68e9fb13579d20cb244
--->Val epoch: 3, batch: 17
batch_labels:  [[1]]
loss:  5.45482 5.3407
accuracy:  0.0
batch_is_nod:  [[ 1.  0.  0.  0.  0.]]
batch_file_names:  4d7df08f074b221eec6311c2617a5ba8
Val step: 20, avg loss: 2.799527, loss: 3.346529, accuracy: 0.600000
--->Val epoch: 3, batch: 21
batch_labels:  [[0]]
loss:  7.83889 7.83889
accuracy:  0.0
batch_is_nod:  [[ 1.  0.  0.  0.  0.]]
batch_file_names:  ef6a37afe024d33b4b1bb2fdee054a59
--->Val epoch: 3, batch: 24
batch_labels:  [[0]]
loss:  1.10477 1.10477
accuracy:  0.0
batch_is_nod:  [[ 0.  0.  0.  0.  0.]]
batch_file_names:  89f003dbfbdbd18a5cdeb9b128cb075b
--->Val epoch: 3, batch: 28
batch_labels:  [[0]]
loss:  11.5116 11.5116
accuracy:  0.0
batch_is_nod:  [[ 0.  0.  0.  0.  0.]]
batch_file_names:  f0f72264cd822301852578cc71288d3c
Val step: 30, avg loss: 2.548533, loss: 2.046543, accuracy: 0.700000
--->Val epoch: 3, batch: 36
batch_labels:  [[1]]
loss:  1.6565 1.50072
accuracy:  0.0
batch_is_nod:  [[ 1.  0.  0.  0.  0.]]
batch_file_names:  f725f46908f16062fd12c141eb47c6a7
Val step: 40, avg loss: 1.961745, loss: 0.201382, accuracy: 0.900000
Val step: 50, avg loss: 1.569434, loss: 0.000191, accuracy: 1.000000
--->Val epoch: 3, batch: 56
batch_labels:  [[0]]
loss:  11.5116 11.5116
accuracy:  0.0
batch_is_nod:  [[ 1.  0.  0.  0.  0.]]
batch_file_names:  2885e3af725bc58dc1522d4bfb24bb2b
--->Val epoch: 3, batch: 57
batch_labels:  [[0]]
loss:  11.5116 11.5116
accuracy:  0.0
batch_is_nod:  [[ 0.  0.  0.  0.  0.]]
batch_file_names:  49a29b3f5bee32b350bedc4cfbad8e9c
Val step: 60, avg loss: 1.695155, loss: 2.323761, accuracy: 0.800000
--->Val epoch: 3, batch: 61
batch_labels:  [[0]]
loss:  11.5116 11.5116
accuracy:  0.0
batch_is_nod:  [[ 0.  0.  0.  0.  0.]]
batch_file_names:  e42065c1145ccf734312cb9edbe5234b
--->Val epoch: 3, batch: 64
batch_labels:  [[1]]
loss:  4.63384 4.63384
accuracy:  0.0
batch_is_nod:  [[ 0.  0.  0.  0.  0.]]
batch_file_names:  c67de8fbbe1e58b464334f93a1dd0447
Val step: 70, avg loss: 1.689641, loss: 1.656554, accuracy: 0.800000
--->Val epoch: 3, batch: 71
batch_labels:  [[1]]
loss:  5.89218 5.77438
accuracy:  0.0
batch_is_nod:  [[ 1.  0.  0.  0.  0.]]
batch_file_names:  028996723faa7840bb57f57e28275e4c
--->Val epoch: 3, batch: 75
batch_labels:  [[0]]
loss:  5.09933 5.09933
accuracy:  0.0
batch_is_nod:  [[ 0.  0.  0.  0.  0.]]
batch_file_names:  6faabf4152bf0ebfd91f686bc37a1f16
--->Val epoch: 3, batch: 77
batch_labels:  [[0]]
loss:  11.5116 11.5116
accuracy:  0.0
batch_is_nod:  [[ 1.  1.  0.  0.  0.]]
batch_file_names:  f8ecf6be8ae631c6dd694c9638a02b45
--->Val epoch: 3, batch: 79
batch_labels:  [[1]]
loss:  5.76925 5.76925
accuracy:  0.0
batch_is_nod:  [[ 0.  0.  0.  0.  0.]]
batch_file_names:  817a99e1a60bcf4e37c904d73845ca50
Val step: 80, avg loss: 1.837791, loss: 2.874845, accuracy: 0.600000
--->Val epoch: 3, batch: 84
batch_labels:  [[1]]
loss:  5.68184 5.68184
accuracy:  0.0
batch_is_nod:  [[ 0.  0.  0.  0.  0.]]
batch_file_names:  9b7524785a9bf40f0651deeb3b05b75f
--->Val epoch: 3, batch: 88
batch_labels:  [[1]]
loss:  3.84268 3.84268
accuracy:  0.0
batch_is_nod:  [[ 0.  0.  0.  0.  0.]]
batch_file_names:  026470d51482c93efc18b9803159c960
--->Val epoch: 3, batch: 89
batch_labels:  [[1]]
loss:  6.5364 6.5364
accuracy:  0.0
batch_is_nod:  [[ 0.  0.  0.  0.  0.]]
batch_file_names:  6541df84fd779ba6513a530c128f4e9b
--->Val epoch: 3, batch: 90
batch_labels:  [[0]]
loss:  3.97849 3.70645
accuracy:  0.0
batch_is_nod:  [[ 1.  1.  1.  1.  0.]]
batch_file_names:  bcc701884a32d8883b73b5844241a354
Val step: 90, avg loss: 1.862579, loss: 2.060882, accuracy: 0.600000
--->Val epoch: 3, batch: 91
batch_labels:  [[0]]
loss:  11.5116 11.5116
accuracy:  0.0
batch_is_nod:  [[ 1.  0.  0.  0.  0.]]
batch_file_names:  483b89a4ffbbd85acc8b9af5a541dd4d
--->Val epoch: 3, batch: 99
batch_labels:  [[1]]
loss:  8.72799 8.53932
accuracy:  0.0
batch_is_nod:  [[ 1.  0.  0.  0.  0.]]
batch_file_names:  ebd601d40a18634b100c92e7db39f585
--->Val epoch: 3, batch: 100
batch_labels:  [[1]]
loss:  2.56081 2.56081
accuracy:  0.0
batch_is_nod:  [[ 1.  0.  0.  0.  0.]]
batch_file_names:  1f49f0c1d7feedcae9024d251797407c
Val step: 100, avg loss: 1.906394, loss: 2.300728, accuracy: 0.700000
Val step: 110, avg loss: 1.734686, loss: 0.017608, accuracy: 1.000000
--->Val epoch: 3, batch: 113
batch_labels:  [[1]]
loss:  8.77999 8.77999
accuracy:  0.0
batch_is_nod:  [[ 0.  0.  0.  0.  0.]]
batch_file_names:  ea01deecde93cd9503a049d71d46e6d5
--->Val epoch: 3, batch: 120
batch_labels:  [[1]]
loss:  4.07722 3.9786
accuracy:  0.0
batch_is_nod:  [[ 0.  1.  0.  0.  0.]]
batch_file_names:  93a6f37a72f60498986374f57bfc30c4
Val step: 120, avg loss: 1.697433, loss: 1.287648, accuracy: 0.800000
--->Val epoch: 3, batch: 126
batch_labels:  [[1]]
loss:  8.75889 8.75889
accuracy:  0.0
batch_is_nod:  [[ 0.  0.  0.  0.  0.]]
batch_file_names:  3252220375d82c3720d36d757bb17345
Val step: 130, avg loss: 1.636803, loss: 0.909245, accuracy: 0.900000
Val step: 140, avg loss: 1.524526, loss: 0.064919, accuracy: 1.000000
--->Val epoch: 3, batch: 141
batch_labels:  [[0]]
loss:  11.5116 11.5116
accuracy:  0.0
batch_is_nod:  [[ 1.  0.  0.  0.  0.]]
batch_file_names:  0334c8242ce7ee1a6c1263096e4cc535
--->Val epoch: 3, batch: 149
batch_labels:  [[1]]
loss:  3.80353 3.72798
accuracy:  0.0
batch_is_nod:  [[ 1.  0.  0.  0.  0.]]
batch_file_names:  15aa585fb2d3018b295df8619f2d1cf7
Val step: 150, avg loss: 1.526083, loss: 1.547892, accuracy: 0.800000
--->Val epoch: 3, batch: 152
batch_labels:  [[0]]
loss:  4.99786 4.99786
accuracy:  0.0
batch_is_nod:  [[ 0.  0.  0.  0.  0.]]
batch_file_names:  fcfab3eddbdf0421c39f71d651cc5c56
--->Val epoch: 3, batch: 157
batch_labels:  [[1]]
loss:  4.38131 4.23096
accuracy:  0.0
batch_is_nod:  [[ 1.  0.  0.  0.  0.]]
batch_file_names:  e38789c5eabb3005bfb82a5298055ba0
Val step: 160, avg loss: 1.490468, loss: 0.956231, accuracy: 0.800000
--->Val epoch: 3, batch: 161
batch_labels:  [[0]]
loss:  11.5116 11.5116
accuracy:  0.0
batch_is_nod:  [[ 1.  1.  0.  0.  0.]]
batch_file_names:  5f383eb9c3d8ea72ddec7e2e874d577d
--->Val epoch: 3, batch: 162
batch_labels:  [[0]]
loss:  7.14998 7.02427
accuracy:  0.0
batch_is_nod:  [[ 1.  0.  0.  0.  0.]]
batch_file_names:  fac65dbf7b6972049cfd37b5b122ec0b
--->Val epoch: 3, batch: 164
batch_labels:  [[1]]
loss:  2.74481 2.74481
accuracy:  0.0
batch_is_nod:  [[ 0.  0.  0.  0.  0.]]
batch_file_names:  761aeadb65fb84c8d04978a75b2f684c
--->Val epoch: 3, batch: 165
batch_labels:  [[1]]
loss:  5.02176 4.92295
accuracy:  0.0
batch_is_nod:  [[ 0.  1.  0.  0.  0.]]
batch_file_names:  54056288ab97cebc4b0ea33c23f47ff6
--->Val epoch: 3, batch: 166
batch_labels:  [[1]]
loss:  3.40464 3.33026
accuracy:  0.0
batch_is_nod:  [[ 1.  0.  0.  0.  0.]]
batch_file_names:  80600d4a5fee7424d689ba7d0906d50f
--->Val epoch: 3, batch: 170
batch_labels:  [[0]]
loss:  5.41683 5.41683
accuracy:  0.0
batch_is_nod:  [[ 1.  0.  0.  0.  0.]]
batch_file_names:  4d86e1657d46b9ee44c2c434fad231ce
Val step: 170, avg loss: 1.610173, loss: 3.525451, accuracy: 0.400000
--->Val epoch: 3, batch: 171
batch_labels:  [[1]]
loss:  3.59972 3.59972
accuracy:  0.0
batch_is_nod:  [[ 0.  0.  0.  0.  0.]]
batch_file_names:  2a2300103f80aadbfac57516d9a95365
--->Val epoch: 3, batch: 172
batch_labels:  [[1]]
loss:  5.28009 5.17636
accuracy:  0.0
batch_is_nod:  [[ 1.  0.  0.  0.  0.]]
batch_file_names:  f2ca85bb9ae82a3d79b9f321f727ac19
Val step: 180, avg loss: 1.572329, loss: 0.928994, accuracy: 0.800000
--->Val epoch: 3, batch: 181
batch_labels:  [[0]]
loss:  8.95906 8.95906
accuracy:  0.0
batch_is_nod:  [[ 1.  0.  0.  0.  0.]]
batch_file_names:  933cc0dec1c737d9654820453ce64284
--->Val epoch: 3, batch: 189
batch_labels:  [[1]]
loss:  5.09564 4.99539
accuracy:  0.0
batch_is_nod:  [[ 1.  0.  0.  0.  0.]]
batch_file_names:  85d59b470b927e825937ea3483571c6d
Val step: 190, avg loss: 1.569216, loss: 1.513174, accuracy: 0.700000
--->Val epoch: 3, batch: 197
batch_labels:  [[0]]
loss:  11.5116 11.5116
accuracy:  0.0
batch_is_nod:  [[ 0.  0.  0.  0.  0.]]
batch_file_names:  337e7a428e7342d1e7f53a04247f7ad8
--->Val epoch: 3, batch: 199
batch_labels:  [[0]]
loss:  8.12583 7.93186
accuracy:  0.0
batch_is_nod:  [[ 1.  0.  0.  0.  0.]]
batch_file_names:  c004a9415539a0bc98c42c1a444cedb8
--->Val epoch: 3, batch: 200
batch_labels:  [[0]]
loss:  11.5116 11.5116
accuracy:  0.0
batch_is_nod:  [[ 1.  0.  0.  0.  0.]]
batch_file_names:  8c5288b86ffcd597f10d639e9948411d
Val step: 200, avg loss: 1.647646, loss: 3.137810, accuracy: 0.700000
--->Val epoch: 3, batch: 202
batch_labels:  [[1]]
loss:  5.35796 5.35796
accuracy:  0.0
batch_is_nod:  [[ 0.  0.  0.  0.  0.]]
batch_file_names:  1fdbc07019192de4a114e090389c8330
--->Val epoch: 3, batch: 204
batch_labels:  [[0]]
loss:  4.2377 4.2377
accuracy:  0.0
batch_is_nod:  [[ 0.  0.  0.  0.  0.]]
batch_file_names:  1a41350d4bbd74b7e0e28239cefa84c2
--->Val epoch: 3, batch: 205
batch_labels:  [[1]]
loss:  4.90317 4.90317
accuracy:  0.0
batch_is_nod:  [[ 0.  0.  0.  0.  0.]]
batch_file_names:  4a782bbc2608288a3ed05e511af6f8bb
--->Val epoch: 3, batch: 206
batch_labels:  [[0]]
loss:  11.5116 11.5116
accuracy:  0.0
batch_is_nod:  [[ 0.  0.  0.  0.  0.]]
batch_file_names:  f7cdd95c94818875ece1175561025038
--->Val epoch: 3, batch: 209
batch_labels:  [[1]]
loss:  4.14312 4.14312
accuracy:  0.0
batch_is_nod:  [[ 0.  0.  0.  0.  0.]]
batch_file_names:  3f6431400c2a07a46386dba3929da45d
--->Val epoch: 3, batch: 210
batch_labels:  [[1]]
loss:  5.20637 5.10391
accuracy:  0.0
batch_is_nod:  [[ 1.  0.  0.  0.  0.]]
batch_file_names:  31136e50b7205e9184227f94cdea0090
Val step: 210, avg loss: 1.737860, loss: 3.542151, accuracy: 0.400000
--->Val epoch: 3, batch: 211
batch_labels:  [[0]]
loss:  1.83393 1.61603
accuracy:  0.0
batch_is_nod:  [[ 1.  0.  0.  0.  0.]]
batch_file_names:  9f19c381184ba62416025849c464630e
--->Val epoch: 3, batch: 213
batch_labels:  [[1]]
loss:  8.98109 8.98109
accuracy:  0.0
batch_is_nod:  [[ 0.  0.  0.  0.  0.]]
batch_file_names:  f467795ce3b50a771085d79ae8d29ecc
--->Val epoch: 3, batch: 215
batch_labels:  [[1]]
loss:  7.24154 7.24154
accuracy:  0.0
batch_is_nod:  [[ 0.  0.  0.  0.  0.]]
batch_file_names:  2f77fd993fbd858dec3c085b9ff1a3a2
--->Val epoch: 3, batch: 216
batch_labels:  [[1]]
loss:  8.75889 8.75889
accuracy:  0.0
batch_is_nod:  [[ 0.  0.  0.  0.  0.]]
batch_file_names:  fe45462987bacc32dbc7126119999392
--->Val epoch: 3, batch: 217
batch_labels:  [[1]]
loss:  2.51047 2.51047
accuracy:  0.0
batch_is_nod:  [[ 0.  0.  0.  0.  0.]]
batch_file_names:  fb99a80cbb2f441bb90135bab5b029fe
Val step: 220, avg loss: 1.793317, loss: 2.957915, accuracy: 0.500000
--->Val epoch: 3, batch: 224
batch_labels:  [[1]]
loss:  1.74666 1.74666
accuracy:  0.0
batch_is_nod:  [[ 0.  1.  0.  0.  0.]]
batch_file_names:  90409f7fcfec3581033559f8340e48a9
--->Val epoch: 3, batch: 226
batch_labels:  [[1]]
loss:  5.17885 5.17885
accuracy:  0.0
batch_is_nod:  [[ 0.  0.  0.  0.  0.]]
batch_file_names:  b17c07114dcf49ce71c8da4b43cf1192
Val step: 230, avg loss: 1.745867, loss: 0.701966, accuracy: 0.800000
--->Val epoch: 3, batch: 233
batch_labels:  [[1]]
loss:  8.85439 8.85439
accuracy:  0.0
batch_is_nod:  [[ 0.  0.  0.  0.  0.]]
batch_file_names:  04a8c47583142181728056310759dea1
--->Val epoch: 3, batch: 236
batch_labels:  [[1]]
loss:  5.2163 5.2163
accuracy:  0.0
batch_is_nod:  [[ 0.  0.  0.  0.  0.]]
batch_file_names:  88acee40bb9d8cb06898d1c5de01d3c8
--->Val epoch: 3, batch: 240
batch_labels:  [[1]]
loss:  5.51678 5.40833
accuracy:  0.0
batch_is_nod:  [[ 1.  0.  0.  0.  0.]]
batch_file_names:  cd10ceca9862ba0cc2ffd0ed8c9b055c
Val step: 240, avg loss: 1.756945, loss: 2.011727, accuracy: 0.700000
--->Val epoch: 3, batch: 243
batch_labels:  [[0]]
loss:  11.5116 11.5116
accuracy:  0.0
batch_is_nod:  [[ 0.  0.  0.  0.  0.]]
batch_file_names:  a53a4a019a24541c277e0a84301d8ec5
--->Val epoch: 3, batch: 245
batch_labels:  [[0]]
loss:  11.5116 11.5116
accuracy:  0.0
batch_is_nod:  [[ 1.  0.  0.  0.  0.]]
batch_file_names:  dcde02d4757bb845376fa6dbb0351df6
--->Val epoch: 3, batch: 248
batch_labels:  [[0]]
loss:  11.5116 11.5116
accuracy:  0.0
batch_is_nod:  [[ 0.  0.  0.  0.  0.]]
batch_file_names:  f73624b8b22774acf9a3e2c748131eac
Val step: 250, avg loss: 1.825294, loss: 3.465673, accuracy: 0.700000
--->Val epoch: 3, batch: 255
batch_labels:  [[1]]
loss:  3.42425 3.35705
accuracy:  0.0
batch_is_nod:  [[ 1.  0.  0.  0.  0.]]
batch_file_names:  a162d204827e4e89a2e5ba81cc53247a
--->Val epoch: 3, batch: 257
batch_labels:  [[0]]
loss:  3.68233 3.68233
accuracy:  0.0
batch_is_nod:  [[ 0.  0.  0.  0.  0.]]
batch_file_names:  46199ffd681fd429aca3823c76f1034d
Val step: 260, avg loss: 1.788498, loss: 0.868603, accuracy: 0.700000
--->Val epoch: 3, batch: 263
batch_labels:  [[0]]
loss:  1.80734 1.80734
accuracy:  0.0
batch_is_nod:  [[ 0.  0.  0.  0.  0.]]
batch_file_names:  5861f8f8e35c0713c61e8ab3bc54c905
Val step: 270, avg loss: 1.729167, loss: 0.186569, accuracy: 0.900000
--->Val epoch: 3, batch: 277
batch_labels:  [[1]]
loss:  4.78228 4.55388
accuracy:  0.0
batch_is_nod:  [[ 1.  1.  0.  0.  0.]]
batch_file_names:  0acbebb8d463b4b9ca88cf38431aac69
--->Val epoch: 3, batch: 278
batch_labels:  [[0]]
loss:  3.59498 3.59498
accuracy:  0.0
batch_is_nod:  [[ 1.  0.  0.  0.  0.]]
batch_file_names:  aadd54d387e9be8fab53507c4cedf338
Val step: 280, avg loss: 1.697334, loss: 0.837848, accuracy: 0.800000
--->Val epoch: 3, batch: 284
batch_labels:  [[1]]
loss:  8.90712 8.90712
accuracy:  0.0
batch_is_nod:  [[ 0.  0.  0.  0.  0.]]
batch_file_names:  6171d57221e26d1f15d3c71fe966ab18
--->Val epoch: 3, batch: 285
batch_labels:  [[1]]
loss:  3.16186 3.09983
accuracy:  0.0
batch_is_nod:  [[ 1.  0.  0.  0.  0.]]
batch_file_names:  77033e4c1591403d1b1255607a20a983
--->Val epoch: 3, batch: 290
batch_labels:  [[1]]
loss:  2.5848 2.5848
accuracy:  0.0
batch_is_nod:  [[ 1.  0.  0.  0.  0.]]
batch_file_names:  9e98136d07b953c3362e0a132c8810b6
Val step: 290, avg loss: 1.692342, loss: 1.552546, accuracy: 0.700000
--->Val epoch: 3, batch: 296
batch_labels:  [[0]]
loss:  2.70306 2.70306
accuracy:  0.0
batch_is_nod:  [[ 0.  0.  0.  0.  0.]]
batch_file_names:  88be713eb83cec7d31c4553ca05b2019
Val step: 300, avg loss: 1.645716, loss: 0.293558, accuracy: 0.900000
Val step: 310, avg loss: 1.593195, loss: 0.017587, accuracy: 1.000000
--->Val epoch: 3, batch: 315
batch_labels:  [[1]]
loss:  3.49476 3.49476
accuracy:  0.0
batch_is_nod:  [[ 0.  0.  0.  0.  0.]]
batch_file_names:  a2a4bc7708f6831470d757cd6f32bffe
--->Val epoch: 3, batch: 316
batch_labels:  [[0]]
loss:  2.91843 2.91843
accuracy:  0.0
batch_is_nod:  [[ 1.  0.  0.  0.  0.]]
batch_file_names:  fd7c0fb3c0e764357aa58e5f047be614
Validation epoch 3 finished in loss: 1.569094, loss2: 1.547946 and accuracy: 0.755486
Validation stat, total: 319, low accuracy: 78, 0.8 above: 241, 0.9 above: 241, 0.95 above: 241
The total time used in training: 84382.4983766079

Process finished with exit code 0
